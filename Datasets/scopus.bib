Scopus
EXPORT DATE: 15 November 2024

@ARTICLE{Katare20232714,
	author = {Katare, Dewant and Perino, Diego and Nurmi, Jari and Warnier, Martijn and Janssen, Marijn and Ding, Aaron Yi},
	title = {A Survey on Approximate Edge AI for Energy Efficient Autonomous Driving Services},
	year = {2023},
	journal = {IEEE Communications Surveys and Tutorials},
	volume = {25},
	number = {4},
	pages = {2714 – 2754},
	doi = {10.1109/COMST.2023.3302474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167839230&doi=10.1109%2fCOMST.2023.3302474&partnerID=40&md5=37bd297ab9eae28432e92c3e828d4744},
	affiliations = {Department of Engineering Systems and Services, Delft University of Technology, Delft, 2628 BX, Netherlands; Telefónica R and D, Telefónica, Barcelona, 08019, Spain; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, 33100, Finland; Department of Multi-Actor Systems, Delft University of Technology, Delft, 2628 BX, Netherlands},
	abstract = {Autonomous driving services depends on active sensing from modules such as camera, LiDAR, radar, and communication units. Traditionally, these modules process the sensed data on high-performance computing units inside the vehicle, which can deploy intelligent algorithms and AI models. The sensors mentioned above can produce large volumes of data, potentially reaching up to 20 Terabytes. This data size is influenced by factors such as the duration of driving, the data rate, and the sensor specifications. Consequently, this substantial amount of data can lead to significant power consumption on the vehicle. Similarly, a substantial amount of data will be exchanged between infrastructure sensors and vehicles for collaborative vehicle applications or fully connected autonomous vehicles. This communication process generates an additional surge of energy consumption. Although the autonomous vehicle domain has seen advancements in sensory technologies, wireless communication, computing and AI/ML algorithms, the challenge still exists in how to apply and integrate these technology innovations to achieve energy efficiency. This survey reviews and compares the connected vehicular applications, vehicular communications, approximation and Edge AI techniques. The focus is on energy efficiency by covering newly proposed approximation and enabling frameworks. To the best of our knowledge, this survey is the first to review the latest approximate Edge AI frameworks and publicly available datasets in energy-efficient autonomous driving. The insights from this survey can benefit the collaborative driving service development on low-power and memory-constrained systems and the energy optimization of autonomous vehicles.  © ; 2023 IEEE.},
	author_keywords = {Approximate computing; connected vehicles; deep learning; edge computing; energy efficiency; intelligent vehicles; machine learning},
	keywords = {Computing power; Constrained optimization; Edge computing; Energy utilization; Green computing; Optical radar; Vehicles; Active Sensing; Autonomous driving; Autonomous Vehicles; Computing units; Edge computing; Energy efficient; Intelligent Algorithms; Large volumes; Performance computing; Simultaneous localization and mapping; Energy efficiency},
	correspondence_address = {D. Katare; Department of Engineering Systems and Services, Delft University of Technology, Delft, 2628 BX, Netherlands; email: d.katare@tudelft.nl; A.Y. Ding; Department of Engineering Systems and Services, Delft University of Technology, Delft, 2628 BX, Netherlands; email: aaron.ding@tudelft.nl},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {1553877X},
	language = {English},
	abbrev_source_title = {IEEE Commun. Surv. Tutor.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mendez2022,
	author = {Mendez, Javier and Bierzynski, Kay and Cuéllar, M.P. and Morales, Diego P.},
	title = {Edge Intelligence: Concepts, Architectures, Applications, and Future Directions},
	year = {2022},
	journal = {ACM Transactions on Embedded Computing Systems},
	volume = {21},
	number = {5},
	doi = {10.1145/3486674},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134883880&doi=10.1145%2f3486674&partnerID=40&md5=bb0d78db839085f00ef8cfc60f987b9a},
	affiliations = {Infineon Technologies Ag, Am Campeon 1-15, Neubiberg, 85579, Germany; Department of Computer Science and Artifcial Intelligence, University of Granada (Spain), C/. Pdta. Daniel Saucedo Aranda s.n., Granada, 18014, Spain; Department of Electronics and Computer Technology, University of Granada (Spain), Avenida de Fuente Nueva s/n, Granada, 18071, Spain},
	abstract = {The name edge intelligence, also known as Edge AI, is a recent term used in the past few years to refer to the confluence of machine learning, or broadly speaking artificial intelligence, with edge computing. In this article, we revise the concepts regarding edge intelligence, such as cloud, edge, and fog computing, the motivation to use edge intelligence, and compare current approaches and analyze application scenarios. To provide a complete review of this technology, previous frameworks and platforms for edge computing have been discussed in this work to provide the general view of the basis for Edge AI. Similarly, the emerging techniques to deploy deep learning models at the network edge, as well as specialized platforms and frameworks to do so, are review in this article. These devices, techniques, and frameworks are analyzed based on relevant criteria at the network edge, such as latency, energy consumption, and accuracy of the models, to determine the current state of the art as well as current limitations of the proposed technologies. Because of this, it is possible to understand the current possibilities to efficiently deploy state-of-the-art deep learning models at the network edge based on technologies such as artificial intelligence accelerators, tensor processing units, and techniques that include federated learning and gossip training. Finally, the challenges of Edge AI are discussed in the work, as well as the future directions that can be extracted from the evolution of the edge computing and Internet of Things approaches. © 2022 Copyright held by the owner/author(s).},
	author_keywords = {artificial intelligence; deep learning; Edge AI; edge computing; Edge intelligence; machine learning},
	keywords = {Deep learning; Energy utilization; Fog computing; Learning systems; 'current; Application scenario; Deep learning; Edge AI; Edge computing; Edge intelligence; Learning models; Machine-learning; Network edges; State of the art; Edge computing},
	publisher = {Association for Computing Machinery},
	issn = {15399087},
	language = {English},
	abbrev_source_title = {ACM Trans. Embedded Comput. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@ARTICLE{Rocha2024,
	author = {Rocha, Atslands and Monteiro, Matheus and Mattos, César and Dias, Madson and Soares, Jorge and Magalhães, Regis and Macedo, José},
	title = {Edge AI for Internet of Medical Things: A literature review},
	year = {2024},
	journal = {Computers and Electrical Engineering},
	volume = {116},
	doi = {10.1016/j.compeleceng.2024.109202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189000347&doi=10.1016%2fj.compeleceng.2024.109202&partnerID=40&md5=c81860e2ca4b76598582bc0b75fac2ad},
	affiliations = {Departamento de Engenharia em Teleinformática, Universidade Federal do Ceará, Campus do Pici, Bloco 725, Fortaleza -CE, Ceará, 60455-970, Brazil; Departamento de Computação, Universidade Federal do Ceará, Campus do Pici, Bloco 910, Fortaleza, Ceará, Brazil; Departamento de Engenharia de Transportes, Universidade Federal do Ceará, Campus do Pici, Bloco 703, Fortaleza, Ceará, 60440-900, Brazil; Universidade Federal do Ceará, Campus de Quixadá, Av. José de Freitas Queiroz, 5003, Cedro, Quixadá, Ceará, 63902-580, Brazil},
	abstract = {The Internet of Things (IoT) consists of heterogeneous devices such as wearables and monitoring devices that collect data to provide autonomous decision-making and smart applications. IoT technologies, such as the Internet of Medical Things (IoMT), have become gradually popular for medical purposes, combining IoT and medical devices to achieve good health and well-being. However, IoMT devices are often tight and have resource constraints, which leads to limited local data processing in the device. Edge computing provides access to additional computation and storage resources for IoMT devices, bringing intelligent processing closer to the data sources. This technology opens up great possibilities for IoMT applications, especially when combined with Artificial Intelligence (AI). Edge AI runs AI computations close to the IoT devices and users instead of centralized services such as cloud servers. This paper investigates the potential of Edge AI and IoMT. In this sense, this survey is the first work to further detail Edge AI and Machine Learning Operations in IoMT domains and wearable technology, thus contributing to the literature by comprehensively exploring the potential of ML strategies and operations at the network's edge and intelligence distribution. This study also presents a case study on heart anomaly detection. © 2024 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Edge computing; Edge intelligence; Internet of medical things; Machine learning operation; Smart health},
	keywords = {Anomaly detection; Data handling; Decision making; Digital storage; Internet of things; Machine learning; Wearable technology; Autonomous decision; Edge computing; Edge intelligence; Heterogeneous devices; Internet of medical thing; Literature reviews; Machine learning operation; Machine-learning; Monitoring device; Smart health; Edge computing},
	correspondence_address = {A. Rocha; Departamento de Engenharia em Teleinformática, Universidade Federal do Ceará, Ceará, Campus do Pici, Bloco 725, Fortaleza -CE, 60455-970, Brazil; email: atslands@ufc.br},
	publisher = {Elsevier Ltd},
	issn = {00457906},
	coden = {CPEEB},
	language = {English},
	abbrev_source_title = {Comput Electr Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Hemmati202411461,
	author = {Hemmati, Atefeh and Raoufi, Parisa and Rahmani, Amir Masoud},
	title = {Edge artificial intelligence for big data: a systematic review},
	year = {2024},
	journal = {Neural Computing and Applications},
	volume = {36},
	number = {19},
	pages = {11461 – 11494},
	doi = {10.1007/s00521-024-09723-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190664823&doi=10.1007%2fs00521-024-09723-w&partnerID=40&md5=db6240354afb9b6a1ac8ee4a07fc04f1},
	affiliations = {Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Department of Computer Engineering, Central Tehran Branch, Islamic Azad University, Tehran, Iran; Future Technology Research Center, National Yunlin University of Science and Technology, Yunlin, Douliou, 64002, Taiwan},
	abstract = {Edge computing, artificial intelligence (AI), and machine learning (ML) concepts have become increasingly prevalent in Internet of Things (IoT) applications. As the number of IoT devices continues to grow, relying solely on cloud computing for real-time data processing and analysis is proving to be more challenging. The synergy between edge computing and AI is particularly intriguing due to AI's reliance on rapid data processing, a capability facilitated by edge computing. Edge AI represents a significant paradigm shift, leveraging AI within edge computing frameworks to reduce reliance on internet connections and mitigate data latency issues. This approach accelerates data processing, supporting use cases that demand real-time inference. Additionally, as cloud storage costs continue to rise, the feasibility of streaming and storing large volumes of data comes into question. Edge AI offers a compelling solution by performing big data analytics closer to the end device where edge computing is deployed. This paper presents a systematic literature review (SLR) of 85 articles published between 2018 and 2023 within Edge AI. The study provides a comprehensive examination of the analysis of measurement environments and assesses factors applied to Edge AI for big data. It offers taxonomies specific to Edge AI within the big data domain, presents case studies, and outlines the challenges and open issues inherent in Edge AI for big data. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.},
	author_keywords = {Artificial intelligence; Big data; Edge computing; Internet of Things; Machine learning},
	keywords = {Big data; Cloud analytics; Data Analytics; Data handling; Digital storage; Edge computing; Machine learning; Artificial intelligence learning; Cloud-computing; Computing frameworks; Data processing and analysis; Edge computing; Machine-learning; Paradigm shifts; Real time data analysis; Real-time data processing; Systematic Review; Internet of things},
	correspondence_address = {A.M. Rahmani; Future Technology Research Center, National Yunlin University of Science and Technology, Douliou, Yunlin, 64002, Taiwan; email: rahmania@yuntech.edu.tw},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09410643},
	language = {English},
	abbrev_source_title = {Neural Comput. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Zhou20191738,
	author = {Zhou, Zhi and Chen, Xu and Li, En and Zeng, Liekang and Luo, Ke and Zhang, Junshan},
	title = {Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing},
	year = {2019},
	journal = {Proceedings of the IEEE},
	volume = {107},
	number = {8},
	pages = {1738 – 1762},
	doi = {10.1109/JPROC.2019.2918951},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067598102&doi=10.1109%2fJPROC.2019.2918951&partnerID=40&md5=ad91a6e8db4dce26e5c696ede789d627},
	affiliations = {The School of Data and Computer Science, Sun Yat-sen University (SYSU), Guangzhou, 510006, China; The School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, 85287-7206, AZ, United States},
	abstract = {| With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
	author_keywords = {Artificial intelligence; deep learning; edge computing; edge intelligence},
	keywords = {Big data; Computer architecture; Deep learning; Internet of things; Job analysis; Security systems; Surveys; Computational modelling; Deep learning; Edge computing; Edge intelligence; Edge intelligence.; Last mile; Network edges; Task analysis; Edge computing},
	correspondence_address = {X. Chen; The School of Data and Computer Science, Sun Yat-sen University (SYSU), Guangzhou, 510006, China; email: chenxu35@mail.sysu.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {00189219},
	coden = {IEEPA},
	language = {English},
	abbrev_source_title = {Proc. IEEE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1446; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Yao20236866,
	author = {Yao, Jiangchao and Zhang, Shengyu and Yao, Yang and Wang, Feng and Ma, Jianxin and Zhang, Jianwei and Chu, Yunfei and Ji, Luo and Jia, Kunyang and Shen, Tao and Anpeng, Wu and Zhang, Fengda and Tan, Ziqi and Kuang, Kun and Wu, Chao and Wu, Fei and Zhou, Jingren and Yang, Hongxia},
	title = {Edge-Cloud Polarization and Collaboration: A Comprehensive Survey for AI},
	year = {2023},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {35},
	number = {7},
	pages = {6866 – 6886},
	doi = {10.1109/TKDE.2022.3178211},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188122067&doi=10.1109%2fTKDE.2022.3178211&partnerID=40&md5=6a7c0bb4a5a864b81b293da8559f216a},
	affiliations = {Alibaba Group, DAMA Academy, Hangzhou, 311121, China; Zhejiang University, Hangzhou, 310027, China; the Institute of Artificial Intelligence, Zhejiang University, Hangzhou, 310027, China; the Shanghai Institute for Advanced Study, Zhejiang University, Shanghai, 200080, China},
	abstract = {Influenced by the great success of deep learning via cloud computing and the rapid development of edge chips, research in artificial intelligence (AI) has shifted to both of the computing paradigms, i.e., cloud computing and edge computing. In recent years, we have witnessed significant progress in developing more advanced AI models on cloud servers that surpass traditional deep learning models owing to model innovations (e.g., Transformers, Pretrained families), explosion of training data and soaring computing capabilities. However, edge computing, especially edge and cloud collaborative computing, are still in its infancy to announce their success due to the resource-constrained IoT scenarioswith very limited algorithms deployed. In this survey, we conduct a systematic review for both cloud and edge AI. Specifically, we are the first to set up the collaborative learning mechanism for cloud and edge modeling with a thorough review of the architectures that enable such mechanism.We also discuss potentials and practical experiences of some on-going advanced edge AI topics including pretrainingmodels, graph neural networks and reinforcement learning. Finally, we discuss the promising directions and challenges in this field. © 2023 IEEE Computer Society. All rights reserved.},
	author_keywords = {Cloud AI; edge AI; edge-cloud collaboration; hardware},
	keywords = {Computer hardware; Deep learning; Internet of things; Reinforcement learning; Cloud artificial intelligence; Cloud-computing; Collaboration; Computational modelling; Edge artificial intelligence; Edge clouds; Edge computing; Edge-cloud collaboration; Hardware; Edge computing},
	correspondence_address = {F. Wu; Alibaba Group, DAMA Academy, Hangzhou, 311121, China; email: wufei@zju.edu.cn; H. Yang; Alibaba Group, DAMA Academy, Hangzhou, 311121, China; email: yang.yhx@alibaba-inc.com},
	publisher = {IEEE Computer Society},
	issn = {10414347},
	coden = {ITKEE},
	language = {English},
	abbrev_source_title = {IEEE Trans Knowl Data Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 51; All Open Access, Green Open Access}
}

@ARTICLE{Silva2021,
	author = {Silva, Mateus C. and da Silva, Jonathan C. F. and Delabrida, Saul and Bianchi, Andrea G. C. and Ribeiro, Sérvio P. and Silva, Jorge Sá and Oliveira, Ricardo A. R.},
	title = {Wearable edge ai applications for ecological environments},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {15},
	doi = {10.3390/s21155082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111078760&doi=10.3390%2fs21155082&partnerID=40&md5=d21f2a69be7061603f01c8954e9de81e},
	affiliations = {Computer Science Department, Federal University of Ouro Preto, Ouro Preto, 35400-000, Brazil; Biology Department, Federal University of Ouro Preto, Ouro Preto, 35400-000, Brazil; Department of Electrical and Computer Engineering, INESC Coimbra, University of Coimbra, Coimbra, P-3030, Portugal},
	abstract = {Ecological environments research helps to assess the impacts on forests and managing forests. The usage of novel software and hardware technologies enforces the solution of tasks related to this problem. In addition, the lack of connectivity for large data throughput raises the demand for edge-computing-based solutions towards this goal. Therefore, in this work, we evaluate the opportunity of using a Wearable edge AI concept in a forest environment. For this matter, we propose a new approach to the hardware/software co-design process. We also address the possibility of creating wearable edge AI, where the wireless personal and body area networks are platforms for building applications using edge AI. Finally, we evaluate a case study to test the possibility of performing an edge AI task in a wearable-based environment. Thus, in this work, we evaluate the system to achieve the desired task, the hardware resource and performance, and the network latency associated with each part of the process. Through this work, we validated both the design pattern review and case study. In the case study, the developed algorithms could classify diseased leaves with a circa 90% accuracy with the proposed technique in the field. This results can be reviewed in the laboratory with more modern models that reached up to 96% global accuracy. The system could also perform the desired tasks with a quality factor of 0.95, considering the usage of three devices. Finally, it detected a disease epicenter with an offset of circa 0.5 m in a 6 m × 6 m × 12 m space. These results enforce the usage of the proposed methods in the targeted environment and the proposed changes in the co-design pattern. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {(Multipurpose) wearable edge AI; Computer vision; Edge computing; Embedded systems; Wearable computing},
	keywords = {Algorithms; Artificial Intelligence; Equipment Design; Humans; Software; Wearable Electronic Devices; Ecology; Forestry; Hardware-software codesign; AI applications; Body Area Network; Building applications; Ecological environments; Forest environments; Hardware resources; Network latencies; Software and hardwares; algorithm; artificial intelligence; electronic device; equipment design; human; software; Wearable technology},
	correspondence_address = {M.C. Silva; Computer Science Department, Federal University of Ouro Preto, Ouro Preto, 35400-000, Brazil; email: mateus.silva1@aluno.ufop.edu.br},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {34372319},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{El Ghati2024,
	author = {El Ghati, Omar and Alaoui-Fdili, Othmane and Chahbouni, Othman and Alioua, Nawal and Bouarifi, Walid},
	title = {Artificial intelligence-powered visual internet of things in smart cities: A comprehensive review},
	year = {2024},
	journal = {Sustainable Computing: Informatics and Systems},
	volume = {43},
	doi = {10.1016/j.suscom.2024.101004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195301322&doi=10.1016%2fj.suscom.2024.101004&partnerID=40&md5=e422550973a4c336822355726f7c7897},
	affiliations = {LMISC, National School of Applied Sciences of Safi, Cadi Ayyad University, Safi, Morocco; LAPSSII, Higher School of Technology of Safi, Cadi Ayyad University, Safi, Morocco; LMC, Polydisciplinary Faculty of Safi Cadi Ayyad University, Safi, Morocco},
	abstract = {The field of smart cities has seen significant advancements in recent years to improve citizens' quality of life. Technologies such as the Internet of Things (IoT) and Edge Computing (EC), along with Artificial Intelligence (AI), are being utilized to achieve this goal. This study focuses on a specific branch of IoT known as Visual IoT, which uses digital cameras as sensors and relies on visual data. Advances in AI have enabled researchers to integrate AI models into camera-based edge devices, increasing the use of AI-powered Visual IoT systems in smart cities. However, since the energy consumption in battery-powered systems is naturally a concern, being deployed outdoors for visual data gathering with the integration of AI-based processing raises a significant challenge. This paper examines AI-powered Visual IoT systems in smart cities with a special emphasis on energy efficiency. Our goal is not only to evaluate how AI is used in Visual IoT systems in the context of smart cities but also to evaluate the level of consideration given to the energy efficiency aspect in the reviewed studies. Furthermore, we explore all of the methods used to address it. Through our work, readers will gain insights into the current landscape of Visual IoT in smart cities and an understanding of how much importance is placed on energy consumption in AI-integrated solutions. © 2024 Elsevier Inc.},
	author_keywords = {Artificial intelligence; Energy efficiency; Internet of things; Internet of Video Things; Smart cities; Visual IoT},
	keywords = {Artificial intelligence; Energy utilization; Internet of things; Smart city; Battery-powered systems; Camera-based; Data gathering; Edge computing; Energy-consumption; Intelligence models; Internet of video thing; Quality of life; Visual data; Visual internet of thing; Energy efficiency},
	correspondence_address = {O. El Ghati; LMISC, National School of Applied Sciences of Safi, Cadi Ayyad University, Safi, Morocco; email: omar.elghati@ced.uca.ma},
	publisher = {Elsevier Inc.},
	issn = {22105379},
	language = {English},
	abbrev_source_title = {Sustainable Computing: Informatics and Systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gill2025,
	author = {Gill, Sukhpal Singh and Golec, Muhammed and Hu, Jianmin and Xu, Minxian and Du, Junhui and Wu, Huaming and Walia, Guneet Kaur and Murugesan, Subramaniam Subramanian and Ali, Babar and Kumar, Mohit and Ye, Kejiang and Verma, Prabal and Kumar, Surendra and Cuadrado, Felix and Uhlig, Steve},
	title = {Edge AI: A Taxonomy, Systematic Review and Future Directions},
	year = {2025},
	journal = {Cluster Computing},
	volume = {28},
	number = {1},
	doi = {10.1007/s10586-024-04686-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207056495&doi=10.1007%2fs10586-024-04686-y&partnerID=40&md5=ad750f45f587bf5916a20f2be448a037},
	affiliations = {School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom; Abdullah Gul University, Kayseri, Turkey; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Center for Applied Mathematics, Tianjin University, Tianjin, China; Department of Information Technology, Dr. B. R. Ambedkar National Institute of Technology, Jalandhar, India; Department of Computer Engineering and Applications, GLA University, Mathura, India; Technical University of Madrid (UPM), Madrid, Spain; Department of Information Technology, National Institute of Technology, Srinagar, India},
	abstract = {Edge Artificial Intelligence (AI) incorporates a network of interconnected systems and devices that receive, cache, process, and analyse data in close communication with the location where the data is captured with AI technology. Recent advancements in AI efficiency, the widespread use of Internet of Things (IoT) devices, and the emergence of edge computing have unlocked the enormous scope of Edge AI. The goal of Edge AI is to optimize data processing efficiency and velocity while ensuring data confidentiality and integrity. Despite being a relatively new field of research, spanning from 2014 to the present, it has shown significant and rapid development over the last five years. In this article, we present a systematic literature review for Edge AI to discuss the existing research, recent advancements, and future research directions. We created a collaborative edge AI learning system for cloud and edge computing analysis, including an in-depth study of the architectures that facilitate this mechanism. The taxonomy for Edge AI facilitates the classification and configuration of Edge AI systems while also examining its potential influence across many fields through compassing infrastructure, cloud computing, fog computing, services, use cases, ML and deep learning, and resource management. This study highlights the significance of Edge AI in processing real-time data at the edge of the network. Additionally, it emphasizes the research challenges encountered by Edge AI systems, including constraints on resources, vulnerabilities to security threats, and problems with scalability. Finally, this study highlights the potential future research directions that aim to address the current limitations of Edge AI by providing innovative solutions. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Artificial intelligence; Cloud computing; Edge AI; Edge computing; Machine learning},
	keywords = {Cloud platforms; Taxonomies; Artificial intelligence systems; Artificial intelligence technologies; Cloud-computing; Data confidentiality; Data integrity; Edge artificial intelligence; Edge computing; Future research directions; Machine-learning; Systematic Review; Adversarial machine learning},
	correspondence_address = {M. Golec; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom; email: m.golec@qmul.ac.uk},
	publisher = {Springer},
	issn = {13867857},
	language = {English},
	abbrev_source_title = {Cluster Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zawish2024730,
	author = {Zawish, Muhammad and Dharejo, Fayaz Ali and Khowaja, Sunder Ali and Raza, Saleem and Davy, Steven and Dev, Kapal and Bellavista, Paolo},
	title = {AI and 6G Into the Metaverse: Fundamentals, Challenges and Future Research Trends},
	year = {2024},
	journal = {IEEE Open Journal of the Communications Society},
	volume = {5},
	pages = {730 – 778},
	doi = {10.1109/OJCOMS.2024.3349465},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184377563&doi=10.1109%2fOJCOMS.2024.3349465&partnerID=40&md5=f110633a18c825455c4178f48c1f6f24},
	affiliations = {Walton Institute for Information and Communication Systems Science, South East Technological University, Waterford, X91 K0EK, Ireland; Khalifa University, Department of Electrical Engineering and Computer Science, Abu Dhabi, United Arab Emirates; University of Sindh, Faculty of Engineering and Technology, Jamshoro, 76080, Pakistan; Quaid-e-Awam University of Engineering, Science and Technology, Department of Electronic Engineering, Larkana, 67480, Pakistan; Technological University Dublin, Centre for Sustainable Digital Technologies, Dublin, D07 EWV4, Ireland; Munster Technological University, Department of Computer Science, Cork, T12 P928, Ireland; Institute of Intelligent Systems, University of Johannesburg, Johannesburg, 2006, South Africa; Lebanese American University, Department of Electrical and Computer Engineering, Byblos, 1111, Lebanon; University of Bologna, Department of Computer Science and Engineering, Bologna, 40136, Italy},
	abstract = {Since Facebook was renamed Meta, a lot of attention, debate, and exploration have intensified about what the Metaverse is, how it works, and the possible ways to exploit it. It is anticipated that Metaverse will be a continuum of rapidly emerging technologies, usecases, capabilities, and experiences that will make it up for the next evolution of the Internet. Several researchers have already surveyed the literature on artificial intelligence (AI) and wireless communications in realizing the Metaverse. However, due to the rapid emergence and continuous evolution of technologies, there is a need for a comprehensive and in-depth survey of the role of AI, 6G, and the nexus of both in realizing the immersive experiences of Metaverse. Therefore, in this survey, we first introduce the background and ongoing progress in augmented reality (AR), virtual reality (VR), mixed reality (MR) and spatial computing, followed by the technical aspects of AI and 6G. Then, we survey the role of AI in the Metaverse by reviewing the state-of-the-art in deep learning, computer vision, and Edge AI to extract the requirements of 6G in Metaverse. Next, we investigate the promising services of B5G/6G towards Metaverse, followed by identifying the role of AI in 6G networks and 6G networks for AI in support of Metaverse applications, and the need for sustainability in Metaverse. Finally, we enlist the existing and potential applications, usecases, and projects to highlight the importance of progress in the Metaverse. Moreover, in order to provide potential research directions to researchers, we underline the challenges, research gaps, and lessons learned identified from the literature review of the aforementioned technologies.  © 2020 IEEE.},
	author_keywords = {5G; 6G; AI; AR/VR/XR; cloud and edge computing; Metaverse; spatial computing},
	keywords = {5G mobile communication systems; Augmented reality; Deep learning; Mixed reality; Queueing networks; 5g; 6g; Augmented reality/virtual reality/XR; Cloud-computing; Edge computing; Emerging technologies; Facebook; Metaverses; Research trends; Spatial computing; Edge computing},
	correspondence_address = {S. Davy; Technological University Dublin, Centre for Sustainable Digital Technologies, Dublin, D07 EWV4, Ireland; email: steven.davy@tudublin.ie},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {2644125X},
	language = {English},
	abbrev_source_title = {IEEE open J. Commun. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access}
}

@ARTICLE{Celik20242433,
	author = {Celik, Abdulkadir and Eltawil, Ahmed M.},
	title = {At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence},
	year = {2024},
	journal = {IEEE Open Journal of the Communications Society},
	volume = {5},
	pages = {2433 – 2489},
	doi = {10.1109/OJCOMS.2024.3362271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184802522&doi=10.1109%2fOJCOMS.2024.3362271&partnerID=40&md5=a8f7b9d1a6bd0e1d7c132783789f050a},
	affiliations = {King Abdullah University of Science and Technology, Computer, Electrical and Mathematical Sciences and Engineering Division, Thuwal, 23955-6900, Saudi Arabia},
	abstract = {As we transition from the 5G epoch, a new horizon beckons with the advent of 6G, seeking a profound fusion with novel communication paradigms and emerging technological trends, bringing once-futuristic visions to life along with added technical intricacies. Although analytical models lay the foundations and offer systematic insights, we have recently witnessed a noticeable surge in research suggesting machine learning (ML) and artificial intelligence (AI) can efficiently deal with complex problems by complementing or replacing model-based approaches. The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, autoregressive GMs, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including 1) physical layer design; 2) network optimization, organization, and management; 3) network traffic analytics; 4) cross-layer network security; and 5) localization & positioning. Furthermore, we outline the central role of GMs in pioneering areas of 6G network research, including semantic communications, integrated sensing and communications, THz communications, extremely large antenna arrays, near-field communications, digital twins, AI-generated content services, mobile edge computing and edge AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the multifarious challenges ahead, suggesting potential strategies and promising remedies. Given its depth and breadth, we are confident that this tutorial-cum-survey will serve as a pivotal reference for researchers and professionals delving into this dynamic and promising domain.  © 2020 IEEE.},
	author_keywords = {5G; 6G; adversarial ML; AI-generated content; artificial intelligence (AI); autoregressive generative models; deep learning (DL); diffusion models; digital twins; discriminative AI; explainable AI; extremely large antenna arrays; generative adversarial networks; generative AI; generative models; generative pre-trained transformers; generative transformers; holographic beamforming; integrated sensing and communications; large language models; machine learning (ML); mMIMO; mmWave; near-field communication; network function virtualization; normalizing flows; open RAN; semantic communications; software defined networks; terahertz; trustworthy AI; trustworthy AI; variational autoencoders; zero-touch service management},
	keywords = {5G mobile communication systems; Beamforming; Deep learning; Near field communication; Network function virtualization; Semantics; Transfer functions; 5g; 6g; 6g mobile communication; Adversarial machine learning; Artificial intelligence; Artificial intelligence-generated content; Auto encoders; Auto-regressive; Autoregressive generative model; Communication system security; Deep learning; Diffusion model; Discriminative artificial intelligence; Explainable artificial intelligence; Extremely large antenna array; Generative artificial intelligence; Generative model; Generative pre-trained transformer; Generative transformer; Holographic beamforming; Integrated sensing; Integrated sensing and communication; Language model; Large antennas; Large language model; Machine learning; Machine-learning; Mm waves; MMIMO; Mobile communications; Near-field communication; Normalizing flow; Open RAN; Semantic communication; Service management; Software-defined networks; Tera Hertz; Trustworthy artificial intelligence; Variational autoencoder; Wireless communications; Zero-touch service management; Generative adversarial networks},
	correspondence_address = {A. Celik; King Abdullah University of Science and Technology, Computer, Electrical and Mathematical Sciences and Engineering Division, Thuwal, 23955-6900, Saudi Arabia; email: abdulkadir.celik@kaust.edu.sa},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {2644125X},
	language = {English},
	abbrev_source_title = {IEEE open J. Commun. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}