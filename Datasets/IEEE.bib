@article{10004922,
 abstract = {Data centralization can potentially increase Internet of Things (IoT) usage. The trend is to move IoT devices to a centralized server with higher memory capacity and a more robust management interface. Hence, a larger volume of data will be transmitted, resulting in more network security issues. Cloud IoT offers more advantages for deploying and managing IoT systems through minimizing response delays, optimal latency, and effective network load distribution. As a result, sophisticated network attack strategies are deployed to leverage the vulnerabilities in the extensive network space and exploit user information. Several attempts have been made to provide network intrusion detection systems (IDS) to the cloud IoT interface using machine learning and deep learning approaches on dedicated IDS datasets. This paper proposes a transfer learning IDS based on the Convolutional Neural Network (CNN) architecture that has shown excellent results on image classification. We use five pre-trained CNN models, including VGG16, VGG19, Inception, MobileNet, and EfficientNets, to train on two selected datasets: CIC-IDS2017 and CSE-CICIDS2018. Before the training, we carry out preprocessing, imbalance treatment, dimensionality reduction, and conversion of the feature vector into images suitable for the CNN architecture using Quantile Transformer. Three best-performing models (InceptionV3, MobileNetV3Small, and EfficientNetV2B0) are selected to develop an ensemble model called efficient-lightweight ensemble transfer learning (ELETL-IDS) using the model averaging approach. On evaluation, the findings show that the ELETL-IDS outperformed existing state-of-the-art proposals in all evaluation metrics, reaching 100% in accuracy, precision, recall, and F-score. We use Matthew’s Correlation Coefficient (MCC) to validate this result and compared it to the AUC-ROC, which maintained an exact value of 0.9996. To this end, our proposed model is lightweight, efficient, and reliable enough to be deployed in cloud IoT systems for intrusion detection.},
 author = {Okey, Ogobuchi Daniel and Melgarejo, Dick Carrillo and Saadi, Muhammad and Rosa, Renata Lopes and Kleinschmidt, João Henrique and Rodríguez, Demóstenes Zegarra},
 doi = {10.1109/ACCESS.2022.3233775},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Cloud computing;Transfer learning;Convolutional neural networks;Security;Deep learning;Data models;Internet of Things;convolutional neural network;cloud IoT;intrusion detection systems;transfer learning;MCC},
 month = {},
 number = {},
 pages = {1023-1038},
 title = {Transfer Learning Approach to IDS on Cloud IoT Devices Using Optimized CNN},
 volume = {11},
 year = {2023}
}

@article{10012334,
 abstract = {The Internet of Things (IoT) has paved the way to a highly connected society where all things are interconnected and exchanging information has become more accessible through the internet. With the use of IoT devices, the threat of malware has increased rapidly. The increased number of existing and new malware variants has made protecting IoT devices and networks challenging. The malware can hide in the systems and disables its activity when there are attempts to discover and detect them. With technological advances, there are various emerging techniques to address this problem. However, they still encounter issues concerning the privacy and security of the user’s data and suffer from a single point of failure. To address this issue, there are recent research developments conducted to use Federated Learning (FL). FL is a decentralized technique that trains the user’s data on-device and exchanges the parameters without sharing the user’s data. FL is implemented to secure the user’s data, provide safe and accurate models, and prevent the single point of failure in the centralized models. This paper provides an overview of different approaches that integrate FL with IoT. Finally, we discuss the applications of FL, the research challenges, and future research directions.},
 author = {Venkatasubramanian, Madumitha and Lashkari, Arash Habibi and Hakak, Saqib},
 doi = {10.1109/ACCESS.2023.3235389},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Malware;Data privacy;Artificial intelligence;Taxonomy;Privacy;Microprogramming;Machine learning;Deep learning;Artificial intelligence;deep learning;federated learning;Internet of Things;machine learning;malware analysis},
 month = {},
 number = {},
 pages = {5004-5018},
 title = {IoT Malware Analysis Using Federated Learning: A Comprehensive Survey},
 volume = {11},
 year = {2023}
}

@article{10020178,
 abstract = {Proliferation of connected services in modern vehicles could make them vulnerable to a wide range of cyber-attacks through intra-vehicle networks that connect various vehicle systems. Designers usually equip vehicles with predesigned counter-measures, but these may not be effective against novel cyber-attacks. Intrusion Detection Systems (IDSs) serve as an additional layer of defence when conventional measures that are implemented by the designers fail. Several intrusion detection techniques have been proposed in the literature but these techniques have limited capability in detecting novel cyber-attacks. This paper proposes a new Machine Learning (ML)-based IDS for detecting novel cyber-attacks in intra-vehicle networks, specifically in Controller Area Networks (CANs). The proposed IDS generates high-level representations of CAN messages transmitted on the bus exploiting their temporal properties as well as the intra and inter message dependencies through the use of Recurrence Plot (RP), which are then fed into a bespoke Neural Network, designed and trained to detect novel intrusions. Evaluation of the performance of the proposed IDS in comparison with that of the state-of-the-art existing IDS schemes demonstrates the superiority of the proposed IDS.},
 author = {Al-Jarrah, Omar Y. and Haloui, Karim El and Dianati, Mehrdad and Maple, Carsten},
 doi = {10.1109/OJVT.2023.3237802},
 issn = {2644-1330},
 journal = {IEEE Open Journal of Vehicular Technology},
 keywords = {Feature extraction;Cyberattack;Hidden Markov models;Neural networks;Intrusion detection;Deep learning;Long short term memory;Cybersecurity;intrusion detection;intra-vehicle networks;LSTM},
 month = {},
 number = {},
 pages = {271-280},
 title = {A Novel Detection Approach of Unknown Cyber-Attacks for Intra-Vehicle Networks Using Recurrence Plots and Neural Networks},
 volume = {4},
 year = {2023}
}

@article{10023499,
 abstract = {Computer viruses, malicious, and other hostile attacks can affect a computer network. Intrusion detection is a key component of network security as an active defence technology. Traditional intrusion detection systems struggle with issues like poor accuracy, ineffective detection, a high percentage of false positives, and an inability to handle new types of intrusions. To address these issues, we propose a deep learning-based novel method to detect cybersecurity vulnerabilities and breaches in cyber-physical systems. The proposed framework contrasts the unsupervised and deep learning-based discriminative approaches. This paper presents a generative adversarial network to detect cyber threats in IoT-driven IICs networks. The results demonstrate a performance increase of approximately 95% to 97% in terms of accuracy, reliability, and efficiency in detecting all types of attacks with a dropout value of 0.2 and an epoch value of 25. The output of well-known state-of-the-art DL classifiers achieved the highest true rate (TNR) and highest detection rate (HDR) when detecting the following attacks: (BruteForceXXS, BruteForceWEB, DoS_Hulk_Attack, and DOS_LOIC_HTTP_Attack) on the NSL-KDD, KDDCup99, and UNSW-NB15 datasets. It also maintained the confidentiality and integrity of users’ and systems’ sensitive information during the training and testing phases.},
 author = {Kandhro, Irfan Ali and Alanazi, Sultan M. and Ali, Fayyaz and Kehar, Asadullah and Fatima, Kanwal and Uddin, Mueen and Karuppayah, Shankar},
 doi = {10.1109/ACCESS.2023.3238664},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Security;Internet of Things;Machine learning;Computer security;Anomaly detection;Cybersecurity;Internet of Things;intrusion detection system (IDS);anomaly detection;security attacks;deep learning},
 month = {},
 number = {},
 pages = {9136-9148},
 title = {Detection of Real-Time Malicious Intrusions and Attacks in IoT Empowered Cybersecurity Infrastructures},
 volume = {11},
 year = {2023}
}

@article{10026342,
 abstract = {The intrusion detection system (IDS) is considered an essential sector in maintaining communication network security and has been desirably adopted by all network administrators. Several existing methods have been proposed for early intrusion detection systems. However, they experience drawbacks that make them subsequently inefficient against new/distinct attacks. To overcome these drawbacks, this paper proposes the enhanced long-short term memory (ELSTM) technique with recurrent neural network (RNN) (ELSTM-RNN) to enhance security in IDS. Intrusion detection technology has been associated with various problems, such as gradient vanishing, generalization, and overfitting issues. The proposed system solves the gradient-clipping issue using the likely point particle swarm optimization (LPPSO) and enhanced LSTM classification. The proposed method was evaluated using the NSL-KDD dataset (KDD TEST PLUS and KDD TEST21) for validation and testing. Many efficient features were selected using an enhanced technique, namely, the particle swarm optimization. The selected features serve for effective classification using an enhanced LSTM framework, where it is used to efficiently classify and detect the attack data from the normal data. The proposed system has been applied to the UNSW-NB15, CICIDS2017, CSE-CIC-IDS2018, and BOT _DATASET datasets for further verification. Results show that the training time of the proposed system is much less than that of other methods for different classes. Finally, the performance of the proposed ELSTM-RNN framework is analyzed using various metrics, such as accuracy, precision, recall, and error rate. Our proposed method outperformed LPBoost and DNNs methods.},
 author = {Donkol, Ahmed Abd El-Baset and Hafez, Ali G. and Hussein, Aziza I. and Mabrook, M. Mourad},
 doi = {10.1109/ACCESS.2023.3240109},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Intrusion detection;Classification algorithms;Recurrent neural networks;Artificial neural networks;Feature extraction;Deep learning;IDS;KDD TEST PLUS;KDD TEST 21~dataset;LSTM;network security;and RNN},
 month = {},
 number = {},
 pages = {9469-9482},
 title = {Optimization of Intrusion Detection Using Likely Point PSO and Enhanced LSTM-RNN Hybrid Technique in Communication Networks},
 volume = {11},
 year = {2023}
}

@article{10050022,
 abstract = {The emergence of cyber-physical smart grid (CPSG) systems has revolutionized the traditional power grid by enabling the bidirectional energy flow between consumers and utilities. However, due to escalated information exchange between the end-users, it has posed a greater challenge to the cyber security mechanisms for the communication networks at the cyber and physical planes. To address these challenges, we propose a Bayesian approach integrated with deep convolutional neural networks (CNN-Bayesian). While, the Bayesian component is used to discriminate cyber-physical intrusions from the normal events in the binary and multi-class events. CNN layers are utilized to handle the high-dimensional feature space prior to the intrusions classification task. The proposed method is validated using real-time Industrial control systems (ICS) dataset against the standard deep learning-based classification methods such as recurrent neural networks (RNN) and long-short term memory (LSTM). From the experimental results, it can be inferred that the proposed CNN-Bayesian method outperforms the existing benchmark classification methods to discriminate intrusions in CPSG systems using evaluation metrics such as accuracy, precision, recall, and  $F1$ -score.},
 author = {Kaur, Devinder and Anwar, Adnan and Kamwa, Innocent and Islam, Shama and Muyeen, S. M. and Hosseinzadeh, Nasser},
 doi = {10.1109/ACCESS.2023.3247947},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Convolutional neural networks;Bayes methods;Uncertainty;Probabilistic logic;Neural networks;Classification algorithms;Deep learning;Intrusion detection;Smart grids;SCADA systems;Bayesian inference;cybersecurity;deep learning;intrusion-detection systems;SCADA;smart grid},
 month = {},
 number = {},
 pages = {18910-18920},
 title = {A Bayesian Deep Learning Approach With Convolutional Feature Engineering to Discriminate Cyber-Physical Intrusions in Smart Grid Systems},
 volume = {11},
 year = {2023}
}

@article{10050187,
 abstract = {Internet of vehicles (IoVs) allows millions of vehicles to be connected and share information for various purposes. The main applications of IoVs are traffic management, emergency messages delivery, E-health, traffic, and temperature monitoring. On the other hand, IoVs lack in location awareness and geographic distribution, which is critical for some IoVs applications such as smart traffic lights and information sharing in vehicles. To support these topographies, fog computing was proposed as an appealing and novel term, which was integrated with IoVs to extend storage, computation, and networking. Unfortunately, it is also challenged with various security and privacy hazards, which is a serious concern of smart cities. Therefore, we can formulate that Fog-assisted IoVs (Fa-IoVs), are challenged by security threats during information dissemination among mobile nodes. These security threats of Fa-IoVs are considered as anomalies which is a serious concern that needs to be addressed for smooth Fa-IoVs network communication. Here, smooth communication refers to less risk of important data loss, delay, communication overhead, etc. This research work aims to identify research gaps in the Fa-IoVs network and present a deep learning-based dynamic scheme named CAaDet (Convolutional autoencoder Aided anomaly detection) to detect anomalies. CAaDet exploits convolutional layers with a customized autoencoder for useful feature extraction and anomaly detection. Performance evaluation of the proposed scheme is done by using the F1-score metric where experiments are carried out by exploiting a benchmark dataset named NSL-KDD. CAaDet also observes the behavior of fog nodes and hidden neurons and selects the best match to reduce false alarms and improve F1-score. The proposed scheme achieved significant improvement over existing schemes for anomaly detection. Identified research gaps in Fa-IoVs can give future directions to researchers and attract more attention to this new era.},
 author = {Yaqoob, Shumayla and Hussain, Asad and Subhan, Fazli and Pappalardo, Giuseppina and Awais, Muhammad},
 doi = {10.1109/ACCESS.2023.3246660},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Cloud computing;Anomaly detection;Edge computing;Heuristic algorithms;Servers;Network intrusion;Fog computing;smooth communication;Internet of Vehicles;anomaly detection;fog-assisted IoVs},
 month = {},
 number = {},
 pages = {19024-19038},
 title = {Deep Learning Based Anomaly Detection for Fog-Assisted IoVs Network},
 volume = {11},
 year = {2023}
}

@article{10050849,
 abstract = {Intrusion detection systems (IDS) play a vital role in protecting networks from malicious attacks. Modern IDS use machine-learning or deep-learning models to deal with the diversity of attacks that malicious users may employ. However, effective machine-learning methods incur a considerable cost in both the pretraining stage and the online detection process itself. Accordingly, this study proposes a quantitative logarithmic transformation-based intrusion detection system (QLT-IDS) that uses a straightforward statistical approach to analyze network behavior. Compared with machine-learning or deep-learning-based IDS methods, the proposed system requires neither a time-consuming and expensive data collection and training process, nor a GPU-included device to achieve a real-time detection performance. Furthermore, the system can deal not only with North-South attacks, but also East-West attacks, which pose a significant risk in real-world operations. The effectiveness of the proposed system is evaluated for both real-world campus network traffic and simulated traffic. The results confirm that QLT-IDS is able to detect a wide range of malicious attacks with a high precision, even under high down-sampling rate of the NetFlow records.},
 author = {Lan, Blue and Lo, Ta-Chun and Wei, Rico and Tang, Heng-Yu and Shieh, Ce-Kuen},
 doi = {10.1109/ACCESS.2023.3248261},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Passwords;Intrusion detection;IP networks;Aggregates;Network security;Telecommunication traffic;Servers;NIDS;NetFlow;network security},
 month = {},
 number = {},
 pages = {20351-20364},
 title = {A Quantitative Logarithmic Transformation-Based Intrusion Detection System},
 volume = {11},
 year = {2023}
}

@article{10057402,
 abstract = {Network intrusion detection is an important technology in national cyberspace security strategy and has become a research hotspot in various cyberspace security issues in recent years. The development of effective and efficient intelligent network intrusion detection methods using advanced machine learning algorithms is of great importance for defending against various network intrusions in complex network environments. In this study, a network intrusion detection method based on decision tree twin support vector machine and hierarchical clustering, named HC-DTTWSVM, is proposed, which can effectively detect different categories of network intrusion. First, the hierarchical clustering algorithm is applied to construct the decision tree for network traffic data, where the bottom-up merging approach is used to maximize the separation of the upper nodes of the decision tree, which reduces the error accumulation in the construction of the decision tree. Then, twin support vector machines are embedded in the constructed decision tree to implement the network intrusion detection model, which can effectively detect the network intrusion category in a top-down manner. The detection performance of the proposed HC-DTTWSVM method is evaluated on NSL-KDD and UNSW-NB15 intrusion detection benchmark datasets. Experimental results show that HC-DTTWSVM can effectively detect different categories of network intrusion and achieves comparable detection performance compared to some of the recently proposed network intrusion detection methods.},
 author = {Zou, Li and Luo, Xuemei and Zhang, Yan and Yang, Xiao and Wang, Xiangwen},
 doi = {10.1109/ACCESS.2023.3251354},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Network intrusion detection;Decision trees;Security;Support vector machines;Machine learning algorithms;Cyberspace;Training;Network intrusion detection;twin support vector machine;hierarchical clustering;decision tree},
 month = {},
 number = {},
 pages = {21404-21416},
 title = {HC-DTTSVM: A Network Intrusion Detection Method Based on Decision Tree Twin Support Vector Machine and Hierarchical Clustering},
 volume = {11},
 year = {2023}
}

@article{10061214,
 abstract = {Due to the growing number of Industrial Internet of Things (IoT) devices, network attacks like denial of service (DoS) and floods are rising for security and reliability issues. As a result of these attacks, IoT devices suffer from denial of service and network disruption. Researchers have implemented different techniques to identify attacks aimed at vulnerable Industrial Internet of Things (IoT) devices. In this study, we propose a novel features selection algorithm FGOA-kNN based on a hybrid filter and wrapper selection approaches to select the most relevant features. The novel approach integrated with clustering rank the features and then applies the Grasshopper algorithm (GOA) to minimize the top-ranked features. Moreover, a proposed algorithm, IHHO, selects and adapts the neural network’s hyper parameters to detect botnets efficiently. The proposed Harris Hawks algorithm is enhanced with three improvements to improve the global search process for optimal solutions. To tackle the problem of population diversity, a chaotic map function is utilized for initialization. The escape energy of hawks is updated with a new nonlinear formula to avoid the local minima and better balance between exploration and exploitation. Furthermore, the exploitation phase of HHO is enhanced using a new elite operator ROBL. The proposed model combines unsupervised, clustering, and supervised approaches to detect intrusion behaviors. This combination can enhance the accuracy and robustness of the proposed model by identifying the most relevant features and detecting known and unknow botnet activity. The N-BaIoT dataset is utilized to validate the proposed model. Many recent techniques were used to assess and compare the proposed model’s performance. The result demonstrates that the proposed model is better than other variations at detecting multiclass botnet attacks.},
 author = {Taher, Fatma and Abdel-Salam, Mahmoud and Elhoseny, Mohamed and El-Hasnony, Ibrahim M.},
 doi = {10.1109/ACCESS.2023.3253432},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Feature extraction;Security;Intrusion detection;Clustering algorithms;Support vector machines;Computer crime;Botnet;features selection;grasshopper algorithm;Harris hawks algorithm;security;botnet detection;reliability;the Industrial Internet of Things;chaotic map;filter;wrapper;clustering},
 month = {},
 number = {},
 pages = {49319-49336},
 title = {Reliable Machine Learning Model for IIoT Botnet Detection},
 volume = {11},
 year = {2023}
}

@article{10064274,
 abstract = {Intrusion detection is the core topic of network security, and the intrusion detection algorithm based on deep learning has become a research hotspot in network security. In this paper, a network intrusion detection classification model (NIDS-CNNLSTM) based on deep learning is constructed for the wireless sensing scenario of the Industrial Internet of Things (IIoT) to effectively distinguish and identify network traffic data and ensure the security of the equipment and operation of the IIoT. NIDS-CNNLSTM combines the powerful learning ability of long short-term memory neural networks in time series data, learns and classifies the features selected by the convolutional neural network, and verifies the applicability based on binary classification and multi-classification scenarios. The model is trained using KDD CUP99, NSL_KDD, and UNSW_NB15 classic datasets. The verification accuracy and training loss on the three datasets all show good convergence and level, and the accuracy rate is high when classifying various types of traffic. The overall performance of NIDS-CNNLSTM has been significantly improved compared with the models proposed in previous studies. The effectiveness shows a high detection rate and classification accuracy and a low false alarm rate through experimental results. It is more suitable for large-scale and multi-scenario network data in the IIoT.},
 author = {Du, Jiawei and Yang, Kai and Hu, Yanjing and Jiang, Lingjie},
 doi = {10.1109/ACCESS.2023.3254915},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Convolutional neural networks;Deep learning;Logic gates;Industrial Internet of Things;Convolution;Security;Network intrusion detection;deep learning;convolutional neural network;long short-term memory neural network},
 month = {},
 number = {},
 pages = {24808-24821},
 title = {NIDS-CNNLSTM: Network Intrusion Detection Classification Model Based on Deep Learning},
 volume = {11},
 year = {2023}
}

@article{10064283,
 abstract = {High-Power electric grid networks require extreme security in their associated telecommunication network to ensure protection and control throughout power transmission. Accordingly, supervisory control and data acquisition systems form a vital part of any critical infrastructure, and the safety of the associated telecommunication network from intrusion is crucial. Whereas events related to operation and maintenance are often available and carefully documented, only some tools have been proposed to discriminate the information dealing with the heterogeneous data from intrusion detection systems and to support the network engineers. In this work, we present the use of deep learning techniques, such as Autoencoders or conventional Multiple Correspondence Analysis, to analyze and prune the events on power communication networks in terms of categorical data types often used in anomaly and intrusion detection (such as addresses or anomaly description). This analysis allows us to quantify and statistically describe high-severity events. Overall, portions of alerts around 5-10% have been prioritized in the analysis as first to handle by managers. Moreover, probability clouds of alerts have been shown to configure explicit manifolds in latent spaces. These results offer a homogeneous framework for implementing anomaly detection prioritization in power communication networks.},
 author = {Feijoo-Martínez, Juan Ramón and Guerrero-Curieses, Alicia and Gimeno-Blanes, Francisco and Castro-Fernández, Mario and Rojo-Álvarez, José Luis},
 doi = {10.1109/ACCESS.2023.3255101},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Deep learning;Standards organizations;Monitoring;Companies;Communications technology;Intrusion detection;Telecommunication security;intrusion detection;deep learning;high power;power communication;latent variables;alert prioritization;alert manifolds},
 month = {},
 number = {},
 pages = {23754-23770},
 title = {Cybersecurity Alert Prioritization in a Critical High Power Grid With Latent Spaces},
 volume = {11},
 year = {2023}
}

@article{10066260,
 abstract = {Internet of Things (IoT) is an emerging technology and its applications are flattering amidst many users, as it makes everything easier. As a consequence of its massive growth, security and privacy are becoming crucial issues where the IoT devices are perpetually vulnerable to cyber-attacks. To overcome this issue, intrusion detection and mitigation is accomplished which enhances the security in IoT networks. In this paper, we proposed Blockchain entrenched Bi-level intrusion detection and graph based mitigation framework named as HybridChain-IDS. The proposed work embrace four sequential processes includes time-based authentication, user scheduling and access control, bi-level intrusion detection and attack graph generation. Initially, we perform time-based authentication to authenticate the legitimate users using NIK-512 hashing algorithm, password and registered time are stored in Hybridchain which is an assimilation of blockchain and Trusted Execution Environment (TEE) which enhances data privacy and security. After that, we perform user scheduling using Cheetah Optimization Algorithm (COA) which reduces the complexity and then the access control is provided to authorized users by smart contract by considering their trust and permission level. Then, we accomplish bi-level intrusion detection using ResCapsNet which extracts sufficient features and classified effectively. Finally, risk of the attack is evaluated, and then the attacks graphs are generated by employing Enhanced k-nearest neighbor (KNN) algorithm to identify the attack path. Furthermore, the countermeasures are taken based on the attack risk level and the attack graph is stored in Hybridchain for eventual attack prediction. The implementation of this proposed work is directed by network simulator of NS-3.26 and the performance of the proposed HybridChain-IDS is enumerated based on various performance metrics.},
 author = {Sharadqh, Ahmed A. M. and Hatamleh, Hazem Abdel Majid and Alnaser, As’ad Mahmoud As’ad and Saloum, Said S. and Alawneh, Tareq A.},
 doi = {10.1109/ACCESS.2023.3256277},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Intrusion detection;Feature extraction;Network security;Blockchains;Authentication;IoT network security;hybrid chain;access control;intrusion detection system (IDS);attack graph generation;deep learning method},
 month = {},
 number = {},
 pages = {27433-27449},
 title = {Hybrid Chain: Blockchain Enabled Framework for Bi-Level Intrusion Detection and Graph-Based Mitigation for Security Provisioning in Edge Assisted IoT Environment},
 volume = {11},
 year = {2023}
}

@article{10068504,
 abstract = {Industrial IoT-enabled critical infrastructures are susceptible to cyber attacks due to their mission-critical deployment. To ensure security by design, radio frequency (RF)-based security is considered an effective way for wirelessly monitored or actuated critical infrastructures. For this purpose, this paper presents a novel augmentation-driven deep learning approach to analyze unique transmitter fingerprints and determine the legitimacy of a user device or transmitter. An RF fingerprinting model is susceptible to various channel and environmental conditions that impact the learning performance of a machine/deep learning model. As data gathering cannot always be considered a feasible alternative, efficient solutions that can tackle the impact of varying propagation channels on learning performance are emergent. This work aims to shed light on the RF fingerprinting problem from a different angle when 4G, 5G, and WiFi data samples are collected from different transmitters by proposing a fine-grained augmentation approach to improve the learning performance of a deep learning model. This work also proposes an enhanced classifier structure following the fine-grained augmentation approach. Results of experiments, conducted on the POWDER dataset, demonstrate promising RF fingerprinting performance when training data are augmented in a waveform-specific fine-grained manner. Thus, the RF identification accuracy can be boosted to 97.84% on unseen RF data instances from our previously published work where we had achieved an accuracy of 87.94% using tapped delay line (TDL)/clustered delay line (CDL)-based augmentation approach. The paper also presents a sensitivity analysis of the fine-grained approach concerning different signal-to-noise-ratio (SNR), signal-to-interference-ratio (SIR) levels (20 dB and 30 dB), and signal-to-interference-plus-noise-ratio (SINR) levels (15 dB, 25 dB). The sensitivity analysis exhibits that it achieves 85.78% accuracy at 20 dB SIR on both Day 1 (train) and Day 2 (test) data. In addition, it achieves 92.37% accuracy even at 20 dB SNR on Day 2 data from POWDER dataset. Furthermore, it achieves 84.95% accuracy at 15 dB SINR on Day 2 data. Hence, these results exhibit the resiliency of the fine-grained augmentation approach against interference and noise.},
 author = {Gul, Omer Melih and Kulhandjian, Michel and Kantarci, Burak and Touazi, Azzedine and Ellement, Cliff and D’amours, Claude},
 doi = {10.1109/ACCESS.2023.3257266},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Fingerprint recognition;Radio frequency;Mathematical models;Signal to noise ratio;Wireless communication;Deep learning;Interference;Autonomous aerial vehicles;Internet of Things;Deep learning;data augmentation;radio frequency fingerprinting;secure design;unmanned aerial vehicles;Internet of Things (IoT)},
 month = {},
 number = {},
 pages = {26289-26307},
 title = {Secure Industrial IoT Systems via RF Fingerprinting Under Impaired Channels With Interference and Noise},
 volume = {11},
 year = {2023}
}

@article{10077581,
 abstract = {Dissolved oxygen content is a key indicator of water quality in aquaculture environment. Because of its nonlinearity, dynamics, and complexity, which makes traditional methods face challenges in the accuracy and speed of dissolved oxygen content prediction. As a solution to these issues, this study introduces a hybrid model consisting of the Light Gradient Boosting Machine (LightGBM) and the Bidirectional Simple Recurrent Unit (BiSRU). Firstly, Linear interpolation and smoothing were used to identify significant parameters. LightGBM algorithm then determines the significance of dissolved oxygen by eliminating irrelevant variables and predicting dissolved oxygen in intensive aquaculture. Finally, the attention method was implemented to map the weighting and learning parameter matrices, so enabling the BiSRU’s hidden states to be assigned different weights. The findings shown that the presented prediction model can accurately anticipate the fluctuating trend of dissolved oxygen over a 10-day period in just 122 seconds, and the accuracy rate reached 96.28%. Comparing the model effects of LightGBM-BiSRU, LightGBM - GRU, LightGBM-LSTM, and BiSRU - Attention takes the least time. Its higher prediction accuracy can provide an essential reference for intensive aquaculture water quality regulation.},
 author = {Liu, Wenjun and Liu, Shuangyin and Hassan, Shahbaz Gul and Cao, Yingying and Xu, Longqin and Feng, Dachun and Cao, Liang and Chen, Weijun and Chen, Yaocong and Guo, Jianjun and Liu, Tonglai and Zhang, Hang},
 doi = {10.1109/ACCESS.2023.3260089},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Predictive models;Aquaculture;Water quality;Technological innovation;Data models;Computational modeling;Market research;Non-linear;LightGBM;BiSRU;attention mechanism},
 month = {},
 number = {},
 pages = {29162-29174},
 title = {A Novel Hybrid Model to Predict Dissolved Oxygen for Efficient Water Quality in Intensive Aquaculture},
 volume = {11},
 year = {2023}
}

@article{10079215,
 abstract = {Detecting Android malware in its spread or download stage is a challenging work, which can realize early detection of malware before it reaches user side. In this paper, we propose a two-stage detection framework based on feature enhancement and cascade deep forest. This method can detect the traffic generated in the encrypted transmission process of Android malware. The first stage realizes the binary classification of benign and malicious software. The second stage realizes the multi-classification of different categories of malware. To enhance data representation, convolutional neural networks is used to extract benign and malicious features in the first stage, and the principal component analysis method is used to extract the malicious features in the second stage. Theses extracted features are spliced with the payload part of the traffic to form fusion features for classification task. In order to adapt to different scale of samples, especially for the small-scale sample, cascaded deep forest method is proposed to construct the classification model. In this model, many layers that consist of base classifiers are cascaded and the number of layers can be automatically adjusted according to the scale of the samples. With different combinations of base classifiers in each layer, the optima detection accuracy is archived in the two stages. The experimental results on several datasets prove that the proposed method is effective for encrypted transmission detection of Android malware. It is also suitable for the detection of unknown attacks.},
 author = {Zhang, Xueqin and Wang, Jiyuan and Xu, Jinyu and Gu, Chunhua},
 doi = {10.1109/ACCESS.2023.3260977},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Malware;Operating systems;Cryptography;Regression analysis;Random forests;Deep learning;Androids;Android malware;anomaly detection;encrypted traffic;feature enhancement;deep forest},
 month = {},
 number = {},
 pages = {29344-29359},
 title = {Detection of Android Malware Based on Deep Forest and Feature Enhancement},
 volume = {11},
 year = {2023}
}

@article{10097653,
 abstract = {Industrial Internet of Things (IIoT) represents the expansion of the Internet of Things (IoT) in industrial sectors. It is designed to implicate embedded technologies in manufacturing fields to enhance their operations. However, IIoT involves some security vulnerabilities that are more damaging than those of IoT. Accordingly, Intrusion Detection Systems (IDSs) have been developed to forestall inevitable harmful intrusions. IDSs survey the environment to identify intrusions in real time. This study designs an intrusion detection model exploiting feature engineering and machine learning for IIoT security. We combine Isolation Forest (IF) with Pearson's Correlation Coefficient (PCC) to reduce computational cost and prediction time. IF is exploited to detect and remove outliers from datasets. We apply PCC to choose the most appropriate features. PCC and IF are applied exchangeably (PCCIF and IFPCC). The Random Forest (RF) classifier is implemented to enhance IDS performances. For evaluation, we use the Bot-IoT and NF-UNSW-NB15-v2 datasets. RF-PCCIF and RF-IFPCC show noteworthy results with 99.98% and 99.99% Accuracy (ACC) and 6.18s and 6.25s prediction time on Bot-IoT, respectively. The two models also score 99.30% and 99.18% ACC and 6.71 s and 6.87s prediction time on NF-UNSW-NB15-v2, respectively. Results prove that our designed model has several advantages and higher performance than related models.},
 author = {Mohy-Eddine, Mouaad and Guezzaz, Azidine and Benkirane, Said and Azrour, Mourade and Farhaoui, Yousef},
 doi = {10.26599/BDMA.2022.9020032},
 issn = {2097-406X},
 journal = {Big Data Mining and Analytics},
 keywords = {Correlation coefficient;Intrusion detection;Forestry;Predictive models;Network security;Feature extraction;Real-time systems;Industrial Internet of Things (IIoT);isolation forest;Intrusion Detection Dystem (IDS);intrusion;Pearson's Correlation Coefficient (PCC);random forest},
 month = {Sep.},
 number = {3},
 pages = {273-287},
 title = {An Ensemble Learning Based Intrusion Detection Model for Industrial IoT Security},
 volume = {6},
 year = {2023}
}

@article{10097662,
 abstract = {Cloud computing (CC) is a novel technology that has made it easier to access network and computer resources on demand such as storage and data management services. In addition, it aims to strengthen systems and make them useful. Regardless of these advantages, cloud providers suffer from many security limits. Particularly, the security of resources and services represents a real challenge for cloud technologies. For this reason, a set of solutions have been implemented to improve cloud security by monitoring resources, services, and networks, then detect attacks. Actually, intrusion detection system (IDS) is an enhanced mechanism used to control traffic within networks and detect abnormal activities. This paper presents a cloud-based intrusion detection model based on random forest (RF) and feature engineering. Specifically, the RF classifier is obtained and integrated to enhance accuracy (ACC) of the proposed detection model. The proposed model approach has been evaluated and validated on two datasets and gives 98.3% ACC and 99.99% ACC using Bot-IoT and NSL-KDD datasets, respectively. Consequently, the obtained results present good performances in terms of ACC, precision, and recall when compared to the recent related works.},
 author = {Attou, Hanaa and Guezzaz, Azidine and Benkirane, Said and Azrour, Mourade and Farhaoui, Yousef},
 doi = {10.26599/BDMA.2022.9020038},
 issn = {2097-406X},
 journal = {Big Data Mining and Analytics},
 keywords = {Training;Support vector machines;Graphics;Machine learning algorithms;Cloud computing security;Intrusion detection;Feature extraction;cloud security;anomaly detection;features engineering;random forest},
 month = {Sep.},
 number = {3},
 pages = {311-320},
 title = {Cloud-Based Intrusion Detection Approach Using Machine Learning Techniques},
 volume = {6},
 year = {2023}
}

@article{10098780,
 abstract = {In recent years, huge increase in attacks and data breaches is noticed. Most of the attacks are performed and focused on the vulnerabilities related to web applications. Hence, nowadays the mitigation of application vulnerabilities is an ignited research area. Thus, due to the potential high severity impacts of web application, many different approaches have been proposed in the past decades to mitigate the damages of application vulnerabilities. Static and dynamic analysis are the two main techniques used. In this paper, a new classification for web application input validation vulnerabilities is proffered. In addition, various techniques/tools that are used to detect them are analyzed and evaluated to apprehend their strengths and weaknesses. Thus, this paper provides both technical as well as literature countermeasures to input validation vulnerabilities. Moreover, various statistical distributions of the reviewed techniques were manifested and scrutinize in different aspects to reveal the perception of the prevailing techniques and the gaps in the literature. In addition, the most widespread metrics are also propounded.},
 author = {Faisal Fadlalla, Faris and Elshoush, Huwaida T.},
 doi = {10.1109/ACCESS.2023.3266385},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Source coding;Security;Databases;Static analysis;Codes;Systematics;Cross-site scripting;Web security;static analysis;dynamic analysis;input validation vulnerabilities;source code review},
 month = {},
 number = {},
 pages = {40128-40161},
 title = {Input Validation Vulnerabilities in Web Applications: Systematic Review, Classification, and Analysis of the Current State-of-the-Art},
 volume = {11},
 year = {2023}
}

@article{10101759,
 abstract = {Machine learning and deep learning techniques are widely used to evaluate intrusion detection systems (IDS) capable of rapidly and automatically recognizing and classifying cyber-attacks on networks and hosts. However, when destructive attacks are becoming more extensive, more challenges develop, needing a comprehensive response. Numerous intrusion detection datasets are publicly accessible for further analysis by the cybersecurity research community. However, no previous research has examined the performance of the proposed model on a variety of publicly accessible datasets in detail. Due to the dynamic nature of the attack and its rapidly changing attack techniques, the publicly accessible intrusion datasets must be updated and benchmarked regularly. The deep neural network (DNN) and convolutional neural network (CNN) are examined in this article as types of deep learning models for developing a flexible and effective IDS capable of detecting and comparing them with the proposed model in detecting cyber-attacks. The constant development of network behavior and the fast growth of attacks need the development of IDS and the evaluation of many datasets produced over time through static and dynamic methods. This kind of research enables the identification of the most efficient algorithm for identifying future cyber-attacks. We proposed a novel two-stage deep learning technique hybridizing Long-Short Term Memory (LSTM) and Auto-Encoders (AE) for detecting attacks. The CICIDS2017 and CSE-CICDIS2018 datasets are used to determine the optimum network parameters for the proposed LSTM-AE. The experimental results show that the proposed hybrid model works well and is applicable for detecting attacks in modern scenarios.},
 author = {Hnamte, Vanlalruata and Nhung-Nguyen, Hong and Hussain, Jamal and Hwa-Kim, Yong},
 doi = {10.1109/ACCESS.2023.3266979},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Convolutional neural networks;Security;Computational modeling;Firewalls (computing);Feature extraction;Convolutional neural network;deep neural networks;network intrusion detection;deep learning;two-stage model;LSTM-AE},
 month = {},
 number = {},
 pages = {37131-37148},
 title = {A Novel Two-Stage Deep Learning Model for Network Intrusion Detection: LSTM-AE},
 volume = {11},
 year = {2023}
}

@article{10103687,
 abstract = {In recent years, the use of Software Defined Networking (SDN) has increased due to various network management requirements. Using SDN in computer network applications has brought several benefits to users, including lower operational costs, better hardware management, flexibility, and centralized network deployment. On the other hand, the Internet of Things (IoT) is another rapidly growing technology. Distributed and dynamic infrastructures are two critical characteristics of IoT. These characteristics lead to some challenges while using SDN in IoT in terms of security and privacy. In this paper, we address security and privacy issues and solutions for SDN-based IoT systems. We analyze the techniques used for defense in previous works to achieve an acceptable level of security and privacy protection in SDN-based IoT systems. In the data plane, SDN-based IoT papers have considered hashing and encryption techniques, in the control plane, certificate authority and access control have been analyzed, and in the application plane, attack detection, and authentication have been discussed. We also provide a statistical analysis of the existing work. This analysis shows that researchers have focused on certain areas more than others in recent years. The final analysis also highlights issues that previous researchers have ignored.},
 author = {Ahmadvand, Hossein and Lal, Chhagan and Hemmati, Hadi and Sookhak, Mehdi and Conti, Mauro},
 doi = {10.1109/ACCESS.2023.3267764},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Privacy;Blockchains;Data privacy;Deep learning;Denial-of-service attack;Software-defined network;privacy-preserving;security;cloud computing},
 month = {},
 number = {},
 pages = {44772-44786},
 title = {Privacy-Preserving and Security in SDN-Based IoT: A Survey},
 volume = {11},
 year = {2023}
}

@article{10105244,
 abstract = {The proliferation of ransomware has become a significant threat to cybersecurity in recent years, causing significant financial, reputational, and operational damage to individuals and organizations. This paper aims to provide a comprehensive overview of the evolution of ransomware, its taxonomy, and its state-of-the-art research contributions. We begin by tracing the origins of ransomware and its evolution over time, highlighting the key milestones and major trends. Next, we propose a taxonomy of ransomware that categorizes different types of ransomware based on their characteristics and behavior. Subsequently, we review the existing research over several years in regard to detection, prevention, mitigation, and prediction techniques. Our extensive analysis, based on more than 150 references, has revealed that significant research, specifically 72.8%, has focused on detecting ransomware. However, a lack of emphasis has been placed on predicting ransomware. Additionally, of the studies focused on ransomware detection, a significant portion, 70%, have utilized Machine Learning methods. This study uncovers a range of shortcomings in research pertaining to real-time protection and identifying zero-day ransomware, and two issues specific to Machine Learning models. Adversarial machine learning exploitation and concept drift have been identified as under-researched areas in the field. This survey is a constructive roadmap for researchers interested in ransomware research matters.},
 author = {Razaulla, Salwa and Fachkha, Claude and Markarian, Christine and Gawanmeh, Amjad and Mansoor, Wathiq and Fung, Benjamin C. M. and Assi, Chadi},
 doi = {10.1109/ACCESS.2023.3268535},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Ransomware;Cryptography;Malware;Taxonomy;Phishing;Encryption;Machine learning;Adversarial machine learning;Ransomware;malware analysis;machine learning;deep learning;cyber attacks;adversarial machine learning},
 month = {},
 number = {},
 pages = {40698-40723},
 title = {The Age of Ransomware: A Survey on the Evolution, Taxonomy, and Research Directions},
 volume = {11},
 year = {2023}
}

@article{10105249,
 abstract = {The security of in-vehicle networks has become an important issue as automobiles become more connected and automated. In this paper, we propose a graph-based intrusion detection and classification system, named G-IDCS, which aims to enhance the security of the in-vehicle controller area network (CAN) protocol. Existing intrusion detection systems (IDSs) using graph theory suffer from limitations, such as requiring a large number of CAN messages for detection and being unable to classify attack types despite analyzing numerous messages. Meanwhile, machine learning or deep learning-based systems have limited sensitivity to environmental changes such as attack type change due to model overfitting, and are unable to provide explanations for classification decisions. Using various graph features, our threshold-based intrusion detection method overcomes these limitations by integrating a threshold-based IDS and a machine learning-based attack type classifier. Our threshold-based intrusion detection method of G-IDCS reduces the number of CAN messages required for detection by more than 1/30 and improves the accuracy of combined attack detection by over 9% compared to an existing intrusion detection method that uses graph theory. Furthermore, unlike existing machine learning and deep learning-based intrusion detection systems, our threshold classifier is robust to changes in attack types and can provide explanations for the features used in attack detection. In addition, our machine learning-based attack type classifier outperforms existing techniques in all performance metrics and can serve as a digital forensic tool for investigating cyber attacks on in-vehicle networks. Using the classifier to identify attack types can facilitate the design of corresponding protection methods, thereby enhancing the security of in-vehicle networks.},
 author = {Park, Sung Bum and Jo, Hyo Jin and Lee, Dong Hoon},
 doi = {10.1109/ACCESS.2023.3268519},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Protocols;Graph theory;Feature extraction;Security;Statistical analysis;Clocks;Attack type classification;controller area network;graph theory;intrusion detection system;in-vehicle CAN security},
 month = {},
 number = {},
 pages = {39213-39227},
 title = {G-IDCS: Graph-Based Intrusion Detection and Classification System for CAN Protocol},
 volume = {11},
 year = {2023}
}

@article{10106238,
 abstract = {The moving target defense (MTD) is a proactive cybersecurity defense technique that constantly changes potentially vulnerable points to be attacked, to confuse the attackers, making it difficult for attackers to infer the system configuration and nullify reconnaissance activities to a victim system. We consider an MTD strategy for software-defined networking (SDN) environment where every SDN switch is controlled by a central SDN controller. As the MTD may incur excessive usage of the network/system resources for cybersecurity purposes, we propose to perform the MTD operations adaptively according to the security risk assessment based on a Bayesian attack graph (BAG) analysis. For accurate BAG analysis, we model random and weakest-first attack behaviors and incorporate the derived analytical models into the BAG analysis. Using the BAG analysis result, we formulate a knapsack problem to determine the optimal set of vulnerabilities to be reconfigured under a constraint of SDN reconfiguration overhead. The experiment results prove that the proposed MTD strategy outperforms the full MTD and random MTD counterparts in terms of the maximum/average of attack success probabilities and the number of SDN reconfiguration updates.},
 author = {Kim, Hyejin and Hwang, Euiseok and Kim, Dongseong and Cho, Jin-Hee and Moore, Terrence J. and Nelson, Frederica F. and Lim, Hyuk},
 doi = {10.1109/ACCESS.2023.3269018},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;IP networks;Bayes methods;Behavioral sciences;Computer security;Analytical models;Risk management;Moving target defense;Bayesian attack graph;software-defined networking},
 month = {},
 number = {},
 pages = {40511-40524},
 title = {Time-Based Moving Target Defense Using Bayesian Attack Graph Analysis},
 volume = {11},
 year = {2023}
}

@article{10107622,
 abstract = {The growth of data generation capabilities, facilitated by advancements in communication and computation technologies, as well as the rise of the Internet of Things (IoT), results in vast amounts of data that significantly enhance the performance of machine learning models. However, collecting all necessary data to train accurate models is often unfeasible due to privacy laws. Federated Learning (FL) evolved as a collaborative machine learning approach for training models without sharing private data. Unfortunately, several in-design vulnerabilities have been exposed, allowing attackers to infer private data of participants and negatively impacting the performance of the federated model. In light of these challenges and to encourage the development of FL solutions, this paper provides a comprehensive analysis of secure FL proposals that both protect user privacy and enhance the performance of the model. We performed a systematic review using predefined criteria to screen and extract data from multiple electronic databases, resulting in a final set of studies for analysis. Through the systematic review methodology, the paper groups the security vulnerabilities of FL into model performance and data privacy attacks. It also presents an analysis and comparison of potential mitigation strategies against these attacks. Additionally, the paper conducts a security analysis of state-of-the-art FL applications and proposals based on the vulnerabilities addressed. Finally, the paper outlines the main applications of secure FL and lists future research challenges. The survey highlights the crucial role of security strategies in ensuring the protection of user privacy and model performance in the context of future FL applications.},
 author = {Neto, Helio N. Cunha and Hribar, Jernej and Dusparic, Ivana and Mattos, Diogo Menezes Ferrazani and Fernandes, Natalia C.},
 doi = {10.1109/ACCESS.2023.3269980},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Computational modeling;Security;Cloud computing;Collaboration;Federated learning;Machine learning;Information security;Edge computing;Federated learning;machine learning;collaborative learning;information security;multiaccess edge computing},
 month = {},
 number = {},
 pages = {41928-41953},
 title = {A Survey on Securing Federated Learning: Analysis of Applications, Attacks, Challenges, and Trends},
 volume = {11},
 year = {2023}
}

@article{10110980,
 abstract = {Network technology has had a distinctive impact on the entire human civilization and has become an important factor of production in many countries and regions. However, with the widespread popularity of network technology, security flaws have been scattered in various fields, and potential crises may break out by attackers at any time. Therefore, it is crucial to establish a traffic monitoring mechanism for network systems. Some researchers have already implemented intrusion detection models by convolutional neural networks (CNNs) combined with attention mechanisms and achieved good results. However, few attempts have been made to improve the computational efficiency of the model by organizing the appropriate image structure, and the integration of attention mechanisms could be further enhanced. In this study, an attention-based CNN intrusion detection model has been proposed. Together with the image generation methods described in this paper, an efficient and accurate processing flow is formed. To optimize the use of the feature information in the experiments, the feature fields in the experimental images were arranged according to the results of their importance analysis. And a more integrated attention mechanism has been applied to the CNN for building the detection model. A series of comparative experiments were conducted on a subset of the CSE-CIC-IDS2018 dataset, and the results show that the detection process and model proposed in this paper can swiftly complete the detection procedure while maintaining high accuracy.},
 author = {Wang, Zhen and Ghaleb, Fuad A.},
 doi = {10.1109/ACCESS.2023.3271408},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Convolutional neural networks;Computational complexity;Security;Network systems;Image synthesis;Computational efficiency;Intrusion detection;convolutional neural network;attention mechanism},
 month = {},
 number = {},
 pages = {43116-43127},
 title = {An Attention-Based Convolutional Neural Network for Intrusion Detection Model},
 volume = {11},
 year = {2023}
}

@article{10114397,
 abstract = {Based on the principles of the biological evolution of nature, bio-inspired algorithms are gaining popularity in developing robust techniques for optimization. Unlike gradient descent optimization methods, these metaheuristic algorithms are computationally less expensive, and can also considerably perform well with nonlinear and high-dimensional data. Objectives: To understand the algorithms, application domains, effectiveness, and challenges of bio-inspired feature selection techniques. Method: A systematic literature review is conducted on five major digital databases of science and engineering. Results: The primary search included 695 articles. After removing 263 duplicated articles, 432 studies remained to be screened. Among those, 317 irrelevant papers were removed. We then excluded 77 studies according to the exclusion criteria. Finally, 38 articles were selected for this study. Conclusion: Out of 38 studies, 28 papers discussed Swarm-based algorithms, 2 papers studied Genetic Algorithms, and 8 papers covered algorithms in both categories. Considering the application domains, 21 of the articles focused on problems in the healthcare sector, while the rest mainly investigated issues in cybersecurity, text classification, and image processing. Hybridization with other BIAs was employed by approximately 18.5% of papers, and 13 out of 38 studies used S-shaped transfer functions. The majority of studies used supervised classification methods such as k-NN and SVM for building fitness functions. Accordingly, we conclude that future research should focus on applying bio-inspired feature selection to a diverse area of applications such as finance and social networks. And further exploration into enhancement techniques such as quantum representation, rough set theory, chaotic maps, and Lévy flight is necessary. Additionally, we suggest investigating other transfer functions besides S-shaped, such as V-shaped and X-shaped. Moreover, clustering and deep learning models for constructing fitness functions in bio-inspired feature selection algorithms need to be investigated further.},
 author = {Pham, Tin H. and Raahemi, Bijan},
 doi = {10.1109/ACCESS.2023.3272556},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Bio-inspired computing;Principal component analysis;Systematics;Optimization;Bibliographies;Dimensionality reduction;Particle swarm optimization;Metaheuristics;Bio-inspired optimization;feature selection;metaheuristics;systematic literature review;swarm intelligence},
 month = {},
 number = {},
 pages = {43733-43758},
 title = {Bio-Inspired Feature Selection Algorithms With Their Applications: A Systematic Literature Review},
 volume = {11},
 year = {2023}
}

@article{10115435,
 abstract = {Internet of Things (IoT) systems are beneficial to our daily lives and have become increasingly important. A complete IoT system includes devices, sensors, networks, software, and other essential components necessary for operation and interconnection. However, devices and sensors of this nature often have low resource requirements and multiple security vulnerabilities from manufacturers. Moreover, edge network areas of IoT systems exhibit several security weaknesses. Consequently, unauthorized hijacking of sensors or denial-of-service attacks on edge network areas can have severe consequences for the system’s operation. In this study, we propose a model that combines machine learning algorithms and principal component analysis techniques to train and predict Distributed Denial of Service (DDoS) attacks. Principal component analysis techniques were applied to reduce data dimensionality. We used accuracy, precision, recall, and F1-Score as the evaluation metrics. We explain the True Positive, False Positive, True Negative, and False Negative measures as basic parts of the above evaluation metrics. Unlike previous studies, we used the Training Time to evaluate the training time of each model. We employed two datasets, CICIDS 2017 and CSE-CIC-IDS 2018, to evaluate our proposed model. In general, the proposed models exhibited the best performance and improved training time.},
 author = {Cam, Nguyen Tan and Trung, Nguyen Gia},
 doi = {10.1109/ACCESS.2023.3273160},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Internet of Things;Machine learning algorithms;Computer crime;Cyber threat intelligence;Classification algorithms;Principal component analysis;Machine learning;principal component analysis;Internet of Things;DDoS attack},
 month = {},
 number = {},
 pages = {44319-44334},
 title = {An Intelligent Approach to Improving the Performance of Threat Detection in IoT},
 volume = {11},
 year = {2023}
}

@article{10121771,
 abstract = {Slow-read Distributed Denial of Service (DDoS) attacks are complex to detect and mitigate. Although existing tools allow one to identify these attacks, these tools mainly generate alerts. However, in real scenarios, a large number of attack detection alerts will put the security workforce in a bottleneck, as they will not be able to implement mitigation actions in a complete and timely manner. Furthermore, since most existing security solutions for DDoS attack mitigation are tested using datasets and simulated scenarios, their applicability to production networks could be unfeasible or ineffective due to possibly incomplete assumptions in their design. Therefore, automated security solutions against DDoS attacks are needed not only to be designed but also to be implemented and evaluated in real scenarios. This study presents a Software-Defined Networking (SDN)-based security framework, which automates the monitoring, detection, and mitigation of slow-rate DDoS attacks. The framework is implemented in a physical network that uses equipment from the European Experimental Facility Smart Networks for Industry (SN4I). The results demonstrate that the framework effectively mitigates malicious connections, with a mitigation efficiency between 91.66%– 100% for different conditions of the number of attackers and victims. In addition, the SDN-SlowRate-DDoS dataset is presented, which contains multiple experiments of slow-rate DDoS attacks performed on the real testbed. The resources provided in this security dataset are useful to the scientific and industry communities in designing and testing realistic solutions for intrusion detection systems.},
 author = {Yungaicela-Naula, Noe M. and Vargas-Rosales, Cesar and Perez-Diaz, Jesus Arturo and Jacob, Eduardo and Martinez-Cagnazzo, Carlos},
 doi = {10.1109/ACCESS.2023.3274577},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Network security;Software defined networkingf;Production;Intrusion detection;Monitoring;Deep learning;Telecommunication network management;Dataset;deep learning;slow-rate DDoS;software defined networking (SDN);intrusion detection system (IDS);intrusion prevention system (IPS)},
 month = {},
 number = {},
 pages = {46820-46831},
 title = {Physical Assessment of an SDN-Based Security Framework for DDoS Attack Mitigation: Introducing the SDN-SlowRate-DDoS Dataset},
 volume = {11},
 year = {2023}
}

@article{10123384,
 abstract = {Cyberattacks represent an ever-growing threat that has become a real priority for most organizations. Attackers use sophisticated attack scenarios to deceive defense systems in order to access private data or cause harm. Machine Learning (ML) and Deep Learning (DL) have demonstrate impressive results for detecting cyberattacks due to their ability to learn generalizable patterns from flat data. However, flat data fail to capture the structural behavior of attacks, which is essential for effective detection. Contrarily, graph structures provide a more robust and abstract view of a system that is difficult for attackers to evade. Recently, Graph Neural Networks (GNNs) have become successful in learning useful representations from the semantic provided by graph-structured data. Intrusions have been detected for years using graphs such as network flow graphs or provenance graphs, and learning representations from these structures can help models understand the structural patterns of attacks, in addition to traditional features. In this survey, we focus on the applications of graph representation learning to the detection of network-based and host-based intrusions, with special attention to GNN methods. For both network and host levels, we present the graph data structures that can be leveraged and we comprehensively review the state-of-the-art papers along with the used datasets. Our analysis reveals that GNNs are particularly efficient in cybersecurity, since they can learn effective representations without requiring any external domain knowledge. We also evaluate the robustness of these techniques based on adversarial attacks. Finally, we discuss the strengths and weaknesses of GNN-based intrusion detection and identify future research directions.},
 author = {Bilot, Tristan and Madhoun, Nour El and Agha, Khaldoun Al and Zouaoui, Anis},
 doi = {10.1109/ACCESS.2023.3275789},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Training;Cyberattack;Graph neural networks;Computer crime;Surveys;Machine learning;Cyberattacks;cybersecurity;deep learning (DL);graph neural networks (GNNs);intrusion detection (IDS);machine learning (ML)},
 month = {},
 number = {},
 pages = {49114-49139},
 title = {Graph Neural Networks for Intrusion Detection: A Survey},
 volume = {11},
 year = {2023}
}

@article{10124203,
 abstract = {Software Defined Networking (SDN) is one of the most significant innovations in telecommunication systems in the past two decades. From the very beginning, the scientific community understood the importance of investigating the possible usages of SDN as a means to increase network security, but also their potential to be exploited as an attack device. For this reason, there has been a massive production of research works, which, however, do not form a well-defined corpus. The literature is spread over many venues and composed of contributions with very different flavors. Though some review works already exist, in this work we conduct a systematic literature review of the field, gathering 466 relevant publications— the largest curated dataset on the topic to the best of our knowledge. In our work, the dataset undergoes a twofold analysis: (a) quantitative, through publication metadata, which allows us to chart publication outlets, approaches, and tackled issues; (b) qualitative, through 14 research questions that provide an aggregated overview of the literature contributions to the key issues, also to spot gaps left open. From these analyses, we derive a call for action to address the main open challenges.},
 author = {Melis, Andrea and Sadi, Amir Al and Berardi, Davide and Callegati, Franco and Prandini, Marco},
 doi = {10.1109/ACCESS.2023.3276238},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Software defined networking;Systematics;Surveys;Bibliographies;Computer crime;Control systems;Attack;defense;mitigation;security;SDN;threat},
 month = {},
 number = {},
 pages = {93431-93463},
 title = {A Systematic Literature Review of Offensive and Defensive Security Solutions With Software Defined Network},
 volume = {11},
 year = {2023}
}

@article{10128125,
 abstract = {Software-Defined Networking (SDN) is an emerging architecture that enables flexible and easy management and communication of large-scale networks. It offers programmable and centralized interfaces for making complex network decisions dynamically and seamlessly. However, SDN provides opportunities for businesses and individuals to build network applications based on their demands and improve their services. In contrast, it started to face a new array of security and privacy challenges and simultaneously introduced the threats of a single point of failure. Usually, attackers launch malicious attacks such as botnets and Distributed Denial of Service (DDoS) to the controller through OpenFlow switches. Deep learning (DL)-based security applications are trending, effectively detecting and mitigating potential threats with fast response. In this article, we analyze and show the performance of the DL methods to detect botnet-based DDoS attacks in an SDN-supported environment. A newly self-generated dataset is used for the evaluation. We also used feature weighting and tuning methods to select the best subset of features. We verify the measurements and simulation outcomes over a self-generated dataset and real testbed settings. The main aim of this study is to find a lightweight DL method with baseline hyper-parameters to detect botnet-based DDoS attacks with features and data that can be easily acquired. We observed that the best subset of features influences the performance of the DL method, and the prediction accuracy of the same method could be variated with a different set of features. Finally, based on empirical results, we found that the CNN method outperforms the dataset and real testbed settings. The detection rate of CNN reaches 99% for normal flows and 97% for attack flows.},
 author = {Nadeem, Muhammad Waqas and Goh, Hock Guan and Aun, Yichiet and Ponnusamy, Vasaki},
 doi = {10.1109/ACCESS.2023.3277397},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Denial-of-service attack;Computer crime;Feature extraction;Deep learning;Chatbots;Internet of Things;Botnet attack;convolutional neural network;deep learning;distributed denial-of-service attack;network security;software-defined networking},
 month = {},
 number = {},
 pages = {49153-49171},
 title = {Detecting and Mitigating Botnet Attacks in Software-Defined Networks Using Deep Learning Techniques},
 volume = {11},
 year = {2023}
}

@article{10130096,
 abstract = {The technological advancements of Internet of Things (IoT) has revolutionized traditional Consumer Electronics (CE) into next-generation CE with higher connectivity and intelligence. This connectivity among sensors, actuators, appliances, and other consumer devices enables improved data availability, and provides automatic control in CE network. However, due to the diversity, decentralization, and increase in the number of CE devices the data traffic has increased exponentially. Moreover, the traditional static network infrastructure-based approaches need manual configuration and exclusive management of CE devices. Motivated from the aforementioned challenges, this article presents a novel Software-Defined Networking (SDN)-orchestrated Deep Learning (DL) approach to design an intelligent Intrusion Detection System (IDS) for smart CE network. In this approach, we have first considered SDN architecture as a promising solution that enables reconfiguration over static network infrastructure and handles the distributed architecture of smart CE network by separating the control planes and data planes. Second, an DL-based IDS using Cuda-enabled Bidirectional Long Short-Term Memory (Cu-BLSTM) is designed to identify different attack types in the smart CE network. The simulations results based on CICIDS-2018 dataset support the validation of the proposed approach over some recent state-of-the-art security solutions and confirms it a phenomenal choice for next-generation smart CE network.},
 author = {Javeed, Danish and Saeed, Muhammad Shahid and Ahmad, Ijaz and Kumar, Prabhat and Jolfaei, Alireza and Tahir, Muhammad},
 doi = {10.1109/TCE.2023.3277856},
 issn = {1558-4127},
 journal = {IEEE Transactions on Consumer Electronics},
 keywords = {Internet of Things;Intrusion detection;Convolutional neural networks;Next generation networking;Denial-of-service attack;Cyberattack;Deep architecture;Software defined networking;Consumer electronics;cyber-attacks;deep learning;Internet of Things;intrusion detection system;software-defined networking},
 month = {Nov},
 number = {4},
 pages = {906-913},
 title = {An Intelligent Intrusion Detection System for Smart Consumer Electronics Network},
 volume = {69},
 year = {2023}
}

@article{10136183,
 abstract = {Distributed Denial of Service (DDoS) attacks are a growing threat to online services, and various methods have been developed to detect them. However, past research has mainly focused on identifying attack patterns and types, without specifically addressing the role of freely available DDoS attack tools in the escalation of these attacks. This study aims to fill this gap by investigating the impact of the easy availability of DDoS attack tools on the frequency and severity of attacks. In this paper, a machine learning solution to detect DDoS attacks is proposed, which employs a feature selection technique to enhance its speed and efficiency, resulting in a substantial reduction in the feature subset. The provided evaluation metrics demonstrate that the model has a high accuracy level of 99.9%, a precision score of 96%, a recall score of 98%, and an F1 score of 97%. Moreover, the examination found that by utilizing a deliberate approach for feature selection, our model’s efficacy was massively raised.},
 author = {Mohammed Sharif, Dyari and Beitollahi, Hakem and Fazeli, Mahdi},
 doi = {10.1109/ACCESS.2023.3280122},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Computer crime;Feature extraction;Servers;Machine learning;Security;Support vector machines;Deep learning;DDoS;DDoS tools;machine learning;deep learning},
 month = {},
 number = {},
 pages = {51810-51819},
 title = {Detection of Application-Layer DDoS Attacks Produced by Various Freely Accessible Toolkits Using Machine Learning},
 volume = {11},
 year = {2023}
}

@article{10136726,
 abstract = {Using deep learning and machine learning techniques for network intrusion detection is of great significance for enhancing the defense capability of network security systems. Given the characteristics of generative adversarial networks, such as the approximate consistency of generated samples with the input data distribution but with a random distribution within a certain bounded interval, and in response to the problem of insufficient classification performance and detection omission caused by the imbalance of different degrees of data categories and quantities in network intrusion traffic, and in light of the fact that the effectiveness of existing classification algorithms based on unbalanced traffic data still has some room for improvement, this paper proposes a network intrusion detection strategy based on auxiliary classifier generative adversarial networks. The data expansion experiments are conducted with the intrusion detection dataset NSL-KDD. The data are classified into twenty-three categories before and after the expansion by binary classification validation. The results show that the expansion of the generated samples for unbalanced network traffic data improve the subsequent recognition effect significantly. Finally, five classification performance index verification experiments are conducted. The results prove that the strategy of this paper performs better in accuracy, precision, recall rate and F-value indexes, and is capable of obtaining a large number of features from limited samples and inferring complete data distribution based on fewer features. The model as a whole has stronger generalization ability and defense effect.},
 author = {Zhu, Naibo and Zhao, Guangyu and Yang, Yang and Yang, Han and Liu, Zhi},
 doi = {10.1109/ACCESS.2023.3280421},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Generative adversarial networks;Data models;Data augmentation;Machine learning;Deep learning;Feature extraction;Behavioral sciences;Intrusion detection;Network security;Data augmentation;generative adversarial networks;intrusion detection;multi-class classification;network security;unbalanced data},
 month = {},
 number = {},
 pages = {52452-52465},
 title = {AEC_GAN: Unbalanced Data Processing Decision-Making in Network Attacks Based on ACGAN and Machine Learning},
 volume = {11},
 year = {2023}
}

@article{10141602,
 abstract = {Real-time deep learning faces the challenge of balancing accuracy and time, especially in cybersecurity where intrusion detection is crucial. Traditional deep learning techniques have been insufficient in identifying network anomalies and intrusions. To address this, a Fully Streaming Big Data Framework based on optimized Deep Learning for cybersecurity (FSBDL) was proposed. The framework leverages two parallel optimization algorithms, Adam and RMSprop, labeled Hyper-parallel optimization (HPO) techniques to enhance efficiency and stability. The optimized CNN in the proposed framework achieves high accuracy in real-time intrusion detection without compromising reliability. The CNN is customized to address overfitting issues in recurrent connections by reducing the number of training parameters, using customized activation functions and regularization techniques. The CNN is trained in parallel using Adam and RMSprop optimization algorithms, resulting in significant accuracy improvements that surpass traditional methods and current state-of-the-art approaches. The HPO is a crucial component of the proposed framework, as it enables the system to detect intrusions in real-time, ensuring prompt response to potential cyber threats. The six-layer FSBDL framework includes data pre-processing, feature selection, hyper-parallelism, a customized CNN, a GUI layer for interpretation, and a detection-evaluation layer. The optimized CNN was designed to detect intrusions in real-time without compromising accuracy or reliability. The proposed algorithms were evaluated using various performance metrics, showing that the accuracy of the framework surpasses 99.9%, indicating its superiority over other intrusion detection models. This novel intrusion detection model offers promising prospects for cybersecurity, and its effectiveness and accuracy have been demonstrated through experimentation.},
 author = {Hussen, Noha and Elghamrawy, Sally M. and Salem, Mofreh and El-Desouky, Ali I.},
 doi = {10.1109/ACCESS.2023.3281893},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Optimization;Deep learning;Feature extraction;Real-time systems;Intrusion detection;Computer security;Data models;Neural networks;Cyber security;streaming data;intrusion detection;deep learning;conventional neural network (CNN);optimization},
 month = {},
 number = {},
 pages = {65675-65688},
 title = {A Fully Streaming Big Data Framework for Cyber Security Based on Optimized Deep Learning Algorithm},
 volume = {11},
 year = {2023}
}

@article{10146000,
 abstract = {Industry 5.0 is a emerging transformative model that aims to develop a hyperconnected, automated, and data-driven industrial ecosystem. This digital transformation will boost productivity and efficiency throughout the production process but will be more prone to new sophisticated cyber-attacks. Deep learning-based Intrusion Detection Systems (IDS) have the potential to recognize intrusions with high accuracy. However, these models are complex and are treated as a black box by developers and security analysts due to the inability to interpret the decisions made by these models. Motivated by the challenges, this paper presents an explainable and resilient IDS for Industry 5.0. The proposed IDS is designed by combining bidirectional long short-term memory networks (BiLSTM), a bidirectional-gated recurrent unit (Bi-GRU), fully connected layers and a softmax classifier to enhance the intrusion detection process in Industry 5.0. We employ the SHapley Additive exPlanations (SHAP) mechanism to interpret and understand the features that contributed the most in the decision of the proposed cyber-resilient IDS. The evaluation of the proposed model using the explainability can ensure that the model is working as expected. The experimental results based on the CICDDoS2019 dataset confirms the superiority of the proposed IDS over some recent approaches.},
 author = {Javeed, Danish and Gao, Tianhan and Kumar, Prabhat and Jolfaei, Alireza},
 doi = {10.1109/TCE.2023.3283704},
 issn = {1558-4127},
 journal = {IEEE Transactions on Consumer Electronics},
 keywords = {Industries;Logic gates;Intrusion detection;Security;Computer architecture;Data models;Cyberattack;Deep learning (DL);cyber-attacks;explainable artificial intelligence;intrusion detection system (IDS);Industry 5.0},
 month = {Feb},
 number = {1},
 pages = {1342-1350},
 title = {An Explainable and Resilient Intrusion Detection System for Industry 5.0},
 volume = {70},
 year = {2024}
}

@article{10147216,
 abstract = {The Internet of Things (IoT) has revolutionized the world with its diverse applications and smart connected devices. These IoT devices communicate with each other without human intervention and make life easier in many ways. However, the independence of these devices raises several significant concerns, such as security and privacy preservation due to malicious and compromised nodes within the network. Trust management has been introduced as a less computationally intensive alternative to traditional approaches such as cryptography. The proposed FedTrust approach addresses these challenges by designing a method for identifying malicious and compromised nodes using federated learning. FedTrust trains edge nodes with a provided dataset and forms a global model to predict the abnormal behavior of IoT nodes. The proposed approach utilizes a novel trust dataset consisting of 19 trust parameters from three major components: knowledge, experience, and reputation. To reduce the computational burden, FedTrust employs the concept of communities with dedicated servers to divide the dataset into smaller parts for more efficient training. The proposed approach is extensively evaluated in comparison to existing approaches in terms of accuracy, precision, and other metrics to validate its performance in IoT networks. Simulation results demonstrate the effectiveness of FedTrust by achieving a higher rate of detection and prediction of malicious and compromised nodes.},
 author = {Awan, Kamran Ahmad and Ud Din, Ikram and Zareei, Mahdi and Almogren, Ahmad and Seo-Kim, Byung and Pérez-Díaz, Jesús Arturo},
 doi = {10.1109/ACCESS.2023.3284677},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Federated learning;Blockchains;Trust management;Security;Deep learning;Computational modeling;Malware;Internet of Things;federated learning;trust management;deep learning;malicious nodes;security;privacy preservation;trustworthiness},
 month = {},
 number = {},
 pages = {58901-58914},
 title = {Securing IoT With Deep Federated Learning: A Trust-Based Malicious Node Identification Approach},
 volume = {11},
 year = {2023}
}

@article{10148964,
 abstract = {Smart home automation is part of the Internet of Things that enables house remote control via the use of smart devices, sensors, and actuators. Despite its convenience, vulnerabilities in smart home devices provide attackers with an opportunity to break into the smart home infrastructure without permission. In fact, millions of Z-Wave smart home legacy devices are vulnerable to wireless injection attacks due to the lack of encryption support and the lack of firmware updates. Worse yet, recent Z-Wave secure S2 devices with built-in encryption are also vulnerable to specific targeted attacks, i.e., attacking S2 devices is possible via vulnerable legacy devices or injecting malicious unencrypted packets that alter S2 devices normal operations. In this paper, we present ZMAD, a lightweight anomaly-based intrusion detection system (IDS) for monitoring and detecting wireless attacks on Z-Wave smart home devices. ZMAD uses a technique called packet formalization to address heterogeneous packets coming from various Z-Wave devices. ZMAD also uses a centralized learning approach to profile normal communication patterns of devices to increase Z-Wave Command Class coverage. By constructing a lightweight artificial neural network built from scratch in consideration of packet formalization and centralized learning, ZMAD can effectively detect abnormal behaviors in Z-Wave networks and runs on an external device to avoid network overhead. We applied ZMAD to an evaluation testbed constructed using 17 top-rated real-world Z-Wave smart home devices. From our experiments, we confirmed that ZMAD could effectively discover wireless injected packets with an accuracy of 98% for its artificial neural network. Our further analysis demonstrated that ZMAD is more effective than existing approaches, increasing the coverage of Z-Wave Command Classes by 663% while reducing five to 47 times the size of the trained model (23.1 KB) compared to existing deep learning architectures.},
 author = {Nkuba, Carlos Kayembe and Woo, Seunghoon and Lee, Heejo and Dietrich, Sven},
 doi = {10.1109/ACCESS.2023.3285476},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart homes;Security;Communication system security;Wireless sensor networks;Motion detection;Threat modeling;Protocols;Internet of Things;smart home security;Z-Wave;intrusion detection systems;artificial neural network},
 month = {},
 number = {},
 pages = {60562-60577},
 title = {ZMAD: Lightweight Model-Based Anomaly Detection for the Structured Z-Wave Protocol},
 volume = {11},
 year = {2023}
}

@article{10151855,
 abstract = {Conventional authentication systems, that are used to protect most modern mobile applications, are faced with usability and security problems related to their static and one-shot nature. Indeed, one-shot authentication mechanisms challenge the user at the beginning of a session leaving them vulnerable to attacks on lost/stolen devices or session hijacking. In addition, static authentication mechanisms always use the same challenges to authenticate the user without considering the dynamic nature of the risk related to the authentication context. To mitigate these challenges, we propose RLAuth, a risk-based authentication system that can automatically adapt the level of challenge presented to the user on each authentication request based on the current context. RLAuth is based on binary anomaly detection, which is solved using a deep reinforcement learning agent that acts as the classifier. To cope with the high class imbalance in the anomaly detection problem, we propose to use a balanced sampling technique during experience replay and an imbalanced correction factor during reward computation. We evaluate RLAuth on a public dataset using the G-mean metric which is the square root of the product of sensitivity with specificity. This metric is efficient to measure the classification performance of a model under class imbalance since it does not overfit to the majority class. Finally, RLAuth obtained a G-Mean of 92.62%. In addition, the reinforcement learning agent can be trained offline for acceptable results in about 130 s and can then be periodically retrained to improve its performance over time.},
 author = {Picard, Claudy and Pierre, Samuel},
 doi = {10.1109/ACCESS.2023.3286376},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Authentication;Reinforcement learning;Sensitivity;Engines;Anomaly detection;Security;Mobile applications;Anomaly detection;deep reinforcement learning;imbalanced classification;risk-based authentication},
 month = {},
 number = {},
 pages = {61129-61143},
 title = {RLAuth: A Risk-Based Authentication System Using Reinforcement Learning},
 volume = {11},
 year = {2023}
}

@article{10156784,
 abstract = {Cyber-physical systems (CPS) combine computational and physical elements to enable effective and intelligent control of several applications. However, the increasing connectivity and complexity of CPS introduce new security challenges, making intrusion detection a critical aspect for maintaining the integrity and reliability of these systems. The rise in artificial intelligence (AI) techniques assists in addressing security problems related to CPS environments. Therefore, this study proposes a Quantum Dwarf Mongoose Optimization with Ensemble Deep Learning Based Intrusion Detection (QDMO-EDLID) technique in the CPS environment. The presented QDMO-EDLID technique aims to recognize the presence of intrusions by the feature selection (FS) and ensemble learning process. For feature subset selection purposes, the QDMO-EDLID technique employs the QDMO algorithm. Moreover, an ensemble of Convolution Residual Networks (CRN), Deep Belief Networks (DBN), and Deep Autoencoder (DAE) models are applied for the intrusion classification process. The experimental outcome of the QDMO-EDLID technique was tested employing benchmark intrusion databases. The simulation results highlighted the improved efficiency of the QDMO-EDLID approach concerning different performance measures.},
 author = {Almutairi, Laila and Daniel, Ravuri and Khasimbee, Shaik and Lydia, E. Laxmi and Acharya, Srijana and Kim, Hyun-Il},
 doi = {10.1109/ACCESS.2023.3287896},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Ensemble learning;Computational modeling;Feature extraction;Social factors;Deep learning;Cyber-physical systems;Deep learning;Cyber-physical system;deep learning;feature selection;intrusion detection;ensemble learning},
 month = {},
 number = {},
 pages = {66828-66837},
 title = {Quantum Dwarf Mongoose Optimization With Ensemble Deep Learning Based Intrusion Detection in Cyber-Physical Systems},
 volume = {11},
 year = {2023}
}

@article{10158784,
 abstract = {The emergence of new disruptive technologies is paving the way towards shaping the upcoming sixth generation (6G) of wireless networks, which are envisioned to enable a large number of innovative applications over a ubiquitous, secure, unified, self-sustainable, and fully intelligent platform. These technologies include but are not limited to, virtual/augmented/mixed reality services, haptics, flying vehicles, brain-machine interface, and telepresence, to name a few. The successful operation of their associated functionalities is subject to meeting stringent network requirements, such as extremely high data rates, ultra-low latency, low complexity, uniquely small-sized designs, and high energy and spectral efficiencies. Therefore, the evolution of 6G networks will be accompanied by diverse novel technological trends, including artificial intelligence, data mining, cloud and edge computing, wireless mobile caching, network slicing, network function virtualization, as well as centralized and decentralized deep learning. While 6G wireless paradigms are envisaged to support the realization of self sustaining, self optimized networks with personalized user experience, privacy and security remain a predominant concern due to the centralized and decentralized data exchange, storage, and process, needed for the successful operation of 6G networks.},
 author = {Mohjazi, Lina and Bariah, Lina and Muhaidat, Sami and Lei, Xianfu and Shami, Abdallah},
 doi = {10.1109/OJVT.2023.3288457},
 issn = {2644-1330},
 journal = {IEEE Open Journal of Vehicular Technology},
 keywords = {Security;6G mobile communication;Vehicular and wireless technologies;Internet of Things;Authentication;Smart homes;Quantum computing;Special issues and sections},
 month = {},
 number = {},
 pages = {470-474},
 title = {Guest Editorial Special Section on Recent Advances in Security and Privacy for 6G Networks},
 volume = {4},
 year = {2023}
}

@article{10159378,
 abstract = {The deployment of Internet of Things (IoT) systems in smart agriculture (SA) operates in extreme environments, including wind, snowfall, flooding, landscape, and so on for collecting and processing real-time data. The increased connectivity and broad adoption of IoT devices with low-power communications on farmland support farmers in making data-driven decisions using various artificial intelligence (AI) techniques. Furthermore, in such an environment, edge computing is also utilized to provide computationally intensive, latency-sensitive, and bandwidth-demanding services at the edge of the network. However, protecting edge-to-Things in the extreme environment of SA is challenging, due to the volume of data, and also attackers exploit network gateways to perform distributed denial of service (DDoS) attacks. Motivated by the aforementioned challenges, we develop a novel deep learning (DL)-based intrusion detection system (IDS) for edge-envisioned SA in extreme environments. Specifically, a hybrid approach is developed by combining bidirectional gated recurrent unit, long-short-term memory with softmax classifier to detect attacks at the edge of the network. To allow faster learning, the proposed IDS employs the truncated backpropagation through time (TBPTT) approach to handle lengthy sequences of network data. Furthermore, we suggest an attack scenario with deployment architecture for the proposed IDS in the extreme environment of SA. Extensive experiments using three publicly available datasets, namely, CIC-IDS2018, ToN-IoT, and Edge-IIoTset prove the effectiveness of the proposed IDS over some traditional and contemporary state-of-the-art techniques.},
 author = {Javeed, Danish and Gao, Tianhan and Saeed, Muhammad Shahid and Kumar, Prabhat},
 doi = {10.1109/JIOT.2023.3288544},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Internet of Things;Image edge detection;Logic gates;Cloud computing;Botnet;Force;Smart agriculture;Edge computing;extreme environment;Internet of Things (IoT);intrusion detection system (IDS);smart agriculture (SA)},
 month = {Aug},
 number = {16},
 pages = {26866-26876},
 title = {An Intrusion Detection System for Edge-Envisioned Smart Agriculture in Extreme Environment},
 volume = {11},
 year = {2024}
}

@article{10162196,
 abstract = {The focus of cloud computing nowadays has been reshaping the digital epoch, in which clients now face serious concerns about the security and privacy of their data hosted in the cloud, as well as increasingly sophisticated and frequent cyberattacks. Therefore, it has become imperative for both individuals and organizations to implement a robust intrusion detection system (IDS) capable of monitoring packets in the network, distinguishing between benign and malicious behavior, and detecting the type of attacks. IDS based on ML are efficient and precise in spotting network threats. Yet, for large dimensional data sizes, the performance of these systems decreases. Thus, it is critical to building a suitable feature selection approach that selects necessary features without having an impact on the classification process or causing information loss. Furthermore, training ML models on unbalanced datasets show a rising false positive rate (FPR) and a lowering detection rate (DR). In this paper, we present an improved cloud IDS designed by incorporating the synthetic minority over-sampling technique (SMOTE) to address the imbalanced data issue, and for feature selection, we propose to use a hybrid approach that includes three techniques: information gain (IG), chi-square (CS), and particle swarm optimization (PSO). Finally, the random forest (RF) model is utilized for detecting and classifying various types of attacks. The suggested system has been verified by the UNSW-NB15 and Kyoto datasets, achieving accuracies of over 98% and 99% in the multi-class classification scenario, respectively. It was noticed that an intrusion detection system with fewer informative features would operate more effectively. The simulation results significantly outperform other methodologies proposed in the related work in terms of different evaluation metrics.},
 author = {Bakro, Mhamad and Kumar, Rakesh Ranjan and Alabrah, Amerah and Ashraf, Zubair and Ahmed, Md Nadeem and Shameem, Mohammad and Abdelsalam, Ahmed},
 doi = {10.1109/ACCESS.2023.3289405},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing;Feature extraction;Computational modeling;Classification algorithms;Proposals;Firewalls (computing);Deep learning;Metaheuristics;Improved design for cloud-IDS;feature selection;PSO-based metaheuristic;random forest},
 month = {},
 number = {},
 pages = {64228-64247},
 title = {An Improved Design for a Cloud Intrusion Detection System Using Hybrid Features Selection Approach With ML Classifier},
 volume = {11},
 year = {2023}
}

@article{10168116,
 abstract = {In order to ensure the security of computer systems and networks, it is very important to design and implement intrusion detection systems that can detect and mitigate network attacks and threats. Deep learning has great advantages in processing complex, high-dimensional and large-scale traffic data. Therefore, intrusion detection system based on deep learning method has better detection effect. Through the analysis of the research status, this paper finds that there are some problems in the existing intrusion detection system. To solve the problems of low detection accuracy, structure to be optimized and high false positive rate, this paper presents a hierarchical intrusion detection model which combines multiple deep learning models with attention mechanism. The advantages of this hierarchical model include: Firstly, the SCDAE model is used to extract the features of traffic data and reduce noise; Secondly, CNN is used to extract spatial features of network traffic data from the spatial dimension; Thirdly, BiLSTM is able to fully consider the relationship between the front and back features, so that the temporal features of network traffic data can be mined; Fourthly, a Self-Attention mechanism is added to weight the output of each time step to sum up and retain the important information in it. Thus, a CNN-BiLSTM-Attention model is constructed; Finally, the Softmax classifier is used to obtain the classification results. To verify the effectiveness of the proposed model, four time-sensitive and representative datasets are selected for experiments and five classical detection models are compared in this paper. The experimental results show that the classification accuracy of the proposed model reaches 93.26 % and the false positive rate reaches 7.53%.},
 author = {Xu, Hongsheng and Sun, Libo and Fan, Ganglong and Li, Wanxing and Kuang, Guofang},
 doi = {10.1109/ACCESS.2023.3290613},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Data models;Mathematical models;Convolutional neural networks;Data mining;Deep learning;Deep learning;intrusion detection system (IDS);stacked convolutional denoising autoencoders (SCDAE);convolution neural network (CNN);bi-directional long short-term memory (BiLSTM);attention mechanism},
 month = {},
 number = {},
 pages = {66212-66226},
 title = {A Hierarchical Intrusion Detection Model Combining Multiple Deep Learning Models With Attention Mechanism},
 volume = {11},
 year = {2023}
}

@article{10171354,
 abstract = {The objective of Advanced Persistent Threat (APT) attacks is to exploit Cyber-Physical Systems (CPSs) in combination with the Industrial Internet of Things (I-IoT) by using fast attack methods. Machine learning (ML) techniques have shown potential in identifying APT attacks in autonomous and malware detection systems. However, detecting hidden APT attacks in the I-IoT-enabled CPS domain and achieving real-time accuracy in detection present significant challenges for these techniques. To overcome these issues, a new approach is suggested that is based on the Graph Attention Network (GAN), a multi-dimensional algorithm that captures behavioral features along with the relevant information that other methods do not deliver. This approach utilizes masked self-attentional layers to address the limitations of prior Deep Learning (DL) methods that rely on convolutions. Two datasets, the DAPT2020 malware, and Edge I-IoT datasets are used to evaluate the approach, and it attains the highest detection accuracy of 96.97% and 95.97%, with prediction time of 20.56 seconds and 21.65 seconds, respectively. The GAN approach is compared to conventional ML algorithms, and simulation results demonstrate a significant performance improvement over these algorithms in the I-IoT-enabled CPS realm.},
 author = {Javed, Safdar Hussain and Ahmad, Maaz Bin and Asif, Muhammad and Akram, Waseem and Mahmood, Khalid and Das, Ashok Kumar and Shetty, Sachin},
 doi = {10.1109/ACCESS.2023.3291599},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Malware;Data models;Sensors;Real-time systems;Industrial Internet of Things;Cyber-physical systems;Threat modeling;Deep learning;Graph neural networks;Advanced persistent threat;deep learning;cyber-physical systems;graph attention networks;graph neural networks;the Industrial Internet of Things},
 month = {},
 number = {},
 pages = {74000-74020},
 title = {APT Adversarial Defence Mechanism for Industrial IoT Enabled Cyber-Physical System},
 volume = {11},
 year = {2023}
}

@article{10172186,
 abstract = {One of the fields where Artificial Intelligence (AI) must continue to innovate is computer security. The integration of Wireless Sensor Networks (WSN) with the Internet of Things (IoT) creates ecosystems of attractive surfaces for security intrusions, being vulnerable to multiple and simultaneous attacks. This research evaluates the performance of supervised ML techniques for detecting intrusions based on network traffic captures. This work presents a new balanced dataset (IDSAI) with intrusions generated in attack environments in a real scenario. This new dataset has been provided in order to contrast model generalization from different datasets. The results show that for the detection of intruders, the best supervised algorithms are XGBoost, Gradient Boosting, Decision Tree, Random Forest, and Extra Trees, which can generate predictions when trained and predicted with ten specific intrusions (such as ARP spoofing, ICMP echo request Flood, TCP Null, and others), both of binary form (intrusion and non-intrusion) with up to 94% of accuracy, as multiclass form (ten different intrusions and non-intrusion) with up to 92% of accuracy. In contrast, up to 90% of accuracy is achieved for prediction on the Bot-IoT dataset using models trained with the IDSAI dataset.},
 author = {Fernando, Gutierrez-Portela and Brayan, Arteaga-Arteaga Harold and Florina, Almenares Mendoza and Liliana, Calderón-Benavides and Héctor-Gabriel, Acosta-Mesa and Reinel, Tabares-Soto},
 doi = {10.1109/ACCESS.2023.3292267},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Intrusion detection;Feature extraction;Classification algorithms;Wireless sensor networks;Telecommunication traffic;Classification tree analysis;Deep learning;internet of things;intrusion detection system;machine learning;wireless sensor network},
 month = {},
 number = {},
 pages = {70542-70559},
 title = {Enhancing Intrusion Detection in IoT Communications Through ML Model Generalization With a New Dataset (IDSAI)},
 volume = {11},
 year = {2023}
}

@article{10177172,
 abstract = {A secured platform is a critical component of digital governance, as it helps to ensure the privacy, security, and reliability of the electronic platforms and systems used to manage and deliver public services. Interoperability and data exchange are essential for digital governance, as they enable different government agencies and departments to share data, information, and resources seamlessly, regardless of the platforms and technologies they use. In this paper, we build a secure platform to enhance the trustworthiness of digital governance interoperability and data exchange using blockchain and deep learning-based frameworks. Initially, an optimal blockchain leveraging approach is designed using the bonobo optimization algorithm to authenticate data generated from smart city environments. Furthermore, we introduce the integration of a lightweight Feistel structure with optimal operations to enhance privacy preservation. This integration provides two levels of security and ensures interoperability and double-secured data exchange in digital governance systems. In addition, we utilize a deep reinforcement learning (DRL) model to detect and prevent intrusions such as fraud/corruption in the smart city data. This approach enhances transparency and accountability in accessing the data and shows its predominance over other cutting-edge techniques on two benchmark datasets, BoT-IoT and ToN-IoT. Furthermore, the effectiveness of the framework in real-time scenarios has been demonstrated through two case studies. Overall, our proposed framework provides a trustworthy platform for digital governance, interoperability, and data exchange, addressing the challenges of privacy, security, and reliability in managing and delivering public services.},
 author = {Malik, Varun and Mittal, Ruchi and Mavaluru, Dinesh and Narapureddy, Bayapa Reddy and Goyal, S. B. and Martin, R. John and Srinivasan, Karthik and Mittal, Amit},
 doi = {10.1109/ACCESS.2023.3293529},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Government;Interoperability;Security;Reliability;Distributed ledger;Waste management;Blockchain;data exchange;deep reinforcement learning;digital governance;interoperability;Internet of Things;voting system;waste management;cybersecurity},
 month = {},
 number = {},
 pages = {70110-70131},
 title = {Building a Secure Platform for Digital Governance Interoperability and Data Exchange Using Blockchain and Deep Learning-Based Frameworks},
 volume = {11},
 year = {2023}
}

@article{10177772,
 abstract = {An insider threat is anyone who has legitimate access to a particular organization’s network and uses that access to harm that organization. Insider threats may act with or without intent, but when they have an intention, they usually also have some specific motivation. This motivation can vary, including but not limited to personal discontent, financial issues, and coercion. It is hard to face insider threats with traditional security solutions because those solutions are limited to the signature detection paradigm. To overcome this restriction, researchers have proposed using Machine Learning which can address Insider Threat issues more comprehensively. Some of them have used batch learning, and others have used stream learning. Batch approaches are simpler to implement, but the problem is how to apply them in the real world. That is because real insider threat scenarios have complex characteristics to address by batch learning. Although more complex, stream approaches are more comprehensive and feasible to implement. Some studies have also used unsupervised and supervised Machine Learning techniques, but obtaining labeled samples makes it hard to implement fully supervised solutions. This study proposes a framework that combines different data science techniques to address insider threat detection. Among them are using semi-supervised and supervised machine learning, data stream analysis, and periodic retraining procedures. The algorithms used in the implementation were Isolation Forest, Elliptic Envelop, and Local Outlier Factor. This study evaluated the results according to the values obtained by the precision, recall, and F1-Score metrics. The best results were obtained by the ISOF algorithm, with 0.78 for the positive class (malign) recall and 0.80 for the negative class (benign) recall.},
 author = {Peccatiello, Rafael Bruno and Gondim, João José Costa and Garcia, Luís Paulo Faina},
 doi = {10.1109/ACCESS.2023.3293825},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Threat assessment;Classification algorithms;Security;Machine learning;Behavioral sciences;Training;Supervised learning;Insider threat detection;data stream;machine learning;one-class classification},
 month = {},
 number = {},
 pages = {70560-70573},
 title = {Applying One-Class Algorithms for Data Stream-Based Insider Threat Detection},
 volume = {11},
 year = {2023}
}

@article{10185042,
 abstract = {The advent of Fifth Generation (5G) technology has ushered in a new era of advancements in the aviation sector. However, the introduction of smart infrastructure has significantly altered the threat landscape at airports, leading to an increased vulnerability due to the proliferation of endpoints. Consequently, there is an urgent requirement for an automated detection system capable of promptly identifying and thwarting network intrusions. This research paper proposes a deep learning methodology that merges a Convolutional Neural Network (CNN) with a Gated Recurrent Unit (GRU) to effectively detect various types of cyber threats using tabular-based image data. To transform time series features into 2D texture images, Gramian Angular Fields (GAFs) are utilized. These images are then stacked to form an N-channel image, which is fed into the CNN-GRU architecture for sequence analysis and identification of potential threats. The provide solution GAF-CNN-GRU achieved an accuracy of 98.6% on the Cranfield Embedded Systems Attack Dataset. We further achieved Precision, Recall and F1-scores of 97.84%, 91% and 94.3%. To evaluate model robustness we further tested this approach, using a benchmark random selection of input features, on the Canadian Institute for Cyber-Security (CIC) 2019 Distributed Denial-of-service attack (DDoS) Dataset achieving an Accuracy of 89.08%. Following feature optimisation our approach was able to achieve an accuracy of 98.36% with Precision, Recall and F1 scores of 93.09%, 95.45% and 94.56% respectively.},
 author = {Whitworth, Huw and Al-Rubaye, Saba and Tsourdos, Antonios and Jiggins, Julia},
 doi = {10.1109/ACCESS.2023.3296311},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Protocols;Entropy;5G mobile communication;Denial-of-service attack;Convolutional neural networks;Topology;Computer security;Neural networks;Aerospace engineering;Aviation;cyber security;denial-of-service attack (DoS);fifth generation (5G);digital aviation;neural network;time series},
 month = {},
 number = {},
 pages = {77518-77542},
 title = {5G Aviation Networks Using Novel AI Approach for DDoS Detection},
 volume = {11},
 year = {2023}
}

@article{10185051,
 abstract = {The Social Internet of Things (SIoT) has revolutionized user experience through various applications and networking services like Social Health Monitoring, Social Assistance, Emergency Alert Systems, and Collaborative Learning Platforms. However, transferring different types of data between the interconnected objects in the SIoT environment, including sensor data, user-generated data, and social interaction data, poses challenges due to their high dimensionality. This paper presents an alternative SIoT method that improves resource efficiency, system performance, and decision-making using the Barnacles Mating Optimizer (BMO). The BMO incorporates Triangular mutation and dynamic Opposition-based learning to enhance search space exploration and prevent getting stuck in local optima. Two experiments were conducted using UCI datasets from different applications and SIoT-related datasets. The results demonstrate that the developed method, DBMT, outperforms other algorithms in predicting social-related datasets in the IoT environment.},
 author = {Al-Qaness, Mohammed A. A. and Ewees, Ahmed A. and Abd Elaziz, Mohamed and Dahou, Abdelghani and Al-Betar, Mohammed Azmi and Aseeri, Ahmad O. and Yousri, Dalia and Ibrahim, Rehab Ali},
 doi = {10.1109/ACCESS.2023.3296255},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Optimization;Clustering algorithms;Social Internet of Things;Heuristic algorithms;Statistics;Sociology;Social IoT;Barnacles Mating Optimizer;triangular mutation;opposition-based learning},
 month = {},
 number = {},
 pages = {73062-73079},
 title = {Boosted Barnacles Algorithm Optimizer: Comprehensive Analysis for Social IoT Applications},
 volume = {11},
 year = {2023}
}

@article{10185955,
 abstract = {Cyber-attacks pose increasing challenges in precisely detecting intrusions, risking data confidentiality, integrity, and availability. This review paper presents recent IDS taxonomy, a comprehensive review of intrusion detection techniques, and commonly used datasets for evaluation. It discusses evasion techniques employed by attackers and the challenges in combating them to enhance network security. Researchers strive to improve IDS by accurately detecting intruders, reducing false positives, and identifying new threats. Machine learning (ML) and deep learning (DL) techniques are adopted in IDS systems, showing potential in efficiently detecting intruders across networks. The paper explores the latest trends and advancements in ML and DL-based network intrusion detection systems (NIDS), including methodology, evaluation metrics, and dataset selection. It emphasizes research obstacles and proposes a future research model to address weaknesses in the methodologies. The decision tree, known for its speed and user-friendliness, is proposed as a model for detecting result anomalies, combining findings from a comparative survey. This research aims to provide insights into building an effective decision tree-based detection framework.},
 author = {Azam, Zahedi and Islam, Md. Motaharul and Huda, Mohammad Nurul},
 doi = {10.1109/ACCESS.2023.3296444},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computer hacking;Taxonomy;Surveys;Decision trees;Phishing;Machine learning;Computer crime;Unsupervised learning;Intrusion detection system;machine learning;inductive learning;DDoS attacks;decision tree;supervised and unsupervised learning},
 month = {},
 number = {},
 pages = {80348-80391},
 title = {Comparative Analysis of Intrusion Detection Systems and Machine Learning-Based Model Analysis Through Decision Tree},
 volume = {11},
 year = {2023}
}

@article{10192903,
 abstract = {Smart contracts based on blockchain are widely used in finance, management, Internet of Things, healthcare, and other fields. However, with the rapid development of smart contracts, the corresponding security vulnerability attack cases occur frequently. Existing Ethereum smart contract vulnerability detection tools based on static analysis techniques rely too much on expert rules, for this reason, this paper proposes an Ethereum smart contract vulnerability detection method SCSVM based on support vector machine technology. A representation of smart contracts is constructed based on the word-to-vector technique, the features of Ethereum smart contracts are extracted based on the support vector machine technique, and these features are combined to identify vulnerabilities. Experiments on Smartbugs and Smartbugs-wild show that SCSVM is significantly effective. It achieves a detection accuracy of 87.51%, outperforming five typical static analysis vulnerability detection tools in terms of F1-score. To alleviate the problems of deep learning methods over-relying on large-scale data to train models and collecting a large number of smart contract attack samples in a short period, this paper proposes a basic learner-meta-learner framework, SCLMF. solc-based acquisition of the bytecode of Ethereum smart contract Solidity, on which smart contract representations are constructed via Python and the use of SCLMF for vulnerability detection. The experiments on WScrawlD show that SCLMF has a certain detection effect. Also, to further verify the effectiveness of SCLMF, experiments were conducted on Omniglot, and the detection accuracy was 96.7% and 98.5% under 5-way 1-shot and 5-way 5-shot conditions, respectively, which exceeded Memory-Augmented Neural Networks and CONVOLUTIONAL SIAMESE NETS. In summary, the experiments proved the effectiveness of SCSVM and SCLMF in Ethereum smart contract vulnerability detection.},
 author = {Yang, Zhongju and Zhu, Weixing and Yu, Minggang},
 doi = {10.1109/ACCESS.2023.3298672},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart contracts;Ethernet;Deep learning;Data models;Semantics;Neural networks;Feature extraction;Metalearning;Support vector machines;Network intrusion;Base learner-meta-learner;Ethereum;smart contracts;support vector machines;vulnerability detection;word embedding},
 month = {},
 number = {},
 pages = {78207-78223},
 title = {Improvement and Optimization of Vulnerability Detection Methods for Ethernet Smart Contracts},
 volume = {11},
 year = {2023}
}

@article{10195850,
 abstract = {The IoT networks are customized to work under various smart environments, utilizing diverse sensors. However, they are vulnerable to several cyberattacks because of their finite resources and limited computing capabilities. Intruders can easily hack the data transmitted across the end nodes. Therefore, it is crucial to protect the privacy of the IoT network against adversarial attacks. For real-time insights from IoT networks, an appropriate networking protocol is essential. In previous studies, several routing protocols have been formulated for intrusion detection with limited performance. Even the application of advanced machine learning (ML) has shown relatively lower accuracy with an increased error rate. To address these issues, an innovative intrusion detection system (IDS) for IoT networks based on medium access control (MAC) protocols with an improved efficient shuffle bidirectional COOT channel attention network (IEsBCCA-Net) method has been proposed. The suggested system uses the MAC protocol to securely transmit the data with low energy consumption and delay, which provides increased throughput. The collected data is stored in the BoT-IoT dataset, which is imbalanced and balanced using the synthetic minority over-sampling technique (SMOTE) and random under-sampling (RUS) techniques. The data is pre-processed using the reformed histogram equalization method, and the optimal features are selected using the modified honey badger algorithm (MHBA). Finally, the intrusions are classified using the IEsBCCA-Net approach, which provides outstanding accuracy compared to state-of-the-art (SOTA) methods.},
 author = {Nayak, Nanavath Kiran Singh and Bhattacharyya, Budhaditya},
 doi = {10.1109/ACCESS.2023.3299031},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Intrusion detection;Media Access Protocol;Deep learning;Classification algorithms;Security;Error analysis;Channel allocation;Improved efficient shuffle bidirectional COOT channel attention network;intrusion detection;IoT network;MAC protocol;modified honey badger algorithm},
 month = {},
 number = {},
 pages = {77385-77402},
 title = {MAC Protocol Based IoT Network Intrusion Detection Using Improved Efficient Shuffle Bidirectional COOT Channel Attention Network},
 volume = {11},
 year = {2023}
}

@article{10196386,
 abstract = {An IoT healthcare system refers to the use of Internet of Things (IoT) devices and technologies in the healthcare industry. It involves the integration of various interconnected devices, sensors, and systems to collect, monitor, and transmit health-related data for medical purposes. Blockchain-assisted intrusion detection on IoT healthcare systems is an innovative approach to enhancing the security and privacy of sensitive medical data. By combining the decentralized and immutable nature of blockchain technology with intrusion detection systems (IDS), it is possible to create a more robust and trustworthy security framework for IoT healthcare systems. With this motivation, this study presents Blockchain Assisted IoT Healthcare System using Ant Lion Optimizer with Hybrid Deep Learning (BHS-ALOHDL) technique. The presented BHS-ALOHDL technique enables IoT devices in the healthcare sector to transmit medical data securely and detects intrusions in the system. To accomplish this, the BHS-ALOHDL technique performs ALO based feature subset selection (ALO-FSS) system to produce a series of feature vectors. The HDL model integrates convolutional neural network (CNN) features and long short-term memory (LSTM) model for intrusion detection. Lastly, the flower pollination algorithm (FPA) is exploited for the optimal hyperparameter tuning of the HDL approach, which results in an enhanced detection rate. The experimental outcome of the BHS-ALOHDL system was tested on two benchmark datasets and the outcomes indicate the promising performance of the BHS-ALOHDL technique over other models.},
 author = {Alamro, Hayam and Marzouk, Radwa and Alruwais, Nuha and Negm, Noha and Aljameel, Sumayh S. and Khalid, Majdi and Hamza, Manar Ahmed and Alsaid, Mohamed Ibrahim},
 doi = {10.1109/ACCESS.2023.3299589},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Internet of Medical Things;Security;Hardware design languages;Intrusion detection;Blockchains;Feature extraction;Deep learning;Security management;Deep learning;ant lion optimizer;Internet of Things;healthcare;blockchain;security},
 month = {},
 number = {},
 pages = {82199-82207},
 title = {Modeling of Blockchain Assisted Intrusion Detection on IoT Healthcare System Using Ant Lion Optimizer With Hybrid Deep Learning},
 volume = {11},
 year = {2023}
}

@article{10210383,
 abstract = {The Internet of Things (IoT) refers to a technology enabler to enhance the urban physical architecture and render public services. But, public access to accumulated heterogeneous IoT urban information is prone to hackers attacking connected devices to the internet intellectual property as well. IoT security serves a dynamic part in the smart city. Some IoT devices are connected in smart homes, and these connections were centred on gateways. In smart homes, the gateways gain a lot of significance; but their centralized structure causes many security vulnerabilities like availability, integrity, and certification. Unified “cloud-like” computing networks and Blockchain (BC) type systems should be used to sort out these problems. Therefore, this article develops a Blockchain-Assisted Secure Smart Home Network using Gradient Based Optimizer with Hybrid Deep Learning (BSSHN-GBOHDL) model. The presented BSSHN-GBOHDL technique employs BC technology to improve the confidentiality of the data in the smart home environment. In addition, the BSSHN-GBOHDL technique identifies malicious activities in the smart home environment via three sub-processes namely data preprocessing, hybrid deep learning (HDL)-based malicious activity classification, and GBO-based hyperparameter tuning. The GBO algorithm assists in the proficient hyperparameter selection of the HDL model, which aids in accomplishing increased detection efficiency. The experimental validation of the BSSHN-GBOHDL approach is tested on a benchmark NSL-KDD dataset with 65495 normal and 60743 attack samples. The results highlight the betterment of the BSSHN-GBOHDL approach over other recent methods with maximum accuracy of 98.29%.},
 author = {Almuqren, Latifah and Mahmood, Khalid and Aljameel, Sumayh S. and Salama, Ahmed S. and Mohammed, Gouse Pasha and Alneil, Amani A.},
 doi = {10.1109/ACCESS.2023.3303087},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart homes;Logic gates;Deep learning;Computer architecture;Blockchains;Computational modeling;Tuning;Internet of Things;Network security;Gradient methods;Smart homes;Internet of Things;blockchain;network security;deep learning;gradient-based optimizer},
 month = {},
 number = {},
 pages = {86999-87008},
 title = {Blockchain-Assisted Secure Smart Home Network Using Gradient-Based Optimizer With Hybrid Deep Learning Model},
 volume = {11},
 year = {2023}
}

@article{10210414,
 abstract = {The characteristics and performance of wireless sensor networks (WSNs) are the main reasons for their rapid expansion in various fields. However, these networks are extremely susceptible to multiple security assaults, including denial-of-service (DoS) attacks, which are among the most prevalent in these networks. This study sheds light on WSN restrictions, weaknesses, and security threats with a focus on DoS attacks. Recent techniques for DoS attack detection have been investigated thoroughly, highlighting their achievements and limitations. This provides valuable insight into the current state of recent research in this field. Accordingly, this study proposes a lightweight machine learning detection approach based on a decision tree (DT) algorithm with the Gini feature selection method to detect DoS attacks in WSNs. An enhanced version of the WSN-DS dataset, developed by the author, was used to train and test the proposed approach. The proposed approach has shown good performance by achieving an accuracy rate of 99.5% with minimum overhead compared to random forest (RF), extreme gradient boosting (XGBoost), and k-nearest neighbor (KNN) classifiers. It only takes 9.7%, 13%, and 2% of the processing time required by FR, XGBoost, and KNN respectively, which indicates that our proposed approach significantly outperforms these classifiers in terms of processing time. It is noteworthy that RF achieved an accuracy that was somewhat superior; however, the proposed approach greatly surpassed RF by taking only 9.7% of the RF processing time, which is an important factor in meeting WSN constraints.},
 author = {Elsadig, Muawia A.},
 doi = {10.1109/ACCESS.2023.3303113},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Security;Machine learning;Internet of Things;Routing;Denial-of-service attack;Deep learning;Computer security;Feature extraction;Network security;Machine learning;Deep learning;DoS attacks;cyber security;feature selection;IoT security;network security;machine learning;wireless sensor networks;WSN attacks;WSN constraints;WSN security},
 month = {},
 number = {},
 pages = {83537-83552},
 title = {Detection of Denial-of-Service Attack in Wireless Sensor Networks: A Lightweight Machine Learning Approach},
 volume = {11},
 year = {2023}
}

@article{10210500,
 abstract = {Safe and secure operations of robotic systems are of paramount importance. Aiming for achieving the trusted operations of a military robotic vehicle under contested environments, we introduce a new cyber-physical system based on the concepts of deep learning Convolutional Neural Network (CNN). The proposed algorithm is specifically designed to reduce the cyber vulnerability of the Robot Operating System (ROS), a well-known middleware platform, widely used in both civilian and military domains. To demonstrate the efficacy of the proposed algorithm, we conduct penetration testing (real-time man-in-the-middle cyberattacks) on the GVR-BOT ground vehicle, a replicate of a military ground robot, developed by the United States Army Combat Capabilities Development Command (CCDC), Ground Vehicle Systems Center. The cyberattacks also exploit the vulnerability of the Robot Operating System employed on its onboard computer. We collect experimental data and train our CNN based on two different operating conditions, namely, legitimate and malicious. We normalize and convert the network traffic data in the form of RGB or grayscale images. We introduce two different types of windowing techniques, namely, the independent and overlapping sliding epochs to efficiently feed the network traffic data to our CNN system. Our research indicates the efficacy of the proposed algorithm as our proposed cyber intrusion detection system can achieve reasonably high accuracies $\geq$≥99% and substantially small false-positive rates $\leq$≤2% supported with minimum detection times. In addition, we also compare and demonstrate the relative merits of our proposed algorithm with respect to the performance of some well-known techniques, namely, ‘bag-of-features’ (BoFs) and Support Vector Machine (SVM) algorithms.},
 author = {Santoso, Fendy and Finn, Anthony},
 doi = {10.1109/TDSC.2023.3302807},
 issn = {1941-0018},
 journal = {IEEE Transactions on Dependable and Secure Computing},
 keywords = {Robots;Robot sensing systems;Cyberattack;Robot kinematics;Operating systems;Land vehicles;Convolutional neural networks;Cybersecurity;Convolutional Neural-Network (CNN);Man-in-the-Middle Cyberattacks;Robot Operating System (ROS);Unmanned Ground Vehicles (UGVs)},
 month = {July},
 number = {4},
 pages = {2273-2284},
 title = {Trusted Operations of a Military Ground Robot in the Face of Man-in-the-Middle Cyberattacks Using Deep Learning Convolutional Neural Networks: Real-Time Experimental Outcomes},
 volume = {21},
 year = {2024}
}

@article{10213280,
 abstract = {Modern vehicles rely on a fleet of electronic control units (ECUs) connected through controller area network (CAN) buses for critical vehicular control. With the expansion of advanced connectivity features in automobiles and the elevated risks of internal system exposure, the CAN bus is increasingly prone to intrusions and injection attacks. As ordinary injection attacks disrupt the typical timing properties of the CAN data stream, rule-based intrusion detection systems (IDS) can easily detect them. However, advanced attackers can inject false data to the signal/semantic level, while looking innocuous by the pattern/frequency of the CAN messages. The rule-based IDS, as well as the anomaly-based IDS, are built merely on the sequence of CAN messages IDs or just the binary payload data and are less effective in detecting such attacks. Therefore, to detect such intelligent attacks, we propose CANShield, a deep learning-based signal level intrusion detection framework for the CAN bus. CANShield consists of three modules: 1) a data preprocessing module that handles the high-dimensional CAN data stream at the signal level and parses them into time series suitable for a deep learning model; 2) a data analyzer module consisting of multiple deep autoencoder (AE) networks, each analyzing the time-series data from a different temporal scale and granularity; and 3) finally an attack detection module that uses an ensemble method to make the final decision. Evaluation results on two high-fidelity signal-based CAN attack data sets show the high accuracy and responsiveness of CANShield in detecting advanced intrusion attacks.},
 author = {Shahriar, Md Hasan and Xiao, Yang and Moriano, Pablo and Lou, Wenjing and Hou, Y. Thomas},
 doi = {10.1109/JIOT.2023.3303271},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Payloads;Intrusion detection;Internet of Things;Automotive engineering;Protocols;Decoding;Safety;Deep learning;Ensemble learning;Controller area networks (CANs);deep learning;ensemble method;intrusion detection systems (IDS)},
 month = {Dec},
 number = {24},
 pages = {22111-22127},
 title = {CANShield: Deep-Learning-Based Intrusion Detection Framework for Controller Area Networks at the Signal Level},
 volume = {10},
 year = {2023}
}

@article{10214541,
 abstract = {In-vehicle controller area network (CAN) is susceptible to various cyberattacks due to its broadcast-based communication nature. An attacker can inject false messages to a vehicle’s CAN via wireless communication, the infotainment system, or the onboard diagnostic port. Thus, an effective intrusion detection system is essential to distinguish authentic CAN messages from false ones. In this study, we developed a hybrid quantum-classical CAN intrusion detection framework using a classical neural network (NN) and a quantum restricted Boltzmann machine (RBM). The classical NN is dedicated to feature extraction from CAN images generated from a vehicle’s CAN bus data. In contrast, the quantum RBM is dedicated to CAN image reconstruction for classification-based intrusion detection. The novelty of the study lies in utilizing the generative ability of an RBM to reconstruct the pixels in a CAN image, a portion of which is dedicated to labeling. Then, that portion of the reconstructed image is used to classify the image as an attack image or a normal image. To evaluate the performance of the hybrid quantum-classical CAN intrusion detection framework, we used a real-world CAN fuzzy attack dataset to create three separate attack datasets, where each dataset represents a unique set of features related to the vehicle. We compared the performance of our hybrid framework to a similar but classical-only framework. Our analyses showed that the hybrid framework performs better in CAN intrusion detection compared to the classical-only framework. For the three datasets considered in this study, the best models in the hybrid framework achieved 97.5%, 97%, and 98.3% intrusion detection accuracies and 94.7%, 93.9%, and 97.2% recalls, respectively. In contrast, the best models in the classical-only framework achieved 92.5%, 95%, and 93.3% intrusion detection accuracies and 84.2%, 89.8%, and 88.9% recalls, respectively.},
 author = {Salek, M Sabbir and Biswas, Pronab Kumar and Pollard, Jacquan and Hales, Jordyn and Shen, Zecheng and Dixit, Vivek and Chowdhury, Mashrur and Khan, Sakib Mahmud and Wang, Yao},
 doi = {10.1109/ACCESS.2023.3304331},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Artificial neural networks;Training;Image reconstruction;Computer hacking;Hybrid power systems;Generative adversarial networks;Artificial intelligence;Controller area network;cyberattack detection;intrusion detection;quantum artificial intelligence;restricted Boltzmann machine;generative artificial intelligence},
 month = {},
 number = {},
 pages = {96081-96092},
 title = {A Novel Hybrid Quantum-Classical Framework for an In-Vehicle Controller Area Network Intrusion Detection},
 volume = {11},
 year = {2023}
}

@article{10224236,
 abstract = {Cybersecurity, as a crucial aspect of the information society, requires significant attention. Fortunately, the concept of trust, originating from the field of sociology, has been under extensive research in order to enhance cybersecurity by evaluating the trustworthiness of nodes with artificial intelligence (AI) techniques in distributed networks (DNs). However, the scalability issues faced by AI-enabled trust hinder its integration with the DNs. Currently, there is a lack of a comprehensive review article that explores the current state of AI-enabled trust development applications. This paper aims to address this gap by providing a review of the state-of-the-art AI-enabled trust in DNs. This review focuses on the concept of trust and how it can be facilitated through AI, particularly utilizing machine learning and deep learning methods. Additionally, the paper provides a comprehensive comparison and analysis of three key domains in the field of AI-enabled trust: trust management (TM), intrusion detection system (IDS), and recommender systems (RS). Some open problems and challenges that currently exist in the field are manifested, and some suggestions for future work are presented.},
 author = {Li, Zhiqi and Fang, Weidong and Zhu, Chunsheng and Gao, Zhiwei and Zhang, Wuxiong},
 doi = {10.1109/ACCESS.2023.3306452},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Sociology;Market research;Intrusion detection;Trust management;Reliability;Internet of Things;Computer crime;Artificial intelligence;Machine learning;Computer security;Artificial intelligence;machine learning;trust;distributed networks;cybersecurity},
 month = {},
 number = {},
 pages = {88116-88134},
 title = {AI-Enabled Trust in Distributed Networks},
 volume = {11},
 year = {2023}
}

@article{10225514,
 abstract = {Machine Learning (ML) techniques, especially deep learning, are crucial to many contemporary real world systems that use Computational Intelligence (CI) as their core technology, including self-deriving vehicles, assisting machines, and biometric authentication systems. We encounter a lot of attacks these days. Drive-by-download is used to covertly download websites when we view them, and emails we receive often have malicious attachments. The affected hosts and networks sustain significant harm as a result of the infection. Therefore, identifying malware is crucial. Recent attacks, however, is designed to evade detection using Intrusion Detection System (IDS). It is essential to create fresh signatures as soon as new malware is found in order to stop this issue. Using a variety of cutting-edge representation methodologies, we develop attack taxonomy and examine it. 1) N-gram-based representation: In this tactic, we look at a number of random representations that consider a technique of sampling the properties of the graph. 2) Signature-based representation: This technique uses the idea of invariant representation of the graph, which is based on spectral graph theory. One of the main causes is that a ML system setup is rely on a number of variables, including the input dataset, ML architecture, attack creation process, and defense strategy. To find any hostile attacks in the network system, we employ IDS with Deep Neural Network (DNN). In conclusion, the efficacy and efficiency of the suggested framework with Convolutional Neural Network (CNN) and Support Vector Machine (SVM) are assessed using the assessment indicators, including throughput, latency rate, accuracy and precision. The findings of the suggested model with a detection rate of 93%, 14%, 95.63% and 95% in terms of throughput, latency rate, accuracy and precision, which is based on adversarial assault, were better and more effective than CNN and SVM models. Additionally at the end we contrast the performance of the suggested model with that of earlier research that makes use of the same dataset, NSL-KDD, as we do in our scenario.},
 author = {Al Ghamdi, Mohammed A.},
 doi = {10.1109/ACCESS.2023.3307018},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Taxonomy;Deep learning;Weapons;Support vector machines;Social networking (online);Malware;Convolutional neural networks;Machine learning;Computational intelligence;Intrusion detection;Neural networks;Machine learning;computational intelligence;intrusion detection system;deep neural network;convolutional neural network;support vector machine},
 month = {},
 number = {},
 pages = {96615-96625},
 title = {A Fine-Grained System Driven of Attacks Over Several New Representation Techniques Using Machine Learning},
 volume = {11},
 year = {2023}
}

@article{10226180,
 abstract = {The traditional support vector machine (SVM) requires manual feature extraction to improve classification performance and relies on the expressive power of manually extracted features. However, this characteristic poses limitations in complex Industrial Internet of Things (IIoT) environments. Traditional manual feature extraction may fail to capture all relevant information, thereby restricting the application effectiveness of SVM in IIoT settings. CNN-RNN, as a deep learning network capable of simultaneously extracting spatial and temporal features, can alleviate researchers’ burden. In this paper, we propose a novel intrusion detection system (IDS) framework based on anomalies, called CRSF. The framework’s pre-training part employs a dimension transformation function to process input data into two-dimensional images. Two-dimensional convolutional kernels are then employed to extract spatial features, and the feature sequences are passed to an RNN to capture richer temporal features. After sufficient pre-training, SVM is used as a classifier to map the pre-training data from the feature space to a high-dimensional space and learn nonlinear decision boundaries, enabling the framework to accurately differentiate feature representations of different classes. Simulation experiments on the TON_IoT-Datasets demonstrate the effectiveness of the CRSF framework in intrusion detection. When using the “linear” kernel function in SVM, the framework achieves an accuracy, F1-score, and AUC of 0.9959, 0.9959, and 0.9977, respectively, indicating its capability and superiority in intrusion detection.},
 author = {Li, Shiming and Chai, Guangzhao and Wang, Yuhe and Zhou, Guohui and Li, Zhenxing and Yu, Dan and Gao, Rencai},
 doi = {10.1109/ACCESS.2023.3307429},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Convolutional neural networks;Support vector machines;Intrusion detection;Industrial Internet of Things;Deep learning;Training data;Recurrent neural networks;Intrusion detection;Industrial Internet of Things;convolutional neural network;recurrent neural network;support vector machine;intrusion detection},
 month = {},
 number = {},
 pages = {92041-92054},
 title = {CRSF: An Intrusion Detection Framework for Industrial Internet of Things Based on Pretrained CNN2D-RNN and SVM},
 volume = {11},
 year = {2023}
}

@article{10226215,
 abstract = {Adversarial attacks have threatened the credibility of machine learning models and cast doubts over the integrity of data. The attacks have created much harm in the fields of computer vision, and natural language processing. In this paper, we focus on the adversarial attack, in particular the poisoning attack, against the network intrusion detection system (NIDS), which is often viewed as the first line of defense against cyber threats. We develop a generative adversarial network (GAN) in AIGAN, which uses deep learning techniques to generate adversarial data and to conduct an anomaly attack on IoT networks. To evaluate the effectiveness of our generator, we measure the similarities between real and fake data using the Jaccard similarity index, in addition comparing the F1-scores from four generic algorithms: multilayer perception, logistic regression, decision tree, random forest. We contrast the performance of ten machine learning classifiers experimented on two real IoT datasets and their fake adversarial samples. Our work highlights a vulnerable side of NIDS created by machine learning when attacked with adversarial perturbation.},
 author = {Liu, Zhipeng and Hu, Junyi and Liu, Yang and Roy, Kaushik and Yuan, Xiaohong and Xu, Jinsheng},
 doi = {10.1109/ACCESS.2023.3307463},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Generative adversarial networks;Biological system modeling;Training data;Perturbation methods;Data augmentation;Internet of Things;Intrusion detection;Toxicology;Generative adversarial network;the IoT;machine learning;network intrusion detection system;poisoning attack},
 month = {},
 number = {},
 pages = {91116-91132},
 title = {Anomaly-Based Intrusion on IoT Networks Using AIGAN-a Generative Adversarial Network},
 volume = {11},
 year = {2023}
}

@article{10227259,
 abstract = {Intrusion Detection Systems (IDSs) have played a crucial role in identifying cyber threats for a very long time. Still, their significance has increased significantly with the advent of 5G/6G technologies, particularly Device-to-Device (D2D) communication. Multiple cyberattacks, such as Man in the Middle (MITM) attacks, Structured Query Language (SQL) injection attacks, Dictionary attacks, Distributed Denial of Service (DDoS) attacks, and others by using specific attack tools such as HULK, RUDY, and GoldenEye, that can cause rapid battery drain, rendering D2D network devices more prone to hardware failure or even to the dissolution of the D2D communication network affecting the operation and the performance of the mobile network. Using a Deep Hierarchical Machine Learning Model/Deep Hierarchical Neural Network (DHMLM/DHNN) technique, we develop an Intrusion Detection System (IDS) for D2D communication that, due to its hierarchical structure, is distinct from other comparable approaches. (i.e., Recurrent Neural Networks (RNN), Deep Neural Networks (DNN), Long short-term memory (LSTM)), has several advantages, including i) reduced training time (training time can be reduced by 56%.); ii) the ability to identify multiple types of attacks; iii) the ability to identify Zero-day/Unknown attacks (i.e., attacks that it has not seen before); iv) a more straightforward model design due to the low number of connections and neurons compared to other approaches (excluding RNN and LSTM), and; v) overall outstanding performance in terms of accuracy (i.e., 99.07%). The custom/unified data set used to train and evaluate the model was partially manually emulated and partially sampled from a large set (>95%) from the commonly used CIC-DDoS-2019 data set. The after-comparison final proposed model’s 99.07% accuracy on this unified data set demonstrates the efficacy of our method. The model was also tested and demonstrated an astounding 99.63% accuracy for zero-day/unknown attacks.},
 author = {Rani, S. V. Jansi and Ioannou, Iacovos I. and Nagaradjane, Prabagarane and Christophorou, Christophoros and Vassiliou, Vasos and Yarramsetti, Harshitaa and Shridhar, Sai and Balaji, L. Mukund and Pitsillides, Andreas},
 doi = {10.1109/ACCESS.2023.3308036},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Device-to-device communication;Intrusion detection;Security;Data models;Recurrent neural networks;Logic gates;Cyberattack;5G mobile communication;Machine learning;Hierarchical systems;5G;D2D;D2D security;intrusion detection systems;multiple cyber attacks;hierarchical machine learning},
 month = {},
 number = {},
 pages = {95161-95194},
 title = {A Novel Deep Hierarchical Machine Learning Approach for Identification of Known and Unknown Multiple Security Attacks in a D2D Communications Network},
 volume = {11},
 year = {2023}
}

@article{10233928,
 abstract = {The automotive domain has realized amazing advancements in communication, connectivity, and automation—and at a breakneck pace. Such advancements come with ample benefits, such as the reduction of traffic accidents and the refinement of transit efficiency. However, these new developments were not necessarily made with security in mind. Researchers have unearthed a number of security vulnerabilities in paradigms such as in-vehicle networks (IVNs), the Internet of Vehicles (IoV), and intelligent transportation systems (ITSs). As automotive technologies continue to evolve, it would be realistic to expect new vulnerabilities to arise—both vulnerabilities that are identified and vulnerabilities that are not. If—or more pragmatically, when—these vulnerabilities are exploited, intrusion detection will be paramount. Therefore, we find it prudent to review intrusion detection in the automotive domain. We explore a myriad of threats and intrusion detection techniques—from the boundaries of the vehicle’s own network to the wider Internet of Vehicles (IoV). Intrusion detection, while not a panacea, can be a cost-effective solution to many automotive security issues. Generally, such intrusion detection systems (IDSs) do not disrupt existing hardware, infrastructure, or communications; rather, they merely tap into the network and monitor for suspicious traffic. Given the very reasonable price tag, the implementation of intrusion detection systems would be an auspicious step by the automotive industry to assure the security—and safety—of the modern automobile. This paper volunteers a comprehensive review of intrusion detection technologies in the automotive domain.},
 author = {Lampe, Brooke and Meng, Weizhi},
 doi = {10.1109/COMST.2023.3309864},
 issn = {1553-877X},
 journal = {IEEE Communications Surveys & Tutorials},
 keywords = {Automotive engineering;Intrusion detection;Vehicular ad hoc networks;Standards;Security;Internet of Vehicles;Surveys;Intrusion detection system (IDS);automotive;in-vehicle network (IVN);controller area network (CAN) bus;vehicular ad hoc network (VANET);Internet of Vehicles (IoV);connected and autonomous vehicles (CAVs);intelligent transportation system (ITS);deep learning (DL);machine learning (ML);blockchain},
 month = {Fourthquarter},
 number = {4},
 pages = {2356-2426},
 title = {Intrusion Detection in the Automotive Domain: A Comprehensive Review},
 volume = {25},
 year = {2023}
}

@article{10239162,
 abstract = {Industrial Control Systems (ICSs) have entered an era of modernization enabled by the recent progress in Information Technologies (IT), particularly the Industrial Internet of Things (IIoT). This enables better automation of industrial processes but now exposes the ICSs to cyber-attacks that exploit the IIoT vulnerabilities. Thus, to ensure ICSs security, numerous research works have focused on designing Intrusion Detection and Prevention Systems (IDPSs), and deep learning has recently received considerable attention, as it has the potential to improve detection accuracy. However, most of the proposed deep learning solutions focus only on the model’s accuracy without considering latency, which is an essential requirement in many ICSs. The novelty of this paper is the time complexity analysis of Deep Neural Networks (DNNs) and the design of a low latency and robust deep learning-based collaborative IDPS. The proposed architecture employs two classification models. In the first model, a lightweight DNN is used to perform a binary classification, i.e., normal or attack, which ensures rapid intrusion detection. A second model ensures the identification of the type of attacks by performing a multi-class classification of the detected anomaly, which is handled by a robust and complex DNN in order to achieve higher accuracy. This research also proposes intrusion response measures to deal with detected attacks, first after the anomaly detection, and then after the identification of the attack type. An experimental evaluation has been provided using various detection features, datasets, DNN algorithms, and the results demonstrate the effectiveness of the proposed solution.},
 author = {Illy, Poulmanogo and Kaddoum, Georges},
 doi = {10.1109/ACCESS.2023.3311822},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Time complexity;Training;Security;Industrial Internet of Things;Computer architecture;Safety;Low latency communication;Deep learning;Industrial control;Intrusion detection;Smart manufacturing;Network security;Deep learning;industrial control system (ICS);industrial Internet of Things (IIoT);intrusion detection system (IDS);intrusion response system (IRS);network security;smart factory},
 month = {},
 number = {},
 pages = {96317-96329},
 title = {A Collaborative DNN-Based Low-Latency IDPS for Mission-Critical Smart Factory Networks},
 volume = {11},
 year = {2023}
}

@article{10243611,
 abstract = {Recent advances in 5G and beyond have further expanded the potential of IoT applications, bringing unprecedented levels of connectivity, speed, and low latency. However, these advances come with significant security threats that can cause widespread damage. An effective approach to addressing these issues involves the integration of cutting-edge technologies like machine learning (ML), particularly deep reinforcement learning (DRL). DRL is a specialized area of ML that integrates the concepts of deep learning and reinforcement learning to create effective solutions for various tasks. In particular, DRL can facilitate the creation of intelligent security systems that can adapt to dynamic and intricate IoT applications connected to 5G and beyond networks. However, effectively implementing DRL-based intrusion detection frameworks in IoT applications connected to 5G networks poses significant challenges due to bandwidth utilization and device behavior. The data generated by IoT devices is often limited, and malicious behavior may be infrequent, making it difficult to accurately identify and train the algorithm to detect such behavior. Moreover, DRL algorithms pose a significant challenge for IoT devices constrained by limited bandwidth, as communicating large amounts of data required by DRL algorithms can cause network congestion and delay critical communications. In this article, we introduce a novel approach to improving the security of IoT applications in the 5G and beyond era by developing an intrusion detection system that employs DRL algorithms. Our approach involves a distributed Q-learning algorithm that observes the behavior of connected devices and predicts anomalous actions. Additionally, to overcome the challenges associated with bandwidth utilization and device behavior, we introduce a bandwidth allocation problem based on a reputation mechanism that allocates bandwidth to only trustworthy devices. Finally, we evaluate our proposed intrusion detection system on the selected indicators. The numerical results demonstrate that our proposed approach outperforms the referenced solutions on the selected indicators.},
 author = {Moudoud, Hajar and Cherkaoui, Soumaya},
 doi = {10.1109/OJCOMS.2023.3313352},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Internet of Things;Security;Intrusion detection;Behavioral sciences;5G mobile communication;Bandwidth;Reliability;5G and beyond;intrusion detection system (IDS);deep reinforcement learning (DRL);Internet of Things (IoT)},
 month = {},
 number = {},
 pages = {2410-2420},
 title = {Empowering Security and Trust in 5G and Beyond: A Deep Reinforcement Learning Approach},
 volume = {4},
 year = {2023}
}

@article{10246280,
 abstract = {Network attacks refer to malicious activities exploiting computer network vulnerabilities to compromise security, disrupt operations, or gain unauthorized access to sensitive information. Common network attacks include phishing, malware distribution, and brute-force attacks on network devices and user credentials. Such attacks can lead to financial losses due to downtime, recovery costs, and potential legal liabilities. To counter such threats, organizations use Intrusion Detection Systems (IDS) that leverage sophisticated algorithms and machine learning techniques to detect network attacks with enhanced accuracy and efficiency. Our proposed research aims to detect network attacks effectively and timely to prevent harmful losses. We used a benchmark dataset named CICIDS2017 to build advanced artificial intelligence-based machine learning methods. We propose a novel approach called Class Probability Random Forest (CPRF) for network attack detection performance enhancement. We created a novel feature set using the proposed CPRF approach. The CPRF approach predicts the class probabilities from the network attack dataset, which are then used as features for building applied machine learning methods. The comprehensive research results demonstrated that the random forest approach outperformed the state-of-the-art approach with a high-performance accuracy of 99.9%. The performance of each applied technique is validated using a k-fold approach and optimized with hyperparameter tuning. Our novel proposed research has revolutionized network attack detection, effectively preventing unauthorized access, service disruptions, sensitive information theft, and data integrity compromise.},
 author = {Raza, Ali and Munir, Kashif and Almutairi, Mubarak S. and Sehar, Rukhshanda},
 doi = {10.1109/ACCESS.2023.3313596},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Random forests;Analytical models;Training;Security;Data models;Cyberattack;Machine learning;Intrusion detection;Network attacks;intrusion detection;machine learning;feature engineering},
 month = {},
 number = {},
 pages = {98685-98694},
 title = {Novel Class Probability Features for Optimizing Network Attack Detection With Machine Learning},
 volume = {11},
 year = {2023}
}

@article{10246880,
 abstract = {Machine learning and deep learning methods have been widely used in network intrusion detection, most of which are supervised intrusion detection methods, which need to train a lot of marked data. However, in some cases, a small amount of exception data is hidden in a large amount of exception data, making methods that require a large amount of the same markup data to learn features invalid. In order to solve this problem, this paper proposes an innovative method of small sample network intrusion detection. The innovation point is that network data is modeled as graph structure to effectively mine the correlation features between data samples, and by comparing the distance similarity, the triplet network structure is used to detect anomalies. The triplet network is composed of triplet graph convolutional neural network which shares the same parameters and is trained by providing triplet samples to the network. Experiments on network traffic datasets CSE-CIC-IDS2018 and UNSW-NB15 as well as system status monitoring datasets verify the effectiveness of the proposed method in network intrusion detection of small samples.},
 author = {Wang, Yue and Jiang, Yiming and Lan, Julong},
 doi = {10.13052/jwe1540-9589.2059},
 issn = {1544-5976},
 journal = {Journal of Web Engineering},
 keywords = {Training;Technological innovation;Network intrusion detection;Telecommunication traffic;Interference;Network security;Feature extraction;Few-shot Learning;intrusion detection;graph convolutional network},
 month = {July},
 number = {5},
 pages = {1527-1552},
 title = {Intrusion Detection Using Few-shot Learning Based on Triplet Graph Convolutional Network},
 volume = {20},
 year = {2021}
}

@article{10246886,
 abstract = {With the development of sensor and communication technologies, the use of connected devices in industrial applications has been common for a long time. Reduction of costs during this period and the definition of Internet of Things (IoTs) concept have expanded the application area of small connected devices to the level of end-users. This paved the way for IoT technology to provide a wide variety of application alternative and become a part of daily life. Therefore, a poorly protected IoT network is not sustainable and has a negative effect on not only devices but also the users of the system. In this case, protection mechanisms which use conventional intrusion detection approaches become inadequate. As the intruders' level of expertise increases, identification and prevention of new kinds of attacks are becoming more challenging. Thus, intelligent algorithms, which are capable of learning from the natural flow of data, are necessary to overcome possible security breaches. Many studies suggesting models on individual attack types have been successful up to a point in recent literature. However, it is seen that most of the studies aiming to detect multiple attack types cannot successfully detect all of these attacks with a single model. In this study, it is aimed to suggest an all-in-one intrusion detection mechanism for detecting multiple intrusive behaviors and given network attacks. For this aim, a custom deep neural network is designed and implemented to classify a number of different types of network attacks in IoT systems with high accuracy and F1-score. As a test-bed for comparable results, one of the up-to-date dataset (CICIDS2017), which is highly imbalanced, is used and the reached results are compared with the recent literature. While the initial propose was successful for most of the classes in the dataset, it was noted that achievement was low in classes with a small number of samples. To overcome imbalanced data problem, we proposed a number of augmentation techniques and compared all the results. Experimental results showed that the proposed methods yield highest efficiency among observed literature.},
 author = {Sahingoz, Ozgur Koray and Cekmez, Ugur and Buldu, Ali},
 doi = {10.13052/jwe1540-9589.2062},
 issn = {1544-5976},
 journal = {Journal of Web Engineering},
 keywords = {Deep learning;Training;Intrusion detection;Social factors;Robustness;Safety;Internet of Things;Convolutional neural networks;deep learning;imbalanced datasets;Internet of Things;IoTs;web security},
 month = {Sep.},
 number = {6},
 pages = {1721-1760},
 title = {Internet of Things (IoTs) Security: Intrusion Detection using Deep Learning},
 volume = {20},
 year = {2021}
}

@article{10246907,
 abstract = {Massive reliance on practical systems has resulted in several security concerns. The ability to identify anomalies is a critical safety feature enabled by anomaly diagnostic techniques. The construction of a data system faces a significant issue in cyber security. Because of the exploitation of valuable data, cybersecurity impacts the privacy of such data. Attack incidents must be examined using an appropriate analytics approach in elevating the safety level. Design of advanced analytical, conceptual model creation gives practical guidance and prioritizes threats/attacks across the network system. There is now substantial effectiveness in attack categorization, and evaluation through Convolution Neural Network (CNN) based classifiers. In light of the drawbacks of previous approaches, this research proposes an approach relying on the Deep Learning (DL) strategies for cyberattacks detection and categorization in the context of cyberspace incidents. Likewise, this article presents an XGBoost Regression Classifier (XRC) using Inception V4 to address those restrictions. XGBoost refers to Extreme Gradient Boosting, a decentralized gradient-boosted decision tree (GBDT) supervised learning framework that is robust and can be used in a decentralized context. XGBoost is a well-known machine learning technique because of its ability to produce outstanding accuracy. The concepts of both XGBoost and Regression classifiers are integrated and represented as a suggested hybridized classifier, which is implemented in Inception V4 to further train and test the model. The proposed XRC categorizes and forecasts several common types of network cyberattacks that includes Distributed Denial of Service (DDoS), Phishing, Cross-site Scripting (CS), Internet of Things (IoT). The sigmoidal function is used as a supportive activator to the hybridized classifier to lower the erroneous ratio and increase the effectiveness. Research shows that training and testing errors were substantially decreased when using XRC. In 9 out of 13 instances, over 97% of threats are detected by the XRC, and over 75% of threats are detected in its most challenging datasets.},
 author = {Raghunath, K. M. Karthick and Kumar, V. Vinoth and Venkatesan, Muthukumaran and Singh, Krishna Kant and Mahesh, T. R. and Singh, Akansha},
 doi = {10.13052/jwe1540-9589.21413},
 issn = {1544-5976},
 journal = {Journal of Web Engineering},
 keywords = {Training;Deep learning;Error analysis;Phishing;Neural networks;Safety;Internet of Things;Cybersecurity;XGBoost regression classifier (XRC);inception V4;hybridized classifier;error rate},
 month = {June},
 number = {4},
 pages = {1295-1322},
 title = {XGBoost Regression Classifier (XRC) Model for Cyber Attack Detection and Classification Using Inception V4},
 volume = {21},
 year = {2022}
}

@article{10261178,
 abstract = {A more widespread Internet of Things (IoT) device is performing a surge in cyber-attacks, with Distributed Denial of Service (DDoS) attacks posing a major risk to the reliability and availability of IoT services. DDoS attacks overwhelm target methods by flooding them with a huge volume of malicious traffic from several sources. Mitigating and identifying these attacks in IoT platforms are vital to maintaining the seamless function of IoT services and the maintenance of secret information. Feature selection (FS) is a key stage in the machine learning (ML) pipeline as it supports decreasing the data size, enhancing model outcomes, and speeding up training and inference. As part of IoT with DDoS attack detection, FS proposes to recognize a subset of IoT-related features that is optimum to represent the traffic features and distinguish between malicious and benign activities. This study designs a new DDoS attack detection using a snake optimizer with ensemble learning (DDAD-SOEL) technique on the IoT platform. The purpose of the DDAD-SOEL approach lies in the effectual and automated identification of DDoS attacks. To attain this, the DDAD-SOEL technique utilizes the SO algorithm for feature subset selection. Besides, an ensemble of three DL approaches namely long short-term memory (LSTM), bidirectional long short-term memory (BiLSTM), and deep belief network (DBN) approach. Finally, the Adadelta optimizer can be applied for the parameter tuning of the DL algorithms. The simulation value of the DDAD-SOEL methodology was tested on the benchmark database and the outcome indicates the improvements of the DDAD-SOEL methodology over other recent models in terms of distinct measures.},
 author = {Aljebreen, Mohammed and Mengash, Hanan Abdullah and Arasi, Munya A. and Aljameel, Sumayh S. and Salama, Ahmed S. and Hamza, Manar Ahmed},
 doi = {10.1109/ACCESS.2023.3318316},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Internet of Things;Computer crime;Feature extraction;Ensemble learning;Tuning;Computer science;Deep learning;Internet of Things;security;deep learning;DDoS attacks;feature selection;ensemble learning;snake optimizer},
 month = {},
 number = {},
 pages = {104745-104753},
 title = {Enhancing DDoS Attack Detection Using Snake Optimizer With Ensemble Learning on Internet of Things Environment},
 volume = {11},
 year = {2023}
}

@article{10272611,
 abstract = {Botnet detection in a cloud-aided Internet of Things (IoT) environment is a tedious process, meanwhile, IoT gadgets are extremely vulnerable to attacks due to poor security practices and limited computing resources. In the cloud-aided IoT environment, Botnet can be identified by monitoring network traffic and analyzing it for signs of malicious activity. It can be performed by using intrusion detection systems, machine learning (ML) algorithms, and other security tools that are devised for identifying known botnet behaviors and signatures. Therefore, this study presents a Hybrid Metaheuristics with Machine Learning based Botnet Detection (HMMLB-BND) method in the Cloud Aided IoT environment. The projected HMMLB-BND technique focuses on the detection and classification of Botnet attacks in the cloud-based IoT environment. In the presented HMMLB-BND technique, modified firefly optimization (MFFO) algorithm for feature selection purposes. The HMMLB-BND algorithm uses a hybrid convolutional neural network (CNN)-quasi-recurrent neural network (QRNN) module for botnet detection. For the optimal hyperparameter tuning process, the chaotic butterfly optimization algorithm (CBOA) is employed. A series of simulations were made on the N-BaIoT dataset and the experimental outcomes stated the significance of the HMMLB-BND technique over other existing approaches.},
 author = {Almuqren, Latifah and Alqahtani, Hamed and Aljameel, Sumayh S. and Salama, Ahmed S. and Yaseen, Ishfaq and Alneil, Amani A.},
 doi = {10.1109/ACCESS.2023.3322369},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Hidden Markov models;Botnet;Internet of Things;Security;Feature extraction;Cloud computing;Classification algorithms;Metaheuristics;Deep learning;cloud computing;Internet of Things;cybersecurity;botnet detection},
 month = {},
 number = {},
 pages = {115668-115676},
 title = {Hybrid Metaheuristics With Machine Learning Based Botnet Detection in Cloud Assisted Internet of Things Environment},
 volume = {11},
 year = {2023}
}

@article{10274903,
 abstract = {Ensuring the security of critical Industrial Internet of Things (IIoT) systems is of utmost importance, with a primary focus on identifying cyber-attacks using Intrusion Detection Systems (IDS). Deep learning (DL) techniques are frequently utilized in the anomaly detection components of IDSs. However, these models often generate high false-positive rates, and their decision-making rationale remains opaque, even to experts. Gaining insights into the reasons behind an IDS’s decision to block a specific packet can aid cybersecurity professionals in assessing the system’s effectiveness and creating more cyber-resilient solutions. In this paper, we offer an explainable ensemble DL-based IDS to improve the transparency and robustness of DL-based IDSs in IIoT networks. The framework incorporates Shapley additive explanations (SHAP) and Local comprehensible-independent Clarifications (LIME) methods to elucidate the decisions made by DL-based IDSs, providing valuable insights to experts responsible for maintaining IIoT network security and developing more cyber-resilient systems. The ToN_IoT dataset was used to evaluate the efficacy of the suggested framework. As a baseline intrusion detection system, the extreme learning machines (ELM) model was implemented and compared with other models. Experiments show the effectiveness of ensemble learning to improve the results.},
 author = {Shtayat, Mousa'B Mohammad and Hasan, Mohammad Kamrul and Sulaiman, Rossilawati and Islam, Shayla and Khan, Atta Ur Rehman},
 doi = {10.1109/ACCESS.2023.3323573},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Intrusion detection;Security;Feature extraction;Artificial intelligence;Ensemble learning;Data models;Classification algorithms;Convolutional neural networks;Explanation AI (XAI);intrusion detection systems (IDS);SHapley additive explanations (SHAP);local comprehensible model-independent clarifications (LIME);ensemble learning;CNN},
 month = {},
 number = {},
 pages = {115047-115061},
 title = {An Explainable Ensemble Deep Learning Approach for Intrusion Detection in Industrial Internet of Things},
 volume = {11},
 year = {2023}
}

@article{10278416,
 abstract = {Driver behavior features extracted from the controller area network (CAN) have potential applications in improving vehicle safety. However, the development of a classifier-based intrusion detection system (IDS) for in-vehicle networks remains an open research problem. To address this challenge, we incorporate novel  $n$ -fold cross-validation windowing techniques on two publicly available driving behavior datasets. A driver classification-based IDS is proposed using the LSTM-FCN model that utilizes the strengths of both fully convolutional network (FCN) and long short-term memory (LSTM) networks. These modules allow the model to learn spatial and temporal features and utilize contextual information. In addition, we combine three squeeze and excite (SnE) layers following FCN layers to incorporate adjacent spatial locations and augment a scaled dot product attention mechanism into the LSTM to improve its feature selection and extraction capabilities. Our proposed IDS uses hacking and countermeasure research lab (HCRL) and test datasets, which achieve an improvement in accuracy of 4.18% and 13.99% respectively, from the baseline LSTM-FCN model. The experimental results of our method exhibited an overall accuracy of 99.36% and 96.36% for both datasets and outperformed various state-of-the-art methods.},
 author = {Khan, Junaid Ahmad and Lim, Dae-Woon and Kim, Young-Sik},
 doi = {10.1109/ACCESS.2023.3323891},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Hidden Markov models;Feature extraction;Behavioral sciences;Biological system modeling;Biometrics (access control);Automotive engineering;Anomaly detection;Intelligent vehicles;Attention;anomaly detection;automotive IDS;controller area networks;driver classification;FCN;in-vehicle networks;LSTM;squeeze and excitation},
 month = {},
 number = {},
 pages = {112814-112829},
 title = {A Deep Learning-Based IDS for Automotive Theft Detection for In-Vehicle CAN Bus},
 volume = {11},
 year = {2023}
}

@article{10283893,
 abstract = {In the dynamic landscape of cyber threats, multistage malware botnets have surfaced as significant threats of concern. These sophisticated threats can exploit Internet of Things (IoT) devices to undertake an array of cyberattacks, ranging from basic infections to complex operations, such as phishing, cryptojacking, and Distributed Denial-of-Service (DDoS) attacks. Existing machine learning solutions are often constrained by their limited generalizability across various data sets and their inability to adapt to the mutable patterns of malware attacks in real world environments, a challenge known as model drift. This limitation highlights the pressing need for adaptive intrusion detection systems (IDSs), capable of adjusting to evolving threat patterns and new or unseen attacks. This article introduces MalBoT-DRL, a robust malware botnet detector using deep reinforcement learning (RL). Designed to detect botnets throughout their entire lifecycle, MalBoT-DRL has better generalizability and offers a resilient solution to model drift. This model integrates damped incremental statistics with an attention reward mechanism, a combination that has not been extensively explored in the literature. This integration enables MalBoT-DRL to dynamically adapt to the ever-changing malware patterns within IoT environments. The performance of MalBoT-DRL has been validated via trace-driven experiments using two representative data sets: 1) MedBIoT and 2) N-BaIoT, resulting in exceptional average detection rates of 99.80% and 99.40% in the early and late detection phases, respectively. To the best of our knowledge, this work introduces one of the first studies to investigate the efficacy of RL in enhancing the generalizability of IDS.},
 author = {Al-Fawa’reh, Mohammad and Abu-Khalaf, Jumana and Szewczyk, Patryk and Kang, James Jin},
 doi = {10.1109/JIOT.2023.3324053},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Internet of Things;Botnet;Malware;Data models;Anomaly detection;Feature extraction;Computational modeling;Bashlite;botnet detection;incremental statistics;intrusion detection;Internet of Things (IoT) botnet;MalBoT-DRL;mirai;network traffic analysis;reinforcement learning (RL);torii},
 month = {March},
 number = {6},
 pages = {9610-9629},
 title = {MalBoT-DRL: Malware Botnet Detection Using Deep Reinforcement Learning in IoT Networks},
 volume = {11},
 year = {2024}
}

@article{10285843,
 abstract = {Software-defined networking (SDN) has been recognized for its potential in network programming and centralized control. However, this advancement brings forth critical security vulnerabilities. It is essential to understand that vulnerabilities, by their inherent nature, may lead to potential attacks if not addressed timely and appropriately. In this paper, we introduce a novel multi-modal deep transfer learning (MMDTL) framework tailored for effective attack detection in SDN environments that helps us to investigate a diverse spectrum of attack types. MMDTL framework comprehensively incorporates diverse data modalities - encompassing network traffic patterns, system logs, and user behavior analytic. A pivotal feature of this framework is its transfer learning approach, which enables the assimilation of insights from pre-trained models that subsequently increases the detection performance of attacks. We rigorously analyze the proposed framework with experiments on the intrusion detection evaluation dataset (CIC-IDS2017). Analyses results show the superiority of our framework with a detection accuracy 99.97%.Thus, MMDTL framework has a significant potential to support security in SDNs.},
 author = {Elubeyd, Hani and Yiltas-Kaplan, Derya and Bahtiyar, Şerif},
 doi = {10.1109/ACCESS.2023.3324878},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Transfer learning;Telecommunication traffic;Deep learning;Feature extraction;Data models;Intrusion detection;Training;Data analysis;Software defined networking;Attack detection;CICIDS2017;data analysis;transfer learning;network programming;software-defined network},
 month = {},
 number = {},
 pages = {114128-114145},
 title = {A Multi-Modal Deep Transfer Learning Framework for Attack Detection in Software-Defined Networks},
 volume = {11},
 year = {2023}
}

@article{10286032,
 abstract = {The increasing prevalence of the Industrial Internet of Things (IIoT) in industrial environments amplifies the potential for security breaches and compromises. To monitor IIoT networks, intrusion detection systems (IDS) have been introduced to detect malicious activities within the network flow, in which machine learning (ML) and deep learning (DL) play an important role. However, existing IDSs face challenges during training when dealing with imbalanced training data and a higher number of classes. These issues can significantly reduce the IDS’s performance and may result in missed network attacks, especially those with fewer training samples. To address these challenges, this paper introduces a multi-head attention-based gated recurrent unit (MAGRU) that scrutinizes IIoT network traffic to detect malicious activities. In the proposed model, the multi-head attention (MA) has the ability to enhance the learning capability of the model to handle limited sample classes. The gated recurrent unit (GRU) is employed for the detection of IIoT network behavior. The proposed MAGRU is evaluated using two publicly available datasets, namely Edge-IIoTset and MQTTset. To validate the performance of the proposed MAGRU, various ML and DL models were implemented and compared against MAGRU using the same dataset. The proposed model outperformed the other models, achieving an average precision, recall, F1-score, and accuracy of 99.62%, 99.67%, 99.64%, and 99.97%, respectively, for the aforementioned datasets. These results demonstrate optimal performance in the detection of intrusions in IIoT networks.},
 author = {Ullah, Safi and Boulila, Wadii and Koubâa, Anis and Ahmad, Jawad},
 doi = {10.1109/ACCESS.2023.3324657},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Logic gates;Intrusion detection;Artificial neural networks;Generative adversarial networks;Cyberattack;Convolutional neural networks;Deep learning;Deep learning;gated recurrent unit;industrial Internet of Things;intrusion detection;multi-head attention},
 month = {},
 number = {},
 pages = {114590-114601},
 title = {MAGRU-IDS: A Multi-Head Attention-Based Gated Recurrent Unit for Intrusion Detection in IIoT Networks},
 volume = {11},
 year = {2023}
}

@article{10287342,
 abstract = {The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI’s Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines.},
 author = {Kholgh, Danial Khosh and Kostakos, Panos},
 doi = {10.1109/ACCESS.2023.3325727},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Generators;Telecommunication traffic;Computer security;Transformers;Task analysis;Protocols;Machine learning;Artificial intelligence;Artificial intelligence;cybersecurity;generative pre-trained transformer;GPT-3;machine learning;NLP;transformer;LLMs},
 month = {},
 number = {},
 pages = {114936-114951},
 title = {PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3},
 volume = {11},
 year = {2023}
}

@article{10287343,
 abstract = {Trials and deployments of sixth Generation (6G) wireless networks, delivering extreme capacity, reliability, and efficiency, are expected as early as 2030. Attempts from both industry and academia are trying to define the next generation network infrastructure. 6G will set in motion the fourth industrial revolution, delivering global, integrated intelligence. In this scenario, Artificial Intelligence (AI)-assisted architecture for 6G networks will realize knowledge discovery, automatic network adjustment and intelligent service provisioning. The long-term vision for implementing 6G security is to implement an autonomous, self-learning AI-assisted architecture that can perform threat mitigation without disrupting the normal use, enabling the resilience and reliability of the network and fulfilling security automation. This work proposes a first implementation of a proactive threat discovery service to be deployed at 6G base stations, paving the way for collective network intelligence in the context of cybersecurity mechanisms. Specifically, a fully unsupervised Deep Learning (DL) model is presented, able to recognize both Denial of Service (DoS) Hulk and DoS Goldeneye, with 97.0% and 92.2% mean F1-score respectively.},
 author = {Paolini, Emilio and Valcarenghi, Luca and Maggiani, Luca and Andriolli, Nicola},
 doi = {10.1109/ACCESS.2023.3325721},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {6G mobile communication;Real-time systems;Base stations;Artificial intelligence;Computer architecture;Training;Security;Denial-of-service attack;Autonomous networks;DoS attack detection;machine learning;autoencoder;6G;real-time detection;autonomous networks;artificial intelligence},
 month = {},
 number = {},
 pages = {115827-115835},
 title = {Real-Time Clustering Based on Deep Embeddings for Threat Detection in 6G Networks},
 volume = {11},
 year = {2023}
}

@article{10287925,
 abstract = {This new era of the industry is characterized by the integration of artificial intelligence and the Internet of Things (IoT) to optimize production processes. To ensure sustainability and continuous industrial performance, Industry 5.0 integrates automated technology, robots, humans, and others. This modern paradigm relies on data and high-level security to achieve sustainability and error-free production operations. For improving the resilience of Industry 5.0 through adversary mitigation, this manuscript introduces a Zero-Trust Network-based Access Control Scheme (ZTN-ACS). This scheme extends its remote and limitless support for managing, monitoring, and controlling devices and operation schedules. For its limiting network over the available controllers, deep learning aids access control. The industrial controller output over the defined access is verified for efficiency and consistency compared to the expected and previous production outputs. In the verification scheme, access interrupts the controllers, and the schedules are initiated using the learning paradigm. This learning process considers the achievable production outcome and the low or high variations in the current access-based output. Therefore, the access control and security features are extended depending on the learning output over the adversaries. This scheme leverages consistency and reduces controller denials, failures, and false positives in Industry 5.0.},
 author = {Abuhasel, Khaled Ali},
 doi = {10.1109/ACCESS.2023.3325879},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industries;Security;Industrial Internet of Things;Authentication;Access control;Production;Sustainable development;Access control;deep learning;Industry 5.0;zero-trust},
 month = {},
 number = {},
 pages = {116398-116409},
 title = {A Zero-Trust Network-Based Access Control Scheme for Sustainable and Resilient Industry 5.0},
 volume = {11},
 year = {2023}
}

@article{10287938,
 abstract = {Cloud computing is a technology for efficiently using computing infrastructures and a business model for selling computing resources and services. However, intruders find such complex and distributed infrastructures appealing targets for cyber-attacks. Cyber-attacks are severe threats that can jeopardize the quality of service provided to clients and compromise data integrity, confidentiality, and availability. Cyber-attacks are becoming more complex, making it more challenging to detect intrusions effectively. Due to the high traffic and increased malicious activities on the Internet, a single Intrusion Detection System (IDS) can be overwhelmed. Despite the various Deep Learning (DL) approaches that have been proposed as alternative solutions, there are still pertinent security issues to be addressed especially in federated cloud computing domains. This work proposes a Secure Federated Intrusion Detection Model Version 1 (SecFedIDM-V1) using blockchain technology and Bidirectional Long Short-Term Memory (BiLSTM) Recurrent Neural Network (RNN). The Cobourg Intrusion Detection Dataset (CIDDS) was acquired, pre-processed and split into 60:20:20, 70:15:15, and 80:10:10 for training, testing, and validation respectively to develop the proposed intrusion traffic classification component of the proposed model. The developed SecFedIDM-V1 was later deployed as a Python-based web application that captures network packets for classifying attacks into normal or an attack type. The attack packets are recorded in a Hyperledger Fabric (a private blockchain technology) to serve as a signature database to be used by other nodes in the network. From the evaluation results of the intrusion classifier, the 80:10:10 BiLSTM network performed better than GRU with a Precision of 0.99624, Recall of 0.99906, F1 Score of 0.99614, False Positive Rate (FPR) of 0.00094, False Negative Rate (FNR) of 0.00395 and True Positive Rate (TPR) of 0.99605. The SecFedIDM-V1 can be deployed alongside Firewalls in a federated cloud computing environment to reinforce the security of the infrastructure.},
 author = {Mbaya, Emmanuel Baldwin and Adetiba, Emmanuel and Badejo, Joke A. and Wejin, John Simon and Oshin, Oluwadamilola and Isife, Olisaemeka and Thakur, Surendra Colin and Moyo, Sibusiso and Adebiyi, Ezekiel F.},
 doi = {10.1109/ACCESS.2023.3325992},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing;Intrusion detection;Blockchains;Computational modeling;Security;Monitoring;Servers;Deep learning;Recurrent neural networks;Blockchain;intrusion detection;deep learning;recurrent neural network},
 month = {},
 number = {},
 pages = {116011-116025},
 title = {SecFedIDM-V1: A Secure Federated Intrusion Detection Model With Blockchain and Deep Bidirectional Long Short-Term Memory Network},
 volume = {11},
 year = {2023}
}

@article{10295488,
 abstract = {As a result of the widespread adoption of the Internet of Things, there are now hundreds of millions of connected devices, increasing the likelihood that they may be vulnerable to various types of cyberattacks. In recent years, distributed denial of service (DDoS) has emerged as one of the most destructive tools utilized by attackers. Traditional machine learning approaches are typically ineffective and unable to cope with actual traffic properties when used to identify DDoS attacks. This paper introduces a novel deep learning-based intrusion detection system, specifically designed for deployment at either the Cloud or Fog level in the IoT environment. The proposed model aims to detect all types of DDoS attacks with their specific subcategory. Our hybrid model combines different types of deep learning models, including Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM), Deep Autoencoder, and Deep Neural Networks (DNNs). Our proposed model is made up of two main levels. The first one contains different parallel sub-neural networks trained with specific algorithms. The second level uses the output of the frozen first level combined with the initial data as input. The idea behind the combination of these various types of deep neural networks is to exploit their different properties to achieve very high performance. To evaluate our model, we used the CIC-DDoS2019 dataset, which satisfies all the constraints of an intrusion detection dataset. The results obtained demonstrate that our proposed model outperformed various well-known machine learning and deep learning models in terms of the true positive rate, accuracy, false alarm rate, average accuracy, and average detection rate.},
 author = {Ahmim, Ahmed and Maazouzi, Faiz and Ahmim, Marwa and Namane, Sarra and Dhaou, Imed Ben},
 doi = {10.1109/ACCESS.2023.3327620},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Deep learning;Computer crime;Machine learning algorithms;Intrusion detection;Computer hacking;Classification algorithms;Machine learning;Convolutional neural networks;Intrusion detection;DDoS detection;IDS;machine learning;deep learning;CNN;LSTM;autoencoder;hybrid model},
 month = {},
 number = {},
 pages = {119862-119875},
 title = {Distributed Denial of Service Attack Detection for the Internet of Things Using Hybrid Deep Learning Model},
 volume = {11},
 year = {2023}
}

@article{10296918,
 abstract = {The rapid integration of IoT, cloud, and edge computing has resulted in highly interconnected networks, emphasizing the need for advanced Intrusion Detection Systems (IDS) to maintain security. Successful AI-based IDS relies on high-quality data for model training. Even though a vast array of datasets from controlled settings are accessible, many fall short as they are outdated and lack the representative data of network traffic dynamics typically seen in public networks. This paper aims to advance understanding in designing testbed architectures for defense mechanisms within public networks. At its core, this research introduces a unique testbed utilizing the connectivity of panOULU Municipal public network in the city of Oulu, Finland. This experimental setup examines AI-driven security across the public network. It utilizes edge-to-cloud infrastructures, incorporating Software-Defined Networking (SDN) and Network Function Virtualization (NFV) via the VMware vSphere platform. During the training phase, a script distinguishes incoming packets as either benign or malicious based on well-defined local parameters and simulated attack scenarios. This labeled data is then utilized for training machine learning models within the Federated Learning framework, FED-ML. Subsequently, these models are evaluated on previously unseen data. The entire procedure, from traffic gathering to model training, operates without human involvement. The evaluation dataset and testbed configuration we have made publicly available through this research can deepen our understanding of the challenges in safeguarding public networks, especially those that blend various technologies in diverse environments.},
 author = {Mahmoodi, Alireza Bakhshi Zadi and Sheikhi, Saeid and Peltonen, Ella and Kostakos, Panos},
 doi = {10.1109/ACCESS.2023.3327922},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Intrusion detection;Training;Internet of Things;Telecommunication traffic;Protocols;Data models;Network security;cybersecurity;federated learning;data engineering;distributed computing;stream processing},
 month = {},
 number = {},
 pages = {121325-121339},
 title = {Autonomous Federated Learning for Distributed Intrusion Detection Systems in Public Networks},
 volume = {11},
 year = {2023}
}

@article{10298209,
 abstract = {The Controller Area Network (CAN) is a major protocol for in-vehicle network communications. This protocol is simple and efficient for message transmission and the smooth functioning of an in-vehicle system. On the other hand, the weaknesses of this protocol, such as the ID-based arbitration method for message transmission and lack of authentication mechanism, make it vulnerable to various security attacks, including DoS attacks, Fuzzy attacks, impersonation attacks, and replay attacks. Since there is no authentication mechanism for transmitted messages, we need a way to distinguish between normal and attack messages. An intrusion detection system (IDS) is an option for this problem because it can raise alarms when there are flaws in the system. IDS is very efficient for intrusion detection where messages with the same IDs are transmitted periodically. The deviation from the normal pattern of message transmission will force the IDS system to trigger alarms. Most studies on the CAN bus IDS system were based on a supervised learning approach. On the other hand, the lack of labeled datasets and a huge amount of training time make it inefficient for new attack patterns. This paper proposes a transfer learning-based IDS system for in-vehicle network intrusion detection. The extraction of quality features using transfer learning (TL) and appropriate fine-tuning methodology is used in the proposed model. This approach can use the available intrusion attack dataset to detect new attacks. The experimental results indicated that the proposed deep hybrid transfer learning (TL) model detects new threats with a high accuracy of approximately 99.9% when compared to state-of-the-art methods, while also lowering training and testing time by more than 30%.},
 author = {Khatri, Narayan and Lee, Sihyung and Nam, Seung Yeob},
 doi = {10.1109/ACCESS.2023.3328182},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Protocols;Intrusion detection;Security;Machine learning algorithms;Training;Feature extraction;Vehicle-to-everything;Vehicular ad hoc networks;Transfer learning;Supervised learning;VANETs;intrusion detection system (IDS);transfer learning;supervised learning;security},
 month = {},
 number = {},
 pages = {120963-120982},
 title = {Transfer Learning-Based Intrusion Detection System for a Controller Area Network},
 volume = {11},
 year = {2023}
}

@article{10299667,
 abstract = {The increasing sophistication of malware threats has led to growing concerns in the anti-malware community, as malware poses a significant danger to online users despite the availability of numerous defense solutions. This study aims to comprehensively review malware evolution and current attack trends to identify effective defense mechanisms. It reviews the most recent journal articles, conference proceedings, reports, and online resources published during the last five years. We extensively review the malware landscape from 1970 to the present and analyze malware types, operational mechanisms, attack vectors, and vulnerabilities. Furthermore, we explore different defensive strategies developed in response to these evolving threats. Our findings highlight the increasing sophistication of malware attack trends, including a surge in cryptojacking, attacks on mobile devices, Internet of Things devices, ransomware, advanced persistent threats, supply chain attacks, fileless malware, cloud-based attacks, exploitation of remote employees, and attack trends on edge networks. Defense strategies have also evolved in parallel, emphasizing multilayered security measures to counter these dynamic threats. This study highlights the critical need for robust, multilayered security measures to combat dynamic malware. Despite these advancements, some open challenges and significant research gaps remain, which require further innovation. This review serves as a valuable guide for cybersecurity professionals by identifying the key trends, challenges, limitations, and future cybersecurity research opportunities.},
 author = {Ferdous, Jannatul and Islam, Rafiqul and Mahboubi, Arash and Islam, Md. Zahidul},
 doi = {10.1109/ACCESS.2023.3328351},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Market research;Ransomware;Trojan horses;Security;Rootkit;Internet of Things;Machine learning;Malware evolution;malware attack trends;defense mechanisms;malware detection;machine learning;deep learning},
 month = {},
 number = {},
 pages = {121118-121141},
 title = {A Review of State-of-the-Art Malware Attack Trends and Defense Mechanisms},
 volume = {11},
 year = {2023}
}

@article{10313082,
 abstract = {Recent developments in cutting-edge robotics constantly face increased cyber threats, not only in terms of quantity and frequency of attacks, but also when it comes to quality and severity of the intrusions. This paper provides a systematic overview and critical assessment of state-of-the-art scientific developments in the security aspects of robotics, autonomous systems, and critical infrastructures. Our review highlights open research questions addressing significant research gaps and/or new conceptual frameworks given recent advancements in artificial intelligence (AI) and machine learning. Thus, the contributions of this paper can be summarized as follows. We first compare and contrast the benefits of multiple cutting-edge AI-based learning algorithms (e.g., fuzzy logic and neural networks) relative to traditional model-based systems (e.g., distributed control and filtering). Subsequently, we point out some specific benefits of AI algorithms to quickly learn and adapt the dynamics of non-linear systems in the absence of complex mathematical models. We also present some potential future research directions (open challenges) in the field. Lastly, this review also delivers an open message to encourage collaborations among experts from multiple disciplines. The implementation of multiple AI algorithms to tackle current security issues in robotics will transform and create novel hybrid knowledge for intelligent cybersecurity at the application level.},
 author = {Santoso, Fendy and Finn, Anthony},
 doi = {10.1109/TSC.2023.3331083},
 issn = {1939-1374},
 journal = {IEEE Transactions on Services Computing},
 keywords = {Robots;Computer security;Robot sensing systems;Security;Autonomous systems;Operating systems;Middleware;Cybersecurity;artificial intelligence;machine learning;robotics;autonomous systems;and critical infrastructures},
 month = {May},
 number = {3},
 pages = {1293-1310},
 title = {An In-Depth Examination of Artificial Intelligence-Enhanced Cybersecurity in Robotics, Autonomous Systems, and Critical Infrastructures},
 volume = {17},
 year = {2024}
}

@article{10315004,
 abstract = {Threat detection in a Cyber-Physical System (CPS) platform is a key feature of ensuring the reliability and security of these connected methods, but digital elements interface with the physical world. CPS platforms are popular in sectors like healthcare, industrial automation, smart cities, and transportation making them vulnerable to different cyber-attacks. Threat detection in CPS contains the detection and mitigation of cybersecurity risks, which disrupt physical processes, compromise data integrity, and potentially cause safety concerns. Machine learning (ML) and deep learning (DL) systems are exploited for detecting anomalies by learning the normal behaviour forms of the CPS and recognizing deviations. This study presents an Automated Threat Detection using the Flamingo Search Algorithm with Optimal Deep Learning (ATD-FSAODL) technique in a CPS environment. Initially, the ATD-FSAODL technique applies FSA-based feature subset selection to elect the better group of features. In addition, the ATD-FSAODL technique makes use of a modified Elman Spike Neural Network (MESNN) model for threat recognition and classification. Finally, the slime mold algorithm (SMA) is used for the optimal selection of the parameters related to the MESNN approach to ensure that the threat detection rate is improved. To estimate the solution of the ATD-FSAODL technique, a sequence of simulations can be carried out on benchmark databases. The performance values portray the capable solution of the ATD-FSAODL methodology with other methods with a maximum accuracy of 99.58%, precision of 99.58%, recall of 99.58%, F-score of 99.58%, and MCC of 99.16%.},
 author = {Alajmi, Masoud and Mengash, Hanan Abdullah and Alqahtani, Hamed and Aljameel, Sumayh S. and Hamza, Manar Ahmed and Salama, Ahmed S.},
 doi = {10.1109/ACCESS.2023.3332213},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Threat assessment;Deep learning;Computer security;Classification algorithms;Behavioral sciences;Social factors;Cyber-physical systems;Fourth Industrial Revolution;Cyber-physical system;industry 40;threat analysis;feature selection;deep learning},
 month = {},
 number = {},
 pages = {127669-127678},
 title = {Automated Threat Detection Using Flamingo Search Algorithm With Optimal Deep Learning on Cyber-Physical System Environment},
 volume = {11},
 year = {2023}
}

@article{10316288,
 abstract = {The increasing dependence on data analytics and artificial intelligence (AI) methodologies across various domains has prompted the emergence of apprehensions over data security and integrity. There exists a consensus among scholars and experts that the identification and mitigation of Multi-step attacks pose significant challenges due to the intricate nature of the diverse approaches utilized. This study aims to address the issue of imbalanced datasets within the domain of Multi-step attack detection. To achieve this objective, the research explores three distinct re-sampling strategies, namely over-sampling, under-sampling, and hybrid re-sampling techniques. The study offers a comprehensive assessment of several re-sampling techniques utilized in the detection of Multi-step attacks on deep learning (DL) models. The efficacy of the solution is evaluated using a Multi-step cyber attack dataset that emulates attacks across six attack classes. Furthermore, the performance of several re-sampling approaches with numerous traditional machine learning (ML) and deep learning (DL) models are compared, based on performance metrics such as accuracy, precision, recall, F-1 score, and G-mean. In contrast to preliminary studies, the research focuses on Multi-step attack detection. The results indicate that the combination of Convolutional Neural Networks (CNN) with Deep Belief Networks (DBN), Long Short-Term Memory (LSTM), and Recurrent Neural Networks (RNN) provides optimal results as compared to standalone ML/DL models. Moreover, the results also depict that SMOTEENN, a hybrid re-sampling technique, demonstrates superior effectiveness in enhancing detection performance across various models and evaluation metrics. The findings indicate the significance of appropriate re-sampling techniques to improve the efficacy of Multi-step attack detection on DL models.},
 author = {Jamal, Muhammad Hassan and Naz, Naila and Khattak, Muazzam A. Khan and Saeed, Faisal and Altamimi, Saad Nasser and Qasem, Sultan Noman},
 doi = {10.1109/ACCESS.2023.3332512},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Data analysis;Cyberattack;Organizations;Deep learning;Training;Prediction algorithms;Machine learning;Artificial intelligence;Deep learning (DL);machine learning (ML);multi-step attacks;synthetic minority over-sampling technique (SMOTE);borderline SMOTE;SMOTEENN;SMOTETomek},
 month = {},
 number = {},
 pages = {127446-127457},
 title = {A Comparison of Re-Sampling Techniques for Detection of Multi-Step Attacks on Deep Learning Models},
 volume = {11},
 year = {2023}
}

@article{10318039,
 abstract = {Using deep learning models, we predict information system security indicators and obtain corresponding security evaluation scores. The scores of these predicted security evaluation are used as the input data of regression tree model, and the security grade protection evaluation system is constructed. The model training process involves four different models: VGG19, ResNet-50, XceptionNet, and EfficientNet. Based on the training results, we find that the EfficientNet model consumes fewer computational resources in single detection while achieves a detection accuracy of 99.93%. Subsequently, we apply the CART regression tree to assess the network security posture of 14 commercial systems. The test results of the model show that the mean absolute percentage error(MAPE) is 0.029 and the correlation coefficient is 0.9. These empirical results strongly support the performance of the proposed model and show its significant potential in improving security assessments. With these training results, we gain preliminary insights into the performance of each model and select the EfficientNet model with the best performance for the generation of subsequent security posture evaluation data.Ultimately, the developed security grade protection assessment system provides a reliable and efficient evaluation means for the network security.},
 author = {Lin, Shaodan and Feng, Chen and Jiang, Tao and Jing, Huasong},
 doi = {10.1109/ACCESS.2023.3333013},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Network security;Deep learning;Intrusion detection;Data models;Computational modeling;Real-time systems;Data collection;CART regression tree;data collection and analysis;EfficientNet;security indicators;security data correlation},
 month = {},
 number = {},
 pages = {130990-131000},
 title = {Evaluation of Network Security Grade Protection Combined With Deep Learning for Intrusion Detection},
 volume = {11},
 year = {2023}
}

@article{10320369,
 abstract = {Adaptive time series Intrusion Detection System (IDS) Classifier is essential to detect real-time cyber-threats. Meanwhile, optimized hyperparameters on time series IDS classifier model will ensure swift detection. However, current studies on Time Series IDS classifier involve additional RNN-LSTM layers and multiple gates to optimize the training and feedback process. Notwithstanding, RNN-LSTM has powerful features to memorize data sequences. The nature of multiple complex hidden states in RNN-type model requires intensive training or epoch to achieve optimized loss function. This paper aims to go beyond conventional deep learning model by removing complex gated states and conventional hidden layers. The goal is to create an optimized adaptive time series classifier. The model leverages various fitting algorithms which include Sinusoidal, Linear, Power Function, Taylor Series and a new “Staircase” function that is introduced in this study. These functions adapt gradually to the real-time target distribution pattern. This will eliminate the need for feedback process to optimize hyperparameters. The model’s performance is evaluated against the realistic benchmarked IDS dataset; a dataset that simulates recent malware attacks and has imbalanced distribution property. This property reflects a realistic low cyber-attack footprint. After 10 epoch over randomized stratified testing samples, the Mean Absolute Error (MAE) rate achieved almost 0.0% after a fitting process reached 100% as compared with the conventional LSTM model that achieved 17%.},
 author = {Muda, Saiyed Rasol Bin Tuan and Yusof, Mohammad Hafiz Mohd and Alfawaz, Khaled Mofawiz and Balfaqih, Mohammed and Alzahrani, Abdulrahman},
 doi = {10.1109/ACCESS.2023.3334160},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Computer security;Cyberattack;Real-time systems;Classification algorithms;Intrusion detection system (IDS);adaptive IDS;machine learning in cybersecurity},
 month = {},
 number = {},
 pages = {129882-129904},
 title = {New Optimized Adaptive Time Series IDS Classifier Algorithm: Beyond Deep Learning},
 volume = {11},
 year = {2023}
}

@article{10322868,
 abstract = {In the internet of things (IoT) networks, machine learning (ML) is significantly used for malware and adversary detection. Recently, research has shown that adversarial attacks have put ML-based models at risk. This problem is exacerbated in an IoT environment because of the absence of adequate security measures. Consequently, it is crucial to evaluate the strength of such malware detectors using powerful adversarial samples. The existing adversarial sample generation strategies either rely on high-level image features or an unfiltered feature set, making it challenging to determine which feature modifications are crucial in evading malware detection systems, without compromising the malware functionality. This encourages us to propose an evasion framework named IF-MalEvade, based on Generative Adversarial Network (GAN) and Deep Reinforcement Learning (DRL) that effectively generates fully-working, malware samples with several effective perturbations such as header Section manipulation and benign bytes insertion. The DRL framework selects a few suitable action sequences to change malicious samples, thus allowing our malware samples to bypass various black-box ML based malware detectors and the detection search engines of VirusTotal, while maintaining the executability and malicious behavior of the original malware samples. The neural networks of GAN take in the unfiltered feature set of malware dataset and using minimax objective function yields a set of useful features that are subsequently used by the DRL agent to make effective changes. Experimental results illustrated that by utilizing the influential features in sequence of transformations, the adversarial samples generated by our model outperformed the state-of-the-art evasion models with an impressive evasion rate. Additionally, the detection rate of well-known machine learning models was also brought down to up to 97%. Furthermore, when the machine learning models were retrained using adversarial samples, a 35% increase in detection accuracy was observed.},
 author = {Arif, Rahat Maqsood and Aslam, Muhammad and Al-Otaibi, Shaha and Martinez-Enriquez, Ana Maria and Saba, Tanzila and Bahaj, Saeed Ali and Rehman, Amjad},
 doi = {10.1109/ACCESS.2023.3334645},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Generative adversarial networks;Detectors;Feature extraction;Closed box;Internet of Things;Reinforcement learning;Generative adversarial network;portable executable PE malware;adversarial attack;malware evasion;deep reinforcement learning;technological development},
 month = {},
 number = {},
 pages = {133717-133729},
 title = {A Deep Reinforcement Learning Framework to Evade Black-Box Machine Learning Based IoT Malware Detectors Using GAN-Generated Influential Features},
 volume = {11},
 year = {2023}
}

@article{10323403,
 abstract = {The Internet of Things (IoT) based Wireless Sensor Networks (WSNs) contain interconnected autonomous sensor nodes (SN), which wirelessly communicate with each other and the wider internet structure. Intrusion detection to secure IoT-based WSNs is critical for identifying and responding to great security attacks and threats that can cooperate with the integrity, availability, and privacy of the network and its data. Machine learning (ML) algorithms are deployed for detecting difficult patterns and subtle anomalies in IoT data. Artificial intelligence (AI) driven methods are learned and adapted from novel data for improving detection accuracy over time. In this article, we introduce a Red Kite Optimization Algorithm with an Average Ensemble Model for Intrusion Detection (RKOA-AEID) technique for Secure IoT-based WSN. The purpose of the RKOA-AEID methodology is to accomplish security solutions for IoT-assisted WSNs. To accomplish this, the RKOA-AEID technique performs pre-processing to scale the input data using min-max normalization. In addition, the RKOA-AEID technique performs an RKOA-based feature selection approach to elect an optimum set of features. For intrusion detection, an average ensemble learning model is used. Finally, the Lévy-fight chaotic whale optimization Algorithm (LCWOA) can be executed for the optimum hyperparameter chosen for the ensemble models. The performance evaluation of the RKOA-AEID algorithm can be tested on the benchmark WSN-DS dataset. The extensive experimental outcomes stated the higher outcome of the RKOA-AEID algorithm with other approaches with an improved accuracy of 98.94%.},
 author = {Alruwaili, Fahad F. and Asiri, Mashael M. and Alrayes, Fatma S. and Aljameel, Sumayh S. and Salama, Ahmed S. and Hilal, Anwer Mustafa},
 doi = {10.1109/ACCESS.2023.3335124},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Intrusion detection;Security;Internet of Things;Feature extraction;Birds;Performance evaluation;Internet of Things;Deep learning;The Internet of Things;security;red kite optimization algorithm;deep learning;feature selection},
 month = {},
 number = {},
 pages = {131749-131758},
 title = {Red Kite Optimization Algorithm With Average Ensemble Model for Intrusion Detection for Secure IoT},
 volume = {11},
 year = {2023}
}

@article{10325459,
 abstract = {The imbalanced distribution of intrusion detection dataset will usually result in low detection rates for the minority categories and more unreported attacks. To reduce the impact of imbalanced dataset on classification performance, a fusional intrusion detection method based on the hierarchical filtering and progressive detection model (HFPD-IDS) is proposed. This method first uses the idea of binary classification to preliminarily filter and identify the normal and abnormal data, and then uses a convolutional neural network model for progressive dimensionality reduction detection for the initially filtered abnormal data. The learning process during the progressive detection, which is entirely based on abnormal data, avoids the interference of normal data and integrates detection method different from the initial filtering process to improve the detection rate for minority categories. Finally, the normal dataset identified in the initial filtering process will be corrected to further identify the abnormal data that has been misjudged as normal data. The experimental results show that this method can significantly improve the detection rate of minority categories data without affecting the detection performance of majority categories data.},
 author = {Gao, Xueqin and Wu, Qian and Cai, Junhui and Li, Qifeng},
 doi = {10.1109/ACCESS.2023.3335669},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Mathematical models;Filtering;Intrusion detection;Training;Convolutional neural networks;Decision trees;Classification algorithms;Learning systems;Intrusion detection;binary classification learning;convolutional neural networks;feature selection;detection rate},
 month = {},
 number = {},
 pages = {131409-131417},
 title = {A Fusional Intrusion Detection Method Based on the Hierarchical Filtering and Progressive Detection Model},
 volume = {11},
 year = {2023}
}

@article{10328057,
 abstract = {Smart grids (SGs), a cornerstone of modern power systems, facilitate efficient management and distribution of electricity. Despite their advantages, increased connectivity and reliance on communication networks expand their susceptibility to cyber threats. Machine learning (ML) can radically transform cyber security in SGs and secure protocols as in IEC 60870 standard, an international standard for electric power system communication. Notwithstanding, cyber adversaries are now exploiting ML-based intrusion detection systems (IDS) using adversarial ML attacks, potentially undermining SG security. This article addresses cyber attacks on the communication network of SGs, specifically targeting the IEC 60870-5-104 protocol. We introduce a novel ML-based IDS framework for the IEC 60870-5-104 protocol. Specifically, we employ an artificial neural network (ANN) to analyze a new and realistically representative dataset of IEC 60870-5-104 traffic data, unlike previous research that relies on simulated or unrelated data. This approach assists in identifying anomalies indicative of cyber attacks more accurately. Furthermore, we evaluate the resilience of our ANN model against adversarial attacks, including the fast gradient sign method, projected gradient descent, and Carlini and Wagner attacks. Our results demonstrate that the proposed framework can accurately detect cyber attacks and remains robust to adversarial attacks. This offers efficient and resilient IDS capabilities to detect and mitigate cyber attacks in real-world ML-based adversarial environments.},
 author = {Teryak, Hadir and Albaseer, Abdullatif and Abdallah, Mohamed and Al-Kuwari, Saif and Qaraqe, Marwa},
 doi = {10.1109/OJIES.2023.3336234},
 issn = {2644-1284},
 journal = {IEEE Open Journal of the Industrial Electronics Society},
 keywords = {IEC Standards;Security;Protocols;Cyberattack;Support vector machines;Data models;Resilience;Adversarial machine learning;Deep learning;Intrusion detection;Machine learning;Smart grids;Adversarial attacks;deep learning;IEC 60870-5-104 protocol;intrusion detection systems (IDS);machine learning (ML);smart grids (SGs)},
 month = {},
 number = {},
 pages = {629-642},
 title = {Double-Edged Defense: Thwarting Cyber Attacks and Adversarial Machine Learning in IEC 60870-5-104 Smart Grids},
 volume = {4},
 year = {2023}
}

@article{10328732,
 abstract = {With the proliferation of network systems, the boundaries between cyber and physical environments are blurring, leading to an increased risk of sophisticated cyber-attacks equipped with advanced technologies. In particular, as advancements in artificial intelligence through learning models have led to automated attacks and attack scenarios, countries are implementing cyber training and constructing training systems to respond to cyber security threats. This cyber training is based on existing cyber-attacks and conducted in virtual spaces similar to reality, generating network traffic through simulators and focusing on training for attack response and cyber resilience. However, the exponential increase in the number of network-based devices and the amount of network traffic they generate is leading to a gradual increase in threats to cyber security. In this study, first investigated the existing port number-based network traffic classification technologies and payload-based network traffic classification technologies to identify their shortcomings in the current network environment. We then categorized existing studies into supervised, unsupervised, and reinforcement learning to analyze the technology of classifying network traffic based on learning models as well as classification methods, procedures, performance standards, evaluation methods, quality of service/quality of experience, etc. Based on the analysis, presented limitations for application to training networks according to the learning method and suggested recommendations for establishing future research directions. Therefore, refining learning model-based network traffic classification technology will contribute to the construction of automated cyber training grounds such as cyber-attack–defense scenarios, network traffic anomaly detection, and maximizing cumulative rewards.},
 author = {Jang, Younghoan and Kim, Dong-Wook and Shin, Gun-Yoon and Cho, Seungjae and Kim, Kwangsoo and Kang, Jaesik and Han, Myung-Mook},
 doi = {10.1109/ACCESS.2023.3336674},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Telecommunication traffic;Training;Behavioral sciences;Cyberattack;Convolutional neural networks;Analytical models;IP networks;Classification algorithms;Reinforcement learning;Supervised learning;Unsupervised learning;Classification;cyber resilience;cyber-attack;network traffic;reinforcement learning supervised learning;unsupervised learning},
 month = {},
 number = {},
 pages = {138712-138731},
 title = {An Investigation of Learning Model Technologies for Network Traffic Classification Design in Cyber Security Exercises},
 volume = {11},
 year = {2023}
}

@article{10330739,
 abstract = {5G emerges as the bedrock for the Industrial Internet of Things (IIoT), it facilitates the seamless, low-latency fusion of artificial intelligence and cloud computing, thereby fortifying the entire industrial procedure within a framework of smart and intelligent IIoT ecosystems. Concurrently, the continuously changing landscape of cybersecurity threats in the realm of the Internet of Things (IoT) is giving rise to unparalleled security complexities. These challenges are particularly pronounced in the context of zero-day attacks, and integration of 5G technology further exacerbates the intricacy of the situation. Thus this paper introduces a cutting-edge 5G-enabled framework for cyberthreat detection leveraging Federated Learning (FL) without the need for data sharing. It employs a dual Autoencoder (AE) based model. Distinctly, our model utilizes two synchronized AEs for each client, integral to FL mechanism. While one AE evaluates the IIoT environment based on normal network patterns, another focuses on attack scenarios. For decisive threat assessment, the system uses the capabilities of a one-class SVM classifier with AEs. Furthermore, our method ensures a synergistic blend of self-learning and collaborative learning by implementing a polling mechanism between overarching AE classifier and those tailored to individual client data and counters zero-day threats and out performs traditional AI/ML techniques.},
 author = {Verma, Priyanka and Bharot, Nitesh and Breslin, John G. and O'Shea, Donna and Vidyarthi, Ankit and Gupta, Deepak},
 doi = {10.1109/TCE.2023.3335385},
 issn = {1558-4127},
 journal = {IEEE Transactions on Consumer Electronics},
 keywords = {Industrial Internet of Things;Data models;5G mobile communication;Training;Support vector machines;Servers;Federated learning;5G;IIoT;cyberthreat;federated learning;autoencoders;zero-day attack},
 month = {Feb},
 number = {1},
 pages = {3856-3866},
 title = {Zero-Day Guardian: A Dual Model Enabled Federated Learning Framework for Handling Zero-Day Attacks in 5G Enabled IIoT},
 volume = {70},
 year = {2024}
}

@article{10332180,
 abstract = {Structured Query Language (SQL) injection attacks represent a critical threat to database-driven applications and systems, exploiting vulnerabilities in input fields to inject malicious SQL code into database queries. This unauthorized access enables attackers to manipulate, retrieve, or even delete sensitive data. The unauthorized access through SQL injection attacks underscores the critical importance of robust Artificial Intelligence (AI) based security measures to safeguard against SQL injection attacks. This study’s primary objective is the automated and timely detection of SQL injection attacks through AI without human intervention. Utilizing a preprocessed database of 46,392 SQL queries, we introduce a novel optimized approach, the Autoencoder network (AE-Net), for automatic feature engineering. The proposed AE-Net extracts new high-level deep features from SQL textual data, subsequently input into machine learning models for performance evaluations. Extensive experimental evaluation reveals that the extreme gradient boosting classifier outperforms existing studies with an impressive k-fold accuracy score of 0.99 for SQL injection detection. Each applied learning approach’s performance is further enhanced through hyperparameter tuning and validated via k-fold cross-validation. Additionally, statistical t-test analysis is applied to assess performance variations. Our innovative research has the potential to revolutionize the timely detection of SQL injection attacks, benefiting security specialists and organizations.},
 author = {Thalji, Nisrean and Raza, Ali and Islam, Mohammad Shariful and Samee, Nagwan Abdel and Jamjoom, Mona M.},
 doi = {10.1109/ACCESS.2023.3337645},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;SQL injection;Databases;Machine learning;Structured Query Language;Deep learning;Training;Encoding;Autoencoder optimization;deep learning;feature engineering;machine learning;SQL injection},
 month = {},
 number = {},
 pages = {135507-135516},
 title = {AE-Net: Novel Autoencoder-Based Deep Features for SQL Injection Attack Detection},
 volume = {11},
 year = {2023}
}

@article{10334031,
 abstract = {Industrial Cyber-Physical Systems (ICPSs) generate cyber and physical data whose joint elaboration can provide insight into ICPSs' operating conditions. Cyber-Physical Anomaly Detection (CPAD) addresses the joint analysis of cyber and physical threats through multi-source and multi-modal data analysis. CPAD is often tailored to specific anomaly types and may use opaque deep learning models, impairing flexibility and explainability. In light of these challenges, we propose a two-level fusion framework for modeling and deploying CPAD in distributed ICPSs. The first detector-level fusion involves deploying CPAD detectors to several distributed ICPS segments and training them through data/decision fusion techniques with historical cyber-physical data. When the distributed ICPS is operational, thus collecting new cyber-physical data, ICPS segments' trained CPAD detectors provide pieces of evidence that go through the second ensemble-level fusion, for which we propose an explainable decision fusion technique based on Time-Varying Dynamic Bayesian networks. The evaluation involves the comprehensive application of the framework to a real hardware-in-the-loop case-study in a laboratory environment. The proposed ensemble-level fusion outperforms the state-of-the-art decision fusion techniques while providing explainable results.},
 author = {Guarino, Simone and Vitale, Francesco and Flammini, Francesco and Faramondi, Luca and Mazzocca, Nicola and Setola, Roberto},
 doi = {10.1109/TICPS.2023.3336608},
 issn = {2832-7004},
 journal = {IEEE Transactions on Industrial Cyber-Physical Systems},
 keywords = {Detectors;Cyber-physical systems;Distributed databases;Feature extraction;Bayes methods;Probabilistic logic;Monitoring;Bayesian networks;cyber-physical anomaly detection;cybersecurity;dependability;industrial cyber-physical systems;industry 4.0;machine learning;operational technologies;resilience;threat recognition},
 month = {},
 number = {},
 pages = {1-13},
 title = {A Two-Level Fusion Framework for Cyber-Physical Anomaly Detection},
 volume = {2},
 year = {2024}
}

@article{10339724,
 abstract = {In recent years, Deep Learning (DL) technique has been widely used in Internet of Things (IoT) and Industrial Internet of Things (IIoT) for edge computing, and achieved good performances. But more and more studies have shown the vulnerability of neural networks. So, it is important to test the robustness and vulnerability of neural networks. More specifically, inspired by layer-wise relevance propagation and neural network verification, we propose a novel measurement of sensitive neurons and important neurons, and propose a novel neuron coverage criterion for robustness testing. Based on the novel criterion, we design a novel testing sample generation method, named DeepSI, which involves definitions of sensitive neurons and important neurons. Furthermore, we construct sensitive-decision paths of the neural network through selecting sensitive neurons and important neurons. Finally, we verify our idea by setting up several experiments, then results show our proposed method achieves superior performances.},
 author = {Lian, Zhichao and Tian, Fengjun},
 doi = {10.26599/TST.2023.9010057},
 issn = {1007-0214},
 journal = {Tsinghua Science and Technology},
 keywords = {Deep learning;Sensitivity analysis;Computational modeling;Neurons;Robustness;Biological neural networks;Testing;neuron sensitivity;Layer-wise Relevance Propagation (LRP);neural network verification;deep learning testing},
 month = {June},
 number = {3},
 pages = {784-794},
 title = {DeepSI: A Sensitive-Driven Testing Samples Generation Method of Whitebox CNN Model for Edge Computing},
 volume = {29},
 year = {2024}
}

@article{10347226,
 abstract = {A Software-Defined Network (SDN) was designed to simplify network management by allowing the control and management of the entire network from a single place. SDN is commonly used in today’s data center network infrastructure, but new forms of threats such as Distributed Denial-of-Service (DDoS), web attacks, and the U2R (User to Root) attack are significant issues that might restrict the widespread adoption of SDNs. Intruders are attractive to SDN controllers because they are valuable targets. An SDN controller can be hijacked by an attacker and used to route traffic in accordance with its own needs, resulting in catastrophic consequences for the whole network. While the unified vision of SDN and deep learning methods opens new possibilities for the security of IDS deployment, the effectiveness of the detection models is dependent on the quality of the training datasets. Even though deep learning for NIDSs has lately shown promising results for a number of issues, the majority of the studies overlooked the impact of data redundancy and an unbalanced dataset. As a consequence, this may adversely affect the resilience of the anomaly detection system, resulting in a suboptimal model performance. In this study, we created a hybrid Convolutional Neural Network (CNN) and bidirectional long short-term memory (BiLSTM) network to enhance network intrusion detection using binary and multiclass classification. The effectiveness of the proposed model was tested and assessed using the most frequently used datasets (UNSW-NB15 and NSL-KDD). In addition, we used the InSDN dataset, which is specifically dedicated to SDN. The outcomes demonstrate the efficiency of the proposed model in achieving high accuracy and requiring less training time.},
 author = {Ben Said, Rachid and Sabir, Zakaria and Askerzade, Iman},
 doi = {10.1109/ACCESS.2023.3340142},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Deep learning;Training;Convolutional neural networks;Security;Computational modeling;Network intrusion detection;Network intrusion;Detection algorithms;Software defined networking;Network intrusion detection system (NIDS);software-defined networking (SDN);CNN-BiLSTM;deep learning},
 month = {},
 number = {},
 pages = {138732-138747},
 title = {CNN-BiLSTM: A Hybrid Deep Learning Approach for Network Intrusion Detection System in Software-Defined Networking With Hybrid Feature Selection},
 volume = {11},
 year = {2023}
}

@article{10353929,
 abstract = {The class imbalance problem negatively impacts learning algorithms’ performance in minority classes which may constitute more severe attacks than the majority ones. This study investigates the benefits of balancing strategies and imbalanced learning approaches on intrusion data from Software Defined Networking (SDN). Although the research community has covered the imbalance problem in machine learning-based intrusion detection, addressing this problem in SDN is novel and powerful. Addressing the class imbalance problem over InSDN (the only publicly available SDN intrusion detection dataset as of recent) is of significant impact on future research in the area of intrusion detection in SDN. We address the class imbalance problem through data-level and classifier-level techniques. Our research objective is to determine suitable methods of addressing the class imbalance problem in machine learning-based intrusion detection in SDN. We propose custom deep learning architectures based on GANs and Siamese Neural Networks for generative modeling and similarity-based intrusion detection. This paper provides benchmarking results from classification with Random Oversampling (ROS), SMOTE, GANs, weighted Random Forest, and Siamese-based one-shot learning. We have found that Random Forest (RF) outperforms deep learning models in the classification of minority class instances. This supports the notion that RF can handle class imbalance well. We also observe that widely-used balancing techniques, ROS and SMOTE, drastically decrease the False Positive Rate (FPR) but increase the False Negative Rate (FNR) in the classification of minority classes. Conclusively, while data-level methods improve classification performance over deep learning models, they, in fact, degrade RF’s performance, i.e. cause higher numbers of false predictions. Therefore, RF does not need additional balancing strategies to get higher performance. Although this work addresses the class imbalance problem in SDN intrusion data, it provides a well-designed benchmark that can be exemplary for any network intrusion detection data. Thus, it may have a significant impact on future studies in this respective domain.},
 author = {Mirsadeghi, Seyed Mohammad Hadi and Bahsi, Hayretdin and Vaarandi, Risto and Inoubli, Wissem},
 doi = {10.1109/ACCESS.2023.3341755},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Classification algorithms;Random forests;Probes;Botnet;Benchmark testing;Training;Machine learning;Deep learning;Software defined networking;Cyberattack;Class imbalance problem;machine learning;deep learning;cyber intrusion detection;software-defined networking},
 month = {},
 number = {},
 pages = {140428-140442},
 title = {Learning From Few Cyber-Attacks: Addressing the Class Imbalance Problem in Machine Learning-Based Intrusion Detection in Software-Defined Networking},
 volume = {11},
 year = {2023}
}

@article{10354322,
 abstract = {Advancements in wireless network technology have provided a powerful tool to boost productivity and serve as a vital communication method that overcomes the limitations of wired networks. However, because of using wireless networks, security is an increasing concern in the community. At the time of our study, people rely on machine learning techniques to create a trustworthy networking system. However, it hinders the development of a reliable network as the number of publicly available malicious data is insufficient to train a model correctly. In real life, people are not very keen to share this data as they are sensitive. In order to deal with this issue, we primarily aim to develop a solution that provides a reliable intrusion detection system despite being trained with a small amount of data. This paper proposes a novel idea of hybrid meta deep learning in detecting malicious packet data. We use a combination of Siamese and Prototypical networks where the Siamese network is used for binary classification and the Prototypical network for multi-class classification. Both approaches are based on meta learning techniques, requiring a minimal amount of data for most attack classes. Utilizing these meta learning characteristics, we could train our model with just 3000 data samples and achieve more than 90% accuracy for both meta learning tactics. Our study aims to provide a secure and trustworthy network domain that enhances communication between end users.},
 author = {Tapu, Sakib Uddin and Shopnil, Samira Afrin Alam and Tamanna, Rabeya Bosri and Dewan, M. Ali Akber and Alam, Md. Golam Rabiul},
 doi = {10.1109/ACCESS.2023.3341911},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Metalearning;Data models;Deep learning;Prototypes;Telecommunication traffic;Cyberattack;Convolutional neural networks;CSE-CIC-IDS2017;CSE-CIC-IDS2018;few-shot learning;hybrid meta learning;intrusion detection;malicious data classification;meta learning;multi-class classification;prototypical network;Siamese network},
 month = {},
 number = {},
 pages = {140609-140625},
 title = {Malicious Data Classification in Packet Data Network Through Hybrid Meta Deep Learning},
 volume = {11},
 year = {2023}
}

@article{10363688,
 abstract = {The use of Open Radio Access Networks (Open RAN) in vehicular networks can lead to better connectivity, reliability, and performance. However, communication in this setting is often done over an unsecured wireless network, which creates a challenge in verifying the validity of received transactions by Internet of Vehicles (IoV) due to the untrusted network. It also creates a potential for attackers to tamper with the data content and conduct different IoV-related attacks. To address these issues, a new framework named “STIoV” has been proposed for secure and trustworthy communication in IoV. The framework includes a mutual authentication scheme to register and exchange session keys among the IoV participants, and a credit-based trust management system to assign reputation scores for the vehicular devices. The latter scheme discards transactions with low credit scores. To overcome the complexity and variability of the IoV network, digital twin technology is used to map Road Side Units (RSU) servers into virtual space, which facilitates constructing the vehicular relation model. An Intrusion Detection System (IDS) based on deep learning techniques is also introduced to detect anomalies in the traffic flow. The legitimate data is further used by the blockchain scheme for transaction verification, block creation and addition. Finally, the proposed framework has been evaluated based on two network intrusion datasets, and the results show the accuracy and efficacy of STIoV in comparison to several recent state-of-the-art solutions.},
 author = {Kumar, Randhir and Kumar, Prabhat and Aljuhani, Ahamed and Jolfaei, Alireza and Islam, A.K.M Najmul and Mohammad, Nazeeruddin},
 doi = {10.1109/TVT.2023.3342127},
 issn = {1939-9359},
 journal = {IEEE Transactions on Vehicular Technology},
 keywords = {Security;Servers;Radio access networks;Cloud computing;Blockchains;Trust management;Digital twins;Digital Twin;Deep Learning;Blockchain;Internet of Vehicles (IoV);Intrusion Detection System (IDS);Trustworthiness},
 month = {July},
 number = {7},
 pages = {9234-9246},
 title = {Secure Data Dissemination Scheme for Digital Twin Empowered Vehicular Networks in Open RAN},
 volume = {73},
 year = {2024}
}

@article{10366798,
 abstract = {Network-based security has emerged as an increasingly critical challenge in the domain of the Internet of Things (IoT). A number of network intrusion detection systems (NIDS), typically relying on sophisticated machine learning (ML) algorithms, have been proposed to monitor network traffic and detect malicious activity. However, these NIDS designs require extensive memory and computational power, exceeding the capability of today’s IoT devices, and often fail to provide timely detection of network attacks. To tackle this issue, we propose  $\mathsf {HyperDetect}$ , the first attempt at NIDS modeling that leverages the highly efficient and parallel operations of brain-inspired hyperdimensional computing (HDC). Our innovative model updating method effectively mitigates model saturation and significantly reduces the number of retraining iterations needed to reach convergence. Additionally, we employ a novel dynamic encoding technique to regenerate insignificant dimensions, considerably lowering the dimensionalities required to achieve high-quality performance and further accelerating the learning process.  $\mathsf {HyperDetect}$  delivers on average  $5.02\times $  faster training and  $31.83\times $  faster inference compared to state-of-the-art (SOTA) learning approaches on a wide range of network intrusion classification tasks. We also extensively evaluate  $\mathsf {HyperDetect}$  on embedded hardware to demonstrate its low-latency and resource-efficient characteristics.},
 author = {Wang, Junyao and Xu, Haocheng and Achamyeleh, Yonatan Gizachew and Huang, Sitao and Faruque, Mohammad Abdullah Al},
 doi = {10.1109/JIOT.2023.3345279},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Internet of Things;Training;Computational modeling;Brain modeling;Task analysis;Encoding;Real-time systems;Bio-inspired learning;hyperdimensional computing (HDC);Internet of Things (IoT);network intrusion detection},
 month = {April},
 number = {8},
 pages = {14844-14856},
 title = {HyperDetect: A Real-Time Hyperdimensional Solution for Intrusion Detection in IoT Networks},
 volume = {11},
 year = {2024}
}

@article{10371310,
 abstract = {The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported.},
 author = {Khatun, Mirza Akhi and Memon, Sanober Farheen and Eising, Ciarán and Dhirani, Lubna Luxmi},
 doi = {10.1109/ACCESS.2023.3346320},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Internet of Things;Security;Sensors;Machine learning;Temperature sensors;Monitoring;Healthcare-IoT;generative AI;5G-IoT;security and privacy challenges;cybersecurity;attacks;anomaly detection;machine learning;deep learning;mitigation techniques;5G NR},
 month = {},
 number = {},
 pages = {145869-145896},
 title = {Machine Learning for Healthcare-IoT Security: A Review and Risk Mitigation},
 volume = {11},
 year = {2023}
}

@article{10372964,
 abstract = {Internet of Things (IoT) devices generate enormous quantities of data, and ensuring the authenticity and integrity of this data is essential. Blockchain (BC) serves as a transparent and secure ledger for recording each data transaction, which prevents unauthorized modification and provides a trust layer for the IoT ecosystem. Data edge verification for BC-enabled IoT platforms is a fundamental aspect of ensuring data trustworthiness, integrity, and security in the system. In such an environment, IoT devices generate vast amounts of data, and BC technology can be used to create a decentralized and immutable ledger that records all the transactions and data exchanges Machine learning (ML) in the context of BC and the IoT offers a powerful toolkit for optimizing and securing these technologies. It enables the analysis of vast and complex data generated by IoT devices, allowing for predictive maintenance, anomaly detection, and pattern recognition. ML also enhances security by developing intrusion detection systems and supporting smart contracts in BC networks. This article introduces a new Capuchin Search Algorithm with a Deep Learning based Data Edge Verification model (CSADL-DEVM) for the Blockchain assisted IoT platform. The purpose of the CSADL-DEVM technique is to integrate the BC with DL and hyperparameter tuning concepts for data edge verification in the IoT environment. In addition, IoT devices comprise a considerable level of decentralized decision-making ability, which accomplishes a consensus on the performance of intra-block transactions. In addition, the CSADL-DEVM technique applies the Elman recurrent neural network (ERNN) model for the identification and classification of faults. Moreover, the hyperparameters related to the ERNN model can be adjusted by the use of CSA which in turn better the detection results. A comprehensive set of simulations has been conducted to exhibit the enhanced results of the CSADL-DEVM method. The obtained outcomes exhibit the superior outcome of the CSADL-DEVM algorithm.},
 author = {Alyoubi, Khaled H. and Khadidos, Adil O. and Alshareef, Abdulrhman M. and Hamed, Diaa and Khadidos, Alaa O. and Ragab, Mahmoud},
 doi = {10.1109/ACCESS.2023.3346437},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Logic gates;Servers;Performance evaluation;Blockchains;Tuning;Deep learning;Parameter estimation;Blockchain;Internet of Things;edge verification;deep learning;parameter selection},
 month = {},
 number = {},
 pages = {351-360},
 title = {Capuchin Search Algorithm With Deep Learning-Based Data Edge Verification for Blockchain-Assisted IoT Environment},
 volume = {12},
 year = {2024}
}

@article{10373830,
 abstract = {Many studies have focused on obtaining high accuracy in the design of Intrusion Detection Systems (IDS) for in-vehicle networks, neglecting the significance of different intensive packet injection techniques. Because of their reliance on scenario-specific training datasets, these IDSs are vulnerable to failing to detect real-world attacks. This study implemented deep learning (DL)–based classification for intrusion detection using a Gated Recurrent Unit (GRU) while considering various intrusion frequencies. Different intrusion frequencies are comprehensively addressed with frequency-agnostic intrusion and resolved by generalizing features for DL input through time series segmentation and frequency domain conversion using Gabor filtering. For training purposes, five types of vehicle data are used, encompassing DoS, fuzzing, and replay attack scenarios. The accuracy range for mechanical version vehicles is typically between 95% and 100%. For electronic vehicles, it is around 90%. Considering the nature of this IDS system, it has been named a Comprehensive Frequency-Agnostic Intrusion Detection System (CF-AIDS). Although this IDS can perform better in all aspects, achieving more efficient results requires a larger amount of situational data.},
 author = {Islam, Md. Rezanur and Sahlabadi, Mahdi and Kim, Keunkyoung and Kim, Yoonji and Yim, Kangbin},
 doi = {10.1109/ACCESS.2023.3346943},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Data models;Transforms;Training;Security;Intrusion detection;Time-frequency analysis;Gabor filters;Vehicles;In-vehicle network;CAN;IDS;Gabor transform;frequency-agnostic},
 month = {},
 number = {},
 pages = {13971-13985},
 title = {CF-AIDS: Comprehensive Frequency-Agnostic Intrusion Detection System on In-Vehicle Network},
 volume = {12},
 year = {2024}
}

@article{10375493,
 abstract = {Most of the traffic on the Internet is encrypted traffic, and the detection of encrypted traffic is the current difficulty, because the internal features of the data are destroyed after encryption, and it is difficult to detect. Most of the existing detection of encrypted traffic is based on the external features of encrypted traffic, which requires the extraction of full-cycle information of traffic, and has poor real-time performance. Therefore, based on the internal features of encrypted traffic, this paper proposes a Key Feature Fusion Detection (KFFD) method based on generative adversarial network, which restores the destroyed internal features by encryption key and generative adversarial network, and then improves the internal feature recognition effect of encrypted traffic. Experiments using the Kaggle dataset show that the KFFD method can improve the detection performance of encrypted traffic to a certain extent.},
 author = {Chen, Fangjie and Bai, Jingpeng and Gao, Weihan},
 doi = {10.1109/ACCESS.2023.3347806},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Cryptography;Data mining;Fingerprint recognition;Generative adversarial networks;Deep learning;Data models;Network security;intrusion detection systems;encrypted traffic detection;GAN;key features;artificial intelligence;machine learning;deep learning},
 month = {},
 number = {},
 pages = {1786-1793},
 title = {Research on Encrypted Traffic Detection Based on Key Features},
 volume = {12},
 year = {2024}
}

@article{10375497,
 abstract = {The software-defined wireless sensor network (SDWSN) has the potential to improve flexibility, scalability, and network performance, but security and quality of service (QoS) are major challenges due to attackers, poor network management, and inefficient route selection. Several existing works for intrusion detection had drawbacks like poor security, inefficient network management, higher energy consumption and latency, and lesser throughput. A modified honeycomb structure-based intrusion detection system for SDWSN is proposed to address these challenges, which includes secure authentication using the 3D cube algorithm, modified honeycomb-based network partitioning, clustering, reinforcement learning-based intelligent routing with a transfer learning-based deep Q network (TLDQN), and a hybrid intrusion detection system. The latter detects malicious nodes using a driver training-based optimization (DTO) algorithm and intrusions with a bidirectional generative adversarial network (Bi-GAN). The results show that the proposed system outperforms existing solutions in terms of security, network performance, and efficiency. The simulation of this research is conducted by NS-3.26 Network Simulator, and the performances are evaluated based on various performance metrics (with respect to the total number of nodes) like energy consumption, latency, throughput, packet delivery ratio, network lifetime, computation overhead, detection accuracy, packet drop ratio, and control overhead, which proved that the proposed work achieves superior performance compared to existing works. The evaluation also includes a total simulation period during which the system’s real-time performance was conducted. Time-based metrics such as precision, recall, and F1-score, as well as confusion matrices, are utilized to analyze the system’s effectiveness in real-time in response to dynamic network threats.},
 author = {Kipongo, Joseph and Swart, Theo G. and Esenogho, Ebenezer},
 doi = {10.1109/ACCESS.2023.3347778},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Routing;Wireless sensor networks;Intrusion detection;Energy consumption;Optimization;Blockchains;SDWSN;3D cube;intrusion detection;secure routing;modified honeycomb-based network construction;authentication},
 month = {},
 number = {},
 pages = {3140-3175},
 title = {Artificial Intelligence-Based Intrusion Detection and Prevention in Edge-Assisted SDWSN With Modified Honeycomb Structure},
 volume = {12},
 year = {2024}
}

@article{10379080,
 abstract = {In this current era, cyber-physical systems (CPSs) have gained concentrated consideration in various fields because of their emergent applications. Though the robust dependence on communication networks creates cyber-physical systems susceptible to deliberated cyber related attacks and detecting these cyber-attacks are the most challenging task. There is the interaction among the components of the cyber and physical worlds, so CPS security needs a distinct approach from past security concerns. Deep learning (DL) distributes better performance than machine learning (ML) due to its layered architecture and the efficient algorithm for extracting prominent information from training data. So, the deep learning models are taken into consideration quickly for detecting cyber-attacks in cyber physical systems. As numerous attack detection methods have been proposed by various authors for enforcing CPS security, this paper reviews and analyzes multiple ways of attack detection presented for CPS using deep learning. We will be putting the excellent potential for detecting cyber-attacks for CPS concerning deep learning modules. The admirable performance is attained partly as highly quality datasets are eagerly obtainable for the use of the public. Moreover, various challenges and research inclinations are also discussed in impending research.},
 author = {Gaba, Shivani and Budhiraja, Ishan and Kumar, Vimal and Martha, Sheshikala and Khurmi, Jebreel and Singh, Akansha and Singh, Krishna Kant and Askar, S. S. and Abouhawwash, Mohamed},
 doi = {10.1109/ACCESS.2023.3349022},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Cyber-physical systems;Cyberattack;Quantum computing;Systematics;Machine learning;Task analysis;Computer security;Detection algorithms;Cybersecurity;cyberattacks;cyber physical systems (CPSs);deep learning (DL);attack detection},
 month = {},
 number = {},
 pages = {6017-6035},
 title = {A Systematic Analysis of Enhancing Cyber Security Using Deep Learning for Cyber Physical Systems},
 volume = {12},
 year = {2024}
}

@article{10379088,
 abstract = {Today, humans pose the greatest threat to society by getting involved in robbery, assault, or homicide activities. Such circumstances threaten the people working alone at night in remote areas especially women. Any such kind of threat in real time is always associated with a sound/noise which may be used for an early detection. Numerous existing measures are available but none of them sounds efficient due to lack of accuracy, delays in exact prediction of threat. Hence a novel software-based prototype is developed to detect threats from a person’s surrounding sound/noise and automatically alert the registered contacts of victims by sending email, SMS, WhatsApp messages through their smartphones without any other hardware components. Audio signals from Kaggle dataset are visualized, analyzed using Exploratory Data Analytics (EDA) techniques. By feeding EDA outcomes into various Deep Learning models: Long short-term memory (LSTM), Convolutional Neural Networks (CNN) yields accuracy of 96.6% in classifying the audio-events.},
 author = {Sen, Amrit and Rajakumaran, Gayathri and Mahdal, Miroslav and Usharani, Shola and Rajasekharan, Vezhavendhan and Vincent, Rajiv and Sugavanan, Karthikeyan},
 doi = {10.1109/ACCESS.2023.3349097},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Natural language processing;Emergency services;Computer science;Cameras;Social networking (online);Smart phones;Audio recording;Classification algorithms;Predictive models;Natural language processing (NLP);deep learning;audio;recording;CNN;LSTM;classification;prediction},
 month = {},
 number = {},
 pages = {6455-6472},
 title = {Live Event Detection for People’s Safety Using NLP and Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10379100,
 abstract = {As reliance on disruptive applications based on Artificial Intelligence (AI) and Blockchain grows, the need for secure and trustworthy solutions becomes ever more critical. Whereas much research has been conducted on AI and Blockchain, there is a shortage of comprehensive studies examining their integration from a security perspective. Hence, this survey addresses such a gap and provides insights for policymakers, researchers, and practitioners exploiting AI and Blockchain’s evolving integration. Specifically, this paper analyzes the potential benefits of the integration of AI and Blockchain as well as the related security concerns, identifying possible mitigation strategies, suggesting regulatory measures, and describing the impact it has on public trust.},
 author = {Kuznetsov, Oleksandr and Sernani, Paolo and Romeo, Luca and Frontoni, Emanuele and Mancini, Adriano},
 doi = {10.1109/ACCESS.2023.3349019},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Artificial intelligence;Security;Task analysis;Deep learning;Decision making;Data models;Distributed ledger;AI;artificial intelligence;blockchain;distributed ledger technology;security},
 month = {},
 number = {},
 pages = {3881-3897},
 title = {On the Integration of Artificial Intelligence and Blockchain Technology: A Perspective About Security},
 volume = {12},
 year = {2024}
}

@article{10379640,
 abstract = {The Internet of Things (IoT) is transforming how we live and work, and its applications are widespread, spanning smart homes, industrial monitoring, smart cities, healthcare, agriculture, and retail. Considering its wide range of applications, addressing the security challenges arising from IoT devices’ massive collection and transmission of user data is vital. Intrusion detection systems (IDS) based on deep learning techniques offer new means and research directions for resolving IoT security issues. Deep learning models can process large volumes of data and extract complex patterns, making them generally more effective than traditional rule based IDSs. While deep learning techniques are gradually gaining popularity in IDS applications, current research needs a comprehensive summary of deep learning-based IDS in IoT. This paper introduces intrusion detection technologies, followed by a detailed comparison, analysis, and discussion of deep learning models, datasets, feature extraction and classifiers, data preprocessing techniques, and experimental design of the models. It also highlights the challenges and issues associated with deep learning models and relevant techniques for IDS. Finally, it concludes by providing recommendations to assist researchers in this domain.},
 author = {Liao, Han and Murah, Mohd Zamri and Hasan, Mohammad Kamrul and Aman, Azana Hafizah Mohd and Fang, Jin and Hu, Xuting and Khan, Atta Ur Rehman},
 doi = {10.1109/ACCESS.2023.3349287},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Internet of Things;Feature extraction;Deep learning;Data models;Data mining;Behavioral sciences;IoT;IDS;deep learning;datasets;data preprocessing;feature extraction;classifiers},
 month = {},
 number = {},
 pages = {4745-4761},
 title = {A Survey of Deep Learning Technologies for Intrusion Detection in Internet of Things},
 volume = {12},
 year = {2024}
}

@article{10379797,
 abstract = {Unmanned aerial vehicles (UAVs) are increasingly being deployed in crucial missions for the armed forces, law enforcement, industrial control monitoring, and other sectors. However, these hostile operating circumstances, along with the UAVs’ dependence on wireless protocols, pose substantial security threats, limiting their mainstream application. With network security being such a major issue for UAV networks, the machine learning-based intrusion detection system (IDS) has been determined to be an effective strategy for protecting them. Additionally, though the existing methods offer effective strategies for detecting and categorizing abnormalities in the system, they are limited by their inability to adjust to various attack patterns. The dataset used as well as the memory and computational requirement of existing models, poses new challenges. One of the main concerns pertains to the reduced computational and memory demands of these models. So, the work carried out in this paper addresses this challenge. A new dimensional reduction technique based on correlation coefficient, information gain, and principal component analysis (PCA) is introduced to reduce the dimensionality of the UAV Attack Dataset. A novel intrusion detection system based on an artificial neural network (ANN) and genetic algorithm (GA) is then proposed. The genetic algorithm is used to generate the optimal weights of the artificial neural network. A comparison is made between the proposed model and the backpropagation network and its variant in terms of its convergence and prediction accuracy. Furthermore, the performance of the proposed model is compared with that of other classifiers. This comparison reveals that the proposed model is time efficient with an increased prediction accuracy of at least 6% more than other classifiers.},
 author = {Cengiz, Korhan and Lipsa, Swati and Dash, Ranjan Kumar and Ivković, Nikola and Konecki, Mario},
 doi = {10.1109/ACCESS.2024.3349469},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Autonomous aerial vehicles;Intrusion detection;Drones;Genetic algorithms;Machine learning;Principal component analysis;Feature extraction;Artificial neural networks;Backpropagation;Artificial neural network;backpropagation;genetic algorithm;information gain;intrusion detection system;Pearson correlation coefficient;principal component analysis;sparsity;unmanned aerial vehicles},
 month = {},
 number = {},
 pages = {4925-4937},
 title = {A Novel Intrusion Detection System Based on Artificial Neural Network and Genetic Algorithm With a New Dimensionality Reduction Technique for UAV Communication},
 volume = {12},
 year = {2024}
}

@article{10381696,
 abstract = {With the increasing reliance on technology in traffic management systems, ensuring road safety and protecting the integrity of these systems against cyber threats have become critical concerns. This research paper investigates the potential of reinforcement learning techniques in enhancing both road safety and cyber security of traffic management systems. The paper explores the theoretical foundations of reinforcement learning, discusses its applications in traffic management, and presents case studies and empirical evidence demonstrating its effectiveness in improving road safety and mitigating cyber security risks. The findings indicate that reinforcement learning can contribute to the development of intelligent and secure traffic management systems, thus minimizing accidents and protecting against cyber-attacks.},
 author = {Agarwal, Ishita and Singh, Aanchal and Agarwal, Aran and Mishra, Shruti and Satapathy, Sandeep Kumar and Cho, Sung-Bae and Prusty, Manas Ranjan and Mohanty, Sachi Nandan},
 doi = {10.1109/ACCESS.2024.3350271},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Reinforcement learning;Road safety;Monitoring;Accidents;Road traffic;Internet of Things;Computer security;Traffic control;Cyber security;traffic management systems;reinforcement learning;road safety},
 month = {},
 number = {},
 pages = {9963-9975},
 title = {Enhancing Road Safety and Cybersecurity in Traffic Management Systems: Leveraging the Potential of Reinforcement Learning},
 volume = {12},
 year = {2024}
}

@article{10381699,
 abstract = {Intrusion detection systems (IDS) are crucial to network security by identifying and stopping harmful actions. The network intrusion data are blended into many typical instances due to the dynamic and time-varying networking surroundings. This leads to a lack of instances for training models and detection outcomes with a high false detection rate. In response to the data imbalance issue, we provide a network intrusion detection (NIDS) technique that combines deep networks and hybrid sampling. With the help of the Difficult Set Sampling Technique (DSSTE) algorithm, we first reduce the noise samples in the majority category before applying Deep Convolutional Generative Adversarial Networks (DCGANs) to boost the minority sample size. Additionally, we create a deep network model using DenseNet169 to extract spatial characteristics and Self Attention-based Transformer (SAT-Net) to extract temporal features. This technique accurately extracts the distinctive characteristics of the data. Finally, we employed the Enhanced Elman Spike Neural Network (EESNN) to classify the attack categories. We undertake experiments on the more recent and comprehensive intrusion datasets BOT-IOT, ToN-IoT, and CICIDS2019 to validate the suggested technique. Results indicate that our suggested system outperforms comparable works regarding accuracy, false alarm rate, recall, and precision.},
 author = {Saikam, Jalaiah and Ch, Koteswararao},
 doi = {10.1109/ACCESS.2024.3350197},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Deep learning;Training;Telecommunication traffic;Network intrusion detection;Random forests;Data mining;Intrusion detection system (IDS);difficult set sampling technique (DSSTE) algorithm;deep convolutional generative adversarial networks (DCGANs);DenseNet 169;self attention based transformer (SAT-Net)},
 month = {},
 number = {},
 pages = {15930-15945},
 title = {EESNN: Hybrid Deep Learning Empowered Spatial–Temporal Features for Network Intrusion Detection System},
 volume = {12},
 year = {2024}
}

@article{10382525,
 abstract = {Supervisory Control and Data Acquisition (SCADA) systems are crucial for modern industrial processes and securing them against increasing cyber threats is a significant challenge. This study presents an advanced method for bolstering SCADA security by employing a modified hybrid deep learning model. A key innovation in this work is integrating the Self-similarity Hurst parameter into the dataset alongside a CNN-LSTM model, significantly boosting the Intrusion Detection System’s (IDS) capabilities. The Hurst parameter, which quantifies the self-similarity in a dataset, is instrumental in detecting anomalies. Our in-depth analysis of the CICIDS2017 dataset sheds light on contemporary attack patterns and network traffic behaviors. The CNN-LSTM architecture was substantially altered by adding multiple convolutional layers with progressively increasing filters, batch normalization for stable training, and dropout layers for regularization. Principal Component Analysis (PCA) was applied for dimensionality reduction, thereby optimizing the dataset. Test results demonstrate the superior performance of the model incorporating the Hurst parameter, achieving 95.21% accuracy and 82.59% recall, significantly surpassing the standard model. The inclusion of the Hurst parameter marks a substantial advancement in identifying emerging threats, while architectural improvements to the CNN-LSTM model led to more robust and accurate intrusion detection in industrial control settings.},
 author = {Balla, Asaad and Habaebi, Mohamed Hadi and Elsheikh, Elfatih A. A. and Islam, Md. Rafiqul and Suliman, Fakher Eldin Mohamed and Mubarak, Sinil},
 doi = {10.1109/ACCESS.2024.3350978},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {SCADA systems;Security;Intrusion detection;Deep learning;Convolutional neural networks;Anomaly detection;Data models;Deep learning;intrusion detection system;supervisory control and data acquisition;self-similarity;Hurst parameter;binary classification},
 month = {},
 number = {},
 pages = {6100-6116},
 title = {Enhanced CNN-LSTM Deep Learning for SCADA IDS Featuring Hurst Parameter Self-Similarity},
 volume = {12},
 year = {2024}
}

@article{10382695,
 abstract = {Current technological advancements in Software Defined Networks (SDN) can provide efficient solutions for smart grids (SGs). An SDN-based SG promises to enhance the efficiency, reliability and sustainability of the communication network. However, new security breaches can be introduced with this adaptation. A layer of defence against insider attacks can be established using machine learning based intrusion detection system (IDS) located on the SDN application layer. Conventional centralised practises, violate the user data privacy aspect, thus distributed or collaborative approaches can be adapted so that attacks can be detected and actions can be taken. This paper proposes a new SDN-based SG architecture, highlighting the existence of IDSs in the SDN application layer. We implemented a new smart meter (SM) collaborative intrusion detection system (SM-IDS), by adapting the split learning methodology. Finally, a comparison of a federated learning and split learning neighbourhood area network (NAN) IDS was made. Numerical results showed, a five class classification accuracy of over 80.3% and F1-score 78.9 for a SM-IDS adapting the split learning technique. Also, the split learning NAN-IDS exhibit an accuracy of over 81.1% and F1-score 79.9.},
 author = {Chatzimiltis, Sotiris and Shojafar, Mohammad and Mashhadi, Mahdi Boloursaz and Tafazolli, Rahim},
 doi = {10.1109/OJCOMS.2024.3351088},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Smart grids;Collaboration;Intrusion detection;Training;Security;Computer architecture;Federated learning;Software defined networks;smart grid;intrusion detection;split learning;federated learning},
 month = {},
 number = {},
 pages = {700-711},
 title = {A Collaborative Software Defined Network-Based Smart Grid Intrusion Detection System},
 volume = {5},
 year = {2024}
}

@article{10385040,
 abstract = {Sixth-generation (6G) networks anticipate intelligently supporting a wide range of smart services and innovative applications. Such a context urges a heavy usage of Machine Learning (ML) techniques, particularly Deep Learning (DL), to foster innovation and ease the deployment of intelligent network functions/operations, which are able to fulfill the various requirements of the envisioned 6G services. The revolution of 6G networks is driven by massive data availability, moving from centralized and big data towards small and distributed data. This trend has motivated the adoption of distributed and collaborative ML/DL techniques. Specifically, collaborative ML/DL consists of deploying a set of distributed agents that collaboratively train learning models without sharing their data, thus improving data privacy and reducing the time/communication overhead. This work provides a comprehensive study on how collaborative learning can be effectively deployed over 6G wireless networks. In particular, our study focuses on Split Federated Learning (SFL), a technique that recently emerged promising better performance compared with existing collaborative learning approaches. We first provide an overview of three emerging collaborative learning paradigms, including federated learning, split learning, and split federated learning, as well as of 6G networks along with their main vision and timeline of key developments. We then highlight the need for split federated learning towards the upcoming 6G networks in every aspect, including 6G technologies (e.g., intelligent physical layer, intelligent edge computing, zero-touch network management, intelligent resource management) and 6G use cases (e.g., smart grid 2.0, Industry 5.0, connected and autonomous systems). Furthermore, we review existing datasets along with frameworks that can help in implementing SFL for 6G networks. We finally identify key technical challenges, open issues, and future research directions related to SFL-enabled 6G networks.},
 author = {Hafi, Houda and Brik, Bouziane and Frangoudis, Pantelis A. and Ksentini, Adlen and Bagaa, Miloud},
 doi = {10.1109/ACCESS.2024.3351600},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {6G mobile communication;Federated learning;Artificial intelligence;Surveys;Training;Wireless networks;Market research;Smart devices;6G networks;wireless communication;federated deep learning;split deep learning;split federated learning},
 month = {},
 number = {},
 pages = {9890-9930},
 title = {Split Federated Learning for 6G Enabled-Networks: Requirements, Challenges, and Future Directions},
 volume = {12},
 year = {2024}
}

@article{10387428,
 abstract = {The fast development of smart home devices and the Internet of Things (IoTs) presents unprecedented accessibility into our day-to-day lives; however, it has also increased major problems regarding security and privacy. A smart home network is a vital element of modern home automation systems, enabling the interconnectivity and control of different smart devices. These networks allow homeowners to remotely control lighting, security, temperature, and entertainment systems via voice commands or smartphones. These offer energy efficiency, convenience, and improved security by permitting residents to monitor and modify their living surroundings. Safeguarding the flexibility of smart home networks against cyberattacks and unauthorized access is important to comprehending the maximum ability of smart living while retaining data integrity and privacy of connected devices. This research develops the Blockchain with Red-Tailed Hawk Algorithm-Enabled Deep Learning (BC-RTHADL) model, aimed to strengthen the safety of smart home systems. BC-RTHADL integrates the safety features of blockchain with a strong malicious action recognition procedure. The blockchain module certifies immutability, transparency, and decentralization, donating to a safe smart home atmosphere. The malicious action detection influences the Red-Tailed Hawk Algorithm for feature selection and an ensemble of Extreme Learning Machine (ELM), Gated Recurrent Unit (GRU), and Long Short-Term Memory (LSTM) techniques for precise recognition. The Equilibrium Optimizer algorithm enhances parameters for improved effectiveness. Complete tests show the greater performance of BC-RTHADL across numerous metrics, reaffirming its promising potential in safeguarding smart home networks.},
 author = {Alruwaili, Fahad F. and Alohali, Manal Abdullah and Aljaffan, Nouf and Alhashmi, Asma A. and Mahmud, Ahmed and Assiri, Mohammed},
 doi = {10.1109/ACCESS.2024.3352502},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart homes;Security;Safety;Internet of Things;Atmospheric modeling;Blockchains;Logic gates;Deep learning;Blockchain;deep learning;ensemble learning;red-tailed hawk algorithm;feature selection},
 month = {},
 number = {},
 pages = {14146-14156},
 title = {A Decentralized Approach to Smart Home Security: Blockchain With Red-Tailed Hawk-Enabled Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10387439,
 abstract = {Data privacy is essential in the financial sector to protect client’s sensitive information, prevent financial fraud, ensure regulatory compliance, and safeguard intellectual property. It has become a challenging task due to the increase in usage of the internet and digital transactions. In this scenario, DDoS attack is one of the major attacks that makes clients’ privacy questionable. It requires effective and robust attack detection and prevention techniques. Machine Learning (ML) is the most effective approach for employing cyber attack detection systems. It paves the way for a new era where human and scientific communities will benefit. This paper presents a hierarchical ML-based hyperparameter-optimization approach for classifying intrusions in a network. CICIDS 2017 standard dataset was considered for this work. Initially, data was preprocessed with the min-max scaling and SMOTE methods. The LASSO approach was used for feature selection, given as input to the hierarchical ML algorithms: XGboost, LGBM, CatBoost, Random Forest (RF), and Decision Tree (DT). All these algorithms are pretrained with hyperparameters to enhance the effectiveness of algorithms. Models performance was assessed in terms of recall, precision, accuracy, and F1-score metrics. Evaluated approaches have shown that the LGBM algorithm gives a proven performance in classifying DDoS attacks with 99.77% of classification accuracy.},
 author = {Dasari, Sandeep and Kaluri, Rajesh},
 doi = {10.1109/ACCESS.2024.3352281},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Classification algorithms;Computer crime;Feature extraction;Intrusion detection;Training;Support vector machines;Machine learning;hyperparameter optimization;classification;cyberattacks;intrusion detection},
 month = {},
 number = {},
 pages = {10834-10845},
 title = {An Effective Classification of DDoS Attacks in a Distributed Network by Adopting Hierarchical Machine Learning and Hyperparameters Optimization Techniques},
 volume = {12},
 year = {2024}
}

@article{10387568,
 abstract = {Nowadays, the Internet of Things (IoT) has become a rapid development; it can be employed by cyber threats in IoT devices. A correct system to recognize malicious attacks at IoT platforms became of major importance to minimize security threats in IoT devices. Botnet attacks have more severe and common attacks and it is threaten IoT devices. These threats interrupt IoT alteration by interrupting networks and services for IoT devices. Several existing methods present themselves to determine unknown patterns in IoT networks for improving security. Recent analysis presents DL and ML methods for classifying and detecting botnet attacks from the IoT environment. Consequently, this paper develops a Bald Eagle Search Optimization with a Hybrid Deep Learning based botnet detection (BESO-HDLBD) algorithm in an IoT platform. The presented BESO-HDLBD approach aims to resolve the security issue by identifying the botnets in the IoT environment. To reduce the high dimensionality problem, the BESO-HDLBD method uses the BESO system for the feature selection process. For botnet detection purposes, the BESO-HDLBD algorithm uses HDL, which is an integration of convolutional neural networks (CNNs), bidirectional long short-term memory (BiLSTM), and attention concept. The desire for the HDL technique in botnet detection utilises the intricate nature of botnet attacks that frequently contain difficult and developing patterns. Combining CNNs permits for effectual feature extraction from spatial data, BiLSTM networks capture temporal dependencies, and attention mechanisms improve the model’s capability to concentrate on fundamental patterns. The selection of hyperparameters of the HDL approach takes place using the dragonfly algorithm (DFA). The experimental analysis of the BESO-HDLBD system could be examined under a benchmark botnet dataset. The obtained outcome infers a better outcome of the BESO-HDLBD technique compared to the recent detection system with respect to distinct estimation measures.},
 author = {Maghrabi, Louai A. and Shabanah, Sahar and Althaqafi, Turki and Alsalman, Dheyaaldin and Algarni, Sultan and Al-Ghamdi, Abdullah Al-Malaise and Ragab, Mahmoud},
 doi = {10.1109/ACCESS.2024.3352568},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Internet of Things;Malware;Hardware design languages;Feature extraction;Tuning;Information technology;Cybersecurity;Internet of Things;botnet attacks;machine learning;parameter tuning;smart environment},
 month = {},
 number = {},
 pages = {8337-8345},
 title = {Enhancing Cybersecurity in the Internet of Things Environment Using Bald Eagle Search Optimization With Hybrid Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10388323,
 abstract = {In the ever-changing world of decision-making, when game theory and reinforcement learning(RL) come together, they create a fascinating combination that shows a new way to solve complex problems in many fields. The combination of game theory and RL is a powerful convergence that opens up a hopeful new frontier for dealing with complex decision-making problems in many different fields. Research on the convergence of game theory and RL has shown to be beneficial, providing essential insights into challenging decision-making issues in various disciplines. This study investigates the recent developments of game theory and RL approaches through a systematic review and highlights the significance of game theory in boosting reinforcement algorithms and increasing the interaction of autonomous vehicles, safeguarding edge caching, and more. It offers a thorough account of the developments at the confluence of game theory and RL. The reviewed papers mainly focus on broad themes and address three important research questions: the impact of game theory on multi-agent reinforcement learning (MARL), the significant contributions of game theory to RL, and the significant impact areas. Following the methodology, search outcomes, and study areas is a discussion on game theory-related terminology, followed by study findings. The review’s conclusions offer ideas for further study and open research questions. The importance of game theory in advancing MARL, the potential of game theory in promoting RL strategies, and the opportunities for combining game theory and RL in cutting-edge fields like mobile edge caching and cyber-physical systems(CPS) are all emphasized in the conclusion. This review article advances our knowledge of the theoretical underpinnings and real-world applications of game theory and RL, laying the groundwork for future improvements in decision-making techniques and algorithms.},
 author = {Jain, Garima and Kumar, Arun and Bhat, Shahid Ahmad},
 doi = {10.1109/ACCESS.2024.3352749},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Game theory;Reinforcement learning;Behavioral sciences;Autonomous vehicles;Terminology;Table lookup;Multi-agent systems;Decision making;Cache storage;Game theory;reinforcement learning;multi-agent reinforcement learning;decision-making;autonomous vehicles;edge caching;cyber-physical systems},
 month = {},
 number = {},
 pages = {9999-10011},
 title = {Recent Developments of Game Theory and Reinforcement Learning Approaches: A Systematic Review},
 volume = {12},
 year = {2024}
}

@article{10398201,
 abstract = {With the rapid development of information communication and mobile device technologies, smart devices have become increasingly popular, providing convenience to households and enhancing the level of intelligence in daily life. This trend is also driving innovation and progress in various fields, including healthcare, transportation, and industry. However, as technology continues to proliferate, network security concerns have become increasingly prominent, making the protection of digital life and data security an urgent priority. Intrusion detection has always played an important role in the field of network security. Traditional intrusion detection systems predominantly rely on anomaly detection technology to identify potential intrusions by detecting abnormal patterns in network traffic. With technological advancements, machine learning-based methods have emerged as the cornerstone of modern intrusion detection, enabling more precise identification of abnormal behaviors and potential intrusions by learning the patterns of normal network traffic. In response to these challenges, this paper introduces an innovative intrusion detection model that amalgamates the Attention-CNN-BiLSTM (ACBL) and Temporal Convolutional Network (TCN) architectures. The ACBL and TCN models excel in processing spatial and temporal features within network traffic data, respectively. This integration harnesses diverse neural network structures to elevate overall model performance and accuracy. Furthermore, a unique approach inspired by dung beetles’ natural behavior, incorporating Tent mapping-enhanced Dung Beetle Optimization Algorithm (TDBO), is leveraged for both optimizing feature selection parameters and searching for optimal model hyperparameters. The feature selection parameters obtained from TDBO are then combined with the importance ranking from the Random Forest algorithm, ensuring optimal features can be better selected to enhance model performance. This paper introduces a novel intrusion detection model, the TDBO-ACBLT model, and validates its performance using the UNSW-NW15 dataset. TDBO excels in feature selection compared to common algorithms and achieves superior parameter optimization accuracy over Harris’s Hawk Optimization (HHO), Particle Swarm Optimization (PSO), and Dung Beetle Optimization (DBO). The proposed model achieves higher accuracy than prevalent machine learning models.},
 author = {Li, Yue and Zhang, Jiale and Yan, Yiting and Lei, Yutian and Yin, Chang},
 doi = {10.1109/ACCESS.2024.3353488},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Optimization;Network intrusion detection;Telecommunication traffic;Machine learning algorithms;Support vector machines;Random forests;Intrusion detection;network security;machine learning;deep learning;model fusion;dung beetle optimization algorithm DBO},
 month = {},
 number = {},
 pages = {9483-9496},
 title = {Enhancing Network Intrusion Detection Through the Application of the Dung Beetle Optimized Fusion Model},
 volume = {12},
 year = {2024}
}

@article{10399786,
 abstract = {The coronavirus disease 2019 (COVID-19) epidemic had a momentous influence on the state of universal health and how people live their lives in every nation. The combination of the Internet of Things (IoT) with medical systems is referred to as the “Internet of Medical Things (IoMT),” and it makes it possible for various medical events to take place, including real-time medicine prescriptions, remote patient observing, and real-time diagnosis, amongst other things. However, the security, integrity, and concealment of medical data on the IoMT remain an endless issue, contributing to the difficulties that arise in providing medical services. However, these conventional methods failed to provide robust security against attacks like distributed denial of service (DDoS). As a result, security IoMT-based COVID-19 detection applications are required. Therefore, this article proposes a novel IoMT-based COVID-19 detection and classification network (ICDC-Net) for smart healthcare applications. Initially, Optimal Feistel Block Cipher (OFBC) encryption was performed on COVID-19-based medical data (chest x-ray images), which provides the highest security to the patient’s data. Here, OFBC loss is optimized by the Hybrid Grey-Wolf Optimizer with Particle Swarm Optimization (HGWO-PSO), which performs DDoS attack detection and prevention. Further, the HGWO-PSO is also used to extract disease-specific features from the COVID-19 chest X-ray (CXR) images. Finally, the Residual Network50 (ResNet50) deep learning model is used to classify multiple diseases from CXR images, including normal, COVID-19, and viral pneumonia. The simulations disclosed that the proposed ICDC-Net resulted in improved attack detection accuracy (ADA), attack detection time (ADT), and reduced attack detection error rates (ADER) as compared to other security standards. Further, the simulations also disclosed that the proposed ICDC-Net developed superior COVID-19 categorization performing as equated to existing classification prototypes.},
 author = {Sripriyanka, G. and Mahendran, Anand},
 doi = {10.1109/ACCESS.2024.3354034},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {COVID-19;Security;Denial-of-service attack;Encryption;Medical services;Feature extraction;Computer crime;Pulmonology;Convolutional neural networks;Chest X-ray image classification;convolutional neural networks;feistel block cipher;grey-wolf optimization;Internet of Medical Things},
 month = {},
 number = {},
 pages = {17328-17348},
 title = {Securing IoMT: A Hybrid Model for DDoS Attack Detection and COVID-19 Classification},
 volume = {12},
 year = {2024}
}

@article{10401918,
 abstract = {Energy efficiency and safety are two essential factors that play a significant role in operating a wireless sensor network. However, it is claimed that these two factors are naturally conflicting. The level of electrical consumption required by a security system is directly proportional to its degree of complexity. Wireless sensor networks require additional security measures above the capabilities of conventional network security protocols, such as encryption and key management. The potential application of machine learning techniques to address network security concerns is frequently discussed. These devices will have complete artificial intelligence capabilities, enabling them to understand their environment and respond. During the training phase, machine-learning systems may face challenges due to the large amount of data required and the complex nature of the training procedure. The main objective of the article is to know about different machine learning algorithms that are used to solve the security issues of wireless sensor networks. This study also focuses on the use of wireless sensor networks in different fields. Furthermore, this study also focuses on different Machine learning algorithms that are used to secure wireless sensor networks. Moreover, this study also addresses issues of adapting machine learning algorithms to accommodate the sensors’ functionalities in the network configuration. Furthermore, this article also focuses on open issues in this field that must be solved.},
 author = {Ghadi, Yazeed Yasin and Mazhar, Tehseen and Shloul, Tamara Al and Shahzad, Tariq and Salaria, Umair Ahmad and Ahmed, Arfan and Hamam, Habib},
 doi = {10.1109/ACCESS.2024.3355312},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Security;Sensors;Machine learning;Artificial intelligence;Safety;Training;Internet of Things;Low-power electronics;Personal area networks;Wireless sensor networks;machine learning;WSNs security;LoWPAN;IoT},
 month = {},
 number = {},
 pages = {12699-12719},
 title = {Machine Learning Solutions for the Security of Wireless Sensor Networks: A Review},
 volume = {12},
 year = {2024}
}

@article{10403882,
 abstract = {The Internet of Things (IoT) infrastructure enables smart devices to learn, think, speak and perform. The facilities of the IoT devices can be enhanced to support an intelligent application through technologies like fog computing, smart networks, federated learning or explainable artificial intelligence infrastructures. In all these cases networking of IoT devices becomes inevitable. Whereever there exists a network, a threat to the network infrastructure is also possible. The proposed work classifies various attacks on the hosts with the support of proven machine learning (ML) algorithms. This work performs the comparative analysis of all these classification parameters of the machine learning algorithms with the use of fuzzy-based recommendation systems. This work also lists out various incidents of intrusions on the IoT hosts in appropriate layers of the interface and proposes an efficient algorithm and framework to overcome the occurrences of intrusions on the host side. In particular, we propose an effective security framework to deal with the intrusions that can deteriorate the host-based systems. The ranking of the algorithms is evaluated using fuzzy-based recommendation systems such as TOPSIS, VIKOR, MORA, WASPAS. The ensemble of machine learning algorithms such as Decision Tree, Lite Gradient Boost, Xtra Gradient Boost and Random Forest provide better values of accuracy (around 99%) with higher precision, re-call and F1-scores, thus proving their efficacy for intrusion detection in IoT networks.},
 author = {Nallakaruppan, M. K. and Somayaji, Siva Rama Krishnan and Fuladi, Siddhesh and Benedetto, Francesco and Ulaganathan, Senthil Kumaran and Yenduri, Gokul},
 doi = {10.1109/ACCESS.2024.3355794},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Intrusion detection;Machine learning algorithms;Machine learning;Deep learning;Classification algorithms;Artificial intelligence;Artificial intelligence;Internet of Things;intrusion detection systems;network security;privacy},
 month = {},
 number = {},
 pages = {31788-31797},
 title = {Enhancing Security of Host-Based Intrusion Detection Systems for the Internet of Things},
 volume = {12},
 year = {2024}
}

@article{10403908,
 abstract = {Given the continually rising frequency of cyberattacks, the adoption of artificial intelligence methods, particularly Machine Learning (ML), Deep Learning (DL), and Reinforcement Learning (RL), has become essential in the realm of cybersecurity. These techniques have proven to be effective in detecting and mitigating cyberattacks, which can cause significant harm to individuals, organizations, and even countries. Machine learning algorithms use statistical methods to identify patterns and anomalies in large datasets, enabling security analysts to detect previously unknown threats. Deep learning, a subfield of ML, has shown great potential in improving the accuracy and efficiency of cybersecurity systems, particularly in image and speech recognition. On the other hand, RL is again a subfield of machine learning that trains algorithms to learn through trial and error, making it particularly effective in dynamic environments. We also evaluated the usage of ChatGPT-like AI tools in cyber-related problem domains on both sides, positive and negative. This article provides an overview of how ML, DL, and RL are applied in cybersecurity, including their usage in malware detection, intrusion detection, vulnerability assessment, and other areas. The paper also specifies several research questions to provide a more comprehensive framework to investigate the efficiency of AI and ML models in the cybersecurity domain. The state-of-the-art studies using ML, DL, and RL models are evaluated in each Section based on the main idea, techniques, and important findings. It also discusses these techniques’ challenges and limitations, including data quality, interpretability, and adversarial attacks. Overall, the use of ML, DL, and RL in cybersecurity holds great promise for improving the effectiveness of security systems and enhancing our ability to protect against cyberattacks. Therefore, it is essential to continue developing and refining these techniques to address the ever-evolving nature of cyber threats. Besides, some promising solutions that rely on machine learning, deep learning, and reinforcement learning are susceptible to adversarial attacks, underscoring the importance of factoring in this vulnerability when devising countermeasures against sophisticated cyber threats. We also concluded that ChatGPT can be a valuable tool for cybersecurity, but it should be noted that ChatGPT-like tools can also be manipulated to threaten the integrity, confidentiality, and availability of data.},
 author = {Ozkan-Okay, Merve and Akin, Erdal and Aslan, ÖMER and Kosunalp, Selahattin and Iliev, Teodor and Stoyanov, Ivaylo and Beloev, Ivan},
 doi = {10.1109/ACCESS.2024.3355547},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer security;Deep learning;Security;Fraud;Prediction algorithms;Telecommunication traffic;Reinforcement learning;Machine learning;Artificial intelligence;Cyberattacks and solutions;deep learning;machine learning;reinforcement learning;AI tools},
 month = {},
 number = {},
 pages = {12229-12256},
 title = {A Comprehensive Survey: Evaluating the Efficiency of Artificial Intelligence and Machine Learning Techniques on Cyber Security Solutions},
 volume = {12},
 year = {2024}
}

@article{10410600,
 abstract = {In recent years, low recall rates and high dependencies on data labelling have become the biggest obstacle to developing deep anomaly detection (DAD) techniques. Inspired by the success of generative adversarial networks (GANs) in detecting anomalies in computer vision and imaging, we propose an anomaly detection model called FlowGANAnomaly for detecting anomalous traffic in network intrusion detection systems (NIDS). Unlike traditional GAN-based approaches, which are composed of a flow encoder, a convolutional encoder-decoder-encoder, a flow decoder and a convolutional encoder, the architecture of this model consists of a generator (G) and a discriminator (D). FlowGANAnomaly maps the different types of traffic feature data from separate datasets to a uniform feature space, thus can capture the normality of network traffic data more accurately in an adversarial manner to mitigate the problem of the high dependence on data labeling. Moreover, instead of simply detecting the anomalies by the output of D, we proposed a new anomaly scoring method that integrates the deviation between the output of two Gs' convolutional encoders with the output of D as weighted scores to improve the low recall rate of anomaly detection. We conducted several experiments comparing existing machine learning algorithms and existing deep learning methods (AutoEncoder and VAE) on four public datasets (NSL-KDD, CIC-IDS2017, CIC-DDoS2019, and UNSW-NB15). The evaluation results show that FlowGANAnomaly can significantly improve the performance of anomaly-based NIDS.},
 author = {Li, Zeyi and Wang, Pan and Wang, Zixuan},
 doi = {10.23919/cje.2022.00.173},
 issn = {2075-5597},
 journal = {Chinese Journal of Electronics},
 keywords = {Deep learning;Machine learning algorithms;Computational modeling;Network intrusion detection;Imaging;Telecommunication traffic;Generative adversarial networks;Anomaly detection;Unsupervised learning;Generative adversarial network;Intrusion detection system},
 month = {January},
 number = {1},
 pages = {58-71},
 title = {FlowGANAnomaly: Flow-Based Anomaly Network Intrusion Detection with Adversarial Learning},
 volume = {33},
 year = {2024}
}

@article{10414101,
 abstract = {The cyber realm is overwhelmed with dynamic malware that promptly penetrates all defense mechanisms, operates unapprehended to the user, and covertly causes damage to sensitive data. The current generation of cyber users is being victimized by the interpolation of malware each day due to the pervasive progression of Internet connectivity. Malware is dispersed to infiltrate the security, privacy, and integrity of the system. Conventional malware detection systems do not have the potential to detect novel malware without the accessibility of their signatures, which gives rise to a high False Negative Rate (FNR). Previously, there were numerous attempts to address the issue of malware detection, but none of them effectively combined the capabilities of signature-based and machine learning-based detection engines. To address this issue, we have developed an integrated Anti-Malware System (AMS) architecture that incorporates both conventional signature-based detection and AI-based detection modules. Our approach employs a Generative Adversarial Network (GAN) based Malware Classifier Optimizer (MCOGAN) framework, which can optimize a malware classifier. This framework utilizes GANs to generate fabricated benign files that can be used to train external discriminators for optimization purposes. We describe our proposed framework and anti-malware system in detail to provide a better understanding of how a malware detection system works. We evaluate our approach using the Figshare dataset and state-of-the-art models as discriminators. Our results showcase enhanced malware detection performance, yielding a 10% performance boost, thus affirming the efficacy of our approach compared to existing models.},
 author = {Khan, Faiza Babar and Durad, Muhammad Hanif and Khan, Asifullah and Khan, Farrukh Aslam and Rizwan, Muhammad and Ali, Aftab},
 doi = {10.1109/ACCESS.2024.3358454},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Generative adversarial networks;Support vector machines;Machine learning;Generators;Terminology;Training;Performance evaluation;Anti-malware system;generative adversarial networks;malware sandboxes;malware;unpacker;performance},
 month = {},
 number = {},
 pages = {27683-27708},
 title = {Design and Performance Analysis of an Anti-Malware System Based on Generative Adversarial Network Framework},
 volume = {12},
 year = {2024}
}

@article{10414983,
 abstract = {Malware targeting user privacy has seen a surge in recent times, attributed to evolving global regulations and the boost of electronic commerce and online services. Moreover, recognizing privacy malware that employs obfuscation as evasion mechanism presents a major challenge due to its dynamics, resilience, and polymorphism at runtime, necessitating the application of forensic techniques such as memory dumping analysis in order to reveal suitable patterns and behaviors that enable its subsequent detection and classification. In this paper, we present three obfuscated privacy malware classifiers trained on the CIC-MalMem-2022 dataset. These solutions include a binary classifier to distinguish benign from malicious samples using logistic regression (LR), a multiclass classifier that further categorizes benign, spyware, ransomware, and trojan horse obfuscated privacy malware; and a more detailed multiclass classifier capable of discriminating benign samples from fifteen specific obfuscated privacy malware families. Multiclass classifiers were built using several traditional machine learning algorithms and a novel Deep Neural Network (DNN). We applied the Synthetic Minority Oversampling Technique (SMOTE) to address data imbalances. In particular, our results demonstrate that DNN outperforms traditional machine learning algorithms, yielding statistically significant improvements in key metrics. These achievements reach practical thresholds, suggesting the potential for enhanced malware protection systems. The dataset and all the coding files required for experiments reproducibility are publicly available at https://github.com/dcevallossalas/PrivacyMalwareClassifiers.},
 author = {Cevallos-Salas, David and Grijalva, Felipe and Estrada-Jiménez, José and Benítez, Diego and Andrade, Roberto},
 doi = {10.1109/ACCESS.2024.3358840},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Privacy;Data privacy;Ransomware;Measurement;Machine learning algorithms;Behavioral sciences;Privacy;malware;obfuscation;classifier;memory dumping;CIC-MalMem-2022;SMOTE;ransomware;spyware;trojan horse},
 month = {},
 number = {},
 pages = {17481-17498},
 title = {Obfuscated Privacy Malware Classifiers Based on Memory Dumping Analysis},
 volume = {12},
 year = {2024}
}

@article{10415173,
 abstract = {The electrification of the transportation sector is a pivotal stride towards ensuring sustainability in our systems. This paradigm offers a promising solution to multiple challenges, including reducing oil consumption, lowering Greenhouse Gas (GHG) emissions, enhancing air quality, improving the efficiency of the transportation sector, and facilitating the integration of renewable energy resources into the electric grid. Despite its potential, the electrification of vehicles encounters a major bottleneck-the need for diverse charging infrastructure options. Three groundbreaking technologies, including Dynamic Wireless Charging (DWC), Battery Swapping Stations, and Fast Charging Stations (FCSs), have emerged, holding the promise to accelerate the adoption of Electric Vehicles (EVs). These technologies address critical challenges such as range anxiety and charging downtime, contributing to a seamless experience for EV users. This work primarily delves into the realm of FCS, recognized as one of the most readily available options in the current market. Optimizing the utilization of charging infrastructure hinges on tackling challenges related to routing EVs to the nearest FCS capable of meeting specific charging requirements. These requirements encompass factors such as wait time, charging duration, and charging cost. In addition to the integration of Vehicle-to-Everything (V2X) communications for enhancing EV routing to FCS, coordinated management of EV charging demand becomes imperative for achieving grid load balancing and preventing grid overload. This paper aims to present the vision and future trends of Smart Green Internet of Vehicles (IoV) in the era of EVs. The focus extends beyond mere vehicular connectivity, delving into sustainable V2X connectivity, grid integration, vehicular networking, data security, and associated services.},
 author = {Aldhanhani, Tasneim and Abraham, Anuj and Hamidouche, Wassim and Shaaban, Mostafa},
 doi = {10.1109/OJVT.2024.3358893},
 issn = {2644-1330},
 journal = {IEEE Open Journal of Vehicular Technology},
 keywords = {Green products;Batteries;Electric vehicle charging;Vehicle-to-everything;Transportation;Costs;Routing;Internet of Vehicles;plug-in charging;wireless charging;electric vehicles;battery swapping stations;V2X technology;machine learning;power grids;sustainability},
 month = {},
 number = {},
 pages = {278-297},
 title = {Future Trends in Smart Green IoV: Vehicle-to-Everything in the Era of Electric Vehicles},
 volume = {5},
 year = {2024}
}

@article{10415191,
 abstract = {Agriculture has played a significant role in the lifespan of human beings for their survival and the better economic growth of the country. Due to its intensified growth, smart agriculture has been a popular domain recently. This aggregates the benefits of any computing technologies, like wireless sensor networks (WSN), drones, Internet of Things (IoT), remote sensing, etc. The IoT system places sensors on agricultural areas to accumulate critical information for the crops and fields to increase the overall rate of productivity. While broadcasting the sensed information in the domains to the target, there is a chance of the existence of cyber-threats, which intruders design to attain access to the content being transferred. Intrusion detection in IoT-based smart farming using deep learning (DL) leverages the power of deep neural networks (DNN) to safeguard agricultural systems from cyber threats. DL algorithms can autonomously detect unauthorized and anomalies activities by analyzing data streams from sensors, IoT devices, and farm management systems. With this motivation, this study designs an Enhanced Black Widow Optimization with Hybrid Deep Learning Enabled Intrusion Detection (EBWO-HDLID) technique in the IoT-based Smart Farming environment. The proposed EBWO-HDLID technique captures complex patterns and detects significant intrusions, assuring the security and reliability of smart farming. In the presented EBWO-HDLID approach, the bald eagle search (BES) algorithm can be used for the feature selection process. For the intrusion detection and classification process, the EBWO-HDLID technique applies the HDL classification model. Finally, the EBWO algorithm can be used for the parameter tuning of the HDL technique. The experimental validation process demonstrates the satisfactory performance of the EBWO-HDLID model on two benchmark datasets: ToN-IoT, and Edge-IIoTset datasets.},
 author = {Aburasain, Rua Y.},
 doi = {10.1109/ACCESS.2024.3359043},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart agriculture;Intrusion detection;Internet of Things;Artificial neural networks;Feature extraction;Mathematical models;Farming;Deep learning;Cyberattack;Smart farming;Internet of Things;deep learning;intrusion detection;cyberattacks;feature selection},
 month = {},
 number = {},
 pages = {16621-16631},
 title = {Enhanced Black Widow Optimization With Hybrid Deep Learning Enabled Intrusion Detection in Internet of Things-Based Smart Farming},
 volume = {12},
 year = {2024}
}

@article{10415442,
 abstract = {Intrusion detection systems (IDS) have seen an increasing number of proposals by researchers utilizing deep learning (DL) to safeguard critical networks. However, they often suffer from high false alarm rates, posing a significant challenge to their deployment in critical networks. This paper presents a comprehensive human-machine framework for mitigating false alarms in DL-based intrusion detection systems. The proposed approach uses probabilistic clustering to enable human-machine collaboration in a synergistic manner. Probabilistic clustering involves regrouping network traffic into clusters based on their probabilities (computed using the DL model). Clusters with high false alarms (H-FAR) are detected, and all traffic falling within them is considered uncertain for efficient classification by the DL model as malicious or benign. They are redirected to human experts to analyze and make a final decision. The proposed framework incorporates a next-generation firewall (NGFW) to help human experts handle the processed traffic efficiently. The proposed framework enhances the performance of DL-based intrusion detection classifiers by reducing false alarms. To validate the proposed concept, assessments were conducted using a customized high-performance convolutional neural network (CNN) and a hybrid recurrent neural network (RNN) model with three open-access benchmark datasets (CICDDoS2019, UNSW-NB15, and CICIDS2017). The evaluation through simulation demonstrated that combining human expertise with deep learning technology can significantly reduce the number of false positives (FPs) and false negatives (FNs) by up to 79.61% and 86.99%, respectively.},
 author = {Maiga, Abdoul-Aziz and Ataro, Edwin and Githinji, Stanley},
 doi = {10.1109/ACCESS.2024.3359595},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Security;Convolutional neural networks;Probabilistic logic;Telecommunication traffic;Denial-of-service attack;Human activity recognition;Clustering methods;Classification algorithms;Deep learning;IDS;false alarms mitigation;human-in-the-loop expertise;human-machine},
 month = {},
 number = {},
 pages = {17836-17858},
 title = {Intrusion Detection With Deep Learning Classifiers: A Synergistic Approach of Probabilistic Clustering and Human Expertise to Reduce False Alarms},
 volume = {12},
 year = {2024}
}

@article{10415536,
 abstract = {The escalating threat and impact of network-based attacks necessitate innovative intrusion detection systems. Machine learning has shown promise, with recent strides in quantum machine learning offering new avenues. However, the potential of quantum computing is tempered by challenges in current noisy intermediate-scale quantum era machines. In this article, we explore quantum neural networks (QNNs) for intrusion detection, optimizing their performance within current quantum computing limitations. Our approach includes efficient classical feature encoding, QNN classifier selection, and performance tuning leveraging current quantum computational power. This study culminates in an optimized multilayered QNN architecture for network intrusion detection. A small version of the proposed architecture was implemented on IonQ's Aria-1 quantum computer, achieving a notable 0.86 F1 score using the NF-UNSW-NB15 dataset. In addition, we introduce a novel metric, certainty factor, laying the foundation for future integration of uncertainty measures in quantum classification outputs. Moreover, this factor is used to predict the noise susceptibility of our quantum binary classification system.},
 author = {Kukliansky, Alon and Orescanin, Marko and Bollmann, Chad and Huffmire, Theodore},
 doi = {10.1109/TQE.2024.3359574},
 issn = {2689-1808},
 journal = {IEEE Transactions on Quantum Engineering},
 keywords = {Quantum computing;Qubit;Computer architecture;Training;Protocols;Noise measurement;Support vector machines;Intrusion detection;network intrusion detection system (NIDS);quantum neural network (QNN)},
 month = {},
 number = {},
 pages = {1-11},
 title = {Network Anomaly Detection Using Quantum Neural Networks on Noisy Quantum Computers},
 volume = {5},
 year = {2024}
}

@article{10417025,
 abstract = {Wi-Fi-based person identification (PI) tasks are performed by analyzing the fluctuating characteristics of the Channel State Information (CSI) data to determine whether the person's identity is legitimate. This technology can be used for intrusion detection and keyless access to restricted areas. However, the related research rarely considers the restricted computing resources and the complexity of real-world environments, resulting in lacking practicality in some scenarios, such as intrusion detection tasks in remote substations without public network coverage. In this paper, we propose a novel neural network model named SimpleViTFi, a lightweight classification model based on Vision Transformer (ViT), which adds a downsampling mechanism, a distinctive patch embedding method and learnable positional embedding to the cropped ViT architecture. We employ the latest IEEE 802.11ac 80MHz CSI dataset provided by [1]. The CSI matrix is abstracted into a special “image” after pre-processing and fed into the trained SimpleViTFi for classification. The experimental results demonstrate that the proposed SimpleViTFi has lower computational resource overhead and better accuracy than traditional classification models, reflecting the robustness on LOS or NLOS CSI data generated by different Tx-Rx devices and acquired by different monitors.},
 author = {Bian, Jichen and Zheng, Min and Liu, Hong and Mao, Jiahui and Li, Hui and Tan, Chong},
 doi = {10.23919/transcom.2023EBP3102},
 issn = {1745-1345},
 journal = {IEICE Transactions on Communications},
 keywords = {Wireless fidelity;Sensors;Task analysis;Transformers;Feature extraction;Data models;Transmitting antennas;Wi-Fi sensing;CSI;person identification;lightweight model;vision transformer},
 month = {April},
 number = {4},
 pages = {377-386},
 title = {SimpleViTFi: A Lightweight Vision Transformer Model for Wi-Fi-Based Person Identification},
 volume = {E107-B},
 year = {2024}
}

@article{10418146,
 abstract = {This state-of-the-art review comprehensively examines the landscape of Distributed Denial of Service (DDoS) anomaly detection in Software Defined Networks (SDNs) through the lens of advanced Machine Learning (ML) and Deep Learning (DL) techniques. The application domain of this work is focused on addressing the inherent security vulnerabilities of SDN environments and developing an automated system for detecting and mitigating network attacks. The problem focused on in this review is the need for effective defensive mechanisms and detection methodologies to address these vulnerabilities. Conventional network measurement methodologies are limited in the context of SDNs, and the proposed ML and DL techniques aim to overcome these limitations by providing more accurate and efficient detection and mitigation of DDoS attacks. The objective of this work is to provide a comprehensive review of related works in the field of SDN anomaly detection recent advances, categorized into two groups via ML and DL techniques. The proposed systems utilize a variety of techniques, including Supervised Learning (SL), Unsupervised Learning (UL) Ensemble Learning (EL) and DL solutions, to process IP flows, profile network traffic, and identify attacks. The output comprises the mitigation policies learned by ML/DL techniques, and the proposed systems act as sophisticated gatekeepers, applying automated mitigation policies to curtail the extent of damage resulting from these attacks. The results obtained from the evaluation metrics, including accuracy, precision, and recall, confirm the marked effectiveness of the proposed systems in detecting and mitigating various types of attacks, including Distributed Denial of Service (DDoS) attacks. The proposed systems’ foundational contributions are manifest in their efficacy for both DDoS attack detection and defense within the SDN environment. However, the review acknowledges certain inherent limitations and the pressing need for further validation within real-world scenarios to assess the proposed methods’ practicality and effectiveness. In summary, this systematic review offers valuable perspectives on the present status of Distributed Denial-of-Service detection in Software-Defined Networks employing Machine Learning and Deep Learning methodologies, highlighting the strengths and limitations of various proposed systems and identifying areas for future research and development.},
 author = {Musa, Nura Shifa and Mirza, Nada Masood and Rafique, Saida Hafsa and Abdallah, Amira Mahamat and Murugan, Thangavel},
 doi = {10.1109/ACCESS.2024.3360868},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Computer crime;Software defined networking;Machine learning;Deep learning;Telecommunication traffic;Protocols;Anomaly detection;Anomaly detection;deep learning (DL);distributed denial of service (DDoS);machine learning (ML);software defined network (SDN)},
 month = {},
 number = {},
 pages = {17982-18011},
 title = {Machine Learning and Deep Learning Techniques for Distributed Denial of Service Anomaly Detection in Software Defined Networks—Current Research Solutions},
 volume = {12},
 year = {2024}
}

@article{10418592,
 abstract = {The absence of essential security protocols in Industrial Internet of Things (IIoT) networks introduces cybersecurity vulnerabilities and turns them into potential targets for various attack types. Although machine learning has been used for intrusion detection in the IIoT, datasets with representative data of common attacks of IIoT network traffic are limited and often imbalanced. Data augmentation techniques address these problems by creating artificial data in classes with fewer samples. In this work, we evaluate the use of data augmentation when training intrusion detection models based on IIoT traffic data. We compare Generative Pre-trained Transformers (GPT) and variations on the Synthetic Minority Over-sampling TEchnique (SMOTE) and evaluate their capability to enhance intrusion detection performance. We examine the performance of five intrusion detection algorithms when trained with augmented datasets to models trained with the original non-augmented dataset. To ensure a fair comparison, we evaluated the algorithms’ performance in the different scenarios using the same test dataset, which does not contain synthetic data. The results show the need for a systematic evaluation before employing data augmentation, as its impact on classification performance depends on the algorithm, data, and used technique. While deep neural networks benefit from data augmentation, the eXtreme Gradient Boosting (XGBoost), which achieved superior performance in intrusion detection between all evaluated classifiers (with F1-Score over 91%), didn’t have any performance improvement when trained with augmented data. The evaluation of data generated by GPT-based methods shows such methods (especially GReaT) generate invalid data for both numerical and categorical features in a way that leads to performance degradation in multiclass classification.},
 author = {Melícias, Francisco S. and Ribeiro, Tiago F. R. and Rabadão, Carlos and Santos, Leonel and Costa, Rogério Luís De C.},
 doi = {10.1109/ACCESS.2024.3360879},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Data augmentation;Data models;Intrusion detection;Telecommunication traffic;Random forests;Classification algorithms;IIoT;cybersecurity;data augmentation;machine learning},
 month = {},
 number = {},
 pages = {17945-17965},
 title = {GPT and Interpolation-Based Data Augmentation for Multiclass Intrusion Detection in IIoT},
 volume = {12},
 year = {2024}
}

@article{10419360,
 abstract = {An intrusion attack on the Internet of Things (IoT) is any malicious activity or unauthorized access that jeopardizes the integrity and security of IoT systems, networks, or devices. Regarding IoT, intrusions can result in severe problems, including service disruption, data theft, privacy violations, and even bodily injury. One of the intrusion attacks is a keylogging attack, sometimes referred to as keystroke logging or keyboard capture, which is a type of cyberattack in which the attacker secretly observes and records keystrokes made on a device’s keyboard. In the context of IoT, where connected objects communicate and exchange data, this assault may be especially concerning. Keylogging attacks can have severe repercussions in the IoT ecosystem since they can compromise sensitive information, including login passwords, personal information, financial information, or confidential communications. This paper explored the possibility of using an ensemble classifier to detect keylogging attacks in IoT networks. We built an ensemble classifier consisting of three classifiers: a convolutional neural network (CNN), a recurrent neural network (RNN), and a long-short memory network (LSTM). A proposed model uses the BoT-IoT dataset to detect a keylogging attack. Results show that the ensemble model can improve the model’s performance. The ensemble model had excellent accuracy and a low false positive rate. It also had significantly improved detection rates for keylogging attacks than other classifiers.},
 author = {Maz, Yahya Alhaj and Anbar, Mohammed and Manickam, Selvakumar and Rihan, Shaza Dawood Ahmed and Alabsi, Basim Ahmad and Dorgham, Osama M.},
 doi = {10.1109/ACCESS.2024.3362232},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Predictive models;Ensemble learning;Classification tree analysis;Classification algorithms;Training;Convolutional neural network;Internet of Things;intrusion detection system;keylogging attacks;long short-term memory network;recurrent neural network},
 month = {},
 number = {},
 pages = {19860-19871},
 title = {Majority Voting Ensemble Classifier for Detecting Keylogging Attack on Internet of Things},
 volume = {12},
 year = {2024}
}

@article{10422789,
 abstract = {Intrusion detection is essential for safeguarding computer systems and networks against unauthorized access, malicious activities, and security breaches. Its application domains include network security, information security, and cybersecurity across various sectors such as finance, healthcare, government, and industry. Federated learning-based intrusion detection offers improved performance compared to conventional mechanisms by leveraging decentralized data sources, preserving data privacy, and enhancing model generalization through collaboration among multiple organizations. However, challenges faced by existing federated learning-based intrusion detection mechanisms include ensuring data privacy and security, mitigating communication overhead, and enhancing detection accuracy. In order to overcome these issues, this research article proposes a federated learning-based intrusion detection methodology that leverages Enhanced Ghost_BiNet, a novel deep learning model, to enhance the security of information sharing and detection accuracy. Federated learning, a privacy-preserving machine learning technique, is utilized to enable multiple entities to collaboratively train a global intrusion detection model without sharing sensitive data. The proposed system first trains local models using Enhanced Ghost_BiNet, which integrates GhostNet and Bidirectional Gated Recurrent Unit (BiGRU). To optimize the model’s performance, the Chaotic Chebyshev Artificial Humming Bird (CAh) algorithm is employed. Homomorphic encryption is applied to encrypt the local model updates, enhancing data privacy and security. Server-side aggregation of updates and collaborative optimization are introduced to minimize communication rounds during data aggregation. The results demonstrate that the Enhanced Ghost_BiNet outperforms traditional models like GhostNet, BiGRU, RNN, Auto Encoder, and CNN in terms of accuracy, precision, recall, F-Score, and mean square error (MSE). For instance, the Enhanced Ghost_BiNet achieves an accuracy of 99.24% on the KDD CUP 99 dataset, surpassing the other models by a significant margin. The proposed methodology provides a robust and secure approach to intrusion detection, ensuring the confidentiality of sensitive data while improving detection accuracy.},
 author = {ChandraUmakantham, Om Kumar and Gajendran, Sudhakaran and Marappan, Suguna},
 doi = {10.1109/ACCESS.2024.3362347},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Intrusion detection;Federated learning;Data privacy;Machine learning;Training;Security;Deep learning;Homomorphic encryption;Federated learning;intrusion detection;hybrid deep learning;homomorphic encryption;enhanced Ghost_BiNet;privacy},
 month = {},
 number = {},
 pages = {24879-24893},
 title = {Enhancing Intrusion Detection Through Federated Learning With Enhanced Ghost_BiNet and Homomorphic Encryption},
 volume = {12},
 year = {2024}
}

@article{10422967,
 abstract = {The rise of the Internet of Things (IoT) technology during the past decade has resulted in multiple applications across a large variety of fields. Some of the data processed using this technology can be specially sensitive, and the devices involved can be prone to cyberattacks, which has resulted in a rising interest in the field of information security applied to IoT. This study presents a method for analyzing an IoT network to detect attacks using side-channel techniques that monitor the power usage of the devices. It shows that it is possible to employ a monitoring system powered by Machine Learning to detect intrusions without interfering with the normal behavior of the devices. Tests yield positive results under a range of scenarios, including using a custom dataset, detecting new attacks previously unseen by the models, and detecting attacks in real time. The main advantages of the proposed system are simplicity, reproducibility (both code and data are made available) and portability, since it can be deployed on all kinds of devices and does not have a high demand of resources. Several deployment strategies are proposed, depending on the structure of the target IoT network and the power constraints of the devices.},
 author = {Campos, Alejandro Domínguez and Lemus-Prieto, Felipe and González-Sánchez, José-Luis and Lindo, Andrés Caro},
 doi = {10.1109/ACCESS.2024.3362670},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Intrusion detection;Computer security;Machine learning;Side-channel attacks;Cybersecurity;intrusion detection system (IDS);Internet of Things (IoT);machine learning;side-channel},
 month = {},
 number = {},
 pages = {98450-98465},
 title = {Intrusion Detection for IoT Environments Through Side-Channel and Machine Learning Techniques},
 volume = {12},
 year = {2024}
}

@article{10423751,
 abstract = {Today’s Internet of Vehicles (IoV) has soared by leveraging data gathered from transportation systems, yet it grapples with security concerns stemming from network vulnerabilities, exposing it to cyber threats. This study proposes an innovative method to anticipate anomalies and exploit IoV services related to road traffic. Using the Unceasement Conditional Random Field Dynamic Bayesian Network Model (U-CRF-DDBN), this approach predicts the impact of network attacks, strategically managing vulnerable nodes and attackers. Through experimentation and comparisons with existing methods, our model demonstrates its effectiveness in mitigating IoV vulnerabilities. The U-CRF-DDBN strikes a superior balance, outperforming other approaches in intrusion detection for Internet of Vehicles systems. Evaluating its performance on the NSL-KDD dataset reveals a promising average Detection Rate of 93.512% and a low False Acceptance Rate of 0.125% for known attacks, highlighting its robustness. However, with unknown attacks, while the Detection Rate remains at 74.157%, there is an increased FAR of 16.47%, resulting in a slightly lower F1-score of 0.822.},
 author = {Mahendran, Rakesh Kumar and Rajendran, Santhosh and Pandian, Prakash and Rathore, Rajkumar Singh and Benedetto, Francesco and Jhaveri, Rutvij H.},
 doi = {10.1109/ACCESS.2024.3363420},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Security;Internet of Vehicles;Bayes methods;Predictive models;Machine learning algorithms;Automobiles;Anomaly detection;Threat assessment;Intelligent transportation systems;Intelligent vehicles;Anomaly detection;conditional random field Bayesian model;cyberthreat vulnerabilities;Internet of Vehicles (IoV)},
 month = {},
 number = {},
 pages = {24644-24658},
 title = {A Novel Constructive Unceasement Conditional Random Field and Dynamic Bayesian Network Model for Attack Prediction on Internet of Vehicle},
 volume = {12},
 year = {2024}
}

@article{10430184,
 abstract = {With the increase of cyber-attacks and security threats in the recent decade, it is necessary to safeguard sensitive data and provide robust protection to information systems and computer networks. In this paper, an anomaly-based network outlier detection system (NODS) is proposed and optimized to check and classify the incoming network traffic stream’s behaviours that affect the computer networks. The proposed NODS has high classification efficiency. Network connection events classified as outliers are reported to the network admin to drop and block its packets. The NSL-KDD and CICIDS2017 intrusion datasets were employed to build the proposed system and test its detection capabilities. Sequential scenarios were implemented to optimize the system’s effectiveness. Network features were normalized by min-max and Z-Score approaches, while the relevant features were selected individually by the principal component analysis (PCA) and correlated features selection (CFS) techniques. Support vector machine (SVM) and Gaussian Naive Bayes (GNB) algorithms are used to build the detection model, while the Genetic algorithm (GA) was employed to tune their control parameters. The obtained evaluation results proved that the proposed SVM based NODS is characterized by low false alarms and detection time as well as high classification accuracy. Furthermore, a comparative analysis was conducted with other existing techniques, and the results obtained demonstrate the effectiveness of the proposed SVM-IDS},
 author = {Alghushairy, Omar and Alsini, Raed and Alhassan, Zakhriya and Alshdadi, Abdulrahman A. and Banjar, Ameen and Yafoz, Ayman and Ma, Xiaogang},
 doi = {10.1109/ACCESS.2024.3364400},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Support vector machines;Eavesdropping;Anomaly detection;Feature extraction;Random forests;Jamming;Telecommunication traffic;Gaussian processes;Bayes methods;Genetic algorithms;Parameter estimation;Cyberattack;Computer security;Outlier detection;NSL-KDD;CICIDS2017;features normalization;features selection;support vector machine;Gaussian Naive Bayes;genetic algorithm;RBF;tunning parameters},
 month = {},
 number = {},
 pages = {24428-24441},
 title = {An Efficient Support Vector Machine Algorithm Based Network Outlier Detection System},
 volume = {12},
 year = {2024}
}

@article{10433134,
 abstract = {The exponential growth of intrusions on networked systems inspires new research directions on developing artificial intelligence (AI) techniques for intrusion detection systems (IDS). In particular, the need to understand and explain these AI models to security analysts (managing these IDS to safeguard their networks) motivates the usage of explainable AI (XAI) methods in real-world IDS. In this work, we propose an end-to-end framework to evaluate black-box XAI methods for network IDS. We evaluate both global and local scopes for these black-box XAI methods for network intrusion detection. We analyze six different evaluation metrics for two popular black-box XAI techniques, namely SHAP and LIME. These metrics are descriptive accuracy, sparsity, stability, efficiency, robustness, and completeness. They cover main metrics from network security and AI domains. We evaluate our XAI evaluation framework using three popular network intrusion datasets and seven AI methods with different characteristics. We release our codes for the network security community to access it as a baseline XAI framework for network IDS. Our framework shows the limitations and strengths of current black-box XAI methods when applied to network IDS.},
 author = {Arreche, Osvaldo and Guntur, Tanish R. and Roberts, Jack W. and Abdallah, Mustafa},
 doi = {10.1109/ACCESS.2024.3365140},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Explainable AI;Closed box;Network intrusion detection;Robustness;Malware;Network security;Detection algorithms;Internet security;Telecommunication traffic;Data science;Data models;Knowledge discovery;Data mining;NSL-KDD;XAI evaluation;intrusion detection systems;SHAP;explainable AI;network security;LIME;black-box AI;NSL-KDD;CICIDS-2017;RoEduNet-SIMARGL2021},
 month = {},
 number = {},
 pages = {23954-23988},
 title = {E-XAI: Evaluating Black-Box Explainable AI Frameworks for Network Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10433445,
 abstract = {Network security situation awareness enables networks to actively and effectively defend against network attacks, relying on the extraction of network situation elements as an initial and decisive step. In existing studies, the stacked sparse autoencoder (SSAE) has been employed to extract features from unlabeled network flows. However, obtaining the optimal hyperparameter combination is challenging due to its numerous hyperparameters. To address this issue, we propose a novel approach named DBO-SSAE that leverages dung beetle optimization (DBO) to select the optimal hyperparameters for SSAE automatically. Applied to the well-known UNSW-NB15 dataset, our model yields an optimal feature subset, which is evaluated across various binary classifiers with different metrics. Experimental results demonstrate that our approach improves accuracy and  $\textit{F}_{1}$ -measure by 0.2% to 1.5% while reducing the false negative rate (FNR) and false positive rate (FPR) by 0.06% to 7%, surpassing other feature extraction methods on the same classifier for the UNSW-NB15 dataset. Particularly, in conjunction with a lightweight bidirectional long short-term memory (BiLSTM), our model achieves metrics of 98.84% accuracy, 98.96%  $\textit{F}_{1}$ -measure, 1.86% FNR, and 0.6% FPR. This study could provide novel insights into the effective representation of network situation elements and lay the groundwork for a high-efficiency intrusion detection system.},
 author = {Yang, Yongchao and Zhao, Pan},
 doi = {10.1109/ACCESS.2024.3365495},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Principal component analysis;Optimization;Intrusion detection;Telecommunication traffic;Classification algorithms;Support vector machines;Encoding;Network security;Dung beetle optimization;network security;network situation element extraction;stacked sparse autoencoder},
 month = {},
 number = {},
 pages = {24014-24026},
 title = {Research on Dung Beetle Optimization Based Stacked Sparse Autoencoder for Network Situation Element Extraction},
 volume = {12},
 year = {2024}
}

@article{10433776,
 abstract = {Cybersecurity is important in the realization of various smart grid technologies. Several studies have been conducted to discuss different types of cyberattacks and provide their countermeasures. The false command injection attack (FCIA) is considered one of the most critical attacks that have been studied. Various techniques have been proposed in the literature to detect FCIAs on different components of smart grids. The predominant focus of current surveys lies on FCIAs and detection techniques for such attacks. This article presents a survey of existing works on FCIAs and classifies FCIAs in smart grids according to the targeted component. The impacts of FCIAs on smart grids are also discussed. Subsequently, this article provides an extensive review of detection studies, categorizing them based on the type of detection technique employed.},
 author = {Usama, Muhammad and Aman, Muhammad Naveed},
 doi = {10.1109/OJIA.2024.3365576},
 issn = {2644-1241},
 journal = {IEEE Open Journal of Industry Applications},
 keywords = {Smart grids;Surveys;Computer crime;Security;Critical infrastructure;Power system reliability;Safety;Artificial intelligence (AI)-based detection algorithms;command injection;cyber-physical systems (CPSs);detection techniques;model-based detection;smart grid},
 month = {},
 number = {},
 pages = {75-85},
 title = {Command Injection Attacks in Smart Grids: A Survey},
 volume = {5},
 year = {2024}
}

@article{10438436,
 abstract = {Crowd behavior recognition plays a critical role in various domains, including public safety, event management, and urban planning. Understanding crowd dynamics and detecting behaviors based on violence levels are crucial for preventing incidents and maintaining order in crowded environments. However, traditional surveillance methods fall short of providing comprehensive and real-time insights into complex crowd behavior patterns and fail to distinguish different violence levels within crowds that affect proactive decision-making. Moreover, most of the current systems do not provide reliable secure data transmission and are not viable in protecting the privacy of individuals. This paper designs an end-to-end secure and smart surveillance system, namely PublicVision, that transmits CCTV data securely to a remote central hub where a deep learning (DL) model based on Swin Transformer is utilized to identify and analyze crowd behaviors. A novel video dataset was created to train the DL model that identifies crowds based on size and violence level. The proposed system incorporates end-to-end security by creating a Dynamic Multipoint Virtual Private Network (DMVPN) and leverages the property of IP Security (IPSec) and Firewall for confidentiality and integrity during transmission and storage. Experiment analysis and real-time inference using DeepStream Software Development Kit (SDK) proved that the proposed system has significant implications for public safety, security, and crowd management in various contexts, including public spaces, transportation hubs, and large-scale events.},
 author = {Qaraqe, Marwa and Elzein, Almiqdad and Basaran, Emrah and Yang, Yin and Varghese, Elizabeth B. and Costandi, Wisam and Rizk, Jack and Alam, Nasim},
 doi = {10.1109/ACCESS.2024.3366693},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Surveillance;Behavioral sciences;Cameras;Streaming media;Security;Real-time systems;Transformers;Crowdsensing;Public security;Data security;System analysis and design;Smart devices;Crowd behavior recognition;deep learning;public safety;secure data transmission;smart surveillance;system design},
 month = {},
 number = {},
 pages = {26474-26491},
 title = {PublicVision: A Secure Smart Surveillance System for Crowd Behavior Recognition},
 volume = {12},
 year = {2024}
}

@article{10439152,
 abstract = {With the advancements in computer networks and systems, the number of security vulnerabilities and cyber attacks targeting/using these vulnerabilities continues to increase. Consequently, various intrusion detection systems (IDS) have been developed to detect cyber attacks and ensure information security. IDSs are categorized into two classes based on the data sources: Network-based intrusion detection system (NIDS) and host-based intrusion detection system (HIDS). In this systematic literature review (SLR), studies are examined that focus on HIDS or propose methods applicable to HIDS, as well as those related to IDSs that can be converted into HIDSs. The studies published between 2020 and 2023 are collected from widely used academic databases through various query statements. Filtering based on specific selection and elimination criteria is undergone by the collected studies, resulting in 21 studies for examination. Subsequently, these studies and their advantages and disadvantages are discussed. In addition, while examining the studies, five research questions are addressed. Finally, the defects, potential areas for improvement, and future research directions related to HIDSs are discussed.},
 author = {Satilmiş, Hami and Akleylek, Sedat and Tok, Zaliha Yüce},
 doi = {10.1109/ACCESS.2024.3367004},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Systematics;Monitoring;Computer hacking;Bibliographies;Databases;Telecommunication traffic;Information security;Reviews;Intrusion detection system;host-based intrusion detection system;information security;machine learning;deep learning},
 month = {},
 number = {},
 pages = {27237-27266},
 title = {A Systematic Literature Review on Host-Based Intrusion Detection Systems},
 volume = {12},
 year = {2024}
}

@article{10440279,
 abstract = {Malicious user recognition for spectrum sensing in Cognitive Radio Networks (CRNs) is a serious safety feature to safeguard effective and trustworthy process of these systems. Spectrum sensing permits CRNs to identify and employ accessible spectrum bands. As well as it is available to prospective interference and mischievous actions. To preserve network integrity, recognition of malicious consumers is vital. Deep learning (DL) based malicious consumer classification powers advanced neural network frameworks to recognize and flag possible threats inside a network. By examining numerous amounts of information, DL techniques can distinguish patterns as well as anomalies that are connected with malicious user performance plus system intrusions, scams or irregular action. This technique provides flexibility benefit that permits a network to learn and develop in evolving threats. It also offers an effectual revenue of improving network security in the difficult and active digital landscape. Therefore, this article develops an Optimal Deep Learning Empowered Malicious User Detection for Spectrum Sensing (ODL-MUDSS) in the CRN. The main intention of ODL-MUDSS model focused on automated identification and classification of MUs in CRN. To accomplish this, the ODL-MUDSS model primarily applies deep belief network (DBN) methodology for automated and accurate detection of MUs. In addition, recognition performance of DBN technique can be enhanced by use of sand cat swarm optimization (SCSO) algorithm and thereby improves the detection results. The performance validation of ODL-MUDSS technique is observed under different processes. The comprehensive outcomes stated enhanced performance of ODL-MUDSS model over other existing models with maximum accuracy of 97.75%, precision of 97.75%, recall of 97.75%, and F-score of 97.75%.},
 author = {Almuqren, Latifah and Maray, Mohammed and Alotaibi, Faiz Abdullah and Alzahrani, Abdulrahman and Mahmud, Ahmed and Rizwanullah, Mohammed},
 doi = {10.1109/ACCESS.2024.3367993},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Sensors;Cognitive radio;Training;Deep learning;Data models;Optimization;Classification algorithms;Communication systems;Radio spectrum management;Particle swarm optimization;Neural networks;Network security;Interference;Trusted computing;Threat assessment;Cognitive radio networks;communication;spectrum sensing;malicious user detection;deep learning},
 month = {},
 number = {},
 pages = {35300-35308},
 title = {Optimal Deep Learning Empowered Malicious User Detection for Spectrum Sensing in Cognitive Radio Networks},
 volume = {12},
 year = {2024}
}

@article{10440604,
 abstract = {Machine learning-based systems have presented increasing learning performance, in a wide variety of tasks. However, the problem with some state-of-the-art models is their lack of transparency, trustworthiness, and explainability. To address this problem, eXplainable Artificial Intelligence (XAI) appeared. It is a research field that aims to make black-box models more understandable to humans. The research on this topic has increased in recent years, and many methods, such as LIME (Local Interpretable Model-Agnostic Explanations) and SHAP (SHapley Additive exPlanations) have been proposed. Machine learning-based Intrusion Detection Systems (IDS) are one of the many application domains of XAI. However, most of the works about model interpretation focus on other fields, like computer vision, natural language processing, biology, healthcare, etc. This poses a challenge for cybersecurity professionals tasked with analyzing IDS results, thereby impeding their capacity to make informed decisions. In an attempt to address this problem, we have selected two XAI methods, LIME, and SHAP. Using the methods, we have retrieved explanations for the results of a black-box model, part of an IDS solution that performs intrusion detection on IoT devices, increasing its interpretability. In order to validate the explanations, we carried out a perturbation analysis where we tried to obtain a different classification based on the features present in the explanations. With the explanations and the perturbation analysis we were able to draw conclusions about the negative impact of particular features on the model results when present in the input data, making it easier for cybersecurity experts when analyzing the model results and it serves as an aid to the continuous improvement the model. The perturbations also serve as a comparison of performance between LIME and SHAP. To evaluate the degree of interpretability increase, and the explanations provided by each XAI method of the model and directly compare the XAI methods, we have performed a survey analysis.},
 author = {Gaspar, Diogo and Silva, Paulo and Silva, Catarina},
 doi = {10.1109/ACCESS.2024.3368377},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Explainable AI;Analytical models;Perturbation methods;Surveys;Internet of Things;Computer security;Machine learning;Artificial intelligence;Multilayer perceptrons;Artificial intelligence;explainability;intrusion detection system;local interpretable model-agnostic explanations;machine learning;shapley additive explanations},
 month = {},
 number = {},
 pages = {30164-30175},
 title = {Explainable AI for Intrusion Detection Systems: LIME and SHAP Applicability on Multi-Layer Perceptron},
 volume = {12},
 year = {2024}
}

@article{10443394,
 abstract = {The internet of things (IoT) is an emerging technological advancement with significant implications. It connects a wireless sensor or node network via low-power and lossy networks (LLN). The routing protocol over a low-power and lossy network (RPL) is the fundamental component of LLN. Its lightweight design effectively addresses the limitations imposed by bandwidth, energy, and memory on both LLNs and IoT devices. Notwithstanding its efficacy, RPL introduces susceptibilities, including the version number attack (VNA), which underscores the need for IoT systems to implement effective security protocols. This work reviews and categorizes the security mechanisms proposed in the literature to detect VNA against RPL-based IoT networks. The existing mechanisms are thoroughly discussed and analyzed regarding their performance, datasets, implementation details, and limitations. Furthermore, a qualitative comparison is presented to benchmark this work against existing studies, showcasing its uniqueness. Finally, this work analyzes research gaps and proposes future research avenues.},
 author = {Alfriehat, Nadia A. and Anbar, Mohammed and Karuppayah, Shankar and Rihan, Shaza Dawood Ahmed and Alabsi, Basim Ahmad and Momani, Alaa M.},
 doi = {10.1109/ACCESS.2024.3368633},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Protocols;Wireless sensor networks;Internet of Things;Reviews;Routing;Throughput;Intrusion detection;Low-power electronics;Research and development;IoT;RPL protocol;VNA;intrusion detection system;security;LLN},
 month = {},
 number = {},
 pages = {31136-31158},
 title = {Detecting Version Number Attacks in Low Power and Lossy Networks for Internet of Things Routing: Review and Taxonomy},
 volume = {12},
 year = {2024}
}

@article{10443932,
 abstract = {This paper focuses on the vulnerabilities of ADS-B, one of the avionics systems, and the countermeasures taken against these vulnerabilities proposed in the literature. Among the proposed countermeasures against the vulnerabilities of ADS-B, anomaly detection methods based on machine learning and deep learning algorithms were analyzed in detail. The advantages and disadvantages of using an anomaly detection system on ADS-B data are investigated. Thanks to advances in machine learning and deep learning over the last decade, it has become more appropriate to use anomaly detection systems to detect anomalies in ADS-B systems. To the best of our knowledge, this is the first survey to focus on studies using machine learning and deep learning algorithms for ADS-B security. In this context, this study addresses research on this topic from different perspectives, draws a road map for future research, and searches for five research questions related to machine learning and deep learning algorithms used in anomaly detection systems.},
 author = {Çevik, Nurşah and Akleylek, Sedat},
 doi = {10.1109/ACCESS.2024.3369181},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Aircraft;Anomaly detection;Surveys;Intrusion detection;Databases;Computer security;Machine learning;ADS-B;anomaly based intrusion detection system;anomaly detection system;cyber security;avionics security;deep learning;IDS;intrusion detection system;machine learning},
 month = {},
 number = {},
 pages = {35643-35662},
 title = {SoK of Machine Learning and Deep Learning Based Anomaly Detection Methods for Automatic Dependent Surveillance- Broadcast},
 volume = {12},
 year = {2024}
}

@article{10444102,
 abstract = {Security attacks are becoming more sophisticated and common as connected devices rapidly exchange personal, sensitive, and important data. Security solutions are therefore required for Internet of Things (IoT) environments. System administrators receive alerts through an automatic Network Intrusion Detection (NID) system when security breaches occur. An automatic NID can be an effective tool to protect IoT networks against various attacks. It is possible to detect intrusions using a variety of intrusion detection techniques, but the performance and class imbalance in the dataset make this a difficult process. To improve detection rates and decrease false alarms, intrusion detection accuracy must be improved. In this paper, an automatic NID system is proposed leveraging a renowned machine learning model named Random Forest (RF) on the (UNSW-NB15) dataset collected from Kaggle. The experimental results indicate that the proposed model not only has higher accuracy at 90.17% surpassing the baseline approach by 7.34%, but also has precision, recall, and F1 scores up to 90.14%, 90.17, and 90.14%, respectively. Moreover, 98.83% accuracy is achieved with a balanced class dataset by using random resampling techniques to generate synthetic data of minority attacks.},
 author = {Maghrabi, Louai A.},
 doi = {10.1109/ACCESS.2024.3369237},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Training;Random forests;Computational modeling;Feature extraction;Convolutional neural networks;Intrusion detection;Classification algorithms;Machine learning;Intrusion detection;IOT;BERT;classification;machine learning;random forest},
 month = {},
 number = {},
 pages = {30839-30851},
 title = {Automated Network Intrusion Detection for Internet of Things: Security Enhancements},
 volume = {12},
 year = {2024}
}

@article{10445149,
 abstract = {This article presents the Augmented Internet of Things (AIoT) framework for cooperatively distributed deep blockchain-assisted vehicle networks. AIoT framework splits the vehicle application into various tasks while executing them on different computing nodes. The vehicle application has different constraints, such as security, time, and accuracy, which are considered during processing them on parallel computing nodes (e.g., fog and cloud). We propose a partitioned AIoT scheme, dividing vehicular tasks into local and remote tasks. The objective is to minimize delays and efficiently execute urgent tasks, such as vehicle, pedestrian, and traffic signals on local vehicles. The existing blockchain technologies suffer from many security issues, such as anonymous node issues and malware attacks in blockchain blocks. This is why we present the combined deep convolutional neural network (DCNN)-assisted Proof-of-Trust Miner (PoTM) scheme. It safely handles tasks in different blocks. The smart contract is a human-written piece of code in blockchain technologies so that malicious code can be integrated into blockchain blocks during the registration of vehicles among nodes. The main limitation of smart contracts is that they are not changeable and cannot be changed once executed for any block. To avoid this situation, we present an augmented adaptive trust management credibility score scheme (TMCSS) scheme that registers the vehicles before starting any services at blockchain miners. These registration certificates are changeable once DCNN detects any malicious activity in the vehicle data. Simulation results show that the proposed schemes improved delays by 35%, reduced the failure ratio of transactions by 39%, and enhanced overall transactions with the minimum failure compared to existing blockchain technologies for road-cooperation services in networks.},
 author = {Lakhan, Abdullah and Mohammed, Mazin Abed and Zebari, Dilovan Asaad and Abdulkareem, Karrar Hameed and Deveci, Muhammet and Marhoon, Haydar Abdulameer and Nedoma, Jan and Martinek, Radek},
 doi = {10.1109/JIOT.2024.3362981},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Blockchains;Cloud computing;Trust management;Smart contracts;Task analysis;Peer-to-peer computing;Malware;Augmented Internet of Things (AIoT);blockchain;malicious;Proof of Work (PoW);sustainability;trust management;trust management credibility score scheme (TMCSS);vehicular},
 month = {Nov},
 number = {22},
 pages = {35825-35838},
 title = {Augmented IoT Cooperative Vehicular Framework Based on Distributed Deep Blockchain Networks},
 volume = {11},
 year = {2024}
}

@article{10445341,
 abstract = {The demand for cyber-physical systems (CPSs) has recently increased in various domains, such as smart grids, intelligent transportation, and critical infrastructure. The massive data networks and communication layers generated make CPSs vulnerable to threats and cyberattacks. To mitigate these threats, artificial intelligence (AI) approaches are employed. However, AI models struggle to keep up with the constantly changing attack landscape. This study investigates the application of extreme gradient boosting (XGBoost) and long-short-term memory (LSTM) AI models for cyberattack detection in a CPS. Accuracy, precision, recall, and the F1-score validate the approach as evaluation metrics. The methods were tested on a gas pipeline industrial control system dataset and other benchmark datasets, such as NetML-2020 and IoT-23, which contain various cyberattacks. The performance of the two methods was found to be better than other models such as support vector machine (SVM) and artificial neural networks (ANN) on several evaluation metrics. Finally, we present recommendations for future research.},
 author = {Abdullahi, Mujaheed and Alhussian, Hitham and Aziz, Norshakirah and Abdulkadir, Said Jadid and Alwadain, Ayed and Muazu, Aminu Aminu and Bala, Abubakar},
 doi = {10.1109/ACCESS.2024.3370436},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cyberattack;Artificial intelligence;Sensors;Data models;Intrusion detection;Analytical models;Pipelines;Detection algorithms;Machine learning;Deep learning;Long short term memory;Cyber-physical systems;Artificial intelligence;attack detection;cyberattacks;cyber-physical systems;deep learning;machine learning;LSTM;XGBoost},
 month = {},
 number = {},
 pages = {31988-32004},
 title = {Comparison and Investigation of AI-Based Approaches for Cyberattack Detection in Cyber-Physical Systems},
 volume = {12},
 year = {2024}
}

@article{10452322,
 abstract = {The Smart Grid is a modern power grid that relies on advanced technologies to provide reliable and sustainable electricity. However, its integration with various communication technologies and IoT devices makes it vulnerable to cyber-attacks. Such attacks can lead to significant damage, economic losses, and public safety hazards. To ensure the security of the smart grid, increasingly strong security solutions are needed. This paper provides a comprehensive analysis of the vulnerabilities of the smart grid and the different approaches for detecting cyber-attacks. It examines the different vulnerabilities of the smart grid, including system vulnerabilities and cyber-attacks, and discusses the vulnerabilities of all its elements. The paper also investigates various approaches for detecting cyber-attacks, including rule-based, signature-based, anomaly detection, and ma-chine learning-based methods, with a focus on their effectiveness and related research. Finally, prospective cybersecurity approaches for the smart grid, such as AI approaches and blockchain, are discussed along with the challenges and future prospects of cyberattacks on the smart grid. The paper’s findings can help policymakers and stakeholders make informed decisions about the security of the smart grid and develop effective strategies to protect it from cyber-attacks.},
 author = {Mohammed, Saad Hammood and Al-Jumaily, Abdulmajeed and Singh, Mandeep S. Jit and Jiménez, Víctor P. Gil and Jaber, Aqeel S. and Hussein, Yaseein Soubhi and Al-Najjar, Mudhar Mustafa Abdul Kader and Al-Jumeily, Dhiya},
 doi = {10.1109/ACCESS.2024.3370911},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart grids;Support vector machines;Feature extraction;Cyberattack;Power system reliability;Machine learning;Reviews;Anomaly detection;Machine learning;Performance evaluation;Sustainable development;Power grids;Artificial intelligence;Blockchains;Smart grid;cyber-attacks;detection methodologies;anomaly detection;machine learning;future prospects},
 month = {},
 number = {},
 pages = {44023-44042},
 title = {A Review on the Evaluation of Feature Selection Using Machine Learning for Cyber-Attack Detection in Smart Grid},
 volume = {12},
 year = {2024}
}

@article{10452338,
 abstract = {This article offers a comprehensive overview of recent literature on the HTTP/2 protocol and conducts an analysis of the security threats and DDoS attack typologies associated with HTTP/2. The investigation revealed that the introduction of new features in HTTP/2 has significantly improved the network transmission speed and utilization. However, these advancements have also brought forth a series of emerging network security risks. This study examines the current state of the art in DDoS attacks tailored for HTTP/2 and their detection methods, proposing future research directions in the field of attack detection. By analyzing the distinctive features of HTTP/2 protocol, the study suggests extending DDoS attack detection techniques established for HTTP/1 to the realm of HTTP/2. Furthermore, the research underscores the ease with which adversaries can exploit the intrinsic multiplexing in HTTP/2 to launch a large number of malicious requests, leading to severe depletion of network bandwidth and exhaustion of valuable server resources. Additionally, it highlights the potential applicability of deep learning algorithms in the context of the HTTP/2 protocol. Additionally, the article proposes strategies to address challenges associated with DDoS attacks and the scarcity of adequate datasets for HTTP/2. This research contributes to a comprehensive understanding of the security implications surrounding the HTTP/2 protocol and provides valuable insights for advancing DDoS attack detection technologies.},
 author = {Ming, Liang and Leau, Yu-Beng and Xie, Ying},
 doi = {10.1109/ACCESS.2024.3371013},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Protocols;Denial-of-service attack;Servers;Network security;Multiplexing;TCP;Optimization methods;Deep learning;Machine learning;HTTP;Hypertext systems;HTTP;HTTP/2;DDoS;deep-learning;machine-learning},
 month = {},
 number = {},
 pages = {33296-33308},
 title = {Distributed Denial of Service Attack in HTTP/2: Review on Security Issues and Future Challenges},
 volume = {12},
 year = {2024}
}

@article{10456888,
 abstract = {While the Internet of Things (IoT) paradigm has transformed connectivity, it has also brought with it previously unheard-of security risks. The categorization of IoT attacks using several machine learning techniques and a deep learning method is the main emphasis of this research. In addition to proposing a binary and multiclass classification framework with Machine Learning (ML) algorithms like Random Forest (RF), Decision tree (DT), Extra Tree Classifier (ETC), Support Vector Machine (SVM), and k-Nearest Neighbor (KNN) and Deep Learning (DL) architectures like Deep Neural Network (DNN), the study assesses a wide range of attack types in IoT environments. Benchmark datasets with real-world IoT attack scenarios, such as Edge-IIoTset, are used for experimentation. Preprocessing is done on the dataset using Principal Componenet Analysis (PCA) for feature selection, Synthetic Minority Oversampling Technique to handle class imbalance and Standard Scaling for feature scaling. These approaches’ comparative performance and efficacy are examined. The outcomes indicate how successful the DL model in managing intricate attack patterns and the generalization capabilities of ML algorithms across various attack classes. The DNN model yields the best results, with 100% accuracy for binary classification, 96.15% accuracy for 6-class classification, and 94.68% accuracy for 15-class classification. Further, 10-fold cross validation has been applied to make sure that the model does not overfit. This work contributes to the improvement of IoT security mechanisms by offering insights into the selection of appropriate approaches for binary and multiclass classification of threats.},
 author = {Sadhwani, Sapna and Modi, Urvi Kavan and Muthalagu, Raja and Pawar, Pranav M.},
 doi = {10.1109/ACCESS.2024.3371996},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Intrusion detection;Sensors;Industrial Internet of Things;Malware;Machine learning algorithms;Machine learning;Detection algorithms;Internet of Things;machine learning;security;intrusion detection system},
 month = {},
 number = {},
 pages = {34720-34740},
 title = {SmartSentry: Cyber Threat Intelligence in Industrial IoT},
 volume = {12},
 year = {2024}
}

@article{10457002,
 abstract = {The rise of Internet of Things (IoT) has led to increased security risks, particularly from botnet attacks that exploit IoT device vulnerabilities. This situation necessitates effective Intrusion Detection Systems (IDS), that are accurate, lightweight, and fast (having less inference time), designed particularly to detect botnet attacks in resource constrained IoT devices. This paper proposes SkipGateNet, a novel deep learning model designed for detecting Mirai and Bashlite botnet attacks in resource constrained IoT and fog computing environments. SkipGateNet is a lightweight, fast model combining 1D-Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) layers. The novelty of this model lies in the integration of ‘Learnable Skip Connections’. These connections feature gating mechanisms that enhance detection by focusing on relevant features and ignoring irrelevant ones. They add adaptability to the architecture, performing feature selection and propagating only essential features to deeper layers. Tested on the N-BaIoT dataset, SkipGateNet efficiently detects ten types of botnet attacks, with a remarkable test accuracy of 99.91%. It is also compact (2596.87 KB) and demonstrates a quick inference time of 8.0 milliseconds, suitable for real-time implementation in resource-limited settings. While evaluating its performance, parameters like precision, recall, accuracy, and F1 score were considered, along with statistical reliability measures like Cohen’s Kappa Coefficient and Matthews Correlation Coefficient. These highlight its reliability and effectiveness in IoT security challenges. The paper also compares SkipGateNet to existing models and four other deep learning architectures, including two sequential CNN architectures, a simple CNN+LSTM architecture, and a CNN+LSTM with standard skip connections. SkipGateNet surpasses all in accuracy and inference time, demonstrating its superiority in addressing IoT security issues.},
 author = {Alshehri, Mohammed S. and Ahmad, Jawad and Almakdi, Sultan and Qathrady, Mimonah Al and Ghadi, Yazeed Yasin and Buchanan, William J.},
 doi = {10.1109/ACCESS.2024.3371992},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Botnet;Feature extraction;Computational modeling;Computer architecture;Intrusion detection;Deep learning;Network security;Botnets;botnet attacks;bashlite;intrusion detection;Mirai},
 month = {},
 number = {},
 pages = {35521-35538},
 title = {SkipGateNet: A Lightweight CNN-LSTM Hybrid Model With Learnable Skip Connections for Efficient Botnet Attack Detection in IoT},
 volume = {12},
 year = {2024}
}

@article{10457539,
 abstract = {Industry 4.0 is fundamentally based on networked systems. Real-time communication between machines, sensors, devices, and people makes it easier to transmit the data needed to make decisions. Informed decision-making is empowered by the comprehensive insights and analytics made possible by this connectedness in conjunction with information transparency. Industry 4.0-based wireless sensor networks (WSNs) are an integral part of modern industrial operations however, these networks face escalating cybersecurity threats. These networks are always vulnerable to cyber-attacks as they continuously collect data and optimize processes. Increased connections make people more susceptible to cyberattacks, necessitating the use of strong cybersecurity measures to protect sensitive data. This study proposes a predictive framework intended to intelligently prioritize and prevent cybersecurity intrusions on WSNs in Industry 4.0. The proposed framework enhances the cybersecurity of WSNs in Industry 4.0 using a multi-criteria approach. It implements machine-learning and deep-learning algorithms for cybersecurity intrusion detection in WSNs of Industry 4.0 and provides prevention by assigning priorities to the threats based on the situation and nature of the attacks. We implemented three models, i.e., Decision Tree, MLP, and Autoencoder, as proposed algorithms in the framework. For multidimensional classification and detection of cybersecurity intrusions, we implemented Decision Tree and MLP models. For binary classification and detection of cybersecurity intrusions in WSNs of Industry 4.0, we implemented Autoencoder model. Simulation results show that the Decision Tree model provides an accuracy of 99.48%, precision of 99.49%, recall of 99.48%, and F1 score of 99.49% in the detection and classification of cybersecurity intrusions. The MLP model provides an accuracy of 99.52%, precision of 99.5%, recall of 99.5%, and F1 score of 99.5% in the detection and classification of cybersecurity intrusions. The implementation of Autoencoder with binary classification yields an accuracy of 91%, a precision of 92%, a recall of 91%, and an F1 score of 91%. The benchmark models, i.e., Random Forest (RF) for multidimensional classification and Logistic Regression (LR) for binary classification, have also been implemented. We compared the performance of the benchmark models with the models implemented in the proposed framework, revealing that the models in the proposed framework},
 author = {Al-Quayed, Fatima and Ahmad, Zulfiqar and Humayun, Mamoona},
 doi = {10.1109/ACCESS.2024.3372187},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Computer security;Fourth Industrial Revolution;Sensors;Intrusion detection;Wireless communication;Cyberattack;Detection algorithms;Predictive models;Machine learning;Deep learning;Cybersecurity;WSN;detection;prediction;intrusions;machine learning and deep learning},
 month = {},
 number = {},
 pages = {34800-34819},
 title = {A Situation Based Predictive Approach for Cybersecurity Intrusion Detection and Prevention Using Machine Learning and Deep Learning Algorithms in Wireless Sensor Networks of Industry 4.0},
 volume = {12},
 year = {2024}
}

@article{10458125,
 abstract = {Network intrusion detection in the Internet of Things (IoT) framework has posed considerable challenges in recent decades. A wide variety of machine-learning approaches are introduced in network intrusion detection. The existing methodologies commonly lack consistency in achieving optimal performance across various multi-class categorization tasks. The present study elucidates implementing a unique intrusion system with the primary objective of enriching the efficacy of network intrusion detection. In the initial phase, it is imperative to employ data-denoising methodologies to effectively tackle the issue of data imbalance. In the next step, the enhanced Crow search algorithm is used to determine the most significant features that aid in better classifying intrusion attacks. In the final phase, the ensemble classifier takes the selected features as input to categorize the standard and invader labels. The present work introduces an ensemble mechanism that comprises four distinct classifiers. The assessment of the proposed approach is validated on two denoised datasets, specifically NSL-KDD and UNSW-NB15. The experimental outcomes demonstrate that the formulated approach achieves exceptional accuracy of 99.4% and 99.2% for the NSL-KDD and UNSW-NB15 datasets, respectively.},
 author = {Jayalatchumy, D. and Ramalingam, Rajakumar and Balakrishnan, Aravind and Safran, Mejdl and Alfarhood, Sultan},
 doi = {10.1109/ACCESS.2024.3372859},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computational modeling;Classification algorithms;Heuristic algorithms;Support vector machines;Metaheuristics;Computer science;Feature extraction;Intrusion detection;Computer network management;Search methods;Machine learning;Ensemble learning;Internet of Things;Network intrusion detection;crow search algorithm;machine learning;ensemble learning;Internet of Things},
 month = {},
 number = {},
 pages = {33218-33235},
 title = {Improved Crow Search-Based Feature Selection and Ensemble Learning for IoT Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10459085,
 abstract = {As cloud computing continues to evolve, the need for efficient and secure management of virtual machine (VM) migrations has become increasingly evident. Traditional models often fall short in optimizing load balancing and energy consumption while ensuring a high level of security. In this work, we propose the load balancing and energy-efficient migration model, an innovative approach that leverages bioinspired algorithms and advanced security measures to optimize VM migrations. The initial novelty of our model is the integration of Genetic Algorithms with Ant Colony Optimization for resource scheduling operations. These algorithms were specifically chosen for their proven effectiveness in solving complex optimization problems by simulating natural processes. Additionally, our model incorporates a deep reinforcement learning-based iterative-learning contextual side chaining model to enhance security measures. This approach not only learns and adapts to new security threats over time but also utilizes contextual side-chaining to link related security events, thereby providing a robust defense mechanism against potential threats. The affinity between VMs and physical machines is quantified using K Means clustering and fuzzy logic, which ensures optimal load balancing while accounting for the uncertainty inherent in the migration process. Furthermore, we employ bidirectional long short-term memory networks with recurrent graph neural network, for accurate workload prediction and informed migration decision making process. The selection of these techniques is grounded in their proven capability to analyze historical data and predict future trends with high accuracy levels. Our proposed model demonstrates marked improvements in several key performance metrics. We achieved a 4.5% reduction in makespan, a 4.9% increase in deadline hit ratio, and a 3.9% improvement in task diversity. Furthermore, computational complexity was reduced by 8.3%, VM migration efficiency improved by 2.5%, and the delay of computation was significantly reduced by 9.5%. Importantly, the integration of the Iterative-learning Contextual Side chaining Model significantly enhanced the security and quality of service (QoS) under attack scenarios, resulting in a 10.4% improvement in response speed, a 2.5% reduction in energy consumption during block mining, a 3.9% improvement in throughput, and an 8.5% reduction in storage costs. This load balancing and energy-efficient migration model represents a significant advancement in addressing the challenges of load balancing, energy efficiency, and security in VM migrations. Through the meticulous integration of bioinspired algorithms, advanced security measures, and machine learning techniques, our model provides a comprehensive and innovative solution that markedly improves system performance, reduces energy consumption, and fortifies security, thereby paving the way for a more efficient and secure cloud computing ecosystem.},
 author = {Brahmam, Madala Guru and R, Vijay Anand},
 doi = {10.1109/ACCESS.2024.3373465},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Cloud computing;Load management;Computational modeling;Biological system modeling;Energy consumption;Virtual machining;Bio-inspired computing;Machine learning;Ant colony optimization;Fuzzy systems;Virtual machine migrations;bioinspired algorithms;advanced security measures;machine learning techniques;cloud computing optimization},
 month = {},
 number = {},
 pages = {39351-39374},
 title = {VMMISD: An Efficient Load Balancing Model for Virtual Machine Migrations via Fused Metaheuristics With Iterative Security Measures and Deep Learning Optimizations},
 volume = {12},
 year = {2024}
}

@article{10459247,
 abstract = {Consumer Electronics (CEs) are smart devices using IoT for connectivity. They’re susceptible to attacks like DoS, DDoS, and Web attacks, impairing functions and enabling remote hijacking. Attackers can exploit CEs to target other systems, like vehicles. Malicious code can propagate through networks or CEs, causing vehicle failures. Existing ML/DL based IDS have high classification accuracy and robustness in traditional Internet environments, but they are overly complex for performance improvement, which hinders their deployment in edge small computing environments. Furthermore, the comparison experiments of these intrusion detection algorithms with other algorithms are not sufficiently comprehensive to evaluate their performance in small computing environments. Therefore, balancing “detection performance and resource consumption” is a key issue in CE network detection. To address this issue, this paper proposes a hybrid feature selection model based on chi-square test and information gain combined Ig-Chi, which effectively reduces the feature dimensionality and improves the classification accuracy of classifiers for high-dimensional data sets. Additionally, layered intrusion detection is employed to perform intrusion detection on the data after feature selection. The experiments on four public data sets demonstrate that this method surpasses six ML/DL algorithms in terms of accuracy and resource indicators.},
 author = {Chen, Xuejiao and Wang, Pan and Yang, Yahong and Liu, Minyao},
 doi = {10.1109/TCE.2024.3373126},
 issn = {1558-4127},
 journal = {IEEE Transactions on Consumer Electronics},
 keywords = {Intrusion detection;Random forests;Computational modeling;Classification algorithms;Wireless sensor networks;Regression analysis;Feature extraction;Intrusion detection;consumer electronic;Internet of Things;deep learning;deep forest;resource-constraint},
 month = {May},
 number = {2},
 pages = {4976-4987},
 title = {Resource-Constraint Deep Forest-Based Intrusion Detection Method in Internet of Things for Consumer Electronic},
 volume = {70},
 year = {2024}
}

@article{10460558,
 abstract = {The primary objective of an anonymity tool is to protect the anonymity of its users through the implementation of strong encryption and obfuscation techniques. As a result, it becomes very difficult to monitor and identify users’ activities on these networks. Moreover, such systems have strong defensive mechanisms to protect users against potential risks, including the extraction of traffic characteristics and website fingerprinting. However, the strong anonymity feature also functions as a refuge for those involved in illicit activities who aim to avoid being traced on the network. As a result, a substantial body of research has been undertaken to examine and classify encrypted traffic using machine-learning techniques. This paper presents a comprehensive examination of the existing approaches utilized for the categorization of anonymous traffic as well as encrypted network traffic inside the darknet. Also, this paper presents a comprehensive analysis of methods of darknet traffic using ML (machine learning) techniques to monitor and identify the traffic attacks inside the darknet.},
 author = {Saleem, Javeriah and Islam, Rafiqul and Islam, Md. Zahidul},
 doi = {10.1109/ACCESS.2024.3373769},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Systematics;Reviews;Monitoring;Internet;Dark Web;Protocols;Bibliographies;Cyberattack;Threat assessment;Dark Web;Data privacy;Data security;Network security;Telecommunication traffic;Cyberattack;cyber threat intelligence;dark web;data privacy;data security;network security;machine learning;traffic analysis;darknet traffic},
 month = {},
 number = {},
 pages = {42423-42452},
 title = {Darknet Traffic Analysis: A Systematic Literature Review},
 volume = {12},
 year = {2024}
}

@article{10464280,
 abstract = {Software Defined network (SDN), as a new network architecture, is the direction of future network development. By decoupling the control plane and data plane of the network, the control and management of network resources can be improved. However, SDN centralized controllers become the target of malicious attacks, prone to the risk of single point of failure, of which DDoS attacks are the main attack behavior. Through extensive literature investigation, this paper systematically reviews the latest progress of DDoS attack detection in SDN environment. Firstly, the SDN architecture and corresponding DDoS attacks are described, and the commonly used data sets and evaluation indicators are summarized. Secondly, the data preprocessing technology is summarized, and the data dimensionality reduction technology is introduced in detail. Then, at the level of detection technology, it focuses on the advantages and disadvantages of detection algorithms based on statistical analysis, machine learning and deep learning. Finally, the challenges of current research are analyzed, and the future development direction is forecasted. In order to provide reference for future research and development, at the same time, it is of great significance to improve the safety of SDN products in the future.},
 author = {Wang, Heyu and Li, Yixuan},
 doi = {10.1109/ACCESS.2024.3375395},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Protocols;Computer crime;Systematics;Switches;Software defined networking;Security;Entropy;Machine learning;Deep learning;Network architecture;SDN;DDoS;entropy;machine learning;deep learning},
 month = {},
 number = {},
 pages = {38351-38381},
 title = {Overview of DDoS Attack Detection in Software-Defined Networks},
 volume = {12},
 year = {2024}
}

@article{10466532,
 abstract = {Polyp segmentation within colonoscopy video frames using deep learning models has the potential to automate colonoscopy screening procedures. This could help improve the early lesion detection rate and in vivo characterization of polyps which could develop into colorectal cancer. Recent state-of-the-art deep learning polyp segmentation models have combined Convolutional Neural Network (CNN) architectures and Transformer Network (TN) architectures. Motivated by the aim of improving the performance of polyp segmentation models and their robustness to data variations beyond those covered during training, we propose a new CNN-TN hybrid model named the FCB-SwinV2 Transformer. This model was created by making extensive modifications to the recent state-of-the-art FCN-Transformer, including replacing the TN branch architecture with a SwinV2 U-Net. The performance of the FCB-SwinV2 Transformer is evaluated on the popular colonoscopy segmentation benchmarking datasets Kvasir-SEG, CVC-ClinicDB and ETIS-LaribPolypDB. Generalizability tests are also conducted to determine if models can maintain accuracy when evaluated on data outside of the training distribution. The FCB-SwinV2 Transformer consistently achieves higher mean Dice and mean IoU scores when compared to other models reported in literature and therefore represents new state-of-the-art performance. The importance of understanding subtleties in evaluation metrics and dataset partitioning are also demonstrated and discussed. Code available: https://github.com/KerrFitzgerald/Polyp_FCB-SwinV2Transformer},
 author = {Fitzgerald, Kerr and Bernal, Jorge and Histace, Aymeric and Matuszewski, Bogdan J.},
 doi = {10.1109/ACCESS.2024.3376228},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Transformers;Feature extraction;Decoding;Convolutional neural networks;Colonoscopy;Deep learning;Training;Image segmentation;Biomedical image processing;Tumors;Colorectal cancer;Medical image processing;polyp segmentation;deep learning;SwinV2;transformer},
 month = {},
 number = {},
 pages = {38927-38943},
 title = {Polyp Segmentation With the FCB-SwinV2 Transformer},
 volume = {12},
 year = {2024}
}

@article{10466560,
 abstract = {Modern networks are crucial for seamless connectivity but face various threats, including disruptive network attacks, which can result in significant financial and reputational risks. To counter these challenges, AI-based techniques are being explored for network protection, requiring high-quality datasets for training. In this study, we present a novel methodology utilizing a Ubuntu Base Server to simulate a virtual network environment for real-time collection of network attack datasets. By employing Kali Linux as the attacker machine and Wireshark for data capture, we compile the Server-based Network Attack (SNA) dataset, showcasing UDP, SYN, and HTTP flood network attacks. Our primary goal is to provide a publicly accessible, server-focused dataset tailored for network attack research. Additionally, we leverage advanced AI methods for real-time detection of network attacks. Our proposed meta-RF-GNB (MRG) model combines Gaussian Naive Bayes and Random Forest techniques for predictions, achieving an impressive accuracy score of 99.99%. We validate the efficiency of MRG using cross-validation, obtaining a notable mean accuracy of 99.94% with a minimal standard deviation of 0.00002. Furthermore, we conducted a statistical t-test to evaluate the significance of MRG compared to other top-performing models.},
 author = {Rustam, Furqan and Raza, Ali and Qasim, Muhammad and Posa, Sarath Kumar and Jurcut, Anca Delia},
 doi = {10.1109/ACCESS.2024.3375878},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Network security;Machine learning;Data models;Intrusion detection;Computer network management;Real-time systems;Artificial intelligence;Servers;Predictive models;Linux;Cyberattack;Network security;Wireshark;machine learning;network dataset;intrusion detection},
 month = {},
 number = {},
 pages = {39614-39627},
 title = {A Novel Approach for Real-Time Server-Based Attack Detection Using Meta-Learning},
 volume = {12},
 year = {2024}
}

@article{10468586,
 abstract = {Network intrusion detection technology has always been an indispensable protection mechanism for industrial network security. The rise of new forms of network attacks has resulted in a heightened demand for these technologies. Nevertheless, the current models’ effectiveness is subpar. We propose a new Deformable Vision Transformer (DE-VIT) method to address this issue. DE-VIT introduces a new deformable attention mechanism module, where the positions of key-value pairs in the attention mechanism are selected in a data-dependent manner, allowing it to focus on relevant areas, capture more informative features, and avoid excessive memory and computational costs. In addition to using deformable convolutions instead of regular convolutions in embedding layers to enhance the receptive field of patches, a sliding window mechanism is also employed to utilize edge information fully. In Parallel, we use a layered focal loss function to improve classification performance and address data imbalance issues. In summary, DE-VIT reduces computational complexity and achieves better results. We conduct experimental simulations on the public intrusion detection datasets, and the accuracy of the enhanced intrusion detection model surpasses that of the Deep Belief Network with Improved Kernel-Based Extreme Learning (DBN-KELM). It reaches 99.5% and 97.5% on the CIC IDS2017 and UNSW-NB15 datasets, exhibiting an increase of 8.5% and 9.1%, respectively.},
 author = {He, Kan and Zhang, Wei and Zong, Xuejun and Lian, Lian},
 doi = {10.1109/ACCESS.2024.3376434},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computer network management;Deformable models;Convolutional neural networks;Vision sensors;Network intrusion detection;Industrial engineering;Transformers;Network intrusion detection;deformable vision transformer;deformable convolution;deformable attention mechanism;vision transformer},
 month = {},
 number = {},
 pages = {44335-44350},
 title = {Network Intrusion Detection Based on Feature Image and Deformable Vision Transformer Classification},
 volume = {12},
 year = {2024}
}

@article{10472482,
 abstract = {Internet of Medical Things (IoMT) are a kind of Internet of Things (IoT) systems which are used in the healthcare domain. Nowadays, there are an abundance of wearable smart devices, either commercial or clinical, which can be used to collect vital signs and transmit the collected data to remote servers for further analysis. Remote patient monitoring, smart diagnostics, and autonomous control of chronic diseases are examples of different healthcare services that can be provided by these systems at a lower cost and higher efficiency compared to traditional healthcare settings. However, as data related to patients’ health status and treatment history, transmitted in these systems, are highly confidential and private, security and privacy concerns in their widespread adoption may arise. Deap Learning (DL) algorithms, with their ability in extracting knowledge from big data generated in these systems, can be leveraged to design smart security mechanisms. In this survey study, the recent literature on the DL-assisted security and privacy provisioning frameworks in IoMT systems are categorized and summarized with respect to their main contributions. Finally, some possible future directions are introduced to assist interested researchers to continue research in this domain.},
 author = {Pakrooh, Rambod and Jabbari, Abdollah and Fung, Carol},
 doi = {10.1109/ACCESS.2024.3377561},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Surveys;Data privacy;Medical services;Reviews;Privacy;Internet of Medical Things;Deep learning;Patient monitoring;Medical services;Smart devices;Medical diagnosis;Deep learning;Internet of Medical Things;privacy;security;survey},
 month = {},
 number = {},
 pages = {40610-40621},
 title = {Deep Learning-Assisted Security and Privacy Provisioning in the Internet of Medical Things Systems: A Survey on Recent Advances},
 volume = {12},
 year = {2024}
}

@article{10473999,
 abstract = {In the contemporary cybersecurity landscape, robust attack detection mechanisms are important for organizations. However, the current state of research in Software-Defined Networking (SDN) suffers from a notable lack of recent SDN-OpenFlow-based datasets. This study seeks to bridge this gap by introducing a novel dataset for intrusion detection in Software-Defined Networking named SDNFlow. The dataset, derived from OpenFlow statistics gathered from real traffic, integrates a comprehensive range of network activities. An empirical evaluation leveraging diverse Machine and deep Learning algorithms was performed. Namely, Logistic regression, decision tree, random forest, K-nearest neighbors, Support Vector Machines, and Multilayer Perceptron were tested getting pretty good results with a precision average of 98% to 99% in binary classification and from 97% to 99% in multiclass classification depending of the attack, we highlight the efficacy of K-Nearest Neighbors (KNN) for traffic classification, particularly in detecting DDoS attacks and port scanning. The dataset is valuable for evaluating intrusion detection systems within SDN environments and deepening the understanding of traffic patterns in Software Defined Networks.},
 author = {Buzzio-García, Jorge and Vergara, Jaime and Ríos-Guiral, Santiago and Garzón, Christian and Gutiérrez, Sergio and Botero, Juan F. and Quiroz-Arroyo, Jose Luis and Pérez-Díaz, Jesús Arturo},
 doi = {10.1109/ACCESS.2024.3378271},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Denial-of-service attack;Telecommunication traffic;Computer crime;Traffic control;Software defined networking;Internet of Things;Data models;Intrusion detection;Programmable control;Dataset;intrusion detection systems;OpenFlow;programmable networks;software defined networking},
 month = {},
 number = {},
 pages = {42163-42180},
 title = {Exploring Traffic Patterns Through Network Programmability: Introducing SDNFLow, a Comprehensive OpenFlow-Based Statistics Dataset for Attack Detection},
 volume = {12},
 year = {2024}
}

@article{10477421,
 abstract = {In this era, plenty of wireless devices are being used with the support of WI-FI (Wireless Fidelity) and need to be maintained and authorized. Wireless Sensor Networks (WSN), a cornerstone of modern wireless technology, offer cost-efficient solutions for diverse monitoring tasks but are exposed to many security threats, including unauthorized access, attacks, and suspicious activities. These vulnerabilities can significantly degrade the performance and reliability of WSNs, making the early detection and mitigation of such threats imperative. Intrusion Detection Systems (IDS) are crucial tools in safeguarding WSNs against these challenges. Numerous studies focus on enhanced Intrusion Detection model accuracy and decrease in loss with higher Detection Rate and lower False Alarm Rate, because of this, eliminating the repetitive feature of the dataset is exhibited. This study introduces a sophisticated Network Intrusion Detection System (NIDS) to safeguard Wi-Fi-based WSNs from prevalent cyber threats, such as impersonation, flooding, and injection attacks. At the heart of our approach is a meticulous feature selection process that enhances the dataset’s utility by eliminating null values, substituting unknown entries with a placeholder (‘NONE’), and refining the feature set to include only the most relevant indicators of potential security breaches. Initially, from a pool of 154 features, a subset of 76 is selected, further narrowed down to 13 pivotal features, ensuring a focused and efficient analysis. Employing standard scaler function for feature scaling and preprocessing, this research train proposed a Convolutional Neural Network (CNN) based approach aiming for optimal intrusion detection and prevention across multiclass classifications within WSN environments. The study aims to enhance detection accuracy, reduce loss values, and decrease false alarm rates, comparing it to CNN, Deep Neural Network (DNN) (5), DNN (3), and (Long Short-Term Memory) LSTM networks. The model’s performance is evaluated using various metrics, including precision, recall, support, F1 score, and macro-average. The culmination of our research efforts is evidenced by the exceptional performance of the CNN model, achieving an impressive accuracy rate of 97% and a loss metric of 0.14, all while maintaining a minimal False Alarm Rate. This study significantly advances IDS accuracy while simultaneously reducing false alarms, thus fortifying the security posture of WSNs in the face of evolving cyber threats.},
 author = {Sadia, Halima and Farhan, Saima and Haq, Yasin Ul and Sana, Rabia and Mahmood, Tariq and Bahaj, Saeed Ali Omer and Khan, Amjad Rehman},
 doi = {10.1109/ACCESS.2024.3380014},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Feature extraction;Intrusion detection;Communication system security;Internet of Things;Convolutional neural networks;Wireless networks;Security;Wireless fidelity;WSN;Wi-Fi;NIDS;WIDS attacks;security issues;network threats;feature engineering;multiclass classification;inclusive innovations},
 month = {},
 number = {},
 pages = {52565-52582},
 title = {Intrusion Detection System for Wireless Sensor Networks: A Machine Learning Based Approach},
 volume = {12},
 year = {2024}
}

@article{10477980,
 abstract = {The Industrial Internet of Things (IIoT) comprises a variety of systems, smart devices, and an extensive range of communication protocols. Hence, these systems face susceptibility to privacy and security challenges, making them prime targets for malicious attacks that can result in harm to the overall system. Privacy breach issues are a notable concern within the realm of IIoT. Various intrusion detection systems based on machine learning (ML) and deep learning (DL) have been introduced to detect malicious activities within these networks and identify attacks. However, traditional ML and DL models encounter significant hurdles when faced with highly imbalanced training data and repetitive patterns within network datasets, hampering their performance in distinguishing between various classes of attacks. To overcome the challenges inherent in existing systems, this paper presents a self-attention-based deep convolutional neural network (SA-DCNN) model designed for monitoring the IIoT networks and detecting malicious activities. The SA mechanism computes the significance value for each input feature, and the DCNN processes these parameters to detect IIoT network behavior. Additionally, a two-step cleaning method has been implemented to eliminate redundancy within the training data, considering both intra-class and cross-class samples. Furthermore, to tackle the issue of underfitting, we have employed a mutual information-based feature filtering method. This method ranks all the features in descending order based on their mutual information and subsequently removes the features with negative impact from the dataset. The performance of the SA-DCNN model is assessed using IoTID20 and Edge-IIoTset datasets. Moreover, the proposed study is demonstrated through a comprehensive comparison with other ML and DL models, as well as against relevant studies, showcasing the superior performance and efficacy of the proposed model.},
 author = {Alshehri, Mohammed S. and Saidani, Oumaima and Alrayes, Fatma S. and Abbasi, Saadullah Farooq and Ahmad, Jawad},
 doi = {10.1109/ACCESS.2024.3380816},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Data models;Filtering;Cleaning;Convolutional neural networks;Computational modeling;Training;Intrusion detection;Smart devices;Deep learning;Attention mechanism;CNN;deep learning;IIoT;intrusion detection},
 month = {},
 number = {},
 pages = {45762-45772},
 title = {A Self-Attention-Based Deep Convolutional Neural Networks for IIoT Networks Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10478731,
 abstract = {In this paper, a novel Elliptic Crypt with Secured Blockchain-backed Federated Q-Learning Framework is proposed to offer an intelligent healthcare system that mitigates the attacks and data misused by malicious intruders. Initially, the entered IoMT data is collected from publicly available datasets and encrypted using the Extended Elliptic Curve Cryptography (E_ECurCrypt) technique for ensuring the security. This encrypted data is fed as an input to the blockchain-powered collaborative learning model. Here, the federated Q-learning model trains the inputs and analyzes the presented attacks to ensure better privacy protection. Afterwards, the data is securely stored in decentralized blockchain technology. Subsequently, an effective Delegated Proof of Stake (Del_PoS) consensus algorithm is used to validate the proposed framework. The experiment is conducted using the WUSTL-EHMS-2020 dataset and the performances are analyzed by evaluating multiple matrices and compared to other existing methods. The performance of the proposed framework can be assessed using multiple matrices and the results will be compared to other existing methods. As a result, the proposed method has achieved 99.23% accuracy, 98.42% precision, 98.12% recall, 98.27% F1 score, 59080.506 average throughput, 59080.506 average decryption time 1.94 seconds and an average encryption time of 1.84 seconds and are superior to conventional methods.},
 author = {Gajendran, Sudhakaran and Muthusamy, Revathi and Ravi, Krithiga and Chandraumakantham, Omkumar and Marappan, Suguna},
 doi = {10.1109/ACCESS.2024.3381528},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Medical services;Security;Medical diagnostic imaging;Federated learning;Training;Internet of Things;Ciphertexts;consensus mechanism;ECC method;end-devices;encryption and decryption;Markov decision process;Q-learning},
 month = {},
 number = {},
 pages = {45923-45935},
 title = {Elliptic Crypt With Secured Blockchain Assisted Federated Q-Learning Framework for Smart Healthcare},
 volume = {12},
 year = {2024}
}

@article{10484536,
 abstract = {Due to the dynamic nature and node mobility, assuring the security of Mobile Ad-hoc Networks (MANET) is one of the difficult and challenging tasks today. In MANET, the Intrusion Detection System (IDS) is crucial because it aids in the identification and detection of malicious attacks that impair the network's regular operation. Different machine learning and deep learning methodologies are used for this purpose in the conventional works to ensure increased security of MANET. However, it still has significant flaws, including increased algorithmic complexity, lower system performance, and a higher rate of misclassification. Therefore, the goal of this paper is to create an intelligent IDS framework for significantly enhancing MANET security through the use of deep learning models. Here, the minmax normalization model is applied to preprocess the given cyber-attack datasets for normalizing the attributes or fields, which increases the overall intrusion detection performance of classifier. Then, a novel Adaptive Marine Predator Optimization Algorithm (AOMA) is implemented to choose the optimal features for improving the speed and intrusion detection performance of classifier. Moreover, the Deep Supervise Learning Classification (DSLC) mechanism is utilized to predict and categorize the type of intrusion based on proper learning and training operations. During evaluation, the performance and results of the proposed AOMA-DSLC based IDS methodology is validated and compared using various performance measures and benchmarking datasets.},
 author = {Sheela, M. Sahaya and Soundari, A. Gnana and Mudigonda, Aditya and Kalpana, C. and Suresh, K. and Somasundaram, K. and Farhaoui, Yousef},
 doi = {10.23919/ICN.2024.0001},
 issn = {2708-6240},
 journal = {Intelligent and Converged Networks},
 keywords = {Training;Deep learning;Benchmark testing;Prediction algorithms;Feature extraction;Classification algorithms;Security;Intrusion Detection System (IDS);Security;Mobile Ad-hoc Network (MANET);min-max normalization;Adaptive Marine Predator Optimization Algorithm (AOMA);Deep Supervise Learning Classification (DSLC)},
 month = {March},
 number = {1},
 pages = {1-18},
 title = {Adaptive Marine Predator Optimization Algorithm (AOMA)-Deep Supervised Learning Classification (DSLC) Based IDS Framework for MANET Security},
 volume = {5},
 year = {2024}
}

@article{10486887,
 abstract = {In data centers, applications are typically deployed in a distributed manner across servers via Virtual Machines (VMs). In order to enhance the application security and performance, the data flows between VMs often traverse a particular set of middleboxes (such as Firewall, NAT, etc.) in a predefined sequence. One of the key challenges that data centers have been facing is how to efficiently place VMs to ensure the application performance and improve the resource efficiency of data centers. On the other hand, Network Function Virtualization (NFV) decouples middlebox function (also called network function) software from specified appliances, and deploys it onto general shared servers by virtualization technology. It has been being regarded as a promising technology to overcome high Capital Expenditures (CAPEX) and Operational Expenditures (OPEX) on the middlebox deployment and maintenance. In NFV, the VM deployed with network function software is called VNF (Virtualized Network Function). When NFV technology is applied in data centers, the locations of VNFs affect the resource efficiency of the data centers as well. To distinguish the VMs hosting the VNFs, the VMs hosting the application business are called Application VMs (AppVMs). As the endpoints of the data flows, the locations of the AppVMs determine the successful deployment of the required VNFs between the AppVMs to a large extent. Therefore, in NFV enabled data centers, it is necessary to study the joint optimization of the AppVM and VNF placement. However, almost all existing studies have ignored it. This paper is the first to deal with the problem of the joint optimization problem of AppVM and VNF placement. Firstly, we model the problem of the joint optimization problem of AppVM and VNF placement as a binary integer linear programming model. Next, due to the NP hard characteristic, we propose two joint optimization methods of AppVM and VNF placement. Finally, through a large number of experiments, compared with the algorithms that deal with the AppVM and VNF placement separately, the advantages of the proposed joint optimization methods in improving the request acceptance rate are verified.},
 author = {Qi, Dandan and Gu, Ruijun},
 doi = {10.1109/ACCESS.2024.3383471},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Servers;Data centers;Optimization;Middleboxes;Costs;Bandwidth;Heuristic algorithms;Application VM placement;VNF placement;jointly optimized placement},
 month = {},
 number = {},
 pages = {51828-51839},
 title = {Jointly Optimized Placement of Application VM and VNF in NFV Based Data Center},
 volume = {12},
 year = {2024}
}

@article{10494736,
 abstract = {In today’s network environments, vulnerable to cyber threats such as hackers and viruses, intrusion detection technology is considered the most effective means of detection and defense. Deep neural networks are commonly used in intrusion detection technology. However, improving the model’s ability to extract feature information and reducing computational space while retaining local feature information are critical challenges that need to be addressed. To tackle these issues, this paper proposes a model named BBO-CFAT, which combines the Biogeography-Based Optimization algorithm (BBO) for feature selection and an improved Transformer model for preserving context information and reducing computational space. Specifically, the BBO-CFAT model employs a roulette selection method to control the operations of migration and mutation operators. It utilizes feature information entropy to weight updates of adaptive variables in these operators, thereby enhancing the credibility of feature selection. Furthermore, the Transformer framework is hierarchically designed to facilitate the acquisition of context information. Additionally, depthwise separable convolutions are employed to reduce computational space, thereby improving computational efficiency and training speed. Experimental evaluations using the CIC-IDS2017 and NSL-KDD datasets demonstrate promising accuracies for BBO-CFAT on both datasets, achieving 99.1% and 97.5% accuracy, respectively, surpassing the performance of comparative experiments. Overall, the BBO-CFAT model provides a comprehensive solution to the challenges of intrusion detection, effectively balancing feature preservation, computational efficiency, and training accuracy.},
 author = {Jiang, Tingyao and Fu, Xiaobo and Wang, Min},
 doi = {10.1109/ACCESS.2024.3386405},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Habitats;Intrusion detection;Computational modeling;Training;Transformers;Vectors;Biological system modeling;Computational efficiency;Context modeling;Adaptation models;Optimization methods;Cyber terrorism;Threat assessment;Intrusion detection;BBO;transformer;feature selection},
 month = {},
 number = {},
 pages = {54191-54201},
 title = {BBO-CFAT: Network Intrusion Detection Model Based on BBO Algorithm and Hierarchical Transformer},
 volume = {12},
 year = {2024}
}

@article{10495036,
 abstract = {A federated learning-based intrusion detection system (FL-IDS) is introduced to enhance the security of vehicular networks in the context of IoT edge device implementations. The FL-IDS system protects data privacy by using local learning, in which devices share only model updates with an aggregation server. The server then generates an enhanced detection model. The FL-IDS system also incorporates a detection model (LR-IDS, PCC-CNN) based on machine learning (ML) and deep learning (DL) classifiers, namely logistic regression (LR) and convolution neural networks (CNN), to prevent attacks in transportation IoT environments. The proposed FL-IDS model uses embedded devices (such as Raspberry Pi for the client and Jetson Xavier for the server model). The real-time performance of the proposed IDS was evaluated using two different datasets, NSL-KDD and Car-Hacking. We deployed our IDS model on different architectures, testbed 1 (with 2 clients) and testbed 2 (with 4 clients). The model evaluation has been evaluated based on the accuracy, and loss parameters. The results show that the FL-IDS system outperforms traditional centralized learning with machine learning and deep learning approaches regarding accuracy (achieved overall 94% and 99%) and loss (achieved overall 0.28 and 0.009). These findings contribute to transportation IoT systems security by proposing a robust framework for enhancing the security and privacy of CAVs against cyber threats.},
 author = {Bhavsar, Mansi H. and Bekele, Yohannes B. and Roy, Kaushik and Kelly, John C. and Limbrick, Daniel},
 doi = {10.1109/ACCESS.2024.3386631},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Sensors;Internet of Things;Data models;Transportation;Intrusion detection;Unified modeling language;Federated learning;Machine learning;Edge computing;Federated learning;deep learning;machine learning;transportation systems;CAV;IDS;edge computing},
 month = {},
 number = {},
 pages = {52215-52226},
 title = {FL-IDS: Federated Learning-Based Intrusion Detection System Using Edge Devices for Transportation IoT},
 volume = {12},
 year = {2024}
}

@article{10495038,
 abstract = {Unmanned Aerial Vehicles (UAVs) are advanced technologies that are initially utilized for military apps like border monitoring and reconnaissance in opposed territories. Internet of Things (IoTs) assisted UAV networks suggest the combination of IoT technology with UAVs to generate a networked system that improves the abilities and utility of UAVs for several apps. UAVs’ inherent features namely quick deployment, high dynamicity, low deployment and operational costs, and line of sight communication motivated researchers in the IoT field to assume UAV’s combination into IoT systems near the concept of UAV-assisted IoT systems. However, security concerns with UAVs are evolving as UAV nodes are suitable attractive targets for cyber threats because of extremely developing volumes and poor and weak inbuilt security. Therefore, this paper presents a Modified Marine Predators Algorithm with a Deep Learning-Driven intrusion detection (MMPADL-ID) approach for IoT Assisted UAV Networks. The presented MMPADL-ID technique proposes to identify and classify the presence of intrusions in accomplishing security in IoT-assisted UAV networks. In the MMPADL-ID technique, the feature selection process is performed by the design of MMPA. In addition, the MMPADL-ID technique incorporates the Elman neural network (ENN) model for the recognition and classification of the intrusions. Furthermore, the honey badger algorithm (HBA) can be applied for the hyperparameter tuning of the ENN model and results in improved performance. The simulation value of the MMPADL-ID technique can be tested on benchmark datasets. An extensive comparative outcome reported the better solution of the MMPADL-ID algorithm with existing approaches for various aspects.},
 author = {Babu, S. Anantha and Ranganath, Abadhan and Goswami, Manish M. and Gnanaprakasam, T. and Ishak, Mohamad Khairi},
 doi = {10.1109/ACCESS.2024.3386570},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Autonomous aerial vehicles;Security;Vectors;Intrusion detection;Classification algorithms;Mathematical models;Entropy;Internet of Things;Deep learning;Intrusion detection system;unmanned aerial vehicles;Internet of Things;security;deep learning},
 month = {},
 number = {},
 pages = {54991-54998},
 title = {Modified Marine Predators Algorithm With Deep Learning-Driven Security Solution for IoT-Assisted UAV Networks},
 volume = {12},
 year = {2024}
}

@article{10495152,
 abstract = {Large scale enterprise networks often use Enterprise Key-Management (EKM) platforms for unified management of cryptographic keys. In such a system, requests and responses commonly use the Key Management Interoperability Protocol (KMIP) format. The KMIP client and server use Transport Layer Security (TLS) to negotiate a mutually-authenti cated connection. Although KMIP traffic is encrypted, monitoring traffic and usage patterns of EKM Systems (EKMS) may enable detection of anomalous (possibly malicious) activity in the enterprise network that is notdetectable by other means. Metadata analysis of enterprise system traffic has been widely studied (for example at the TLS protocol level). However, KMIP metadata in EKMS has not been used for anomaly detection. In this paper, wepresent a framework for automated outlier rejection and anomaly detection. This involves investigati on of KMIP metadata, determining characteristics to extract for dataset generation, and looking for patt erns from which behaviors can be inferred. For automated labeling and detection, a deep learning-based model is applied to thegenerated datasets: Long Short-Term Memory (LSTM) auto-encoder neural networks with specific parameters. As aproof of concept, we simulated an enterprise environment, collected relevant KMIP metadata, and deployed this framework. Although our implementati on used Quintessence Labs EKMS, the framework we proposed is vendorneutral. The experimental results (Precision, Recall, F1 = 1.0) demonstrate that our framework can accurately detectall anomalous enterprise network activities. This approach could be integrated with other enterprise information toenhance detection capabilities. Our proposal can be used as a general-purpose framework for anomaly detecti on and diagnosis.},
 author = {Baee, Mir Ali Rezazadeh and Simpson, Leonie and Armstrong, Warren},
 doi = {10.1109/OJCS.2024.3386715},
 issn = {2644-1268},
 journal = {IEEE Open Journal of the Computer Society},
 keywords = {Metadata;Protocols;Anomaly detection;Servers;Security;Long short term memory;Interoperability;KMIP metadata analysis;deep learning;anomaly detection;enterprise key-management system;framework},
 month = {},
 number = {},
 pages = {156-169},
 title = {Anomaly Detection in the Key-Management Interoperability Protocol Using Metadata},
 volume = {5},
 year = {2024}
}

@article{10497567,
 abstract = {The internet, a cornerstone of modern life, has profound implications across personal, business, and society. However, its widespread use has posed challenges, especially concerning privacy and cybersecurity. Besides, the threats on the internet are increasing in terms of danger, intensity, and complexity. Distributed denial-of-service (DDoS) attacks have emerged as a common and dangerous cybersecurity threat capable of disabling the network systems of targeted organizations and services. Therefore, various security strategies, such as firewalls and intrusion detection systems (IDS), are employed to protect against DDoS attacks. Enhancing the defensive capabilities of IDS systems through machine learning (ML) and deep learning (DL) technologies is a significant trend nowadays. However, despite notable successes, detecting DDoS attacks using ML and DL technologies still faces challenges, especially with Unknown DDoS Attacks. In this research, the primary goal is to address the unknown DDoS detection problem through efficient and advanced techniques. Our proposed method, CNN-RPL, integrates Convolutional Neural Network (CNN) with Reciprocal Points Learning (RPL), a novel Open-Set Recognition (OSR) technology. This model can effectively handle both known and unknown attacks. The CNN-RPL model demonstrates excellent results, achieving an accuracy exceeding 99.93% against known attacks in the CICIDS2017 dataset. Simultaneously, the model achieves a commendable average accuracy of up to 98.51% against unknown attacks in the CICDDoS2019 dataset. In particular, the CNN-RPL model simplifies the architecture of the deep neural network by significantly reducing the number of training parameters without compromising defense capabilities. Therefore, our proposed method is genuinely efficient, particularly flexible, and lightweight compared to traditional methods. This can equip organizations and businesses with a highly applicable yet powerful security approach against the evolving complexities in the network space.},
 author = {Shieh, Chin-Shiuh and Ho, Fu-An and Horng, Mong-Fong and Nguyen, Thanh-Tuan and Chakrabarti, Prasun},
 doi = {10.1109/ACCESS.2024.3388149},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Computer crime;Deep learning;Convolutional neural networks;Adaptation models;Machine learning;Intrusion detection;Computer security;Cybersecurity;unknown attack detection;distributed denial-of-service (DDoS);open-set recognition (OSR);reciprocal points learning (RPL);machine learning;deep learning;incremental learning;convolutional neural networks (CNN)},
 month = {},
 number = {},
 pages = {56461-56476},
 title = {Open-Set Recognition in Unknown DDoS Attacks Detection With Reciprocal Points Learning},
 volume = {12},
 year = {2024}
}

@article{10500368,
 abstract = {This study introduces a deep learning approach for network intrusion detection (NIDS), which excels in both binary and multi-classification tasks. This approach combines the strengths of six distinct deep learning algorithms: DNN, CNN, RNN, LSTM, GRU, and a Hybrid CNN-LSTM architecture. The NSL-KDD dataset, a widely recognized benchmark for intrusion detection research, was utilized for implementation and evaluation. In binary classification, the approach demonstrates exceptional capabilities, with the GRU approach outperforming others. Similarly, the DNN, LSTM, CNN, and RNN approaches exhibit robust performance, showcasing their efficacy in detecting anomalies within network data. In the multi-classification setting, the DNN approach stands out with outstanding performance. While other approaches, including RNN, CNN, LSTM, GRU, and the Hybrid CNN-LSTM approach, also maintain commendable results, the DNN approach proves to be the most effective in handling complex network patterns. This research provides valuable insights into the application of deep learning approaches using the NSL-KDD dataset for network anomaly detection, emphasizing their versatility and reliability across different classification scenarios. The findings lay the groundwork for further exploration and utilization of deep learning methodologies in enhancing network security.},
 author = {Elsayed, Salwa and Mohamed, Khalil and Madkour, Mohamed Ashraf},
 doi = {10.1109/ACCESS.2024.3389096},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Anomaly detection;Feature extraction;Telecommunication traffic;Long short term memory;Classification algorithms;Adaptation models;Network security;Classification algorithms;Intrusion detection;Network security;anomaly detection;NIDS;deep learning algorithms;NSL-KDD dataset;binary classification;multi-classification},
 month = {},
 number = {},
 pages = {58851-58870},
 title = {A Comparative Study of Using Deep Learning Algorithms in Network Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10500433,
 abstract = {Anomaly detection research focuses on identifying rare patterns derived from daily occurrences. This study introduces an innovative anomaly–object control system that utilizes adaptive policies through anomaly detection algorithms. Effectively blocking anomalous objects in real–world scenarios poses significant challenges. Therefore, we empirically validate the proposed anomaly object control methodology using the traffic history associated with malicious cyber–attacks in vulnerable network environments. We propose an anomaly object control methodology based on DeepSARSA that utilizes unsupervised anomaly detection deep learning models trained on historical data collected from an environment in which the anomaly object control system operates. Through this approach, we confirmed the adaptive policies for optimal anomaly object control. By employing the out–of–distribution detection and DeepSVDD algorithms as reward functions and comparing the results, we verified the stability of the proposed anomaly object control system. Our experimental results highlight the practical limitations of single–class anomaly detection algorithms and propose new research directions for anomaly detection.},
 author = {Sakong, Won and Kim, Wooju},
 doi = {10.1109/ACCESS.2024.3389067},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Anomaly detection;Reinforcement learning;Control systems;Computer crime;Entropy;Training;Intrusion detection;Anomaly detection;deepSARSA;deepSVDD;network intrusion detection;network intrusion response;ODIN},
 month = {},
 number = {},
 pages = {55281-55291},
 title = {An Adaptive Policy-Based Anomaly Object Control System for Enhanced Cybersecurity},
 volume = {12},
 year = {2024}
}

@article{10504276,
 abstract = {Cybersecurity in the Internet of Things (IoT) is the practice of implementing measures to secure networks and connected devices from data breaches, cyber threats, and unauthorized access. It is essential owing to the increasing interconnectivity of devices, ranging from smart home appliances to industrial sensors. The potential attack surface expands, necessitating strong cybersecurity measures to protect sensitive data, ensure privacy, and prevent disruptions to critical services with these increasing number of IoT devices. Artificial intelligence (AI) technologies, particularly deep learning (DL) and machine learning (ML) approaches, hold the potential to mitigate and identify cyberattacks on IoT networks. DL demonstrates promise for effectively preventing and detecting security threats within IoT devices. Despite the importance of Intrusion Detection Systems (IDS) in maintaining confidentiality by detecting suspicious activities, classical IDS solutions might face difficulties in the IoT platform. Therefore, this study presents an Artificial Orca Algorithm with Ensemble Learning cyberattack detection and classification (AOAEL-CDC) methodology in an environment of IoT. The presented AOAEL-CDC technique exploited the feature selection (FS) approach with an ensemble learning approach for cyberattack recognition and identification in the IoT atmosphere. In the developed AOAEL-CDC model, the feature selection takes place using the AOA technique. For the cyberattack detection process, the ensemble learning process is carried out by the use of three models such as bidirectional long short-term memory (BiLSTM), gated recurrent unit (GRU), and extreme learning machine (ELM). Finally, the hyperparameter range of the DL techniques takes place using the marine predator’s algorithm (MPA). To examine the performance analysis of the AOAEL-CDC methodology, a series of simulations take place using a benchmark dataset. An extensive comparative study reported that the BCODL-SDSC technique reaches an effective performance with other models with a maximum accuracy of 99.31%.},
 author = {Allafi, Randa and Alzahrani, Ibrahim R.},
 doi = {10.1109/ACCESS.2024.3390093},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Ensemble learning;Computer security;Computer crime;Security;Safety;Tuning;Hyperparameter optimization;Deep learning;Cyberattack;Artificial Orca Algorithm;ensemble learning;hyperparameter tuning;deep learning},
 month = {},
 number = {},
 pages = {63282-63291},
 title = {Enhancing Cybersecurity in the Internet of Things Environment Using Artificial Orca Algorithm and Ensemble Learning Model},
 volume = {12},
 year = {2024}
}

@article{10504797,
 abstract = {In the rapidly evolving landscape of computing and networking, the concepts of cloud networks have gained significant prominence. Although the cloud network offers on-demand access to shared resources, anomalies pose potential risks to the integrity and security of cloud networks. However, protecting the cloud network against anomalies remains a challenge. Unlike traditional detection techniques, machine learning (ML) and deep learning (DL) offer new and adaptable methods for detecting anomalies in cloud networks. The objective of this study is to comprehensively explore existing ML /DL methods for detecting different anomalies based on distributed denial of service anomaly (DDoS) and intrusion detection systems (IDS) in cloud networks. The study seeks to address the gaps in anomaly detection for cloud networks, proposing potential solutions for anomaly detection in these cloud environments. The ultimate goal is to contribute valuable insights and practical solutions to enhance the security and reliability of cloud networks through effective anomaly detection by ML/ DL techniques. Methodologies for ML/DL are explained, along with their advantages, disadvantages, and respective approaches. In addition, a summary of the comparison between different ML/ DL models is also included.},
 author = {Abdallah, Amira Mahamat and Saif Rashed Obaid Alkaabi, Aysha and Bark Nasser Douman Alameri, Ghaya and Rafique, Saida Hafsa and Musa, Nura Shifa and Murugan, Thangavel},
 doi = {10.1109/ACCESS.2024.3390844},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing;Anomaly detection;Security;Reviews;Computer crime;Deep learning;Time series analysis;Cloud network;cloud computing;could;machine learning (ML);deep learning (DL);distributed denial of service (DDoS);intrusion detection system (IDS);anomaly detection;security},
 month = {},
 number = {},
 pages = {56749-56773},
 title = {Cloud Network Anomaly Detection Using Machine and Deep Learning Techniques— Recent Research Advancements},
 volume = {12},
 year = {2024}
}

@article{10504835,
 abstract = {The prevalence of cyber-attacks perpetrated over the last two decades, including coordinated attempts to breach targeted organizations, has drastically and systematically exposed some of the more critical vulnerabilities existing in our cyber ecosystem. Particularly in Supervisory Control and Data Acquisition (SCADA) systems with targeted attacks aiming to bypass signature-based protocols, attempting to gain control over operational processes. In the past, researchers utilized deep learning and reinforcement learning algorithms to mitigate threats against industrial control systems (ICS). However, as technology evolves, these techniques become ineffective in monitoring and enhancing the cybersecurity defenses of those system against unwanted attacks. To address these concerns, we propose a deep reinforcement learning (DRL) framework for anomaly detection in the SCADA network. Our model utilizes a “Q-network”, which allows it to achieve state-of-the-art performance in pattern recognition from complex tasks. We validated our solution on two publicly available datasets. The WUSTL-IIoT-2018 and the WUSTL-IIoT-2021, each comprised of twenty-five networking features representing benign and attack traffic. The results obtained shows that our model successfully achieved an accuracy of 99.36% in attack detection, highlighting DRL’s potential to enhance the security of critical infrastructure and laying the foundation for future research in this domain.},
 author = {Mesadieu, Frantzy and Torre, Damiano and Chennamaneni, Anitha},
 doi = {10.1109/ACCESS.2024.3390722},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Critical infrastructure;Training;SCADA systems;Anomaly detection;Task analysis;Software algorithms;Protocols;Critical infrastructure;Deep reinforcement learning;Computer security;SCADA systems;Critical infrastructure;deep reinforcement learning;cybersecurity;SCADA},
 month = {},
 number = {},
 pages = {63381-63399},
 title = {Leveraging Deep Reinforcement Learning Technique for Intrusion Detection in SCADA Infrastructure},
 volume = {12},
 year = {2024}
}

@article{10506515,
 abstract = {In the wake of the expanding digital realm, the imperative for robust cybersecurity measures has burgeoned significantly. This extensive investigation digs into the complicated realm of cybersecurity datasets, with the goal of improving our understanding and implementation of these critical tools. This study’s comprehensive evaluation of 37 distinct datasets shows a complicated world in which no one dataset stands out as totally suitable for all uses. A precise balance must be struck between crucial dataset qualities such as diversity, authenticity, and usefulness. Using a complete assessment technique, this paper illuminates the challenges and possibilities that developers and researchers face in the field of cybersecurity datasets. Although some databases accurately identify certain forms of cyberattacks, their coverage may not include the whole range of cyber threats. On the other hand, datasets with a strong emphasis on accurate portrayal may forgo comprehensiveness or practical use. This intricacy is heightened by the dynamic and sophisticated nature of cyber threats, emphasizing the delicate balance required between accuracy and practicality. The study emphasizes the necessity of selecting datasets strategically and contextually for cybersecurity studies, with the goal of matching research objectives with the most appropriate dataset selections. Furthermore, it emphasizes the need of continual cooperation and innovation within the cybersecurity community in developing datasets that accurately represent the ever-changing nature of cyber threats. After analyzing 37 cybersecurity datasets, it is obvious that no one dataset can meet all of the field’s unique demands, demonstrating the need of a flexible, adaptable, and developing dataset for intrusion detection systems (IDS). This inquiry offers a critical assessment of dataset characteristics and their related issues, providing essential insights for academics, professionals, and dataset creators, enabling the construction of a more resilient and adaptable cybersecurity infrastructure.},
 author = {Khanan, Akbar and Abdelgadir Mohamed, Yasir and Mohamed, Abdul Hakim H. M. and Bashir, Mohamed},
 doi = {10.1109/ACCESS.2024.3392338},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computer security;Security;Systematics;Feature extraction;Deep learning;Computer crime;Data models;Attacks;intrusion detection system;datasets},
 month = {},
 number = {},
 pages = {59289-59317},
 title = {From Bytes to Insights: A Systematic Literature Review on Unraveling IDS Datasets for Enhanced Cybersecurity Understanding},
 volume = {12},
 year = {2024}
}

@article{10506810,
 abstract = {Big data has the ability to open up innovative and ground-breaking prospects for the electrical grid, which also supports to obtain a variety of technological, social, and financial benefits. There is an unprecedented amount of heterogeneous big data as a consequence of the growth of power grid technologies, along with data processing and advanced tools. The main obstacles in turning the heterogeneous large dataset into useful results are computational burden and information security. The original contribution of this paper is to develop a new big data framework for detecting various intrusions from the smart grid systems with the use of AI mechanisms. Here, an AdaBelief Exponential Feature Selection (AEFS) technique is used to efficiently handle the input huge datasets from the smart grid for boosting security. Then, a Kernel based Extreme Neural Network (KENN) technique is used to anticipate security vulnerabilities more effectively. The Polar Bear Optimization (PBO) algorithm is used to efficiently determine the parameters for the estimate of radial basis function. Moreover, several types of smart grid network datasets are employed during analysis in order to examine the outcomes and efficiency of the proposed AdaBelief Exponential Feature Selection- Kernel based Extreme Neural Network (AEFS-KENN) big data security framework. The results reveal that the accuracy of proposed AEFS-KENN is increased up to 99.5% with precision and AUC of 99% for all smart grid big datasets used in this study.},
 author = {Muthubalaji, Sankaramoorthy and Muniyaraj, Naresh Kumar and Rao, Sarvade Pedda Venkata Subba and Thandapani, Kavitha and Mohan, Pasupuleti Rama and Somasundaram, Thangam and Farhaoui, Yousef},
 doi = {10.26599/BDMA.2023.9020022},
 issn = {2097-406X},
 journal = {Big Data Mining and Analytics},
 keywords = {Computational modeling;Neural networks;Training data;Big Data;Feature extraction;Turning;Smart grids;smart grid;big data analytics;Machine Learning (ML);AdaBelief Exponential Feature Selection (AEFS);Polar Bear Optimization (PBO);Kernel Extreme Neural Network (KENN)},
 month = {June},
 number = {2},
 pages = {399-418},
 title = {An Intelligent Big Data Security Framework Based on AEFS-KENN Algorithms for the Detection of Cyber-Attacks from Smart Grid Systems},
 volume = {7},
 year = {2024}
}

@article{10506836,
 abstract = {This article examines the interplay between artificial intelligence (AI) and cybersecurity in light of future regulatory requirements on the security of AI systems, specifically focusing on the robustness of high-risk AI systems against cyberattacks in the context of the European Union’s AI Act. The paper identifies and analyses three challenges to achieve compliance of AI systems with the cybersecurity requirement: accounting for the diversity and the complexity of AI technologies, assessing AI-specific risks, and developing secure-by-design AI systems. The contribution of the article consists in providing an overview of AI cybersecurity practices and identifying gaps in current approaches to security conformity assessment for AI systems. Our analysis highlights the unique vulnerabilities present in AI systems and the absence of established cybersecurity practices tailored to these systems, and emphasises the need for continuous alignment between legal requirements and technological capabilities, acknowledging the necessity for further research and development to address the challenges. It concludes that comprehensive cybersecurity practices must evolve to accommodate the unique aspects of AI, with a collaborative effort from various sectors to ensure effective implementation and standardisation.},
 author = {Hamon, Ronan and Junklewitz, Henrik and Soler Garrido, Josep and Sanchez, Ignacio},
 doi = {10.1109/ACCESS.2024.3391021},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Computer security;Machine learning;Regulation;Data models;Terminology;Adversarial machine learning;Conformance testing;Life cycle assessment;Risk management;Trust management;Adversarial machine learning;artificial intelligence;conformity assessment;cybersecurity;lifecycle management;regulation;risk management;trustworthy AI},
 month = {},
 number = {},
 pages = {61022-61035},
 title = {Three Challenges to Secure AI Systems in the Context of AI Regulations},
 volume = {12},
 year = {2024}
}

@article{10506908,
 abstract = {Due to the sensitive and mission-critical nature of the data collected and transferred, security in IoT-assisted UAV networks is of great significance. Intrusion detection in IoT-assisted UAV networks includes the deployment of complex monitoring systems to identify and respond to cyberattacks, physical breaches, or unauthorized access. This system employs a combination of anomaly detection and signature-based methods to find malicious or unusual activities within the network. A robust intrusion detection mechanism is essential for protecting the security and integrity of the UAVs and the data collected, ensuring that any possible vulnerabilities are promptly addressed and identified. Consequently, this study introduces an adaptive mongoose optimizer algorithm with a deep learning-based intrusion detection (AMOA-DLID) method in IoT-assisted UAV networks. The AMOA-DLID technique intends to ensure security in the IoT-assisted UAV networks via an intrusion detection process. In the presented AMOA-DLID technique, AMOA is initially applied for the feature selection process. The following sparse autoencoder (SAE) model can be exploited for the recognition of the intrusions. Lastly, the recognition rate of the SAE model can be improved by employing the Harris Hawks optimizer (HHO) technique. The detailed experimental study of the AMOA-DLID model is performed on the benchmark dataset of IDS. The extensive results portrayed that the AMOA-DLID technique reaches improved security over other models on the IoT-assisted UAV networks.},
 author = {Alotaibi, Saud S. and Sayed, Ahmed and Samir Abd Elhameed, Elmouez and Alghushairy, Omar and Assiri, Mohammed and Saadeldeen Ibrahim, Sara},
 doi = {10.1109/ACCESS.2024.3392618},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Autonomous aerial vehicles;Security;Atmospheric modeling;Intrusion detection;Feature extraction;Internet of Things;Smart cities;Deep learning;Optimization methods;Intrusion detection system;UAV;IoT;deep learning;Harris Hawks optimization;feature selection},
 month = {},
 number = {},
 pages = {63768-63776},
 title = {Enhancing Security in IoT-Assisted UAV Networks Using Adaptive Mongoose Optimization Algorithm With Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10508380,
 abstract = {Software-Defined Networking (SDN) is a groundbreaking technology that has transformed network management significantly. By integrating data and control, SDN offers unparalleled flexibility and responsiveness, thereby overcoming the limitations of conventional network architectures. However, a centralized controller, which is a hallmark of SDN, is a double-edged security sword that offers easy control. This also becomes a dangerous point of failure for the entire network. To the best of our knowledge, this is the first comprehensive study to explore traditional-based, artificial intelligence (AI)-based, and moving target defense (MTD) approaches to securing SDN. The study begins with a survey of traditional security solutions for SDN, encompassing authentication, authorization, encryption, security protocols, firewalls, and flow verification, by addressing security threats and vulnerabilities in both data and control planes. The study then investigates the application of AI-based security solutions in an SDN environment, focusing on how Machine Learning (ML) and Deep Learning (DL) techniques are leveraged to address advanced security threats. Additionally, the survey examines MTD mechanisms within data and control plane security. Several in-depth techniques, including the randomization of Internet Protocol (IP) and Media Access Control (MAC) addresses, port numbers, and flow tables, and delving into the relationship between security threats, MTD strategies, and the specific controllers employed in experimental implementations. We utilized the widely recognized STRIDE cybersecurity framework to systematically identify and evaluate the potential threats to SDN security. Our analysis resulted in a comprehensive list of security challenges, and we propose future research directions aimed at addressing emerging threats in both the data and control planes.},
 author = {Abdi, Abdinasir Hirsi and Audah, Lukman and Salh, Adeb and Alhartomi, Mohammed A. and Rasheed, Haroon and Ahmed, Salman and Tahir, Ahmed},
 doi = {10.1109/ACCESS.2024.3393548},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Artificial intelligence;Surveys;Reviews;Protocols;Programming;IP networks;Computer security;Software defined networking;AI;control plane;cybersecurity;data plane;moving target defense;SDN security;southbound interface;traditional SDN security},
 month = {},
 number = {},
 pages = {69941-69980},
 title = {Security Control and Data Planes of SDN: A Comprehensive Review of Traditional, AI, and MTD Approaches to Security Solutions},
 volume = {12},
 year = {2024}
}

@article{10510320,
 abstract = {Anomaly detection is a critical task in ensuring the security and safety of infrastructure and individuals in smart environments. This paper provides a comprehensive analysis of recent anomaly detection solutions in data streams supporting smart environments, with a specific focus on multivariate time series anomaly detection in various environments, such as smart home, smart transport, and smart industry. The aim is to offer a thorough overview of the current state-of-the-art in anomaly detection techniques applicable to these environments. This includes an examination of publicly available datasets suitable for developing these techniques. The survey is designed to inform future research and practical applications in the field, serving as a valuable resource for researchers and practitioners. It not only reviews a range of state-of-the-art anomaly detection methods, from statistical and proximity-based to those adopting deep learning-methods but also covers fundamental aspects of anomaly detection. These aspects include the categorization of anomalies, detection scenarios, challenges associated, and evaluation metrics for assessing the techniques’ performance.},
 author = {Fährmann, Daniel and Martín, Laura and Sánchez, Luis and Damer, Naser},
 doi = {10.1109/ACCESS.2024.3395051},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Internet of Things;Anomaly detection;Security;Surveys;Industrial Internet of Things;Industries;Anomaly detection;human activity recognition;machine learning;pattern recognition;safety},
 month = {},
 number = {},
 pages = {64006-64049},
 title = {Anomaly Detection in Smart Environments: A Comprehensive Survey},
 volume = {12},
 year = {2024}
}

@article{10510449,
 abstract = {Cybersecurity is a vital technology and measures intended to protect networks, computers, information, and programs from threats and illegal access, modification, or damage. A security model covers a network and a computer safety method. Each system has antivirus software, firewalls, and an intrusion detection system (IDS). IDS helps in discovering and identifying illegal system behavior such as usage, copying, alteration, and damage. By estimating network traffic anomalies and patterns, deep learning (DL) models can enhance the detection abilities of IDS when compared to traditional rule-based methods. These models learn complex representations from data, authorizing them to recognize subtle and developing attack patterns. Techniques like recurrent neural network (RNN) and convolutional neural network (CNN) can be applied to progress consecutive or spatial features in network data, correspondingly. This manuscript empowers Cybersecurity by utilizing an Enhanced Rat Swarm Optimizer with a Deep Stack-Based Ensemble Learning (ERSO-DSEL) model. The ERSO-DSEL approach leverages feature selection (FS) with EL strategies to boost cybersecurity. In the ERSO-DSEL system, Z-score normalization is employed to measure the input data. Besides, an improved equilibrium optimizer (IEO) based FS approach is applied to choose a set of features. For cyberattack recognition, the ERSO-DSBEL approach uses the DSEL approach comprising three models namely deep neural network (DNN), long short-term memory (LSTM), and bidirectional LSTM (Bi-LSTM). Furthermore, the hyperparameter selection of these DL models takes place using the ERSO system. The solution result of the ERSO-DSBEL model is executed on a benchmark IDS database. A wide-contrast study reported that the ERSO-DSBEL model accomplishes an enhanced accuracy outcome of 99.67% over other models of cybersecurity.},
 author = {Manickam, P. and Girija, M. and Kumar Dutta, Ashit and Ramesh Babu, Palamakula and Arora, Krishan and Jeong, Mun and Acharya, Srijana},
 doi = {10.1109/ACCESS.2024.3395328},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer security;Long short term memory;Cyberattack;Transfer functions;Unified modeling language;Space exploration;Social factors;Computer security;Intrusion detection;Ensemble learning;Hyperparameter optimization;Cybersecurity;intrusion detection systems;ensemble learning;equilibrium optimizer;hyperparameter tuning},
 month = {},
 number = {},
 pages = {62492-62501},
 title = {Empowering Cybersecurity Using Enhanced Rat Swarm Optimization With Deep Stack-Based Ensemble Learning Approach},
 volume = {12},
 year = {2024}
}

@article{10516690,
 abstract = {Artificial intelligence and cyber-physical systems (CPS) are two of the key technologies of the future that are enabling major global shifts. However, most of the current implementations of AI in CPS are not explainable, which creates serious problems in ethical, legal, regulatory, and other domains. Therefore, it is necessary for explainable artificial intelligence (XAI) to be integrated with cyber-physical systems to meet the vital needs for control, fairness, accountability, safety, cyber-resilience, and cybersecurity. The goal of this review is to demonstrate the need, benefits, challenges, and implementation of XAI for CPS. We review the existing literature about XAI and CPS, discuss the current state of the art, examine applications in different domains, and make recommendations for future research directions. To the best of our knowledge, this is the first peer-reviewed academic article to provide a comprehensive review of general XAI for CPS. We also contribute new research ideas including development of multisensory explanations and outputs for these systems, application of XAI to CPS to decrease occupational burnout and increase employee engagement, and enumeration of the multidisciplinary goals and benefits of XAI as applied to cyber-physical systems.},
 author = {Hoenig, Amber and Roy, Kaushik and Acquaah, Yaa Takyiwaa and Yi, Sun and Desai, Salil S.},
 doi = {10.1109/ACCESS.2024.3395444},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Cyber-physical systems;Explainable AI;Biological system modeling;Reviews;Safety;Computer security;Fifth Industrial Revolution;Cyber-physical systems (CPS);cyber-resilience;cybersecurity;explainable artificial intelligence (XAI);industrial CPS;Industry 5.0},
 month = {},
 number = {},
 pages = {73113-73140},
 title = {Explainable AI for Cyber-Physical Systems: Issues and Challenges},
 volume = {12},
 year = {2024}
}

@article{10518015,
 abstract = {The Internet of Things (IoT) represents a swiftly expanding sector that is pivotal in driving the innovation of today’s smart services. However, the inherent resource-constrained nature of IoT nodes poses significant challenges in embedding advanced algorithms for cybersecurity, leading to an escalation in cyberattacks against these nodes. Contemporary research in Intrusion Detection Systems (IDS) predominantly focuses on enhancing IDS performance through sophisticated algorithms, often overlooking their practical applicability. This paper introduces Deep-IDS, an innovative and practically deployable Deep Learning (DL)-based IDS. It employs a Long-Short-Term-Memory (LSTM) network comprising 64 LSTM units and is trained on the CIC-IDS2017 dataset. Its streamlined architecture renders Deep-IDS an ideal candidate for edge-server deployment, acting as a guardian between IoT nodes and the Internet against Denial of Service, Distributed Denial of Service, Brute Force, Man-in-the-Middle, and Replay Attacks. A distinctive aspect of this research is the trade-off analysis between the intrusion Detection Rate (DR) and the False Alarm Rate (FAR), facilitating the real-time performance of the Deep-IDS. The system demonstrates an exemplary detection rate of 96.8% at the 70% threshold of DR-FAR trade-off and an overall classification accuracy of 97.67%. Furthermore, Deep-IDS achieves precision, recall, and F1-scores of 97.67%, 98.17%, and 97.91%, respectively. On average, Deep-IDS requires 1.49 seconds to identify and mitigate intrusion attempts, effectively blocking malicious traffic sources. The remarkable efficacy, swift response time, innovative design, and novel defense strategy of Deep-IDS not only secure IoT nodes but also their interconnected sub-networks, thereby positioning Deep-IDS as a leading IDS for IoT-enhanced computer networks.},
 author = {Racherla, Sandeepkumar and Sripathi, Prathyusha and Faruqui, Nuruzzaman and Alamgir Kabir, Md and Whaiduzzaman, Md and Aziz Shah, Syed},
 doi = {10.1109/ACCESS.2024.3396461},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Long short term memory;Mathematical models;Intrusion detection;Logic gates;Recurrent neural networks;Real-time systems;Network security;Deep learning;Network security;deep learning;intrusion-detection system (IDS);Internet of Things (IoT);LSTM;response mechanism;intrusion detection rate},
 month = {},
 number = {},
 pages = {63584-63597},
 title = {Deep-IDS: A Real-Time Intrusion Detector for IoT Nodes Using Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10521850,
 abstract = {Cyber Threat Detection (CTD) is subject to complicated and rapidly accelerating developments. Poor accuracy, high learning complexity, limited scalability, and a high false positive rate are problems that CTD encounters. Deep Learning defense mechanisms aim to build effective models for threat detection and protection allowing them to adapt to the complex and ever-accelerating changes in the field of CTD. Furthermore, swarm intelligence algorithms have been developed to tackle the optimization challenges. In this paper, a Chaotic Zebra Optimization Long-Short Term Memory (CZOLSTM) algorithm is proposed. The proposed algorithm is a hybrid between Chaotic Zebra Optimization Algorithm (CZOA) for feature selection and LSTM for cyber threat classification in the CSE-CIC-IDS2018 dataset. Invoking the chaotic map in CZOLSTM can improve the diversity of the search and avoid trapping in a local minimum. In evaluating the effectiveness of the newly proposed CZOLSTM, binary and multi-class classifications are considered. The acquired outcomes demonstrate the efficiency of implemented improvements across many other algorithms. When comparing the performance of the proposed CZOLSTM for cyber threat detection, it outperforms six innovative deep learning algorithms for binary classification and five of them for multi-class classification. Other evaluation criteria such as accuracy, recall, F1 score, and precision have been also used for comparison. The results showed that the best accuracy was achieved using the proposed algorithm for binary is 99.83%, with F1-score of 99.82%, precision of 99.83%, and recall of 99.82%. The proposed CZOLSTM algorithm also achieved the best performance for multi-class classification among other compared algorithms.},
 author = {Amin, Reham and El-Taweel, Ghada and Ali, Ahmed F. and Tahoun, Mohamed},
 doi = {10.1109/ACCESS.2024.3397303},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Optimization methods;Feature extraction;Particle swarm optimization;Machine learning algorithms;Long short term memory;Threat assessment;Computer security;Deep learning;Intrusion detection;Cyber security;deep learning;feature selection;long short-term memory;intrusion detection;swarm intelligence;zebra optimization algorithm},
 month = {},
 number = {},
 pages = {93235-93260},
 title = {Hybrid Chaotic Zebra Optimization Algorithm and Long Short-Term Memory for Cyber Threats Detection},
 volume = {12},
 year = {2024}
}

@article{10522495,
 abstract = {Vehicle-road cooperation systems (VRCSs) use next-generation Internet technologies, including 5G, edge computing, and artificial intelligence to improve mobility, comfort, and travel efficiency. Internet of Vehicles (IoV) ecosystem serves as the technological backbone for VRCS by enabling seamless communication and data exchange between vehicles, infrastructure, and traffic management centers. This enables real-time, high-speed communication, efficient data processing, and enhanced security, fostering the development of autonomous driving, smart traffic management, and seamless connectivity within the VRCS ecosystem. At the same time, cyber attacks have become more complex, persistent, organized, and weaponized in IoV network. Threat intelligence (TI) has emerged as a prominent security approach to obtain a complete view of the dynamically growing cyber threat environment. On the other hand, modeling TI is a challenging task due to the limited labels available for different cyber threat sources. Second, most of the available designs require a large investment of resources and use handcrafted features, making the entire process error-prone and time-consuming. To tackle these challenges, this article presents TIMIF, a deep-learning-based TI modeling and identification framework for intelligent IoV and is based on three key modules: first, the proposed TIMIF adopts an automated pattern extractor (APE) module to extract hidden patterns from IoV networks. Employing its output, we design a TI-based detection (TIBD) module to detect abnormal behavior and TI-attack type identification (TIATI) module to identify attack types. Extensive experiments are carried out on three different publicly intrusion data sources, namely, HCRL-car hacking, ToN-IoT, and CICIDS-2017 to illustrate the utility of the TIMIF framework over some commonly used baselines and state-of-the-art techniques.},
 author = {Kumar, Prabhat and Kumar, Randhir and Jolfaei, Alireza and Mohammad, Nazeeruddin},
 doi = {10.1109/JIOT.2024.3397652},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Security;Biological system modeling;Servers;Computer crime;Ecosystems;Threat modeling;Soft sensors;Cyber threats;deep learning (DL);Internet of Vehicles (IoV);threat intelligence (TI);vehicle–road cooperation systems (VRCSs)},
 month = {Nov},
 number = {22},
 pages = {35964-35974},
 title = {An Automated Threat Intelligence Framework for Vehicle–Road Cooperation Systems},
 volume = {11},
 year = {2024}
}

@article{10522640,
 abstract = {The goal of current research will be to increase the accuracy and generalisation capacity of intrusion detection models in order to better handle the complex network security issues of today. In this paper, a new hybrid attention mechanism is introduced along with an enhanced algorithm. Through the effective channel layer and curve space layer, the feature information will be concentrated on the necessary feature information, allowing the model to concentrate more on the features linked to classification and become more broadly applicable. Increase the model’s precision. The experimental results demonstrated that the accuracy can achieve 100%, 99.79%, and 98.10% on binary classification problems and 96.37%, 98.12%, and 99.06% on multiclassification problems, respectively, using the UNSW-NB15, CICIDS-2017, and CICIDS-2018 datasets for validation.},
 author = {Hu, Xuntao and Meng, Xiancai and Liu, Shaoqing and Liang, Lizhen},
 doi = {10.1109/ACCESS.2024.3398007},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Logic gates;Feature extraction;Intrusion detection;Adaptation models;Convolutional neural networks;Residual neural networks;Data models;Long short term memory;Bidirectional control;Intrusion detection;residual networks;hybrid attention mechanisms;bidirectional long and short memory networks},
 month = {},
 number = {},
 pages = {66432-66441},
 title = {An Improved Algorithm for Network Intrusion Detection Based on Deep Residual Networks},
 volume = {12},
 year = {2024}
}

@article{10530014,
 abstract = {To solve the problem that the existing intrusion traffic detection models generally adopt machine learning algorithm and supervised deep learning algorithm, and the classification accuracy of model small samples is low, A unsupervised learning intrusion traffic classification model based on Wasserstein divergence objective for generative adversarial nets (WGAN-div) and information maximizing generative adversarial nets (Info GAN) is presented. The algorithm uses generative adversarial network to optimize the sampling of unbalanced data sets and effectively improves the feature extraction capability of small samples of the model. Firstly, the unbalanced data training set is oversampled by WGAN-div to improve the data distribution. Then, the non-data part is processed by independent thermal coding and integrated with the data part to reduce the complexity of pretreatment. Finally, the Info GAN model is used for data training. Performance evaluation and algorithm performance comparison were carried out in NSL-KDD, CICIDS2017 and UNSW-NB15 data sets. The experimental results show that the accuracy of multi-classification task is 91.1%, 97.1%, 79.9% respectively, and the accuracy of binary classification task is 90.9%, 96.9%, 86.1% respectively. Compared with the classical deep learning algorithm, the Info GAN model has higher accuracy and lower false positive rate, and has higher reliability and engineering application value.},
 author = {Zhong, Zhaogen and Xie, Cunxiang and Tang, Xibo},
 doi = {10.1109/ACCESS.2024.3400213},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Generative adversarial networks;Machine learning algorithms;Training;Deep learning;Generators;Task analysis;Intrusion detection;Data models;Performance evaluation;Intrusion traffic detection;generative adversarial nets;oversampling;unbalanced datasets},
 month = {},
 number = {},
 pages = {67860-67879},
 title = {Intrusion Traffic Detection and Classification Based on Unsupervised Learning},
 volume = {12},
 year = {2024}
}

@article{10531223,
 abstract = {During the past 10 years, researchers have extensively explored the use of machine learning (ML) in enhancing network intrusion detection systems (IDS). While many studies focused on improving accuracy of ML-based IDS, true effectiveness lies in robust generalization: the ability to classify unseen data accurately. Many existing models train and test on the same dataset, failing to represent the real unseen scenarios. Others who train and test using different datasets often struggle to generalize effectively. This study emphasizes the improvement of generalization through a novel composite approach involving the use of a lifecycle-based dataset (characterizing the attack as sequences of techniques), automatic feature learning (auto-learning), and a CNN-based deep learning model. The established model is tested on five public datasets to assess its generalization performance. The proposed approach demonstrates outstanding generalization performance, achieving an average F1 score of 0.85 and a recall of 0.94. This significantly outperforms the 0.56 and 0.42 averages recall achieved by attack-based datasets using CIC-IDS-2017 and CIC-IDS-2018 as training data, respectively. Furthermore, auto-learning features boost the F1 score by 0.2 compared to traditional statistical features. Overall, the efforts have resulted in significant advancements in model generalization, offering a more robust strategy for addressing intrusion detection challenges.},
 author = {Sudyana, Didik and Lin, Ying-Dar and Verkerken, Miel and Hwang, Ren-Hung and Lai, Yuan-Cheng and D’Hooge, Laurens and Wauters, Tim and Volckaert, Bruno and De Turck, Filip},
 doi = {10.1109/TMLCN.2024.3402158},
 issn = {2831-316X},
 journal = {IEEE Transactions on Machine Learning in Communications and Networking},
 keywords = {Testing;Feature extraction;Training;Data models;Machine learning;Deep learning;Training data;Intrusion detection;ML-based IDS;model generalization;lifecycle-based dataset;auto-learning features},
 month = {},
 number = {},
 pages = {645-662},
 title = {Improving Generalization of ML-Based IDS With Lifecycle-Based Dataset, Auto-Learning Features, and Deep Learning},
 volume = {2},
 year = {2024}
}

@article{10531741,
 abstract = {Network management is a crucial task to maintain modern systems and applications running. Some applications have become vital for society and are expected to have zero downtime. Software-defined networks is a paradigm that collaborates with the scalability, modularity and manageability of systems by centralizing the network’s controller. However, this creates a weak point for distributed denial of service attacks if unprepared. This study proposes an anomaly detection system to detect distributed denial of service attacks in software-defined networks using generative adversarial neural networks with gated recurrent units. The proposed system uses unsupervised learning to detect unknown attacks in an interval of 1 second. A mitigation algorithm is also proposed to stop distributed denial-of-service attacks from harming the network’s operation. Two datasets were used to validate this model: the first developed by the computer networks study group Orion from the State University of Londrina. The second is a well-known dataset: CIC-DDoS2019, widely used by the anomaly detection community. Besides the gated recurrent units, other types of neurons are also tested in this work, they are: long short-term memory, convolutional and temporal convolutional. The detection module reached an F1-score of 99@ in the first dataset and 98@ in the second, while the mitigation module could drop 99@ of malicious flows in both datasets.},
 author = {Brandão Lent, Daniel M. and da Silva Ruffo, Vitor G. and Carvalho, Luiz F. and Lloret, Jaime and Rodrigues, Joel J. P. C. and Lemes Proença, Mario},
 doi = {10.1109/ACCESS.2024.3402069},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Logic gates;Generators;Generative adversarial networks;Control systems;Neurons;Training;Biological neural networks;Anomaly detection;Deep learning;Software defined networking;Anomaly detection;deep learning;generative adversarial networks;software-defined networks},
 month = {},
 number = {},
 pages = {70690-70706},
 title = {An Unsupervised Generative Adversarial Network System to Detect DDoS Attacks in SDN},
 volume = {12},
 year = {2024}
}

@article{10536874,
 abstract = {Systemic vulnerabilities in the Internet of Things (IoT) pose a challenge for establishing robust cybersecurity strategies. These challenges leave IoT devices susceptible to infection, often falling victim to far-reaching Botnets. To counter these risks, Intrusion Detection Systems (IDS) are designed to detect attacks within the network, mitigating the dangers presented by architecturally vulnerable IoT devices. However, IDS solutions are designed to operate at the center of the network, requiring network traffic to be forwarded inwards and consequently hampers reaction times while straining network resources. This paper introduces an IoT Botnet detection pipeline composed of a novel network traffic visualization methodology and a Convolutional Neural Network (CNN). The pipeline operates on an embedded system at the edge of the network, transforming network traffic into a visual format for subsequent cyberattack classification by the CNN. By leveraging the advantages of CNNs in efficiently classifying images, the pipeline achieves high accuracy in detecting Botnet attacks while maintaining an efficient design. During testing, we applied the pipeline to the N-BaIoT and IoT-23 datasets and observed high cyberattack detection rates of 100% and 99.78%, respectively. Furthermore, we observed a 2.4 times greater throughput (packets/second) and a 21.4% reduction in model size compared to a Deep Neural Network of similar accuracy.},
 author = {Arnold, David and Gromov, Mikhail and Saniie, Jafar},
 doi = {10.1109/ACCESS.2024.3404270},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Internet of Things;Convolutional neural networks;Telecommunication traffic;Visualization;Cyberattack;Computer security;Detection algorithms;Telecommunication traffic;Botnets;cybersecurity;convolutional neural network;intrusion detection systems},
 month = {},
 number = {},
 pages = {73547-73560},
 title = {Network Traffic Visualization Coupled With Convolutional Neural Networks for Enhanced IoT Botnet Detection},
 volume = {12},
 year = {2024}
}

@article{10538129,
 abstract = {As a consequence of increased complexity, technical requirements of services and expectations of end-users, telecommunication networks and systems must still increase their efficiency. Research currently focuses on introducing automation and intelligence into network control and management. Neural Networks form a class of Machine Learning techniques utilizing the supervised learning paradigm. The class is mature and comprises a significant number of algorithms. As a result, Neural Networks-based solutions are widely applicable, also in the context of communications and networking. The aim of this tutorial is twofold. Firstly, to provide fundamentals regarding the Neural Network (NN) method. Secondly, to comprehensively study the examples of applying NN-based solutions to solve problems in different aspects of communications and networking. Studies are supplemented with additional explanations, figures and critical considerations, including pros and cons of using selected methods for particular purposes. This part uniquely complements the tutorial one and facilitates in-depth understanding of NN. Based on the conducted studies, we draw a comparative analysis, summaries and expected future research topics and challenges of using NN in communications and networking.},
 author = {Borylo, Piotr and Biernacka, Edyta and Domzal, Jerzy and Kadziolka, Bartosz and Kantor, Miroslaw and Rusek, Krzysztof and Skala, Maciej and Wajda, Krzysztof and Wojcik, Robert and Zabek, Wojciech},
 doi = {10.1109/ACCESS.2024.3404866},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial neural networks;Tutorials;Wireless communication;Quality of service;Neural networks;Quality of experience;Optical fiber networks;Computer networks;Computer networks;example-based tutorial;neural networks},
 month = {},
 number = {},
 pages = {132856-132890},
 title = {Neural Networks in Selected Aspects of Communications and Networking},
 volume = {12},
 year = {2024}
}

@article{10538232,
 abstract = {The growth of cyber threats demands a robust and adaptive intrusion detection system (IDS) capable of effectively recognizing malicious activities from network traffic. However, the existing imbalance of class in network data possesses a significant challenge to traditional IDS. To overcome these challenges, this project proposes a novel hybrid Intrusion Detection System using machine learning algorithms, which includes XGBoost, Long Short-Term Memory (LSTM), Mini-VGGNet, and AlexNet, which is used to handle the unbalanced network traffic data. Furthermore, the Random Forest Regressor is used to ascertain the importance of features for enhancing detection accuracy and interpretability. Addressing the inherent class imbalance in network data is crucial for ensuring the IDS’s effectiveness. The proposed system employs a combination of oversampling techniques for minority classes and under sampling techniques for majority classes during data preprocessing. This balanced representation of network traffic data helps prevent the IDS from being biased towards the majority class and improves its ability to detect rare or novel intrusions. The utilization of Random Forest Regressor for feature extraction serves a dual purpose. It helps identify the most relevant features within the network traffic data that contribute significantly to detecting intrusions. It enables the system to prioritize and focus on these important features during model training, thereby enhancing detection accuracy while reducing computational complexity. This research contributes to the ongoing efforts to mitigate cyber threats and safeguard critical network infrastructures.},
 author = {Pavithra, S. and Venkata Vikas, K.},
 doi = {10.1109/ACCESS.2024.3405187},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Telecommunication traffic;Computer hacking;Cloud computing;Autonomous aerial vehicles;Random forests;Long short term memory;Cyberattack;Computer security;Ensemble learning;Network security;Cyber threats;cyber security;deep learning (DL);ensemble learning;intrusion detection;network security},
 month = {},
 number = {},
 pages = {74096-74107},
 title = {Detecting Unbalanced Network Traffic Intrusions With Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10538333,
 abstract = {The ever-expanding Internet of Things (IoT) landscape presents a double-edged sword. While it fosters interconnectedness, the vast amount of data generated by IoT devices creates a larger attack surface for cybercriminals. Intrusions in these environments can have severe consequences. To combat this growing threat, robust intrusion detection systems (IDS) are crucial. The data comprised by this attack is multivariate, highly complex, non-stationary, and nonlinear. To extract the complex patterns from this complex data, we require the most robust, optimized tools. Machine learning (ML) and deep learning (DL) have emerged as powerful tools for IDSs, offering high accuracy in detecting and preventing security breaches. This research delves into anomaly detection, a technique that identifies deviations from normal system behavior, potentially indicating attacks. Given the complexity of anomaly data, we explore methods to improve detection performance. This research investigates the design and evaluation of a novel IDS. We leverage and optimize supervised ML methods like tree-based Support Vector Machines (SVM), ensemble methods, and neural networks (NN) alongside the cutting-edge DL approach of long short-term memory (LSTM) and vision transformers (ViT). We optimized the hyperparameters of these algorithms using a robust Bayesian optimization approach. The implemented ML models achieved impressive training accuracy, with Random Forest and Ensemble Bagged Tree surpassing 99.90% of accuracy, an AUC of 1.00, an F1-score, and a balanced Matthews Correlation Coefficient (MCC) of 99.78%. While the initial deep learning LSTM model yielded an accuracy of 99.97%, the proposed ViT architecture significantly boosted performance with 100% of all metrics, along with a validation accuracy of 78.70% and perfect training accuracy. This study demonstrates the power of our new methods for detecting and stopping attacks on Internet of Things (IoT) networks. This improved detection offers a three-pronged approach to security: increased system reliability through attack prevention, enhanced security by swiftly identifying and mitigating fraudulent activity, and optimized network performance by preventing malicious attacks. Consequently, these methods offer significant potential for fortifying the security of IoT networks.},
 author = {Sana, Laraib and Nazir, Muhammad Mohsin and Yang, Jing and Hussain, Lal and Chen, Yen-Lin and Ku, Chin Soon and Alatiyyah, Mohammed and Alateyah, Sulaiman Abdullah and Por, Lip Yee},
 doi = {10.1109/ACCESS.2024.3404778},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Anomaly detection;Intrusion detection;Security;Transformers;Telecommunication traffic;Computer science;Deep learning;Vision transformers;anomaly detection;intrusion detection;IoT;deep learning},
 month = {},
 number = {},
 pages = {82443-82468},
 title = {Securing the IoT Cyber Environment: Enhancing Intrusion Anomaly Detection With Vision Transformers},
 volume = {12},
 year = {2024}
}

@article{10540092,
 abstract = {The relentless global population growth and the ever-increasing food demand pose formidable challenges to the agricultural sector. Farmers grapple with the ongoing challenge of wildlife-induced crop damage and human loss, which not only impedes food production but also exacerbates supply and demand imbalances. However, the rise of TinyML enables Edge AI as a promising avenue for implementing resource-efficient deep learning techniques on low-end edge devices. In this paper, we introduce an innovative solution that harnesses the power of Edge AI using tinyML-based deep learning algorithms in conjunction with the Internet of Things (IoT) for animal intrusion detection and deterrence system. The proposed system is developed to create remotely managed defense system tailored to safeguard vast agricultural expanses. It integrates a laser detection system and an AI-CAM with light weight deep learning algorithms for animal intrusion detection and classification. This system also ensures efficient animal deterrence and real-time monitoring for farmers, enabling them to assess the situation with the assistance of an intelligent rover build using IoT. This work emphasizes on proposing a light-weight deep learning model named EvoNet for animal classification. Results reveal that the proposed model achieves the highest accuracy at 96.7%, surpassing other models presented in this paper. However, for edge devices where compact file sizes are crucial, the model also offers comparable accuracy with file sizes as low as 1.63MB with the help of pruning and quantization techniques. This conceptualized solution has the potential to revolutionize agricultural wildlife management, ushering in a new era of crop protection and economic resilience.},
 author = {Reddy, Konkala Venkateswarlu and Reddy, B. S. Karthikeya and Goutham, Veerapu and Mahesh, Miriyala and Nisha, J. S. and Palanisamy, Gopinath and Golla, Mallikarjuna and Purushothaman, Swetha and Reddy, Katangure Rithisha and Ramkumar, Varsha},
 doi = {10.1109/ACCESS.2024.3406585},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Crops;Wildlife;Deep learning;Agriculture;Internet of Things;Wireless sensor networks;Intrusion detection;Animals;Edge computing;Artificial intelligence;Sustainable development;Smart agriculture;Farming;Threat assessment;Animal intrusion detection;attention mechanism;deep learning;edge AI;EvoNet;intelligent rover;Internet of Things;sustainable farming;TinyML},
 month = {},
 number = {},
 pages = {77707-77723},
 title = {Edge AI in Sustainable Farming: Deep Learning-Driven IoT Framework to Safeguard Crops From Wildlife Threats},
 volume = {12},
 year = {2024}
}

@article{10540382,
 abstract = {The exponential growth of intrusions on networked systems inspires new research directions on developing artificial intelligence (AI) techniques for intrusion detection systems (IDS). In this context, several AI techniques have been leveraged for automating network intrusion detection tasks. However, each AI model has unique strengths points and weaknesses, and one may be better than the other depending on the dataset, which might aggravate which model to choose. Thus, combining these AI models can improve their use of generalization and application in network intrusion detection tasks. In this paper, we aim to fill such a gap by evaluating diverse ensemble methods for network intrusion detection systems. In particular, we build a two-level ensemble learning framework for evaluating such ensemble learning methods in network intrusion detection tasks. In the first level of our framework, we load the input dataset, train the base learners and ensemble methods, and generate the evaluation metrics. This level also produces new datasets (needed to train the second level) based on both prediction probabilities of base and ensemble models used in the first level. The second level of the framework consists of loading the datasets generated from the first level, training the ensemble methods, and generating the evaluation metrics. Our framework also considers feature selection for both levels. In particular, we perform XAI-based feature selection in the first level and Information Gain-based feature selection in the second level. We present results for several ensemble model combinations in our two-level framework (i.e., 24 methods), including different bagging, stacking, and boosting methods on several base learners (e.g., decision trees, support vector machines, deep neural networks, and others). We evaluate our framework on three network intrusion datasets with different characteristics (RoEduNet-SIMARGL2021, NSL-KDD, and CICIDS-2017). We also categorize AI models according to their performances on our evaluation metrics. Our evaluation shows that it is beneficial to perform two-level learning for most setups considered in this work. We also release our source codes for the community to access as a baseline two-level ensemble learning framework for network intrusion detection.},
 author = {Arreche, Osvaldo and Bibers, Ismail and Abdallah, Mustafa},
 doi = {10.1109/ACCESS.2024.3407029},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Ensemble learning;Artificial intelligence;Feature extraction;Decision trees;Stacking;Computational modeling;Bayes methods;Intrusion detection;Network security;Intrusion detection systems;ensemble learning;network security;two-level learning;feature selection;machine learning;NSL-KDD;CICIDS-2017;RoEduNet-SIMARGL2021},
 month = {},
 number = {},
 pages = {83830-83857},
 title = {A Two-Level Ensemble Learning Framework for Enhancing Network Intrusion Detection Systems},
 volume = {12},
 year = {2024}
}

@article{10542382,
 abstract = {Large scale enterprise networks often use Enterprise Key-Management (EKM) platforms for unified management of cryptographic keys. Monitoring access and usage patterns of EKM Systems (EKMS) may enable detection of anomalous (possibly malicious) activity in the enterprise network that is not detectable by other means. Analysis of enterprise system logs has been widely studied (for example at the operating system level). However, to the best of our knowledge, EKMS metadata has not been used for anomaly detection. In this article we present a framework for anomaly detection based on EKMS metadata. The framework involves automated outlier rejection, normal heuristics collection, automated anomaly detection, and system notification and integration with other security tools. This is developed through investigation of EKMS metadata, determining characteristics to extract for dataset generation, and looking for patterns from which behaviors can be inferred. For automated labeling and detection, a deep learning-based model is applied to the generated datasets: Long Short-Term Memory (LSTM) auto-encoder neural networks with specific parameters. This generates heuristics based on categories of behavior. As a proof of concept, we simulated an enterprise environment, collected the EKMS metadata, and deployed this framework. Our implementation used QuintessenceLabs EKMS. However, the framework is vendor neutral. The results demonstrate that our framework can accurately detect all anomalous enterprise network activities. This approach could be integrated with other enterprise information to enhance detection capabilities. Further, our proposal can be used as a general-purpose framework for anomaly detection and diagnosis.},
 author = {Baee, Mir Ali Rezazadeh and Simpson, Leonie and Armstrong, Warren},
 doi = {10.1109/OJCS.2024.3407547},
 issn = {2644-1268},
 journal = {IEEE Open Journal of the Computer Society},
 keywords = {Metadata;Anomaly detection;Security;Servers;Long short term memory;Organizations;Training;Anomaly detection;deep learning;enterprise key-management system;framework;metadata analysis},
 month = {},
 number = {},
 pages = {315-328},
 title = {Anomaly Detection in Key-Management Activities Using Metadata: A Case Study and Framework},
 volume = {5},
 year = {2024}
}

@article{10542982,
 abstract = {Fields such as machine learning and artificial intelligence are proven business enablers, we have several use cases in the field of technology from basic implementations such as automated scanners, and weak forms such as Alexa and Siri that have paved the way for further development. Search for more avenues of investment in this field continues till date. It’s also evident that researchers and organizations have barely scratched the surface in terms of exploring and using AI (Artificial intelligence) as a technology. Theoretical forms of AI have not yet been implemented. This paper aims to provide some context around the various forms of AI currently used and can be explored in the near future. It’s important to be mindful that, with the use of any technology, even AI, there are challenges, regulations, and security risks that tag along. Firms need to pay close attention to the macro factors that could impact the adoption and AI in their respective businesses. This study aims to provide a brief overview of the aforementioned road blocks that could impact AI adoption, however, there are some solution strategies or approaches that could help firms along the way to overcome those road blocks. These strategies might take time to build and take effect but they will be beneficial in the long run and thus help with not only sustainable implementation, but also complete and successful adoption of AI as a technology enabler.},
 author = {Shetty, Pranith},
 doi = {10.1109/ACCESS.2024.3408144},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Security;Virtual assistants;Data models;Business;Regulation;Deep learning;Generative AI;Risk management;Artificial intelligence;generative AI;security;risk;risk management;AI for security;security for AI;AI security},
 month = {},
 number = {},
 pages = {77468-77474},
 title = {AI and Security, From an Information Security and Risk Manager Standpoint},
 volume = {12},
 year = {2024}
}

@article{10543240,
 abstract = {In practical abnormal traffic detection scenarios, traffic often appears as drift, imbalanced and rare labeled streams, and how to effectively identify malicious traffic in such complex situations has become a challenge for malicious traffic detection. Researchers have extensive studies on malicious traffic detection with single challenge, but the detection of complex traffic has not been widely noticed. Queried adaptive random forests (QARF) is proposed to detect traffic streams with concept drift, imbalance and lack of labeled instances. QARF is an online active learning based approach which combines adaptive random forests method and adaptive margin sampling strategy. QARF achieves querying a small number of instances from unlabeled traffic streams to obtain effective training. We conduct experiments using the NSL-KDD dataset to evaluate the performance of QARF. QARF is compared with other state-of-the-art methods. The experimental results show that QARF obtains 98.20% accuracy on the NSL-KDD dataset. QARF performs better than other state-of-the-art methods in comparisons.},
 author = {Niu, Zequn and Xue, Jingfeng and Wang, Yong and Lei, Tianwei and Han, Weijie and Gao, Xianwei},
 doi = {10.23919/cje.2022.00.360},
 issn = {2075-5597},
 journal = {Chinese Journal of Electronics},
 keywords = {Training;Streams;Random forests;Active learning;Online learning;Malicious traffic;Concept drift;Data imbalance},
 month = {May},
 number = {3},
 pages = {645-656},
 title = {QARF: A Novel Malicious Traffic Detection Approach via Online Active Learning for Evolving Traffic Streams},
 volume = {33},
 year = {2024}
}

@article{10549916,
 abstract = {Distributed denial of service (DDoS) is an awful cyber threat, becoming more prevalent with mature heterogeneous IoT (HetIoT) applications like intelligent agriculture, wearables, and self-driving cars. Developing intelligent intrusion detection systems (IDS) using deep learning (DL) techniques to protect HetIoT has sparked a lot of attention. Federated learning (FL) helps to train the IDS locally with local data while respecting data privacy. Edge computing (EC) enhances security by processing data closer to the edge network. Therefore, the research contributed by integrating EC, FL, and DL and the proposed Edge-FL-based IDS. The proposed Edge-FL-based IDS aims to enhance HetIoT security by safeguarding data privacy against DDoS attacks. The research developed a DL-based convolutional neural network (CNN) classifier and used the CICDDoS2019 dataset to evaluate the success rate of the proposed Edge-FL-based IDS against DDoS attacks. The research employed IID and non-IID data distributions with participant clients K =3, K =5, and K =7. The findings indicate that the proposed Edge-FL-based IDS outperforms centralized and other state-of-the-art FL models. The proposed Edge-FL-based IDS correctly detects and classifies DDoS attacks with the following accuracy: (a) 8-class IID: K =3 is 99.98%, K =5 is 99.97%, K =7 is 99.96%. (b) 8-class non-IID: K =3 is 99.97%, K =5 is 99.94%, K =7 is 99.90%. (c) 12-class IID: K =3 is 99.96%, K =5 is 99.96%, K =7 is 99.95%. (d)12-class non-IID: K =3 is 99.07%, K =5 is 96.44%, K =7 is 52.39%.},
 author = {Mahadik, Shalaka S. and Pawar, Pranav M. and Muthalagu, Raja},
 doi = {10.1109/ACCESS.2024.3410046},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Training;Security;Computer crime;Data privacy;Performance evaluation;Denial-of-service attack;Heterogeneous networks;Internet of Things;Edge computing;Heterogeneous IoT;distributed denial of service (DDoS);federated learning (FL);independent and identically distributed (IID);non-IID;edge computing (EC)},
 month = {},
 number = {},
 pages = {81736-81757},
 title = {Edge-Federated Learning-Based Intelligent Intrusion Detection System for Heterogeneous Internet of Things},
 volume = {12},
 year = {2024}
}

@article{10552160,
 abstract = {In-network function offloading using programmable data plane languages like P4 offers computational resource savings and efficient operations at the network edge. However, the deployment of ML functions in P4~switches exploiting no additional hardware remains a challenge. In this paper, we tackle the challenges in deploying Deep Neural Networks (DNNs) within programmable network devices, introducing a novel distillation based on Look-Up Tables (LUTs). The proposed method maps quantized DNNs into a cascaded arrangement of LUTs without loss in accuracy and independently of the quantized network depth. The developed approach is demonstrated in two network function use cases: a cyber security use case focused on mitigating Distributed Denial of Service attacks and a malicious activity classification task in IoT Networks. Experimental results show a trade-off between model’s accuracy, expressed in terms of F1-Score and the computational demands, influenced by bit size and number of LUTs. In addition, the latency for deploying these models ranged from 54ns to 112ns, showing the method's practical applicability in network functions.},
 author = {Paolini, Emilio and de Marinis, Lorenzo and Scano, Davide and Paolucci, Francesco},
 doi = {10.1109/OJCOMS.2024.3411071},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Table lookup;Pipelines;Hardware;Artificial neural networks;Optical switches;Computer crime;Feature extraction;Cyber security;deep neural networks;look-up tables;P4;traffic classification},
 month = {},
 number = {},
 pages = {3556-3567},
 title = {In-Line Any-Depth Deep Neural Networks Using P4 Switches},
 volume = {5},
 year = {2024}
}

@article{10552260,
 abstract = {Cybersecurity in the Internet of Things (IoT) ecosystem is vital to protect sensitive data, stop unauthorized access, and mitigate the risk of disruptive cyberattacks. Cyberattack recognition utilizing an intrusion detection system (IDS) is a major imperative given the increase in the number of connected devices. Advanced cybersecurity methods deploy machine learning (ML) approaches, anomaly detection, and behavioral analysis to analyze IoT network traffic for irregular patterns indicative of potential cyberattacks. The combination of feature selection (FS) and deep learning (DL) approaches in cyberattack recognition suggests a proactive and sophisticated manner to bolster cybersecurity. Leveraging DL structures like neural networks (NNs) assists the automatic extraction and analysis of intricate patterns in the difficult IoT data landscape. This paper develops an Improved Mayfly Optimization Algorithm with a Hybrid Deep Learning based Intrusion Detection (IMFOHDL-ID) approach in IoT environments. The designed IMFOHDL-ID approach’s main goal is to classify intrusions and accomplish security in the IoT environment. The IMFOHDL-ID technique initially follows data normalization as a preprocessing stage. In addition, the IMFOHDL-ID technique makes use of the IMFO-based feature selection (FS) method to elect feature subsets. For IDs, the IMFOHDL-ID technique applies the Long Short Term Memory based Deep Stacked Sequence-to-Sequence Autoencoder (LSTM-DSSAE) model. Finally, the dipper-throated optimization algorithm (DTOA) was utilized for optimal hyperparameter selection of the LSTM-DSSAE method. To highlight better results of the IMFOHDL-ID model, a series of simulation analyses were performed. Extensive comparative results stated the improved outcome of the IMFOHDL-ID technique over existing approaches.},
 author = {Duraibi, Salahaldeen and Mujawib Alashjaee, Abdullah},
 doi = {10.1109/ACCESS.2024.3411612},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Feature extraction;Optimization;Cyberattack;Long short term memory;Safety;Intrusion detection;Computer security;Detection algorithms;Cybersecurity;intrusion detection system;feature selection;hybrid deep learning;Internet of Things},
 month = {},
 number = {},
 pages = {84752-84762},
 title = {Enhancing Cyberattack Detection Using Dimensionality Reduction With Hybrid Deep Learning on Internet of Things Environment},
 volume = {12},
 year = {2024}
}

@article{10552262,
 abstract = {The growing interest in applying neural networks for cybersecurity has prompted a substantial increase in related research. This paper presents a comprehensive bibliometric analysis of research on cybersecurity towards neural networks published in the Web of Science over the past two decades (2003–2023) using bibliometric methods and CiteSpace software. The analysis encompasses yearly publication trends, types of publications, and trends across various dimensions such as publishing sources, organizations, researchers, countries, and keywords. Additionally, timeline and burst detection analyses were conducted to identify significant topic trends and citations in the last two decades. It also outlines the latest trends, under-explored topics, and open challenges.},
 author = {Shevchuk, Ruslan and Martsenyuk, Vasyl},
 doi = {10.1109/ACCESS.2024.3411632},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Neural networks;Computer security;Market research;Bibliometrics;Visualization;Knowledge engineering;Databases;Neural network;cybersecurity;scientometric database;domaine map analysis;CiteSpace},
 month = {},
 number = {},
 pages = {81265-81280},
 title = {Neural Networks Toward Cybersecurity: Domain Map Analysis of State-of-the-Art Challenges},
 volume = {12},
 year = {2024}
}

@article{10555270,
 abstract = {Blockchain networks serve as a transparent and secure ledger storage solution, yet they remain vulnerable to attacks. There must be some mechanism to protect the blockchain network from attacks. Among various attacks, the Distributed Denial of Service (DDoS) attack is considered severe, which is challenging to detect accurately and reliably. Machine learning techniques are used to detect the attack, which requires exploring all global attack data in a single system, which is difficult in practice. This article proposes a distributed machine learning mechanism called Federated Machine Learning for detecting the presence of DDoS attacks. But in federated machine learning the model itself can be poisoned by the malicious collaborating node which is another problem that this article solves by storing the model in blockchain and by introducing a new reputation-based miner selection procedure. The proposed framework integrates the federation of machine learning within the blockchain network framework for detecting DDoS attacks. Under the integrated framework, miners are used to train the blocks and they also participate in the machine learning training. A dynamic reputation-based miner selection mechanism that can balance exploration and exploitation is proposed for optimal miner selection, which can ensure the high accuracy of the machine learning model and improve the security of blockchain from attacks like DDoS attacks and 51% attacks. The proposed framework is tested with Random Forest, Multilayer Perceptron, and Logistic Regression machine learning algorithms. The proposed mechanism achieved maximum accuracy of 99.1% using random forest model which is superior to the existing mechanism of detection of DDoS attacks.},
 author = {Saveetha, D. and Maragatham, G. and Ponnusamy, Vijayakumar and Zdravković, Nemanja},
 doi = {10.1109/ACCESS.2024.3413076},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Denial-of-service attack;Machine learning;Computer crime;Training;Federated learning;Data models;Random forests;Accuracy;Secure storage;Reliability;Multilayer perceptrons;Blockchain;DDoS attack;federated learning;flower framework;machine learning},
 month = {},
 number = {},
 pages = {127903-127915},
 title = {An Integrated Federated Machine Learning and Blockchain Framework With Optimal Miner Selection for Reliable DDOS Attack Detection},
 volume = {12},
 year = {2024}
}

@article{10559222,
 abstract = {Cloud-based deployments face increasing threats from various types of attacks, necessitating robust anomaly detection frameworks to safeguard against potential security breaches. Existing solutions, such as RSSI, GTM, and APG, though effective to a certain extent, exhibit limitations in terms of precision, accuracy, and scalability. To address these shortcomings, this paper proposes a novel anomaly detection framework that integrates multimodal feature analysis, deep learning models, and QoS-aware sidechains to enhance the prediction accuracy of cloud attacks and optimize blockchain-based cloud installations. By maximizing feature variance across different sample types and leveraging advanced deep learning techniques, the proposed approach significantly outperforms conventional methods in terms of precision, accuracy, recall, and AUC performance. Furthermore, the framework demonstrates superior efficiency in block mining delay, energy consumption, and throughput, making it highly suitable for real-time cloud attack prediction scenarios. The proposed methodology represents a significant advancement in anomaly detection and cloud security, offering a comprehensive solution for addressing challenges in blockchain-based cloud deployments. Thus, the proposed anomaly detection framework employs both Deep Learning and Blockchain technologies. Using Recurrent Neural Networks (RNN) with Convolutional Neural Networks (CNN), the system examines system logs and identifies unusual behavior patterns associated with different attacks. Using Blockchain technology, the framework ensures the transparency and integrity of system logs, and Deep Learning models provide precise and timely anomaly detection. The decision to combine Deep Learning and Blockchain technology is justified by the merits of each technique. The distributed, immutable ledger provided by blockchain technology makes it impossible to tamper with system logs and ensures the accuracy of anomaly detection. While, deep learning models, have exceptional pattern recognition abilities and can adapt to changing attack methods, resulting in high precision, accuracy, recall, and AUC metrics. Analyses of experimental data demonstrate that the proposed framework is effective. The framework achieves impressive performance metrics, such as low delays, 98.5% precision, 99.4% accuracy, 98.3% recall, and 99.2% Area Under the Curve (AUC).},
 author = {Nagarjun, A. Venkata and Rajkumar, Sujatha},
 doi = {10.1109/ACCESS.2024.3414998},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing;Anomaly detection;Blockchains;Deep learning;Accuracy;Delays;Security;Privacy;Anomaly detection;attacks;blockchain;cloud computing;deep learning;privacy},
 month = {},
 number = {},
 pages = {84843-84862},
 title = {Design of an Anomaly Detection Framework for Delay and Privacy-Aware Blockchain-Based Cloud Deployments},
 volume = {12},
 year = {2024}
}

@article{10562250,
 abstract = {The surge in the number of driverless cars highlights the necessity for enhanced transportation safety and efficiency. Achieving fully autonomous driving depends on the ability of vehicles to comprehend environmental conditions and respond to collective behaviors facilitated by communication technology. Connected and Automated Vehicles (CAV) rely on vehicular ad hoc networks (VANET) to exchange information among vehicles and with infrastructure such as RoadSide Units (RSU). While conventional security measures fall short in the dynamic and uncharted VANET field, machine learning presents a promising avenue for fortification. However, the scarcity of data, particularly regarding Vehicle-to-Infrastructure (V2I) communication, poses a significant challenge for applying machine learning, particularly deep learning. Existing efforts have primarily focused on synthesizing datasets for vehicle-to-vehicle (V2V) communication, leaving a void in the V2I security research. This study bridges this gap with the development of GenVRAM, a simulated CAV dataset generator tailored for creating both normal and attack data, with a specific focus on misbehaving RSU. Through rigorous experimentation with various machine and deep learning models, our research elucidates the inadequacies of traditional machine-learning algorithms in addressing VANET security concerns. Although deep learning exhibits promise, further refinement, and investigation are imperative to ascertain its efficacy in safeguarding VANET. GenVRAM is a pioneering contribution in the realm of VANET security, providing researchers and practitioners with a valuable tool for advancing the resilience of autonomous vehicle systems against malicious attacks.},
 author = {Ramsamooj, Devaj and Sharma, Prinkle and Liu, Hong},
 doi = {10.1109/ACCESS.2024.3416840},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Vehicular ad hoc networks;Security;Deep learning;Peer-to-peer computing;Generators;Protocols;Benchmark testing;Machine learning;Data models;Cyberattack;Autonomous automobiles;Security;machine learning;deep learning;dataset;cyber-attacks;vehicle-to-infrastructure (V2I);misbehavior},
 month = {},
 number = {},
 pages = {86176-86193},
 title = {GenVRAM: Dataset Generator for Vehicle to Roadside Attacks and Misbehavior},
 volume = {12},
 year = {2024}
}

@article{10570412,
 abstract = {The advent of the sixth generation of mobile communications (6G) ushers in an era of heightened demand for advanced network intelligence to tackle the challenges of an expanding network landscape and increasing service demands. Deep Learning (DL), as a crucial technique for instilling intelligence into 6G, has demonstrated powerful and promising development. This paper provides a comprehensive overview of the pivotal role of DL in 6G, exploring the myriad opportunities and challenges that arise. Firstly, we present a detailed vision for DL in 6G, emphasizing areas such as adaptive resource allocation, intelligent network management, robust signal processing, ubiquitous edge intelligence, and endogenous security. Secondly, this paper reviews how DL models leverage their unique learning capabilities to solve complex service demands in 6G. The models discussed include Convolutional Neural Networks (CNN), Generative Adversarial Networks (GAN), Graph Neural Networks (GNN), Deep Reinforcement Learning (DRL), Transformer, Federated Learning (FL), and Meta Learning. Additionally, we examine the specific challenges each DL model faces within the 6G context. Moreover, we delve into the rapidly evolving field of Artificial Intelligence Generated Content (AIGC), examining its development and impact within the 6G framework. Finally, this paper culminates in a detailed discussion of ten critical open problems in integrating DL with 6G, setting the stage for future research and development in this field.},
 author = {Jiao, Licheng and Shao, Yilin and Sun, Long and Liu, Fang and Yang, Shuyuan and Ma, Wenping and Li, Lingling and Liu, Xu and Hou, Biao and Zhang, Xiangrong and Shang, Ronghua and Li, Yangyang and Wang, Shuang and Tang, Xu and Guo, Yuwei},
 doi = {10.1109/ACCESS.2024.3418900},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {6G mobile communication;Resource management;Adaptation models;Artificial intelligence;Transformers;Deep learning;Intelligent networks;Content management;Deep learning;6G;network intelligence;artificial intelligence generated content (AIGC);open problems},
 month = {},
 number = {},
 pages = {133245-133314},
 title = {Advanced Deep Learning Models for 6G: Overview, Opportunities, and Challenges},
 volume = {12},
 year = {2024}
}

@article{10570419,
 abstract = {An autonomous network defense method under attack is a critical part of preventing network infrastructure from potential damage in real time. Despite various network intrusion detection techniques, our network space is not safe enough due to the increasing exploitation of software vulnerabilities. Thus, timely response and defense methods under network intrusion are important techniques given the large scope of cyberattacks in recent years. In this paper, we design a scalable and autonomous network defense method by using the model of a zero-sum Markov game between an attacker and a defender agent. To scale up the proposed defense model, we utilize a graph convolutional network (GCN) along with framestacking to address the partial observability of the environment. The agents are trained using Proximal Policy Optimization (PPO) which allows for good convergence in a reasonable timeframe. In experiments, we evaluate the proposed model under the large network size while simulating network dynamics including link failures and other network events. The experimental results demonstrate that the proposed method scales well for larger networks and achieves state of the art results on various threat scenarios.},
 author = {Campbell, Robert G. and Eirinaki, Magdalini and Park, Younghee},
 doi = {10.1109/ACCESS.2024.3418931},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Games;Reinforcement learning;Topology;Network topology;Game theory;Optimization;Markov processes;Graph neural networks;Convolutional neural networks;Reinforcement learning;network defense;Markov games;deep learning;graph convolutional networks},
 month = {},
 number = {},
 pages = {92919-92930},
 title = {Scalable and Autonomous Network Defense Using Reinforcement Learning},
 volume = {12},
 year = {2024}
}

@article{10570491,
 abstract = {AI-based Network Intrusion Detection Systems (NIDS) provide effective mechanisms for cybersecurity analysts to gain insights and thwart several network attacks. Although current IDS can identify known/typical attacks with high accuracy, current research shows that such systems perform poorly when facing atypical and dynamically changing (polymorphic) attacks. In this paper, we focus on improving detection capability of the IDS for atypical and polymorphic network attacks. Our system generates adversarial polymorphic attacks against the IDS to examine its performance and incrementally retrains it to strengthen its detection of new attacks, specifically for minority attack samples in the input data. The employed attack quality analysis ensures that the adversarial atypical/polymorphic attacks generated through our system resemble original network attacks. We showcase the high performance of the IDS that we have proposed by training it using the CICIDS2017 and CICIoT2023 benchmark datasets and evaluating its performance against several atypical/polymorphic attack flows. The results indicate that the proposed technique, through adaptive training, learns the pattern of dynamically changing atypical/polymorphic attacks, identifies such attacks with approximately 90% balanced accuracy for most of the cases, and surpasses various state-of-the-art detection and class balancing techniques.},
 author = {Sabeel, Ulya and Heydari, Shahram Shah and El-Khatib, Khalil and Elgazzar, Khalid},
 doi = {10.1109/TMLCN.2024.3418756},
 issn = {2831-316X},
 journal = {IEEE Transactions on Machine Learning in Communications and Networking},
 keywords = {Training;Feature extraction;Data models;Computer security;Artificial intelligence;Benchmark testing;Accuracy;Artificial intelligence;atypical attacks;class imbalance;feature profile;intrusion detection system;polymorphic attacks},
 month = {},
 number = {},
 pages = {869-887},
 title = {Incremental Adversarial Learning for Polymorphic Attack Detection},
 volume = {2},
 year = {2024}
}

@article{10574805,
 abstract = {This paper introduces Matrix-Valued Neural Coordinated Federated Deep Extreme Machine Learning, a novel approach for enhancing health prediction and intrusion detection on the Internet of Healthcare Things (IoHT). By leveraging Machine Learning (ML), blockchain, and Intrusion Detection Systems (IDS), this technique ensures the security of medical data while enabling predictive health analytics. The IoHT, characterized by its vast network of interconnected devices, poses significant challenges in security and confidentiality. However, the integration of proposed technique empowers healthcare systems to proactively address these concerns while enhancing patient outcomes and reducing healthcare costs. Smart healthcare, enabled by ML and blockchain, is revolutionizing healthcare 5.0. Healthcare systems may employ IoHTs’ intelligent and interactive characteristics using proposed approach. Despite its benefits, medical data aggregation poses security, ownership, and regulatory compliance challenges. Federated Learning (FL) is a key technique for distributed learning that protects data. The proposed architecture has several unique benefits like 1) it provides a thorough examination of the incorporation of blockchain technology with FL for healthcare 5.0; 2) it takes the lead in creating a robust healthcare monitoring system that utilizes blockchain technology and IDS to identify and prevent harmful actions; 3) the development of crucial blockchain elements by means of mutual neuronal synchronization of Artificial Neural Networks (ANNs) showcases pioneering progress in safeguarding medical data; and 4) the framework underwent a thorough empirical assessment and outperformed existing methods in accurately predicting intrusion detection and disease prediction, achieving an impressive efficiency rate of 97.75% and 98% respectively. This development represents a major step forward in improving security and predictive abilities within the IoHT ecosystem, offering the potential for revolutionary advancements in healthcare delivery and patient care.},
 author = {Alzakari, Sarah A. and Sarkar, Arindam and Khan, Mohammad Zubair and Alhussan, Amel Ali},
 doi = {10.1109/ACCESS.2024.3420078},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Blockchains;Security;Intrusion detection;Internet;Training;Smart healthcare;Federated learning;Internet of Medical Things;Network security;Federated learning;blockchain;cloud security;Internet of Health Things (IoHT)},
 month = {},
 number = {},
 pages = {99469-99498},
 title = {Converging Technologies for Health Prediction and Intrusion Detection in Internet of Healthcare Things With Matrix- Valued Neural Coordinated Federated Intelligence},
 volume = {12},
 year = {2024}
}

@article{10574822,
 abstract = {Malware detection is an ever-evolving area given that the strides in the detection capabilities being matched by radical attempts to bypass the detection. As the sophistication of malware continues to increase, the demand for innovative approaches to improve detection capabilities become paramount. Machine learning/Deep learning models are being increasingly used for Malware Detection, however one of the most important and frequently overlooked aspects of building such models is feature encoding. This research paper explores the importance of feature encoding to improve the efficiency of threat detection and proposes a novel entropy-based encoding scheme for the categorical features present in the data extracted from malicious inputs. The KDDCUP99, UNSW-NB15 and CIC-Evasive-PDFMal2022 datasets have been used to evaluate the effectiveness of the proposed encoding scheme. The results of the proposed encoding scheme are validated against seven other encoding schemes to ascertain the credibility and usability of the proposed scheme. The efficiency of the proposed system evaluated by applying different encoded versions of the datasets to train various machine learning models and determining the classification performance of the models on each dataset. The machine learning models trained with the proposed encoding scheme produced stable classification results and outperformed other encoding schemes when dimensionality reduction was applied on the data. The ensemble classifier trained using the proposed scheme was able to classify the data with an F1 score of 99.99% when the dimension-reduced entropy-encoded KDD Cup99 dataset was used to build the model. On the CIC-Evasive-PDFMal2022 dataset, the entropy encoding has exhibited a slightly improved classification parameters with the ensemble methods yielding a peak F1 score of 99.27%. We have also determined the feature importance values of the features present in the datasets to study the change in the contribution levels of the features when multiple categorical encoding schemes are applied upon the data.},
 author = {Das, Vipin and Nair, Binoy B. and Thiruvengadathan, Rajagopalan},
 doi = {10.1109/ACCESS.2024.3420080},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Codes;Encoding;Machine learning;Feature extraction;Grippers;Static analysis;Computer security;Intrusion detection;Classification algorithms;Detection algorithms;Cybersecurity;categorical encoding;intrusion detection;machine learning;malware classification;malware detection},
 month = {},
 number = {},
 pages = {91187-91216},
 title = {A Novel Feature Encoding Scheme for Machine Learning Based Malware Detection Systems},
 volume = {12},
 year = {2024}
}

@article{10577764,
 abstract = {DDoS attacks pose serious threats to the availability and reliability of computer networks. With the increasing complexity of DDoS attacks, the accurate detection and classification of these attacks is essential to ensure the protection of network systems. In this paper, we leverage the power of the LSTM model for DDoS attack classification and its ability to automatically learn complex patterns and select features from raw traffic at the packet level. LSTM models have remarkable performance in network traffic classification, however explaining the internal workings of them remains challenging, which hinders their wider adoption in real-world applications. To address this limitation, we propose the SHAP with Pattern Dependency (SHAPPD) approach to explain the predictions of the LSTM model. The results demonstrate significant performance in classifying the DDoS attacks from raw traffic using the LSTM model. SHAPPD effectively explains the predictions of the LSTM model, highlighting the underlying packet traffic fields that drive the LSTM to make its true and false positive predictions and finding the common fields between the DDoS attacks. The results of the comparison between the SHAPPD and the original SHAP emphasize that the SHAPPD is superior to the original SHAP in providing more elaborative justifications for DDoS attacks classification results. The SHAPPD, by quantifying the contribution of each input feature and considering the interdependencies between the features as well as the continued traffic packets, enables security analysts to gain insights into the decision-making process of the LSTM model and identify critical indicators about the DDoS attacks.},
 author = {Assadhan, Basil and Bashaiwth, Abdulmuneem and Binsalleeh, Hamad},
 doi = {10.1109/ACCESS.2024.3421299},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Telecommunication traffic;Feature extraction;Long short term memory;Data models;Predictive models;Protocols;DDoS attacks;machine learning;DL classification;DL explanation;SHAP},
 month = {},
 number = {},
 pages = {90707-90725},
 title = {Enhancing Explanation of LSTM-Based DDoS Attack Classification Using SHAP With Pattern Dependency},
 volume = {12},
 year = {2024}
}

@article{10582439,
 abstract = {The rapid evolution of modern automobiles into intelligent and interconnected entities presents new challenges in cybersecurity, particularly in Intrusion Detection Systems (IDS) for In-Vehicle Networks (IVNs). This survey paper offers an in-depth examination of advanced machine learning (ML) and deep learning (DL) approaches employed in developing sophisticated IDS for safeguarding IVNs against potential cyber-attacks. Specifically, we focus on the Controller Area Network (CAN) protocol, which is prevalent in in-vehicle communication systems, yet exhibits inherent security vulnerabilities. We propose a novel taxonomy categorizing IDS techniques into conventional ML, DL, and hybrid models, highlighting their applicability in detecting and mitigating various cyber threats, including spoofing, eavesdropping, and denial-of-service attacks. We highlight the transition from traditional signature-based to anomaly-based detection methods, emphasizing the significant advantages of AI-driven approaches in identifying novel and sophisticated intrusions. Our systematic review covers a range of AI algorithms, including traditional ML, and advanced neural network models, such as Transformers, illustrating their effectiveness in IDS applications within IVNs. Additionally, we explore emerging technologies, such as Federated Learning (FL) and Transfer Learning, to enhance the robustness and adaptability of IDS solutions. Based on our thorough analysis, we identify key limitations in current methodologies and propose potential paths for future research, focusing on integrating real-time data analysis, cross-layer security measures, and collaborative IDS frameworks.},
 author = {Almehdhar, Mohammed and Albaseer, Abdullatif and Khan, Muhammad Asif and Abdallah, Mohamed and Menouar, Hamid and Al-Kuwari, Saif and Al-Fuqaha, Ala},
 doi = {10.1109/OJVT.2024.3422253},
 issn = {2644-1330},
 journal = {IEEE Open Journal of Vehicular Technology},
 keywords = {Security;Sensors;Protocols;Automobiles;Surveys;Real-time systems;Vehicular ad hoc networks;In-vehicle network (IVN);intrusion detection system (IDS);machine learning (ML);deep learning (DL);cybersecurity;controller area network (CAN)},
 month = {},
 number = {},
 pages = {869-906},
 title = {Deep Learning in the Fast Lane: A Survey on Advanced Intrusion Detection Systems for Intelligent Vehicle Networks},
 volume = {5},
 year = {2024}
}

@article{10589407,
 abstract = {It remains important to make abnormity detection from largescale behavioral data of Internet. Existing related approaches mostly failed to employ high-dimensional characteristics of Internet data, which limits the detection effect. To deal with this issue, we introduce graph convolution network (GCN) to generate fine-grained feature representation towards largescale behavioral data. And a deep GCN-based abnormity detection model for largescale behavioral data is proposed in this paper. Firstly, GCN is used to extract global co-occurrence information from largescale behavior data. Then, global embedding is applied to the encoder to obtain local features, which are fused into advanced features to better capture the relationships among nodes in social network. Finally, based on the idea of support vector domain description, a new objective function is optimized to determine whether abnormal behavior occurs in behavior data. Empirically, we have also carried out some experiments to make performance evaluation. The research results indicate that the proposal has higher Precision and robustness compared to traditional methods.},
 author = {Liang, Shaolin and Shao, Kangjie},
 doi = {10.1109/ACCESS.2024.3424879},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Anomaly detection;Data models;Convolutional neural networks;Complex networks;Accuracy;Graph convolutional networks;Deep learning;Behavioral sciences;Graph convolution network;behavioral modeling;deep learning;high-dimensional data},
 month = {},
 number = {},
 pages = {94380-94392},
 title = {A Deep Graph Convolution Network-Based Abnormity Detection Model for Largescale Behavioral Data},
 volume = {12},
 year = {2024}
}

@article{10599515,
 abstract = {With the continuous evolution of novel network attacks, traditional Intrusion Detection Systems (IDSs) have commonly employed Deep Neural Networks (DNNs) for intrusion detection. However, the effectiveness of a DNN in this respect is closely related to the quality of the training data set, and large-scale network traffic data are difficult to label accurately. Therefore, some challenges still need to be addressed to detect network attacks. In this paper, we introduce a Time-Space Separable Attention Network (TSSAN) for intrusion detection. TSSAN utilizes depth wise separable convolution and a time-space self-attention mechanism to effectively extract temporal and spatial features. By extracting the common features from the unlabeled data, TSSAN significantly enhanced the detection performance for rare attack types. Experimental evaluations were conducted using UNSW-NB15 and CICIDS-2017 datasets. Meticulous experiments for evaluating the individual components of the model were rigorously carried out using the CICIDS-2017 dataset. In the unsupervised learning experiment, our method achieved 0.86 and 0.92 f1score in the two datasets. In semi-supervised learning, the experiment showed that our method performed significantly better than the traditional deep learning method when the labelled data were gradually reduced.},
 author = {Xu, Rui and Zhang, Qi and Zhang, Yunjie},
 doi = {10.1109/ACCESS.2024.3429420},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Anomaly detection;Telecommunication traffic;Unsupervised learning;Data models;Generative adversarial networks;Deep learning;Intrusion detection;Network security;Intrusion detection;deep learning;network security;self attention;multi-class classification},
 month = {},
 number = {},
 pages = {98734-98749},
 title = {TSSAN: Time-Space Separable Attention Network for Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10614131,
 abstract = {With the popularity of electronic devices, the number of malware has increased dramatically, posing a serious threat to the digital world. Accurately identifying malware has become a research focus. However, there are many difficulties in the research, such as insufficient algorithm generalization ability, unbalanced datasets, and long processing and identification times. To address these problems, this study proposes a malware detection framework (VBDN) based on a convolutional neural network (CNN). The framework incorporates data visualization, balanced adoption, data augmentation, and convolutional neural network techniques to achieve over 90% accuracy in classifying malware on all four open-source datasets. The experimental work has two other contributions: first, it not only focuses on the overall recognition effect of the algorithm during the research process, but also on the recognition effect of each category with the help of a confusion matrix, which provides useful information for cybersecurity personnel, researchers, and others to carry out subsequent targeted research. Secondly, the balanced approach adopted in this paper has the following advantages: no need to construct a new dataset, consumes fewer hardware resources, automatically evaluates the sampling weights, etc. Additionally, to enhance the generalization ability of the algorithm and alleviate the overfitting problem, this paper employs data augmentation techniques to improve the adopted method. By comparing with several state-of-the-art algorithms, it can be observed that the VBDN framework proposed in this paper achieves the desired results in time with acceptable accuracy.},
 author = {Liu, Yajun and Fan, Hong and Zhao, Jianguang and Zhang, Jianfang and Yin, Xinxin},
 doi = {10.1109/ACCESS.2024.3435362},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Biological neural networks;Convolutional neural networks;Classification algorithms;Deep learning;Mathematical models;Data visualization;Malware detection;convolutional neural network (CNN);data visualization;balanced adoption;data enhancement},
 month = {},
 number = {},
 pages = {104317-104332},
 title = {Efficient and Generalized Image-Based CNN Algorithm for Multi-Class Malware Detection},
 volume = {12},
 year = {2024}
}

@article{10614597,
 abstract = {The coming 6G wireless network is poised to achieve unprecedented data rates, latency, and integration with newer technologies like AI and IoE. On the other hand, along with this kind of growth in the AI domain and the large-scale connectivity in 6G. It is also going to raise many security concerns at the level of intrusion detection and prevention. For intrusion detection, centralized approaches won’t be able to work effectively, therefore there is an utmost need to design decentralized and privacy-preserving solutions. In this work, we propose a novel secure gradients exchange algorithm for distributed intrusion detection in 6G networks. Our method is designed to take into account the use of Federated Learning with secure multi-party computation and blockchain technology. This way ensures that the collaborating parties are able to conduct the training of intrusion detection models in a secure and collaborative manner by retaining privacy in the data. Gradient compression and adaptive secure aggregation strategies are used to further optimize communication overhead and computational complexity. Therefore, our design works in a robust and efficient manner with the high data rates and huge connectivity that 6G networks will provide. To achieve our goal, experiments using the CICIoT2023 dataset were performed, and results showed that our federated learning-based hybrid model composed of CNN1D and a multi-head attention mechanism outperformed other well-known deep learning models in terms of performance. It achieved the highest average accuracy with 79.92%, the highest average detection rate with 77.41%, and a low false alarm rate with 2.55%.},
 author = {Sakraoui, Sabrina and Ahmim, Ahmed and Derdour, Makhlouf and Ahmim, Marwa and Namane, Sarra and Ben Dhaou, Imed},
 doi = {10.1109/ACCESS.2024.3435920},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {6G mobile communication;Intrusion detection;Security;Accuracy;Data models;5G mobile communication;Deep learning;Computer security;Blockchains;Machine learning;Convolutional neural networks;Long short term memory;Federated learning;6G;computer security;network security;intrusion detection;IDS;blockchain;IoT;machine learning;deep learning;multi-head attention CNN;LSTM;hybrid model;anomaly detection;federated learning},
 month = {},
 number = {},
 pages = {105887-105905},
 title = {FBMP-IDS: FL-Based Blockchain-Powered Lightweight MPC-Secured IDS for 6G Networks},
 volume = {12},
 year = {2024}
}

@article{10616010,
 abstract = {The present era is characterized by the interconnection, communication, connectivity, and data exchange of Internet of Things (IoT) devices. However, current systems often neglect to incorporate security protocols for IoT devices in the energy sector, the Internet of Medical Things, smart homes, and other areas. This poses a significant challenge in IoT networks as these devices possess constrained resources, making them vulnerable to attacks. Attackers can exploit these vulnerabilities to gain unauthorized access and retrieve sensitive information or data from the targeted devices. This paper presents a machine learning-driven intrusion detection system to tackle these issues, aiming to devise a system for early identification of such attacks. The system is tested using the WUSTL and UNSW-NB18 datasets to detect Man-in-the-Middle (MITM) and Botnet attacks. The developed system selects the optimal features from both datasets using Mutual Information (MI) and chi-square feature selection. It applies the Synthetic Minority Oversampling Technique (SMOTE) resampling method to resample the attack class and the Random Under Sampling method to resample the normal class. This study utilizes TabNet, Support Vector Machine (SVM), and Random Forest (RF) for both datasets. The performance is then compared with the proposed Ensemble Weighted Voting (EWV) classifier. The experimental results show that the proposed method PSO-EWV on the WUSTL dataset achieves 99.958% and 99.992% F-scores on the UNSW 2018 dataset for MITM attack and Botnet attack classification with MI feature selection. The experimental findings conclude that this method effectively detects attacks within an intrusion detection system.},
 author = {Waqas Khan, Qazi and Nawaz Khan, Anam and Ahmad, Rashid and Rizwan, Atif and Ibrahim, Muhammad and Kim, Do Hyeun},
 doi = {10.1109/ACCESS.2024.3436088},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Accuracy;Internet of Things;Feature extraction;Artificial neural networks;Learning systems;Chatbots;Particle swarm optimization;Ensemble learning;Ensemble learning;particle swarm optimization;TabNet;abnormal detection;botnet attack;MITM attack},
 month = {},
 number = {},
 pages = {138483-138500},
 title = {Enhanced Abnormality Detection via PSO-Driven Adaptive Ensemble Weighting for Energy AIoT Device Security},
 volume = {12},
 year = {2024}
}

@article{10620207,
 abstract = {The healthcare industry relies heavily on a robust medical infrastructure but generates sensitive data about patients whose confidentiality and integrity protection must be guaranteed. But, although the Internet of Medical Things (IoMT) facilitates the interconnection of medical devices, software applications, and health systems, it also introduces vulnerabilities for adversaries to exploit. Moreover, in recent years, integrating machine learning (ML) into intrusion detection systems (IDS) have shown great potential in identifying malicious actions in the Internet of Things. However, such methods often require representative data for training, which is not commonly available for the IoMT. In this work, we introduce the IoMT-TrafficData, a dataset comprising IoMT network traffic data with features built over packet and network flow information for benign traffic and eight types of attacks. We present results from using several traditional ML algorithms and deep models to identify malicious traffic (binary classification) and the type of attack (multiclass classification), along with a comparative analysis of employing packet and flow statistics in ML-based intrusion detection. We show that ML algorithms can achieve high performance in identifying malicious traffic and distinct attacks, as most of the evaluated methods achieved an F1-score of over 90%. We also show that their performance on traffic-packets is, on average, almost 3% better for identifying malicious traffic than the individual attacks, and they achieve up to 5% better performance when dealing with traffic-flow statistics than when working on packed-based features. Hence, our experiments show the potential of using IoMT traffic flows in ML-based IDS and the usefulness of the IoMT-TrafficData dataset in such a context and present results that may be a benchmark reference for those who work with the dataset. The dataset can be openly accessed through the DOI 10.5281/zenodo.8116337.},
 author = {Areia, José and Bispo, Ivo Afonso and Santos, Leonel and Costa, Rogério Luís de C.},
 doi = {10.1109/ACCESS.2024.3437214},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Security;Intrusion detection;Protocols;Sensors;Telecommunication traffic;Sensor systems;Computer security;Artificial neural networks;Internet of Medical Things;Machine learning;Cybersecurity;deep neural network;Internet of Medical Things;intrusion detection system;machine learning},
 month = {},
 number = {},
 pages = {115370-115385},
 title = {IoMT-TrafficData: Dataset and Tools for Benchmarking Intrusion Detection in Internet of Medical Things},
 volume = {12},
 year = {2024}
}

@article{10621008,
 abstract = {With the advancement and refinement of intelligence and connectivity, intelligent connected vehicles have emerged as a prominent trend in contemporary development. Consequently, invasion attacks targeting these intelligent connected vehicles have also arisen. Mainstream intrusion detection systems (IDS) based on deep learning technologies can address malicious traffic infiltrations; however, they often fail to meet the real-time and lightweight requirements of vehicles. This paper introduces a lightweight vehicular intrusion detection method leveraging the MobileNetV3 architecture. By utilizing MobileNetV3 as the core framework, this method incorporates advanced techniques and design principles such as Depthwise Separable Convolution, Bottleneck structures, and Squeeze-and-Excitation (SE) modules. These innovations significantly reduce computational and parameter overhead while maintaining high model accuracy. Furthermore, MobileNetV3 is specifically designed for deployment on mobile devices, ensuring efficient operation even in resource-constrained environments. The proposed intrusion detection model achieved an accuracy, recall, precision, and F1 score of 100% on the Car-Hacking dataset, and an accuracy, recall, precision, and F1 score of 99.98% on the CICIDS-2017 dataset. The model size is 16MB. Experimental results demonstrate that this intrusion detection scheme not only accurately detects malicious attacks on vehicles but also meets the lightweight requirements of vehicular applications.},
 author = {Wang, Shaoqiang and Wang, Yizhe and Zheng, Baosen and Cheng, Jiahui and Su, Yu and Dai, Yinfei},
 doi = {10.1109/ACCESS.2024.3437416},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computational modeling;Computer architecture;Vehicle-to-everything;Training;Deep learning;Real-time systems;Intrusion detection;MobileNetV3;lightweight and efficient;connected vehicle networks},
 month = {},
 number = {},
 pages = {106285-106302},
 title = {Intrusion Detection System for Vehicular Networks Based on MobileNetV3},
 volume = {12},
 year = {2024}
}

@article{10623141,
 abstract = {A web application is prone to security threats due to its open nature. The security of these platforms is imperative for organizations of all sizes because they store sensitive information. Consequently, exploiting web application vulnerabilities could result in large-scale data breaches and significant brand and financial damages. SQL injection (SQLi) represents a popular attack vector that malicious actors use to compromise website security. Web application firewalls (WAFs) play a primary role in preventing such malicious attack typologies. In the recent literature, several advances have been proposed in the field of WAF enhancement to prevent SQLi exploitation. However, many of them test the effectiveness of a WAF without releasing a patch to fix security flaws if a WAF is bypassed. In other cases, the patch is distributed exclusively according to the syntax specified by the WAF tested. This paper introduces a framework that leverages PROxy Grammar to Enhance web application firewalls for SQL Injection prevention (PROGESI). The proposed solution can act as an intermediary layer between the targeted web server and the incoming application level requests. Specifically, PROGESI can be used individually or in combination with a WAF and includes a series of rules that patch SQLi vulnerabilities exposed by a specific web server. Furthermore, it can identify and mitigate SQLi attempts, also when attackers use mutation techniques, since the rules used encompass generalization mechanisms. The experiments performed revealed two strengths of PROGESI: (i) the ability to identify SQLi even in the presence of server-side defense mechanisms, which increases as the generalization rate implemented by the rule generation algorithm increases; (ii) impressive detection performance even for low generalization rate values, which is higher than that achieved by competitors using a state-of-the-art SQLi dataset.},
 author = {Coscia, Antonio and Dentamaro, Vincenzo and Galantucci, Stefano and Maci, Antonio and Pirlo, Giuseppe},
 doi = {10.1109/ACCESS.2024.3438092},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Firewalls (computing);Structured Query Language;Grammar;SQL injection;Prevention and mitigation;Symbols;Context-free grammar;proxy;SQL injection;web application firewall},
 month = {},
 number = {},
 pages = {107689-107703},
 title = {PROGESI: A PROxy Grammar to Enhance Web Application Firewall for SQL Injection Prevention},
 volume = {12},
 year = {2024}
}

@article{10630565,
 abstract = {Leveraging advanced technologies, such as the cascaded YOLOv8-based approach, this research aims to detect wild animals, thereby preventing Wild animal intrusion in residential areas and sudden road crossings. A reliable wildlife animal detection system is essential for monitoring biodiversity, understanding animal behaviour, and supporting global conservation efforts. This paper uses datasets to introduce a cascaded YOLOv8-based approach for wildlife animal detection. Initially, the input dataset undergoes adaptive histogram equalisation for contrast enhancement, followed by super-pixel-based Fast Fuzzy C-Means (FCM) for segmentation. Features are then extracted using ResNet50, DarkNet19, and Local Binary Pattern, and finally, the optimal cascaded YOLOv8 detects the wildlife animals based on these features. The proposed MATLAB-based technique for detecting wildlife animals performs at its best, achieving 97% accuracy along with excellent metrics for kappa, precision, sensitivity, specificity, and F measures. This research contributes to advancing wildlife conservation efforts by providing a robust and efficient method for monitoring and preserving biodiversity. Future research endeavours may explore integrating advanced deep learning models and incorporating diverse datasets to refine further and enhance wildlife animal detection capabilities, ultimately facilitating more effective conservation strategies in natural ecosystems.},
 author = {Chappidi, Johnwesily and Sundaram, Divya Meena},
 doi = {10.1109/ACCESS.2024.3439230},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Image segmentation;Wildlife;Feature extraction;Biological system modeling;Convolutional neural networks;Accuracy;Training;YOLO;Fuzzy systems;Cascaded YOLOv8;superpixels based fast fuzzy C-mean;ResNet50;DarkNet19;local binary pattern},
 month = {},
 number = {},
 pages = {110575-110587},
 title = {Novel Animal Detection System: Cascaded YOLOv8 With Adaptive Preprocessing and Feature Extraction},
 volume = {12},
 year = {2024}
}

@article{10632117,
 abstract = {Securing user electronics devices has become a significant concern in the digital period, and a forward-thinking solution covers the fusion of blockchain (BC) technology and deep learning (DL) methods. Blockchain improves device safety by transforming access management, storing credentials on a tamper-resistant ledger, mitigating the risk of unauthorized access and giving a robust defence against malevolent actors. Integrating DL into this framework also raises safety measures, as it permits devices to inspect and regulate to develop attacks distinctly. DL models accurately recognize intricate designs and anomalies, allowing the technique to distinguish and threaten possible attacks in real time. The fusion of BC and DL not only improves the reliability of user electronics but also establishes a dynamic and adaptive safety system, enhancing consumer confidence in the safety of their devices. Therefore, this study presents a BC-Based Access Management with DL Threat Modeling (BCAM-DLTM) technique for securing consumer electronics devices in the IoT ecosystems. The BCAM-DLTM technique mainly follows a two-phase procedure: access management and threat detection. Moreover, BC technology can be applied to the access management of consumer electronics devices. Besides, the BCAM-DLTM technique applies a deep belief networks (DBNs) model for proficiently identifying threats. To enhance the recognition results of the DBN model, the hyperparameter tuning procedure uses the reptile search algorithm (RSA). The experimental outcome study of the BCAM-DLTM approach employs the NSLKDD dataset. The comprehensive results of the BCAM-DLTM approach portrayed a superior accuracy outcome of 99.63% over existing models in terms of distinct metrics.},
 author = {Asiri, Mashael M. and Alfraihi, Hessa and Said, Yahia and Othman, Kamal M. and Salama, Ahmed S. and Marzouk, Radwa},
 doi = {10.1109/ACCESS.2024.3441094},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Biological system modeling;Safety;Consumer electronics;Internet of Things;Computational modeling;Threat modeling;Ecosystems;Blockchains;Deep learning;Search methods;Evidence theory;Blockchain;Internet of Things;deep learning;reptile search algorithm;deep belief network},
 month = {},
 number = {},
 pages = {110671-110680},
 title = {Securing Consumer Electronics Devices: A Blockchain-Based Access Management Approach Enhanced by Deep Learning Threat Modeling for IoT Ecosystems},
 volume = {12},
 year = {2024}
}

@article{10634166,
 abstract = {The Internet of Things (IoT) is transforming everyday objects. However, its devices’ limited memory, processing power, and network capabilities make them susceptible to security breaches. The Routing Protocol for Low-Power and Lossy Networks (RPL) is a promising IoT protocol but faces significant security challenges. Existing research often focuses on individual attacks, utilizing various mitigation strategies, including machine learning and deep learning for detection. This paper proposes an Intrusion Detection System (IDS) using the ROUT-4-2023 dataset, which encompasses Black Hole, Flooding, DODAG Version Number, and Decreased Rank attacks. The study utilizes statistical information graphs to investigate network traffic features encompassing all four attacks. Additionally, it experiments with various machine learning models and deep learning architectures for comparative analysis, focusing on confusion matrix outcomes and computational efficiency. Results indicate that the Random Forest classifier achieves 99% accuracy, while Transformers reach 97% F1-Score with a training time of only 16.8 minutes over five epochs.},
 author = {Shahid, Usama and Zunnurain Hussain, Muhammad and Zulkifl Hasan, Muhammad and Haider, Ali and Ali, Jibran and Altaf, Jawad},
 doi = {10.1109/ACCESS.2024.3442529},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Routing protocols;Routing;Prevention and mitigation;Network topology;Intrusion detection;Data science;Intrusion detection system;data science;machine learning;deep learning;security;RPL;routing protocols;IoT;black hole attack;decreased rank attack;DODAG VNA;flooding attack},
 month = {},
 number = {},
 pages = {113099-113112},
 title = {Hybrid Intrusion Detection System for RPL IoT Networks Using Machine Learning and Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10634496,
 abstract = {Cybersecurity continues to be a significant problem for all industries involved in digital activities, and it is specified as the cyclical surge in security occurrences. Considering more Internet of Things (IoT) devices are being employed in the medical field, homes, transportation, offices, and other locations, malicious attacks are arising more regularly. While IoT provides numerous advantages to users or service providers, security and privacy remain a significant problem. An Intrusion Detection System (IDS) can be employed to mitigate cyber threats in such an interconnected network. However, several existing performances for IDS in IoT need more extensiveness of the categories of attack the network was showing, higher-level feature dimensional, systems built on out-of-date databases, and a shortage of consideration of the imbalanced databases. Therefore, this study presents a Distributed Multiclass Cyberattack Detection using Golden Jackal Optimization with Deep Learning (DMCD-GJODL) technique for IoT networks. The main aim of the DMCD-GJODL method is to ensure security in the IoT environment by detecting cyberattacks using the DL model. In the DMCD-GJODL method, the min-max scalar is primarily used to scale the input data. The DMCD-GJODL method applies a Chaotic Crow Search Optimization Algorithm (CSSOA) based feature selection approach to select features. Moreover, the Bi-Directional Gated Recurrent Unit (BiGRU) approach can be exploited to detect and classify cyberattacks. Eventually, the GJO methodology can boost the BiGRU approach’s hyperparameter choice, enhancing the overall classification process. The performance evaluation of the DMCD-GJODL approach takes place on the BoT-IoT dataset. Extensive comparative results stated the betterment of the DMCD-GJODL approach in detecting cyberattacks with a maximum accuracy of 98.70%, precision of 98.92%, recall of 97.62%, and F-score of 98.25%.},
 author = {Alrayes, Fatma S. and Nemri, Nadhem and Aljaffan, Nouf and Alshuhail, Asma and Alhashmi, Asma A. and Mahmud, Ahmed},
 doi = {10.1109/ACCESS.2024.3443202},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Cyberattack;Feature extraction;Optimization;Classification algorithms;Logic gates;Deep learning;Cyberattack detection;Internet of Things;deep learning;golden jackal optimization;feature selection},
 month = {},
 number = {},
 pages = {132434-132443},
 title = {Distributed Multiclass Cyberattack Detection Using Golden Jackal Optimization With Deep Learning Model for Securing IoT Networks},
 volume = {12},
 year = {2024}
}

@article{10634505,
 abstract = {The rising Internet of Things (IoT) device count has caused security concerns among high-tech companies and groups, which has resulted in several evaluations. IoT’s pervasive, portable, and intelligent qualities make developing automated methods for spotting suspicious activity on IoT devices linked to regional infrastructure very vital. Using input factors, including network traffic attributes and output parameters, including accuracy, time complexity, and specificity, this work examines datasets, including NSL-KDD, CIC-IDS17, ToN_IoT, and UNSW-NB15. Our suggested approach uses a ResNeSt model with Split-Attention (ResNeSt), improved using the Jaya Algorithm (RSG-MJ) and augmented by a Gated Recurrent Unit (GRU). This method attained a 15% boost in efficiency considering computational complexity and an accuracy rating of 98.45%. Early-stage threat detection and computing efficiency of our system show significant advances over current techniques. The statistical analysis measures support the resilience and efficiency of our approach even more in line with the journal’s goal of advancing IoT security via creative approaches. Our method is a viable solution for real-world IoT security issues as the testing results reveal its faster detection of DDoS attacks, hence improving performance.},
 author = {Alshdadi, Abdulrahman A. and Almazroi, Abdulwahab Ali and Alsolami, Eesa and Ayub, Nasir and Lytras, Miltiadis D.},
 doi = {10.1109/ACCESS.2024.3443067},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Accuracy;Security;Object recognition;Computer crime;Performance evaluation;Denial-of-service attack;Artificial neural networks;Optimization methods;DDOS attack;IoT;intrusion detection;deep neural networks;optimization techniques;security},
 month = {},
 number = {},
 pages = {112368-112380},
 title = {Enhanced IoT Security for DDOS Attack Detection: Split Attention-Based ResNeXt-GRU Ensembler Approach},
 volume = {12},
 year = {2024}
}

@inproceedings{10635055,
 abstract = {The smart grid architecture, which represents a deep integration of information technology and power systems, brings many conveniences to people. However, due to the highly open communication network and complex information interaction environment, it also faces more security risks. Existing intrusion detection algorithms based on machine learning cannot cope with the increasing features in the Energy Internet. To address this issue, this paper proposes the Improved Gravitational Search Algorithm (IGSA) for feature selection. Our core idea is to utilize IGSA for efficient feature selection, reducing the learning cost of machine learning methods and improving detection accuracy. Furthermore, to enhance the algorithm's global search capability and robustness, a novel elite selection strategy and adaptive mutation strategy are introduced. Experimental results on three public datasets demonstrate that IGSA improves detection accuracy by an average of 11.14% compared to other feature selection methods.},
 author = {Li, Jiahao and Lia, Dinavi and Luo, Tao and Zhou, Jie},
 booktitle = {2024 9th International Conference on Automation, Control and Robotics Engineering (CACRE)},
 doi = {10.1109/CACRE62362.2024.10635055},
 issn = {2997-6278},
 keywords = {Accuracy;Machine learning algorithms;Intrusion detection;Machine learning;Power system stability;Nearest neighbor methods;Feature extraction;smart grid;intrusion detection;feature selection},
 month = {July},
 number = {},
 pages = {69-73},
 title = {Novel Methods for Smart Grid Intrusion Detection System Using Feature Selection Based on Improved Gravitational Search Algorithm},
 volume = {},
 year = {2024}
}

@article{10636157,
 abstract = {In the last decade, with the increase in cyberattacks the privacy of network traffic has become a critical issue. Currently, simple network intrusion detection techniques are inefficient in terms of time complexity and are characterized by low detection accuracy and high false alarm rates, whereas techniques using complex algorithms such as recurrent neural network (RNN) and transformer-based deep learning, face challenges of high time complexity, large computational resource usage, and high latency rate in detecting intrusion in real-time traffic. To overcome these issues, we propose an advanced intrusion detection random forest “IDRandom-Forest” for real-time intrusion detection with reduced testing time and with higher accuracy. In this technique, an accuracy sliding window and feature weighting based on stratified feature sampling are introduced to determine the optimal sub-ensemble from the classical random forest. Experimental results demonstrated that the proposed hybrid classification system outperforms current state-of-the-art techniques in terms of accuracy and testing time.},
 author = {Azhar, Muhammad and Perveen, Shahida and Iqbal, Asma and Lee, Bumshik},
 doi = {10.1109/ACCESS.2024.3443408},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Accuracy;Intrusion detection;Random forests;Real-time systems;Testing;Feature extraction;Telecommunication traffic;Cyberattack;Sampling methods;Telecommunication traffic;Cyberattacks;random forest;real-time intrusion detection systems (IDS);stratified subspace sampling},
 month = {},
 number = {},
 pages = {113842-113854},
 title = {IDRandom-Forest: Advanced Random Forest for Real-Time Intrusion Detection},
 volume = {12},
 year = {2024}
}

@article{10637392,
 abstract = {The next generation architectures of computer networks and systems and commercial technologies such as Big Data, Decentralized Storage, and 6G require novel approaches to prevent cybersecurity breaches which can negatively affect organizations, operations, and individual customers and stakeholders. In this proposal, we present an approach for identifying transformed features via statistical analysis which can be used in Artificial Intelligence (AI) and machine learning (ML) based systems. We also present a deep learning framework, Small Set of Linearized Variables (SSOLV), for training neural networks based on labeled Zeek datasets containing both malicious and benign activity in real or near-real time. In addition, we present a mechanism for transfer learning using domain adaptation techniques to adapt neural networks trained on one labeled Zeek dataset to another neural network trained on a different labeled Zeek dataset. This research uses a combination of 3 techniques commonly used in network traffic flow analysis: deep neural networks, linear regression, and ANOVA. Our results show that we can classify malicious activity with up to 97-99% accuracy in select cases and high precision (>95%) and recall (>90%) rate. This framework demonstrates a mechanism that stand-alone systems disconnected from larger networks can use to recognize adversarial activity in real time and is transferrable to other stand-alone systems. This work is patent pending under U.S. Patent App. Ser. No. 18/121,716 “Linearized Real-Time Network Intrusion Detection System” and U.S. Patent App. Ser. No. 17/900,982 “Real-Time Network Intrusion Detection System.”},
 author = {Powell, Makia S. and Drozdenko, Benjamin M.},
 doi = {10.1109/ACCESS.2024.3444703},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Real-time systems;Computer security;Analysis of variance;Artificial neural networks;Feature extraction;Telecommunication traffic;Linear regression;Artificial intelligence;Machine learning;Artificial neural networks;Artificial intelligence;machine learning;cybersecurity;real-time;statistics;ANOVA;linear regression;artificial neural networks;KDDCUP99;KDD99;UNSW-NB15;CICIDS2017},
 month = {},
 number = {},
 pages = {114786-114794},
 title = {SSOLV: Real-Time AI/ML-Based Cybersecurity via Statistical Analysis},
 volume = {12},
 year = {2024}
}

@article{10637459,
 abstract = {Due to the rapid development of technologies such as cloud computing and the Internet of Things (IoT), wireless sensor networks are becoming increasingly popular in the field of environmental monitoring. Anomaly detection algorithm is often used as the main method of sensor data detection. The development and application of IoT technology has led to a significant increase in data traffic. However, current anomaly detection methods are difficult to effectively detect heterogeneous data sequences from multiple sources. In this study, the sensor monitoring model of an intelligent greenhouse is constructed by using the spatio-temporal correlation anomaly detection algorithm in edge computing. The data is chunked by a sliding window to reduce the error of one-sided estimation of single data on the detection results. The spatial correlation anomaly detection algorithm is formed on the basis of the temporal correlation detection algorithm, fusing the two algorithms with the edge computation to construct a multi-source multi-dimensional data anomaly detection model. The results of the time-related anomaly detection algorithm experiment showed that the F1-score of the algorithm was 91.26%. Compared with other methods, the false alarm rate of spatial correlation anomaly detection algorithm was reduced by 56.50% ~ 83.45%, and F1-score was increased by 1.37% ~ 22.25%. In the case of big data, the detection time of the sensor monitoring model was 0.47s, the required energy consumption was reduced by 36.75% ~ 79.20%, and the delay time was the least. The anomaly detection algorithm in this study is related to time and space, which effectively improves the detection rate and detection accuracy, thus reducing the computing load of the cloud platform, and is superior to the deep learning method in processing delay.},
 author = {Zhang, Rui and Zhou, Lide and Mei, Aoqi and He, Yipeng},
 doi = {10.1109/ACCESS.2024.3444046},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Correlation;Monitoring;Transportation;Anomaly detection;Mathematical models;Distributed databases;Intrusion detection;Sensors;Cloud computing;Sensor monitoring techniques;anomaly detection;spatio-temporal correlation;sliding window;cloud computing},
 month = {},
 number = {},
 pages = {116516-116529},
 title = {Sensor Monitoring Techniques in Edge Computing Using Spatio-Temporal Correlation Anomaly Detection Algorithms},
 volume = {12},
 year = {2024}
}

@article{10638639,
 abstract = {As the connectivity between Electronic Control Units (ECUs) and the external environment intensifies, the security and safeguarding of In-Vehicle Networks (IVNs) have become pressing issues. The Controller Area Network (CAN) bus, the most commonly employed vehicular network protocol, is particularly vulnerable due to its inherent lack of security measures, making it susceptible to various attacks. In this paper, we introduce a novel intrusion detection model for CAN networks, named IVN-ViT. The proposed IVN-ViT model utilizes an enhanced Vision Transformer architecture (Edge-ViT), incorporating self-supervised learning with Cutout data augmentation, Particle Swarm Optimization (PSO) for feature selection, and a fine-tuning strategy that merges Parameter Instance Discrimination (PID) with supervised loss. This not only enhances the model’s convergence speed and predictive accuracy but also meets the lightweight requirements of CAN networks. Experimental results on the “HCRL-car hacking” dataset and the “X-CANIDS” dataset demonstrate that our model achieves over 99% accuracy across all types of attacks. In a simulated vehicular environment, the detection latency for each message averages approximately 1.04ms, fully meeting the first-time requirements of CAN networks. The experiments validate that our proposed method significantly improves model accuracy while ensuring efficient operation within the limited computational resources available in vehicle systems.},
 author = {Wang, Shaoqiang and Zheng, Baosen and Liu, Zhaoyuan and Fan, Ziyao and Liu, Yubao and Dai, Yinfei},
 doi = {10.1109/ACCESS.2024.3445498},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computational modeling;Feature extraction;Data models;Transformers;Protocols;Task analysis;In-Vehicle network;controller area network;intrusion detection;lightweight;vision transformer},
 month = {},
 number = {},
 pages = {118842-118856},
 title = {A Lightweight Intrusion Detection System for Vehicular Networks Based on an Improved ViT Model},
 volume = {12},
 year = {2024}
}

@article{10639388,
 abstract = {With the popularization of the Internet, it is very important to effectively identify abnormal behaviors in network traffic. This study focuses on the construction of an internet traffic monitoring model, aiming to improve the accurate recognition rate of abnormal behavior and reduce information loss during small block segmentation. To this end, a internet traffic monitoring algorithm based on the improved Transformer is optimized. This model adopts a block segmentation algorithm that preserves important information during the segmentation process, thereby enhancing the segmentation quality and accuracy of the model. By effectively interacting with multiple receptive field information, the model reduces information loss and improves accuracy and efficiency. After experimental verification, the model performed well on CICIDS sample data, with an F1 value of 93% for normal internet traffic. The F1 value of internet attack traffic was 91%. Compared with the original Transformer model, it increased by 5% and 2.4%, respectively. On the NSLKDD sample, the improved algorithm proposed in the study had an area under the curve value of 0.90, which outperformed other models. This proves that it has significant advantages in the dual classification task of internet traffic anomaly monitoring. This study provides an effective deep learning algorithm for internet traffic anomaly monitoring, which is expected to provide strong support for network security assurance in practical application scenarios.},
 author = {Liu, Jiejing and Liu, Xu and Wang, Yanhai and Fu, Hua},
 doi = {10.1109/ACCESS.2024.3445996},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Internet;Accuracy;Transformers;Telecommunication traffic;Feature extraction;Attention mechanisms;Deep learning;Deep learning;transformer;internet;flow rate;block segmentation;monitoring;Trans-M},
 month = {},
 number = {},
 pages = {116801-116815},
 title = {Construction of Internet Traffic Monitoring Model Based on Improved Transformer Algorithm},
 volume = {12},
 year = {2024}
}

@article{10646204,
 abstract = {The Internet of Things (IoT) ecosystem presents substantial challenges in terms of privacy and security, rendering it an attractive target for malicious actors. In this context, the literature review highlights the ongoing difficulty in addressing privacy and security through a unified mechanism owing to the heterogeneous nature of IoT devices, their dynamic behavior, and the continual advancement of intelligent hacking tools. Hence, encoding techniques have been considered from the perspective of privacy in Artificial Intelligence (AI) models. To overcome these challenges, this study introduces an integrated single mechanism for privacy and security in the IoT. In order to safeguard sensitive data during AI model training, a novel privacy mechanism called Replacement Encoding (RE) is proposed. This mechanism ensures the camouflage of sensitive information while preserving the integrity and utility of trained models. Additionally, this approach provides automated preprocessing, enhancing the performance of AI models. Message packet features were derived, extracted, and analyzed from the CICIoT2023 dataset (PCAP files) using Wireshark. The proposed replacement encoding scheme is integrated with AI classifiers to detect attacks, achieving an accuracy of 88.94% and 86.61% for the Random Forest (RF) and Deep Neural Network (DNN) models, respectively, utilizing 100 features. These results are compared to accuracies of 90.16% and 94.81% for the same models with up to 15 features using genetic algorithm-based correlation features. Finally, the proposed RF mechanism demonstrates its utility across multiple domains, including privacy preservation, automated data preprocessing, and protection of sensitive user data in Generative Pre-Training Transformer (GPT) applications as well as AI models.},
 author = {Farea, Ali Hamid and Alhazmi, Omar H. and Samet, Refik and Guzel, Mehmet Serdar},
 doi = {10.1109/ACCESS.2024.3449630},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Encoding;Artificial intelligence;Security;Internet of Things;Data privacy;Privacy;Data models;AI;encoding;IoT;privacy;optimization;security},
 month = {},
 number = {},
 pages = {121368-121386},
 title = {AI-Powered Integrated With Encoding Mechanism Enhancing Privacy, Security, and Performance for IoT Ecosystem},
 volume = {12},
 year = {2024}
}

@article{10648607,
 abstract = {Over the past few years, smart cities have seamlessly integrated into our daily lives, offering convenience and simplicity. However, as these cities become increasingly interconnected and reliant on the Internet of Things (IoT), ensuring heightened security measures becomes paramount. The potential compromise of IoT devices due to vulnerabilities poses significant risks, including the theft of personal data, leading to severe hazards for individuals. Thus, Security plays a pivotal role in safeguarding IoT devices. In this modern era, integrating security measures with machine learning has emerged as a solution to automate and streamline security protocols. This requires a comprehensive analysis of enhancing security levels in IoT devices within innovative city environments. Our study extensively surveys security issues across various facets of IoT infrastructure, including hardware, cloud environments, applications, data, software, and networks. Through thorough examination, we identify the effects of these issues and propose countermeasures to bolster Security, mainly focusing on IoT devices. Furthermore, our study delves into various machine learning algorithms, providing examples, detailing attack types, and assessing accuracy rates for each algorithm. We offer a quick reference guide that outlines the benefits and drawbacks of different machine-learning algorithms and their applications. Additionally, we aim to identify and mitigate various security threats by exploring diverse datasets, evaluation metrics, IoT threats, and machine-learning techniques. By thoroughly exploring these aspects, our study equips future researchers with the knowledge to effectively identify potential security threats and implement robust safeguards against them.},
 author = {Muniswamy, Arunkumar and Rathi, R.},
 doi = {10.1109/ACCESS.2024.3450180},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Smart cities;Temperature sensors;Machine learning algorithms;Medical services;Software systems;IoT;security;machine learning;smart city;attacks},
 month = {},
 number = {},
 pages = {120389-120413},
 title = {A Detailed Review on Enhancing the Security in Internet of Things-Based Smart City Environment Using Machine Learning Algorithms},
 volume = {12},
 year = {2024}
}

@article{10649027,
 abstract = {Integrating Internet of Things (IoTs) devices with secure smart home networks assisted by the cloud signifies a cutting-edge and potent tool for contemporary home automation. This allows various appliances and devices in a home remotely controlled by the internet to communicate and share data. The typical smart home system depends on the cloud service or centralized server, which makes them further vulnerable to potential security breaches and single points of failure. As a decentralized nature, Blockchain (BC) distributes the control and storage of data across the network, preventing unauthorized attacks. Integrating BC technology into the protected smart home network boosts the system’s dependability, safety, and privacy. In addition, machine learning (ML) and analytics offer behaviour analysis and predictive maintenance for optimized energy consumption. Finally, combining IoT with cloud-assisted security transforms homes into smart, connected ecosystems, offering convenience without integrating confidentiality or dependability. Accordingly, this study presents a BC-based Deep Learning in the Secure Smart Home Network (BPDL-SSHN) methodology in the IoT-cloud platform. In the BPDL-SSHN methodology, BC technology permits secret proficient data from the smart home network. Furthermore, the BPDL-SSHN method follows a series of processes to detect malicious activities such as Binary Fox Optimization Algorithm (BFOA) based feature selection, Attention-based Long Short-Term Memory (ALSTM)-based classification, and Harbor Seal Whiskers Optimization (HSWO)-based hyperparameter tuning. The HSWO method’s design helps better the hyperparameter choice of the ALSTM method, significantly enhancing the recognition performance. The comparative outcome of the BPDL-SSHN methodology reported the proficient solution of the smart home network to detect and monitor malicious or harmful activities. The experimental outcome implied that the BPDL-SSHN methodology accomplishes a maximum accuracy performance of 98.91% over other approaches.},
 author = {Alruwaili, Fahad F.},
 doi = {10.1109/ACCESS.2024.3450796},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart homes;Tuning;Security;Feature extraction;Computational modeling;Safety;Biological system modeling;Internet of Things;Blockchains;Hyperparameter optimization;Deep learning;Internet of Things;blockchain;hyperparameter tuning;deep learning;binary fox optimization algorithm},
 month = {},
 number = {},
 pages = {119927-119936},
 title = {Blockchain-Powered Deep Learning for Internet of Things With Cloud-Assisted Secure Smart Home Networks},
 volume = {12},
 year = {2024}
}

@article{10658641,
 abstract = {Protection against unwanted intrusions is crucial for preserving the integrity and security of connected devices in the context of Internet of Things (IoT) networks. The growing number of IoT devices has made several industries more vulnerable to cyberattacks and security breaches, including smart homes, industrial automation, and healthcare. In response to this pressing dilemma, the goal of this project is to create a novel method for intrusion detection in Internet of Things systems utilizing Denoising Autoencoder (DAE) models. Traditional intrusion detection methods often prove inadequate in Internet of Things scenarios due to resource restrictions, dynamic network topologies, and a diversity of communication protocols. By utilizing DAEs’ unsupervised learning and feature extraction skills, our suggested approach creates a system that can identify and stop intrusion attempts in real-time. The evaluation of the study additionally makes use of the NSL-KDD and CICIDS 2017 datasets. DAE integration yields an unequaled accuracy of 99.991% when the CICIDS 2017 dataset is used, and an accuracy of 99.4% when the NSL-KDD dataset is used. The CICIDS 2017 dataset analysis reveals several notable performance measures, including an accuracy of 1.0, a precision of 0.995, and an F1-score of 0.998. Analyses of the NSL-KDD dataset also produce outstanding results, with an F1-score of 0.989, recall of 0.991, accuracy of 0.994, and precision of 0.984. The results also show how well the suggested DAE-based intrusion detection method works to stop unauthorized users from accessing IoT devices, which lowers the risk of issues with system integrity, privacy, and security. By strengthening resilience against evolving cyber threats in the networked Internet of Things landscape, this research enhances cybersecurity strategies tailored to address the unique challenges encountered by IoT ecosystems.},
 author = {Alrayes, Fatma S. and Zakariah, Mohammed and Amin, Syed Umar and Iqbal Khan, Zafar and Helal, Maha},
 doi = {10.1109/ACCESS.2024.3451726},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Intrusion detection;Accuracy;Security;Noise reduction;Biological system modeling;Feature extraction;Machine learning;Data models;Autoencoders;Intrusion detection system;Internet of Things;machine learning;CICIDS2017 dataset;denoising autoencoder},
 month = {},
 number = {},
 pages = {122401-122425},
 title = {Intrusion Detection in IoT Systems Using Denoising Autoencoder},
 volume = {12},
 year = {2024}
}

@article{10662895,
 abstract = {Anomaly detection in graphs is increasingly used to reveal fraud, fakes, security attacks and unusual behaviours in networks, such as social networks, financial transaction networks and the Internet of Things. Accurately detecting such graph anomalies using deep learning approaches faces challenges in terms of obtaining sufficient labelled data, as well as an imbalance between normal and anomalous instances. These contribute to model bias or over-fitting problems and inferior anomaly detection outcomes. In order to address these challenges in graphs, we propose a novel generative framework, called LabelGen, that can generate additional anomalous labels, in terms of graph objects, such as nodes, through augmentation and provide updated deep embedding for the graph concurrently. In particular, we propose the use of a k-hop neighborhood sampling strategy, an anomaly scoring mechanism and an adversarial learning framework with a generator and discriminator pair in order to generate sufficient and informative anomalous nodes that closely resemble the characteristics of existing anomalies in the graph. Evaluation on benchmark network datasets, as well as ablation and comparison studies with random label generation processes and other existing works reveal that the proposed generative framework is superior in improving the anomaly detection accuracy in graphs, while achieving a balanced trade-off between accuracy and computational efficiency.},
 author = {Xia, Siqi and Rajasegarar, Sutharshan and Pan, Lei and Leckie, Christopher and Erfani, Sarah M. and Chan, Jeffrey},
 doi = {10.1109/ACCESS.2024.3453178},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Generators;Training;Detectors;Data models;Data augmentation;Generative adversarial networks;Deep learning;Fraud;Network security;Graphical models;Anomalies in graphs;generative adversarial networks;k-hop neighborhood sampling;deep learning},
 month = {},
 number = {},
 pages = {121971-121982},
 title = {LabelGen: An Anomaly Label Generative Framework for Enhanced Graph Anomaly Detection},
 volume = {12},
 year = {2024}
}

@article{10662914,
 abstract = {Many malware detection models have been proposed to protect computers from the ever- increasing number of malware attacks. The features that are obtained from surface analysis and machine learning are often used for malware detection. Previous studies that performed surface analysis have proposed image-based methods using ensemble learning. However, no natural language processing (NLP)-based malware detection method that combines multiple features has yet been reported. Instead, previous malware detection methods using NLP techniques have focused only on single features. When hybrid features are used, the word order and detection rate is affected if the data are initially handled by combining the hybrid features into one data point. Consequently, using NLP techniques is challenging when considering the word order. This paper proposes a hybrid model that uses three hybrid features obtained from surface analysis for malware detection and demonstrates the effectiveness of using NLP techniques in combination with hybrid features. The F-measure for the combination of these three features was 0.927.},
 author = {Mimura, Mamoru and Kanno, Satoki},
 doi = {10.1109/ACCESS.2024.3452675},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Accuracy;Surface treatment;Machine learning;Long short term memory;Ensemble learning;Natural language processing;Artificial neural networks;Malware detection;natural language processing;deep neural network},
 month = {},
 number = {},
 pages = {121198-121207},
 title = {Hybrid Input Model Using Multiple Features From Surface Analysis for Malware Detection},
 volume = {12},
 year = {2024}
}

@article{10668871,
 abstract = {The detection of zero-day attacks remains one of the most critical challenges in cybersecurity. This systematic literature review focuses on the various AI-based methods employed for detecting zero-day attacks, identifying both the strengths and weaknesses of these approaches. By critically evaluating existing literature, this review provides new insights and highlights the gaps that future research must address. The findings suggest that while artificial intelligence, particularly machine learning, offers promising solutions, there are significant challenges related to data availability, algorithmic complexity, and real-time application. This review contributes to the field by providing a comprehensive analysis of current AI-driven methods and proposing future research directions to enhance zero-day attack detection.},
 author = {Yee Por, Lip and Dai, Zhen and Juan Leem, Siew and Chen, Yi and Yang, Jing and Binbeshr, Farid and Yuen Phan, Koo and Soon Ku, Chin},
 doi = {10.1109/ACCESS.2024.3455410},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Databases;Intrusion detection;Systematics;Search problems;Object recognition;Anomaly detection;Zero-day attack;CrowdStrike;intrusion detection;anomaly detection;machine learning;artificial intelligence;cybersecurity},
 month = {},
 number = {},
 pages = {144150-144163},
 title = {A Systematic Literature Review on AI-Based Methods and Challenges in Detecting Zero-Day Attacks},
 volume = {12},
 year = {2024}
}

@article{10676989,
 abstract = {The modern digital environment is becoming increasingly interconnected, underscoring the critical need to safeguard network infrastructures. Detecting anomalies in network traffic remains essential as cyber threats continue to evolve. Analyzing trends, patterns, and relationships in network traffic data over time poses challenges. On the other hand, traditional generative neural networks emphasize detecting network attacks but encounter difficulties due to limitations in capturing the temporal and dynamic aspects of network traffic. This paper introduces a new methodology aimed at enhancing the identification of irregularities in network traffic using a Temporal Metric-Driven GRU Embedded Generative Neural Network (TMG-GRU-VAE). This method incorporates Gated Recurrent Units (GRU) into variational autoencoders to effectively train on the temporal characteristics of network traffic in temporal sequential networks. Moreover, we present a Temporal Correlation Index (TCI) score designed for anomaly detection in Network Intrusion Detection Systems (NIDS). This innovative metric offers a sophisticated and dynamic assessment of temporal behavior within network traffic. TCI’s ability to distinguish between normal and anomalous temporal patterns plays a pivotal role in mitigating false positives. Our proposed method greatly improves the detection of small changes in abnormal sequences over time, enhancing accuracy by making anomalies stand out more clearly and reducing false alarms, thereby making the system more reliable. The proposed work, validated using the CIC-IDS-2017 and CIC-IDS-2018 datasets, demonstrates a significant decrease in False Positives (FP) across all models. Notable improvements range from 7.2% to 12.9% for the CIC-IDS-2017 dataset and from 7.1% to 14.1% for the CIC-IDS-2018 dataset. This highlights its significant impact on decreasing false positive rates.},
 author = {Nasreen Fathima, A. H. and Ibrahim, S. P. Syed and Khraisat, Ansam},
 doi = {10.1109/ACCESS.2024.3458903},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Telecommunication traffic;Network intrusion detection;Deep learning;Anomaly detection;Indexes;Correlation;Network security;Anomaly detection;deep learning;generative model;network intrusion detection system;network traffic;security;temporal correlation;unknown attack;variational autoencoder},
 month = {},
 number = {},
 pages = {136805-136824},
 title = {Enhancing Network Traffic Anomaly Detection: Leveraging Temporal Correlation Index in a Hybrid Framework},
 volume = {12},
 year = {2024}
}

@article{10680036,
 abstract = {A large number of Internet of Things (IoT) devices have been deployed in numerous applications (e.g., smart homes, healthcare, smart grids, manufacturing processes, and product supply chains). However, IoT networks’ wide range and heterogeneity make them prone to cyberattacks. Most IoT devices have limited resource capabilities (e.g., memory capacity, processing power, and energy consumption) to function as conventional intrusion detection systems (IDSs). Many research approaches to lightweight IDSs have been taken, namely energy-based IDSs, machine learning/deep learning (ML/DL)–based IDSs, and federated learning (FL)–based IDSs. FL has become a promising solution for IDSs in IoT networks because it reduces overhead in the learning process by engaging IoT devices during the training process. In this paper, we present a comprehensive survey on FL for IDSs in an IoT environment with resource-constrained devices. We investigate the existing studies of FL in different architectures, namely centralized (client-server), decentralized (device-to-device), and semi-decentralized. The study’s findings highlight the necessity for enhancing the FL framework to better suit IoT networks. This enhancement is crucial, particularly in addressing two key challenges: the need to lightweight FL client’s models to accommodate the resource constraints of IoT devices and having a design aggregation algorithm capable of effectively handling the heterogeneity and limited resources inherent in IoT devices. Finally, we discuss the open challenges and future directions for scientists and researchers interested in FL-based IDS for IoT environments.},
 author = {Alsaleh, Shuroog S. and El Bachir Menai, Mohamed and Al-Ahmadi, Saad},
 doi = {10.1109/ACCESS.2024.3460468},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Intrusion detection;Surveys;Industrial Internet of Things;Data models;Federated learning;Analytical models;Anomaly detection;Machine learning;Transfer learning;Internet of Things;intrusion detection system;anomaly detection;machine learning;deep learning;federated learning;energy based;centralized FL;decentralized FL;semi-decentralized FL;transfer learning},
 month = {},
 number = {},
 pages = {134256-134272},
 title = {Federated Learning-Based Model to Lightweight IDSs for Heterogeneous IoT Networks: State-of-the-Art, Challenges, and Future Directions},
 volume = {12},
 year = {2024}
}

@article{10681070,
 abstract = {This paper proposes a novel Convolutional Kolmogorov-Arnold Network (CKAN) model for Intrusion Detection Systems (IDS) in an IoT environment. The CKAN model is developed by replacing the Multi-Layer Perceptrons (MLPs) layers with Kolmogorov-Arnold Networks (KANs) layers inside the Convolutional Neural Networks (CNN) architecture. The KANs give high performance compared to the MLPs layers with fewer parameters. The performance of the proposed CKAN model has been evaluated against other well-known Deep Learning (DL) models like CNN, recurrent neural networks (RNN), and Autoencoder. The evaluation process has been carried out with three benchmark datasets: NSL_KDD, which is treated as a standard IDS dataset; CICIoT2023; TONIoT, which are IoT IDS datasets. The results point out the superiority of the CKAN model over other DL models for both binary and multi-classification tasks as per the accuracy, precision, recall, and F1 score. The proposed CKAN model achieved accuracies of 98.71%, 99.22%, and 99.93% for binary classification, and 99.2%, 98.84%, and 93.3% for multi-classification on the NSL_KDD, CICIoT2023, and TONIoT datasets, respectively. The CKAN model gives better performance metrics with a smaller number of parameters compared to other DL models. In this way, our findings point out that KANs are promising for being a substitute for MLPs.},
 author = {Abd Elaziz, Mohamed and Ahmed Fares, Ibrahim and Aseeri, Ahmad O.},
 doi = {10.1109/ACCESS.2024.3462297},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Convolutional neural networks;Computer architecture;Accuracy;Splines (mathematics);Computational modeling;Deep learning;Intrusion detection;Kolmogorov-Arnold networks (KANs);multi-layer perceptrons;deep learning;intrusion detection systems (IDS);IoT},
 month = {},
 number = {},
 pages = {134837-134851},
 title = {CKAN: Convolutional Kolmogorov–Arnold Networks Model for Intrusion Detection in IoT Environment},
 volume = {12},
 year = {2024}
}

@article{10681247,
 abstract = {Electromagnetic Side Channel Analysis (EM-SCA) is a major area of interest within the field of cybersecurity. EM-SCA makes use of the electromagnetic radiation that naturally leaks from any device that runs on electricity. Information about the observed device can be gained by gathering and analysing these electromagnetic traces. Numerous studies have demonstrated the applicability of this side channel in various environments for legal and illegal objectives. On the other hand, multi-robot systems, including swarm robotics, have received considerable attention in recent years due to their ability to conduct complex tasks using simple robots cooperating with each other. Although multi-robot and swarm robot systems are likely to be widely used in practical applications in the near future, security concerns in this context have not yet received enough attention. In particular, to the best of our knowledge, EM-SCA threats and benefits have never been thoroughly examined in this context before. In order to spotlight this matter, this work begins with a thorough introduction to EM-SCA and provides a taxonomic structure. Then, guided by this taxonomy, we present a range of EM-SCA scenarios that need to be considered in multi-robot applications.},
 author = {Ibrahim, Yomna Mokhtar and Kermanshahi, Shabnam Kasra and Kasmarik, Kathryn and Hu, Jiankun},
 doi = {10.1109/OJCS.2024.3461808},
 issn = {2644-1268},
 journal = {IEEE Open Journal of the Computer Society},
 keywords = {Surveys;Robots;Security;Electromagnetics;Cryptography;Timing;Power demand;Electromagnetic side-channel analysis;electromagnetic side-channel attacks;multi-robot systems},
 month = {},
 number = {},
 pages = {511-529},
 title = {A Taxonomy-Based Survey of EM-SCA and Implications for Multi-Robot Systems},
 volume = {5},
 year = {2024}
}

@article{10681423,
 abstract = {Internet of Things (IoT) has more security issues due to the data being shared in an open platform. Integrating blockchain into IoT for security is a new development in computational communication systems. However, attackers are adapting their methods and creating new vulnerabilities in blockchain-based IoT platforms. Furthermore, when the blockchain is integrated with IoT networks, vulnerabilities, privacy issues, and security threats are amplified due to malicious transactions and active attacks. This paper proposes BlockDLO, an approach to IoT security that combines blockchain technology with deep learning. A five-phase architecture is proposed for the edge computing blockchain. In its first phase, network localization is resolved with chaotic map-based identification and authentication. The second phase proposes page rank-based clustering for edge computing. Then, BlockDLO combines the shared-chain technique with a deep distributed file system to address issues with block creation and ledger distribution, and an ethereum smart contract to address data security concerns. The communication route optimization is done with page rank centrality search optimization in its next phase. Finally, the integration of deep learning model to detect malicious data in the IoT network is done using the authenticated received data. BlockDLO creates an efficient intrusion detection system by combining a deep convolution neural network with blockchain. The proposed system is trained using public data sources and tested using an in-house network testbed. The results demonstrate that the proposed system outperforms existing work in terms of energy usage, packet loss rate, end-to-end delay, routing overhead, network lifetime, accuracy, and security strength.},
 author = {Kokila, M. and Srinivasa Reddy, K.},
 doi = {10.1109/ACCESS.2024.3462735},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Blockchains;Deep learning;Cryptography;Privacy;Optimization;Data security;Clustering methods;Search methods;Optimization methods;Internet of Things;blockchain;deep learning;data security;clustering;search optimization},
 month = {},
 number = {},
 pages = {134521-134540},
 title = {BlockDLO: Blockchain Computing With Deep Learning Orchestration for Secure Data Communication in IoT Environment},
 volume = {12},
 year = {2024}
}

@article{10684706,
 abstract = {Intrusion detection systems (IDS) identify network intrusions by detecting abnormal traffic data, thereby ensuring network security. However, intrusion detection data can vary with changes in the network and attack environment, resulting in poor performance and portability of intrusion detection algorithms. Therefore, an intrusion detection method based on PSO-GA hyperparameter optimized ResNet-BiGRU is proposed. The two-layer bidirectional gated recurrent unit (BiGRU) is connected to the fully connected layer of the residual neural network (ResNet). Firstly, ResNet is used to extract parallel local features, and BiGRU is used to extract long-distance-dependent features from the parallel local features, and the attention mechanism is added after the BIGRU to utilize correlation between the features to assign weights to the extracted features, so as to more comprehensively capture the important features of network intrusion and improve the detection performance. At the same time, the parameters of the basic particle swarm optimization (PSO) are dynamically optimized and combined with the genetic algorithm (GA) to perform a mutation operation when the iterative process falls into a local optimal solution, adding a random perturbation to the current velocity and position of the particles, so that the particles are able to explore new regions in the space in order to jump out of the local optimal solution, and ultimately achieve automatic optimization of the hyperparameters of the ResNet-BiGRU model to achieve a model with better generalization performance. Finally, the proposed method is validated by using the variant NSL-KDD dataset, which achieves an accuracy of 98.46% and average precision, average recall and average False Alarm Rate(FAR) of 91.84%, 95.99% and 0.31%, and achieved high accuracy on three datasets KDD99, UNSW-NB15, and CIC-IDS 2017. The method is proved to have a strong intrusion detection capability by comparison experiments with other algorithms.},
 author = {Xia, Zhixin and He, Siyuan and Liu, Changwei and Liu, Yongshan and Yang, Xiaolei and Bu, Huifeng},
 doi = {10.1109/ACCESS.2024.3464529},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Optimization;Deep learning;Accuracy;Convolutional neural networks;Adaptation models;Bidirectional control;Particle swarm optimization;Residual neural networks;Bidirectional gated recurrent unit;intrusion detection;particle swarm optimization algorithm;residual neural network},
 month = {},
 number = {},
 pages = {135535-135550},
 title = {PSO-GA Hyperparameter Optimized ResNet-BiGRU-Based Intrusion Detection Method},
 volume = {12},
 year = {2024}
}

@article{10689394,
 abstract = {The rapid evaluation of smart cities has revolutionized the research and development field to a very extensive level which presents challenges in handling massive amounts of data. However, the integration of IoT into various aspects of life has introduced various challenges related to the security and privacy of IoT systems. IoT sensors capture large volumes of sensitive customer data, which can potentially make them a target and pose serious threats, including financial loss and identity theft. Strong intrusion detection systems are essential for protecting networked, data-driven ecosystems from potential cyber threats. In this paper, we propose a novel deep learning-based approach that focuses on emerging zero-touch networks that autonomously manage network resources to ensure network security, the proposed approach identifies various network intrusions such as DDoS, Botnet, Brute force, and Infiltration. Our proposed approach presents a major improvement in IoT security. We have used the CICIDS-2018 benchmark dataset and propose a deep learning-based network intrusion detection System for Zero Touch Networks (DL-NIDS-ZTN). The proposed study utilizes convolutional neural networks that correctly identify benign and malicious traffic and achieve 99.80% accuracy with the CICIDS-2018 dataset. By implementing the DL-NIDS-ZTN methodology, we aim to strengthen the security framework of smart cities and ensure the secure and seamless integration of IoT.},
 author = {Qazi, Emad-Ul-Haq and Zia, Tanveer and Hamza Faheem, Muhammad and Shahzad, Khurram and Imran, Muhammad and Ahmed, Zeeshan},
 doi = {10.1109/ACCESS.2024.3466470},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart cities;Security;Autonomous networks;Deep learning;Network security;Feature extraction;Cyberattack;Intrusion detection;Convolutional neural networks;Intrusion detection;zero-touch networks;smart city;IoT;deep learning;convolutional neural networks},
 month = {},
 number = {},
 pages = {141625-141638},
 title = {Zero-Touch Network Security (ZTNS): A Network Intrusion Detection System Based on Deep Learning},
 volume = {12},
 year = {2024}
}

@article{10689592,
 abstract = {Detecting source code vulnerabilities is a critical challenge in secure software development. Early identification of vulnerabilities ensures that software performance and security remain uncompromised. However, existing vulnerability detection methods often struggle to capture the semantic meaning of source code, particularly for vulnerability types that require a deeper understanding of code flow and context. This work addresses this challenge by introducing ContextCPG, a novel enhancement of the code property graph (CPG) representation. ContextCPG augments the CPG by incorporating additional information about variable names and data types within the source code. Our approach combines natural language processing analysis with graph-based analysis to capture a richer context surrounding the source code, relying on both the structural features of the graph representation and the naming, type, and value of nodes as natural language analysis. These additional features enhance the capability of graph neural network models to capture the semantic meaning of the source code and better detect vulnerabilities. We evaluate ContextCPG by applying it to three selected C/C++ vulnerabilities (buffer overflow, invalid input, and use-after-free) and comparing its performance against CPGs. The evaluation results reveal that ContextCPG consistently outperforms the CPG on all vulnerability types, demonstrating an average accuracy increase of 8%. ContextCPG showcases the value of providing supplementary information within the graph representation, consistently enhancing vulnerability detection efficacy.},
 author = {Rozi, Muhammad Fakhrur and Ban, Tao and Ozawa, Seiichi and Yamada, Akira and Takahashi, Takeshi and Inoue, Daisuke},
 doi = {10.1109/ACCESS.2024.3467180},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Source coding;Codes;Security;Feature extraction;Vectors;Malware;Analytical models;Graph neural networks;Vulnerability detection;code property graph;source code representation;graph neural network},
 month = {},
 number = {},
 pages = {142101-142126},
 title = {Securing Code With Context: Enhancing Vulnerability Detection Through Contextualized Graph Representations},
 volume = {12},
 year = {2024}
}

@article{10701303,
 abstract = {The emergence of small-drone technology has revolutionized the way we use drones. Small drones leverage the Internet of Things (IoT) to provide precise navigation and location-based services, making them versatile tools for various applications. However, small drones’ structural and design vulnerabilities expose them to significant security and privacy threats. To ensure the secure and reliable operation of small drones, developing a robust network infrastructure and implementing tailored security and privacy mechanisms is essential. The research evaluates the performance of deep learning (DL) models, including Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), CNN-LSTM, and ConvLSTM, in detecting intrusions within UAV communication networks. The study utilizes five diverse and realistic datasets, namely KDD Cup-99, NSL-KDD, WSN-DS, CICIDS2017, and Drone datasets, to simulate real-world intrusion scenarios. Notably, the ConvLSTM model consistently achieves an accuracy of 99.99%, showcasing its potential in securing UAVs from cyber threats. This research underscores the significance of robust cybersecurity measures in the ever-expanding realm of UAV technology and highlights the pivotal role played by high-quality datasets in enhancing UAV security. As UAVs become increasingly integral to various industries, this study contributes to ensuring their safety, security, and reliability in the face of evolving cyber risks.},
 author = {Alzahrani, Abdulrahman},
 doi = {10.1109/ACCESS.2024.3471806},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Drones;Security;Autonomous aerial vehicles;Computer security;Privacy;Safety;Internet of Things;Communication system security;Long short term memory;Convolutional neural networks;Autonomous vehicles;UAVs;GPS;cyber-security;spoofing;ConvLSTM},
 month = {},
 number = {},
 pages = {149238-149253},
 title = {Novel Approach for Intrusion Detection Attacks on Small Drones Using ConvLSTM Model},
 volume = {12},
 year = {2024}
}

@article{10707635,
 abstract = {In recent years, the rapid growth of Internet of Things (IoT) devices has introduced significant security risks, emphasizing the need for effective IoT device management. Traditional device identification methods, such as traffic analysis and machine learning, which rely heavily on static features and prior knowledge, often struggle to maintain accuracy in dynamic IoT environments characterized by frequent changes and large-scale deployments. To address this challenge, we propose the Feature Extraction-Deep IoT (FE-DIoT) method to improve the accuracy and reliability of IoT device identification in large-scale networks by integrating a feature selection algorithm with a classification model. Our approach leverages the Dynamic Weight Adjustment-Based Recursive Feature Elimination (DWA-RFE) algorithm to effectively minimize redundancy, thus enhancing the robustness of the model. Additionally, we implement a Deep Cross Network with Feature Extraction (DCN-FE) module to improve device classification precision by extracting the most significant features from network traffic data. The experimental results in our dataset and other public datasets demonstrate that FE-DIoT significantly outperforms existing methods in terms of robustness and classification accuracy. These findings indicate that FE-DIoT provides a practical and effective solution to improve IoT device management and security in complex large-scale networks.},
 author = {Zheng, Hanxi and Yin, Huanpu and Li, Haisheng},
 doi = {10.1109/ACCESS.2024.3476136},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Feature extraction;Object recognition;Accuracy;Telecommunication traffic;Heuristic algorithms;Performance evaluation;Classification algorithms;Protocols;Adaptation models;Internet of things;device identification;feature selection;dynamic weight adjustment},
 month = {},
 number = {},
 pages = {149099-149114},
 title = {FE-DIoT: IoT Device Classification Through Dynamic Feature Selection and Adaptive Cross-Network Model},
 volume = {12},
 year = {2024}
}

@article{10713374,
 abstract = {As the threat landscape for Operational Technology (OT) and Supervisory Control and Data Acquisition (SCADA) systems grows more complex, there is a pressing need for intrusion detection systems that can dynamically adapt to evolving attack patterns. Traditional Machine Learning (ML) approaches often require frequent manual retraining and struggle to respond efficiently to these dynamic threats. Deep Reinforcement Learning (DRL) models present a promising solution, offering autonomous learning capabilities, adaptability to diverse scenarios with minimal human intervention, and enhanced intrusion detection for Industrial Control Systems (ICS). This paper presents a novel investigation into the application of various DRL models, including Deep Q-Network (DQN), Double Deep Q-Network (DDQN), Dueling Double Deep Q-Network (D3QN), REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), for network intrusion detection in ICS. Performance comparisons with traditional ML methods are conducted using relevant metrics. To assess their effectiveness without a live environment, labeled pre-recorded intrusion datasets are utilized, with tailored adaptations for DRL model training outlined. These adaptations include generating data samples in mini-batches, integrating small discount factors, and employing straightforward reward functions. Comprehensive results underscore the efficacy of DRL models in bolstering the detection of advanced cyberattacks within OT environments, surpassing conventional ML approaches.},
 author = {Sangoleye, Fisayo and Johnson, Jay and Eleni Tsiropoulou, Eirini},
 doi = {10.1109/ACCESS.2024.3477415},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Adaptation models;Intrusion detection;Feature extraction;Training;Protocols;Microgrids;Heuristic algorithms;Industrial control;Deep reinforcement learning;Accuracy;SCADA systems;Deep reinforcement learning;network intrusion detection;SCADA;industrial control systems;microgrids},
 month = {},
 number = {},
 pages = {151444-151459},
 title = {Intrusion Detection in Industrial Control Systems Based on Deep Reinforcement Learning},
 volume = {12},
 year = {2024}
}

@article{10713384,
 abstract = {The increasing focus on cyber-physical security in Smart Grids (SGs) has catalyzed a surge in research over recent years. This paper comprehensively reviews SG cyber-physical security advancements, diverging from conventional studies that concentrate on specific attack types. It begins with a structured overview of SGs, delineating their cyber and physical layers and analyzing the key processes: generation, transmission, distribution, and consumption. Subsequent sections critique existing survey studies, identifying gaps and underscoring overlooked aspects in the current literature, particularly concerning the challenges faced. The review progresses to analyze current research trends in SG security, evaluating methodologies across both layers and categorizing them into Machine Learning-based, data-driven, and model-based approaches. The analysis includes a detailed classification of research focused on Control, Monitoring, and Protection across each component and stage of SGs. Additionally, the paper examines emerging cyberattack strategies in SGs that have not been extensively reviewed in existing literature. In conclusion, the paper reflects on significant gaps and challenges in SG cyber-physical security research, underscoring the need for further exploration and innovation in this domain. Thus, this review serves as a critical roadmap for future research, delineating the current state and potential directions in the rapidly evolving field of SG security.},
 author = {Manias, Dimitris M. and Saber, Ahmad Mohammad and Radaideh, Mohammed I. and Gaber, Abdelrahman Tarek and Maniatakos, Michail and Zeineldin, Hatem and Svetinovic, Davor and El-Saadany, Ehab F.},
 doi = {10.1109/ACCESS.2024.3477714},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Reviews;Security;Market research;Smart grids;Surveys;Computer security;Physical layer;Resilience;Cyberattack;Cyber-physical systems;Cyberattacks;cyber-physical systems;cybersecurity;FDIA;novel cyberattacks;smart grids},
 month = {},
 number = {},
 pages = {161329-161356},
 title = {Trends in Smart Grid Cyber-Physical Security: Components, Threats, and Solutions},
 volume = {12},
 year = {2024}
}

@article{10714347,
 abstract = {Distributed Denial of Service (DDoS) attacks are a major concern in network security, as they overwhelm systems with excessive traffic, compromise sensitive data, and disrupt network services. Accurately detecting these attacks is crucial to protecting network infrastructure. Traditional approaches, such as single Convolutional Neural Networks (CNNs) or conventional Machine Learning (ML) algorithms like Decision Trees (DTs) and Support Vector Machines (SVMs), struggle to extract the diverse features needed for precise classification, resulting in suboptimal performance. This research addresses this gap by introducing a novel approach for DDoS attack detection. The proposed method combines three distinct CNN architectures: SA-Enabled CNN with XGBoost, SA-Enabled CNN with LSTM, and SA-Enabled CNN with Random Forest. Each model extracts features at multiple scales, while self-attention mechanisms enhance feature integration and relevance. The weighted ensemble approach ensures that both prominent and subtle features contribute to the final classification, improving adaptability to evolving attack patterns and novel threats. The proposed method achieves a precision of 98.71%, an F1-score of 98.66%, a recall of 98.63%, and an accuracy of 98.69%, outperforming traditional methods and setting a new benchmark in DDoS attack detection. This innovative approach addresses critical limitations in current models and advances the state of the art in network security.},
 author = {Venkatraman, Shravan and Kanthimathi, S. and Jayasankar, K. S. and Pranay Jiljith, T. and Jashwanth, R.},
 doi = {10.1109/ACCESS.2024.3478764},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Feature extraction;Convolutional neural networks;Accuracy;Computer crime;Random forests;Artificial neural networks;Telecommunication traffic;Network security;Long short term memory;Deep learning;Convolutional neural network (CNN);deep learning;distributed denial of service (DDoS);network security},
 month = {},
 number = {},
 pages = {151515-151531},
 title = {A Novel Self-Attention-Enabled Weighted Ensemble-Based Convolutional Neural Network Framework for Distributed Denial of Service Attack Classification},
 volume = {12},
 year = {2024}
}

@article{10716376,
 abstract = {In light of the flourishing proliferation of internet services, the popularity of the Internet of Things (IoT) has swiftly grown in the medical and healthcare fields, and this has been accompanied by a simultaneous escalation in the sophistication of intrusion attacks. Drawing inspiration from the accomplishments of deep learning in cyber threat detection, we propose a multigrained scanning-based deep stacking network (MGDSN) to defend against sophisticated cyberattacks on Internet of Medical Things (IoMT) networks. To address the obscured characteristics of intricate cyberattacks, the MGDSN incorporates four components. First, the feature augmentation process leverages an improved multigrained scanning technique to enhance discriminative information. Second, a deep stacking network (DSN) with a weighting mechanism is employed to generate a set of predictive results for making the final decision. Third, a meta-classifier is introduced to scrutinize the influence of the predictive results when producing the final decision and exploiting a set of meaningfully extracted features. Finally, a loss function is properly designed to take both the predictive losses of the DSN modules and the final predictive loss into account. The outstanding performance achieved by the MGDSN is confirmed through comprehensive evaluations comparing it with the state-of-the-art techniques, encompassing metrics such as the accuracy, precision, recall, F1 score, Cohen’s kappa coefficient, Matthews correlation coefficient, and area under the curve achieved on the IoMT datasets. The MGDSN exhibits a notable improvement ranging from approximately 0.12%-329.21%.},
 author = {Musikawan, Pakarat and Kongsorot, Yanika and Aimtongkham, Phet and So-In, Chakchai},
 doi = {10.1109/ACCESS.2024.3480011},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Stacking;Intrusion detection;Long short term memory;Principal component analysis;Classification tree analysis;Classification algorithms;Training;Support vector machines;NSL-KDD;Internet of Medical Things;Machine learning;Computer security;Intrusion detection system (IDS);Internet of Medical Things (IoMT);machine learning (ML);deep learning (DL);cybersecurity},
 month = {},
 number = {},
 pages = {152482-152497},
 title = {Enhanced Multigrained Scanning-Based Deep Stacking Network for Intrusion Detection in IoMT Networks},
 volume = {12},
 year = {2024}
}

@article{10716383,
 abstract = {Cyber-physical systems (CPSs) have become vital to network communication. The CPS combines numerous interconnected computing resources, networking units, and physical processes to monitor the activities of computing devices. The perception layer in the CPS is employed to gather data from the physical surroundings. Still, the interconnection of the physical and cyber worlds creates more security concerns; hence, the operations of the communication networks become more complex. Devices on the CPS perception layer are especially susceptible due to their limited resources. To resolve the issues, the Spiking Visual Geometry Group-16 is developed for intrusion detection in the CPS perception layer. The log file collected from the dataset is normalized using the Quantile Normalization (QN) approach. The major function of QN is to reduce data redundancy. The required features from the normalized data are selected using the Skill Optimization Algorithm (SOA). The proposed Spiking VGG-16 is utilized to detect intrusion. In addition, performance computing metrics like accuracy, precision, recall, F1-score, and Matthew’s correlation coefficient (MCC) are utilized for validating the Spiking VGG-16-based model, in which the outcomes of 91.32%, 90.98%, 89.57%, 90.39%, and 90.51% are achieved.},
 author = {Abdul Rahim, Shaik and Manoharan, Arun},
 doi = {10.1109/ACCESS.2024.3479310},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Security;Sensors;Feature extraction;Computational modeling;Accuracy;Actuators;Training data;Telecommunication traffic;Real-time systems;Cyber-physical systems;Communication networks;Cyber-physical systems (CPSs);intrusion detection;quantile normalization (QN);skill optimization algorithm (SOA);visual geometry group-16 (VGG-16)},
 month = {},
 number = {},
 pages = {152709-152720},
 title = {An Optimization-Based Feature Selection and Hybrid Spiking VGG 16 for Intrusion Detection in the CPS Perception Layer},
 volume = {12},
 year = {2024}
}

@article{10720176,
 abstract = {In today’s digital landscape, critical services are increasingly dependent on network connectivity, thus cybersecurity has become paramount. Indeed, the constant escalation of cyberattacks, including zero-day exploits, poses a significant threat. While Network Intrusion Detection Systems (NIDSs) leveraging machine-learning and deep-learning models have proven effective in recent studies, they encounter limitations such as the need for abundant samples of malicious traffic and full retraining upon encountering new attacks. These limitations hinder their adaptability in real-world scenarios. To address these challenges, we design a novel NIDS capable of promptly adapting to classify new attacks and provide timely predictions. Our proposal for attack-traffic classification adopts Few-Shot Class-Incremental Learning (FSCIL) and is based on the Rethinking Few-Shot (RFS) approach, which we experimentally prove to overcome other FSCIL state-of-the-art alternatives based on either meta-learning or transfer learning. We evaluate the proposed NIDS across a wide array of cyberattacks whose traffic is collected in recent publicly available datasets to demonstrate its robustness across diverse network-attack scenarios, including malicious activities in an Internet-of-Things context and cyberattacks targeting servers. We validate various design choices as well, involving the number of traffic samples per attack available, the impact of the features used to represent the traffic objects, and the time to deliver the classification verdict. Experimental results witness that our proposed NIDS effectively retains previously acquired knowledge (with over 94% F1-score) while adapting to new attacks with only few samples available (with over 98% F1-score). Thus, it outperforms non-FSCIL state of the art in terms of classification effectiveness and adaptation time. Moreover, our NIDS exhibits high performance even with traffic collected within short time frames, achieving 95% F1-score while reducing the time-to-insight. Finally, we identify possible limitations likely arising in specific application contexts and envision promising research avenues to mitigate them.},
 author = {Di Monda, Davide and Montieri, Antonio and Persico, Valerio and Voria, Pasquale and De Ieso, Matteo and Pescapè, Antonio},
 doi = {10.1109/OJCOMS.2024.3481895},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Power capacitors;Training;Metalearning;Computer crime;Denial-of-service attack;Transfer learning;Network intrusion detection;Telecommunication traffic;Vectors;Traffic control;Attack-traffic classification;deep learning;few-shot class-incremental learning;network intrusion detection system;network security},
 month = {},
 number = {},
 pages = {6736-6757},
 title = {Few-Shot Class-Incremental Learning for Network Intrusion Detection Systems},
 volume = {5},
 year = {2024}
}

@article{10736606,
 abstract = {Network monitoring is essential for IT infrastructure health, enabling proactive threat detection, bandwidth optimization, and data analysis. Federated Learning facilitates collaboration and expands threat detection capabilities by allowing multiple clients to train models while preserving privacy and security without compromising sensitive information. This work explores the application of Federated Learning for secure network monitoring by investigating its use in various data partitioning settings to train Deep Learning models across multiple data partitions, incorporating secure aggregation to enhance data privacy. We propose an approach for multiparty training of deep neural networks for time series-based network load forecasting with secure aggregation. Our approach shows that a collaboratively trained model, on horizontal partitions, performs 11%-14% better than model training only on a single partition of that type. The model trained on vertical partitions achieved performance comparable to that of the models trained on a complete data set. Finally, examining the proposed approach on horizontal and vertical partitions proved its viability in both aggregation settings, regular and secure. These contributions demonstrate the feasibility of Federated Learning to improve interoperability between multiple organizations while addressing privacy and security concerns.},
 author = {Lytvyn, Oleksandr and Nguyen, Giang},
 doi = {10.1109/ACCESS.2024.3486810},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Data models;Federated learning;Computational modeling;Training;Security;Predictive models;Load modeling;Distributed databases;Context modeling;Network monitoring;federated learning;secret sharing;secure aggregation;time-series modeling},
 month = {},
 number = {},
 pages = {163262-163284},
 title = {Secure Federated Learning for Multi-Party Network Monitoring},
 volume = {12},
 year = {2024}
}

@article{10737061,
 abstract = {Despite its widespread adoption, Tor remains vulnerable to traffic analysis attacks, which enables both ends of the communication to be inferred by network-level adversaries. Notable examples of such attacks include website fingerprinting and end-to-end flow correlation attacks. Various defense techniques have been proposed to enhance the security of Tor against these threats, with traffic splitting defenses standing out as particularly effective. These defenses allow packets to be sent through multiple circuits without incurring additional bandwidth overhead, thereby limiting the amount of traffic observable by adversaries. In this paper, the potential of correlating split traces is thoroughly investigated using the proposed deep learning-based correlator called DeepCoAST. It is shown that properly merged split traces, upon correlated detection, could enable website fingerprinting attacks to effectively identify websites with high accuracy. Superior performance is demonstrated by DeepCoAST, achieving an Area Under the Receiver Operating Characteristic Curve (AUC) of 0.98 against 95 pairs of split traces generated by three traffic splitting defenses: TrafficSliver, HyWF, and CoMPS. This result highlights the need for further enhancement of traffic splitting Website Fingerprinting (WF) defense mechanisms against DeepCoAST-style attacks.},
 author = {Kim, Goun and Kwak, Hyeonjeong and Kim, Sujin and Park, Youhee and Park, Jihyeun and Oh, Se Eun},
 doi = {10.1109/ACCESS.2024.3487505},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Correlation;Feature extraction;Correlators;Fingerprint recognition;Security;Deep learning;Timing;Monitoring;Vectors;Traffic control;Anonymity;flow correlation attack;Tor;website fingerprinting},
 month = {},
 number = {},
 pages = {158266-158281},
 title = {DeepCoAST: Unveiling Split Trace Correlation to Counter Traffic Splitting Defenses},
 volume = {12},
 year = {2024}
}

@article{10737193,
 abstract = {Presents corrections to the paper, (Corrections to “Deep Learning-Based Intrusion Detection Systems: A Systematic Review”).},
 author = {Lansky, Jan and Ali, Saqib and Mohammadi, Mokhtar and Majeed, Mohammed Kamal and Karim, Sarkhel H. Taher and Rashidi, Shima and Hosseinzadeh, Mehdi and Rahmani, Amir Masoud},
 doi = {10.1109/ACCESS.2024.3474808},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection},
 month = {},
 number = {},
 pages = {150940-150940},
 title = {Corrections to “Deep Learning-Based Intrusion Detection Systems: A Systematic Review”},
 volume = {12},
 year = {2024}
}

@article{10737327,
 abstract = {An Internet of Things (IoT) platform is a software architecture that enables the connection, management, and analysis of IoT devices, sensors, and data. It provides a centralized system for IoT devices to interact with each other and with the cloud, facilitating the collection, processing, and analysis of data from these devices. However, in the automotive manufacturing industry, traditional Internet of Things (IoT) platforms are facing challenges such as bottleneck issues due to business volume growth and system challenges. To address these challenges, we propose a design methodology for an IoT platform based on microservices. The platform’s modules are divided into front end, database, security, and operation maintenance architecture, all effectively designed. Through practical applications, the platform enables interconnections between different information systems, production status monitoring, efficiency management, performance evaluation, energy consumption analysis, quality detection, and equipment asset evaluation. Finally, a data-driven deep learning algorithm, named Long Short-Term Memory Neural Network (LSTM) is developed for the state recognition of the industrial robot based on the Intelligent data services platform, which validate the effectiveness of the constructed IoT platforms. This platform offers advantages in extendibility, reusability, and provides methods for upgrading, expanding functions, and maintaining industrial IoT platforms in the discrete manufacturing industry.},
 author = {He, Yi and Zhang, Yanzhong and Wu, Che and Yang, Meng and Xu, Weidong and Wan, Haiyang and Chen, Zhuyun},
 doi = {10.1109/ACCESS.2024.3487832},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Microservice architectures;Industrial Internet of Things;Computer architecture;Maintenance;Manufacturing;Business;Security;Databases;Monitoring;Automotive engineering;Long short term memory;Automobile manufacturing;IoT platform;microservices;deep learning;long short-term memory recurrent neural network (LSTM);state recognition},
 month = {},
 number = {},
 pages = {166834-166842},
 title = {Architecture Design and Application of IIoT Platform in Automobile Manufacturing Based on Microservices and Deep Learning Techniques},
 volume = {12},
 year = {2024}
}

@article{10738793,
 abstract = {Recent statistics indicate a continuous rise in cryptojacking malware. This malware covertly exploits users’ device resources to mine cryptocurrencies, such as Bitcoin, without their knowledge or consent. Cryptocurrency mining involves participants competing to generate a unique hash, with successful miners earning cryptocurrency tokens as rewards. As the difficulty of mining new cryptocurrencies increases, greater computational power and resources are required. Unfortunately, the growing popularity of cryptocurrencies has led to a significant increase in cryptojacking malware. Compounding this issue is the lack of adequate, practical solutions to combat this threat. Current shortcomings include a limited number of related studies, particularly in host-based cryptojacking, a scarcity of recent research, reliance on small or outdated datasets, and a shallow understanding of the behavior and characteristics of cryptojacking malware. This paper aims to address these gaps by introducing a holistic, intelligent cryptojacking malware detection system that: 1) provides a detailed analysis of the lifecycle of both host-based and web-based cryptojacking malware; 2) conducts a critical comparison of existing solutions, highlighting their weaknesses; 3) applies deep static analysis to identify key indicators crucial for cryptojacking analysis; 4) executes thorough dynamic analysis to demonstrate the real-world impact of cryptojacking; 5) utilizes a new, large, and robust cryptojacking dataset (CJDS) with over 100,000 samples, where the details of constructing this dataset are provided, (f) develops vision-based predictive models using 23 convolutional neural network (CNN) algorithms, extensively evaluated with comprehensive metrics; and 6) integrates the best-performing model to bulid a highly efficient cryptojacking detection system with an accuracy of 99%. This research offers valuable insights into the characteristics and consequences of cryptojacking, paving the way for further advancements in cybersecurity. It aims to protect digital environments from unauthorized resource exploitation and enhance the security of cryptocurrency-based systems.},
 author = {Almurshid, Hadeel A. and Almomani, Iman and Khalifa, M. A. and El-Shafai, Walid},
 doi = {10.1109/ACCESS.2024.3488192},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Bitcoin;Predictive models;Blockchains;Static analysis;Convolutional neural networks;Prediction algorithms;Heuristic algorithms;Feature extraction;Cryptocurrency;Deep learning;Cryptojacking;malware;blockchain;CNN;cryptocurrency;cryptomining;dataset;deep learning;host-based;web-based;predictive models;detection system;artificial intelligence;static analysis;dynamic analysis},
 month = {},
 number = {},
 pages = {161417-161439},
 title = {A Holistic Intelligent Cryptojacking Malware Detection System},
 volume = {12},
 year = {2024}
}

@article{10741204,
 abstract = {To enhance the accuracy and real-time response of network security-aware systems, the convolutional neural network is optimized by introducing exponentially weighted dempster-shafer evidence theory. Additionally, the gated recurrent unit is improved using an adaptive boosting algorithm. A novel network security-aware model integrating both methods is constructed. Experimental results show that the model achieves a detection accuracy of up to 94%, with the lowest values for miss rate, false positive rate, and false alarm rate being 7.84%, 2.47%, and 3.11%, respectively. This indicates that the proposed model provides an efficient and accurate solution for network security defense.},
 author = {Huang, Yu and Zhao, Ziyi and Shi, Canbin},
 doi = {10.1109/ACCESS.2024.3489664},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Network security;Convolutional neural networks;Accuracy;Network security;Mathematical models;Convolutional neural networks;Hidden Markov models;Adaptation models;Real-time systems;Heuristic algorithms;Detection algorithms;Convolutional neural network;gated recurrent unit;network security;perception;detection},
 month = {},
 number = {},
 pages = {163805-163818},
 title = {Network Security Perception System Integrating Improved CNN Algorithm and Improved GRU Algorithm},
 volume = {12},
 year = {2024}
}

@article{10741273,
 abstract = {Many interconnected IoT devices driven by imperatives of efficiency and convenience often lack adequate security measures, making them susceptible to exploitation by cyber-criminals. Effective network security necessitates meticulous intrusion detection, which typically involves scrutinizing the network traffic using deep packet or stateful protocol inspection techniques. However, traditional inspection methods often require manual feature engineering, which can result in loss of payload information and thus, false alarms. In this study, a controlled testbed environment is established to capture botnet traffic. The paper introduces a detection approach that involves converting raw NetFlow data to IDX, short for ‘Index,’ image representations. A hybrid deep learning architecture is designed, integrating VGG19 and GRU structures to learn the spatial and temporal features, respectively. The detection results show that the proposed solution achieves 98.883% true positives rate and 0.9% false negatives rate, surpassing conventional anomaly detection. In addition, an adaptive sliding window technique is introduced for live intrusion detection and prevention. Through iterative testing and refinement, a runtime of 0.041 ms per image and 0.00171 ms per packet is achieved, confirming the robust nature of the proposed method.},
 author = {Saeed, Rimsha and Khaliq Qureshi, Hassaan and Ioannou, Christiana and Lestas, Marios},
 doi = {10.1109/ACCESS.2024.3489772},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Prevention and mitigation;Accuracy;Image representation;Denial-of-service attack;Botnet;Servers;Real-time systems;Monitoring;Botnet detection;flow-to-image conversion;intrusion detection;intrusion prevention;sliding windows;spatial features;temporal features},
 month = {},
 number = {},
 pages = {160653-160666},
 title = {A Proactive Model for Intrusion Detection Using Image Representation of Network Flows},
 volume = {12},
 year = {2024}
}

@article{10746482,
 abstract = {In the rapidly evolving field of network architecture, Software-Defined Networking (SDN) has emerged as a transformative approach, providing unprecedented flexibility and control over network resources. While SDN enhances efficiency and programmability, it also introduces various security vulnerabilities, primarily due to its architecture, which distinctly separates the control plane from the data plane. This division enables dynamic and adaptable network management but also exposes networks to sophisticated cyber threats, including Distributed Denial of Service (DDoS) attacks, SQL injections, and other forms of intrusion targeting the centralised SDN controllers and open interfaces of its switches. This paper explores the complex security landscape of SDN, identifying critical vulnerabilities within this modern networking model. By analysing prevalent network attacks such as DDoS, DoS, Probe, and SQL Injection, we underscore the pressing need for resilient intrusion detection systems (IDS) that are specifically designed to meet the unique security challenges of SDN environments. Our investigation highlights significant gaps in current research, particularly in the development of real-time traffic processing and system overload mitigation strategies, both of which are vital for establishing durable and resilient SDN architectures. This study contributes to the discourse on SDN security by proposing a strategic framework for developing sophisticated IDS solutions that can adapt to the evolving dynamics of network threats. Our findings emphasise the importance of continuous innovation and a focus on sustainable, secure infrastructure within Software-Defined Networking, supporting its role as a safe and efficient foundation for future network developments.},
 author = {Janabi, Ahmed H. and Kanakis, Triantafyllos and Johnson, Mark},
 doi = {10.1109/ACCESS.2024.3493384},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer security;Intrusion detection;Telecommunication traffic;Computer crime;Software defined networking;Denial-of-service attack;Surveys;Protocols;Network security;Network architecture;Machine learning;Software-defined networking (SDN);intrusion detection system (IDS);cybersecurity;deep learning (DL);dataset;machine learning (ML)},
 month = {},
 number = {},
 pages = {164097-164120},
 title = {Survey: Intrusion Detection System in Software-Defined Networking},
 volume = {12},
 year = {2024}
}

@article{10747334,
 abstract = {As the growth of IoT networks increases exponentially, the number of cyber attacks is also increasing on IoT networks day-by-day. This results in the vital requirement of cyber security mechanisms to secure IoT networks from cyberattacks. To build such a security mechanism, researchers and cybersecurity practitioners need relevant IoT datasets. However, until now, only a few publicly available IoT network intrusion datasets exist in the literature. Moreover, these datasets lack coverage of IoT network traffic containing IoT application layer protocols like AMQP, XMPP, STOMP, etc. and various IoT-based attacks. So, in this work, we generate a new realistic and comprehensive IoT network intrusion dataset called MU-IoT for IoT cybersecurity. The network traffic contained in the MU-IoT dataset is collected from the Manipur University (MU) IoT Smart Lab, which is our own IoT network testbed. The testbed includes more than 30 devices, which include both physical and emulated IoT devices, and general-purpose devices such as laptops, desktops, servers, etc., that are usually present in a Smart Lab. The dataset contains normal network traffic generated from various applications and attack network traffic comprised of 16 attack types, including IoT-based attacks, which are categorized into six categories. From the testbed, we collected 22.8 GB of raw network data and extracted 15.8 GB of preprocessed network data by using our own feature extraction approach. The preprocessed network data contains 121 flow-based features and 3 class labels of more than 34.8 million records. Additionally, this dataset covers extensive IoT-specific application protocols and a variety of normal network behaviours, which is a notable advantage over existing datasets. The MU-IoT dataset can be utilized to develop and validate machine learning-based Intrusion Detection and Mitigation Systems (IDMS). Moreover, the MU-IoT dataset helps to validate the centralized and federated learning-based IDMS. In addition, we also include the prior exploratory data analysis with the ranking of the features given by various feature selection algorithms as well as from our own feature ranking approach and the performance given by some common machine learning algorithms, as a future reference to the research community. The MU-IoT dataset is publicly available in the link https://manipuruniv.ac.in/CSDmuIOTdataset/.},
 author = {Clinton, Urikhimbam Boby and Hoque, Nazrul},
 doi = {10.1109/ACCESS.2024.3494052},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Telecommunication traffic;Feature extraction;Cyberattack;Network intrusion;Protocols;Performance evaluation;Costs;Industrial Internet of Things;Machine learning;Computer security;Internet of Things;IoT dataset;cybersecurity;network testbed;machine learning},
 month = {},
 number = {},
 pages = {166068-166092},
 title = {MU-IoT: A New IoT Intrusion Dataset for Network and Application Layer Attacks Analysis},
 volume = {12},
 year = {2024}
}

@article{10750193,
 abstract = {With the growing demand for delay-sensitive voice, video, and data-based applications, the challenge of efficient spectrum utilization is becoming more critical. To address the challenges of spectrum scarcity, the Federal Communications Commission (FCC) has authorized the sharing of the federally held Citizen Broadband Radio Service (CBRS) band, also known as the 3.5 GHz spectrum band, with commercial use. The 3.5 GHz spectrum band controlled by the spectrum access system (SAS) is shared with three types of users i.e., Incumbent users, Primary access licensee (PAL) users, and general authorized access (GAA) users as opportunistic users. In this paper we proposed the SAS-based channel allocation (SAS-CA) algorithm to optimize spectrum utilization and system performance, considering the potential risks of adding opportunistic GAA users. The proposed algorithm ensures low outage probability for PAL users and provides an optimized channel allocation strategy for GAA users when PAL users are inactive in PAL reserved channels. Additionally, a security module integrated with SAS enhances spectrum utilization and reduces interference levels. The algorithm’s efficiency is validated through multiple test sets, showing rapid convergence within 100 iterations. The integration of the security module results in a median spectrum utilization increase of 16 points and a notable reduction in interference levels, enhancing execution efficiency by approximately 37% compared to traditional methods. These findings demonstrate the substantial benefits of advanced allocation algorithms and robust security mechanisms in ensuring equitable access, stabilizing system performance, and optimizing spectrum utilization within the CBRS band.},
 author = {Abbass, Waseem and Ahmad Khan, Muzammil and Hussain Farooqi, Ashfaq and Nawaz, Waqas and Abbas, Nasim and Ali, Zulfiqar},
 doi = {10.1109/ACCESS.2024.3495972},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Gallium arsenide;Security;Interference;Resource management;Synthetic aperture sonar;FCC;Channel allocation;5G mobile communication;System performance;Nearest neighbor methods;Optimization methods;Security;CBRS;SAS;resource utilization;optimization},
 month = {},
 number = {},
 pages = {165992-166010},
 title = {Optimizing Spectrum Utilization and Security in SAS-Enabled CBRS Systems for Enhanced 5G Performance},
 volume = {12},
 year = {2024}
}

@article{8066291,
 abstract = {Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.},
 author = {Yin, Chuanlong and Zhu, Yuefei and Fei, Jinlong and He, Xinzheng},
 doi = {10.1109/ACCESS.2017.2762418},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Recurrent neural networks;Training;Computational modeling;Testing;Support vector machines;Recurrent neural networks;RNN-IDS;intrusion detection;deep learning;machine learning},
 month = {},
 number = {},
 pages = {21954-21961},
 title = {A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks},
 volume = {5},
 year = {2017}
}

@article{8171725,
 abstract = {Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading.},
 author = {Loukas, George and Vuong, Tuan and Heartfield, Ryan and Sakellari, Georgia and Yoon, Yongpil and Gan, Diane},
 doi = {10.1109/ACCESS.2017.2782159},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Robot sensing systems;Intrusion detection;Monitoring;Aircraft;Machine learning;Intrusion detection;machine learning;autonomous vehicles},
 month = {},
 number = {},
 pages = {3491-3508},
 title = {Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning},
 volume = {6},
 year = {2018}
}

@article{8171733,
 abstract = {The development of an anomaly-based intrusion detection system (IDS) is a primary research direction in the field of intrusion detection. An IDS learns normal and anomalous behavior by analyzing network traffic and can detect unknown and new attacks. However, the performance of an IDS is highly dependent on feature design, and designing a feature set that can accurately characterize network traffic is still an ongoing research issue. Anomaly-based IDSs also have the problem of a high false alarm rate (FAR), which seriously restricts their practical applications. In this paper, we propose a novel IDS called the hierarchical spatial-temporal features-based intrusion detection system (HAST-IDS), which first learns the low-level spatial features of network traffic using deep convolutional neural networks (CNNs) and then learns high-level temporal features using long short-term memory networks. The entire process of feature learning is completed by the deep neural networks automatically; no feature engineering techniques are required. The automatically learned traffic features effectively reduce the FAR. The standard DARPA1998 and ISCX2012 data sets are used to evaluate the performance of the proposed system. The experimental results show that the HAST-IDS outperforms other published approaches in terms of accuracy, detection rate, and FAR, which successfully demonstrates its effectiveness in both feature learning and FAR reduction.},
 author = {Wang, Wei and Sheng, Yiqiang and Wang, Jinlin and Zeng, Xuewen and Ye, Xiaozhou and Huang, Yongzhong and Zhu, Ming},
 doi = {10.1109/ACCESS.2017.2780250},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Telecommunication traffic;Feature extraction;Intrusion detection;Recurrent neural networks;Natural language processing;Network intrusion detection;deep neural networks;representation learning},
 month = {},
 number = {},
 pages = {1792-1806},
 title = {HAST-IDS: Learning Hierarchical Spatial-Temporal Features Using Deep Neural Networks to Improve Intrusion Detection},
 volume = {6},
 year = {2018}
}

@article{8240589,
 abstract = {Intrusion detection has been an important countermeasure to secure computing infrastructures from malicious attacks. To improve detection performance and reduce bias towards frequent attacks, this paper proposes a two-step hybrid method based on binary classification and k-NN technique. Step 1 employs several binary classifiers and one aggregation module to effectively detect the exact classes of network connections. After step 1, the connections whose classes are uncertain are sent to step 2 to further determine their classes by the k-NN algorithm. Step 2 is based on the outcomes of step 1 and yields a beneficial supplement to step 1. By combining the two steps, the proposed method achieves reliable results on the NSL-KDD data set. The effectiveness of the proposed method is evaluated in comparison with five supervised learning techniques. Experimental results demonstrate that the proposed method outperforms baselines with respect to various evaluation criteria. In particular, for U2R and R2L attacks, the F1-scores of the proposed method are much higher than those of baselines. Furthermore, comparisons with some recent hybrid approaches are also listed. The results illustrate that the proposed method is competitive.},
 author = {Li, Longjie and Yu, Yang and Bai, Shenshen and Hou, Ying and Chen, Xiaoyun},
 doi = {10.1109/ACCESS.2017.2787719},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Support vector machines;Feature extraction;Training;Principal component analysis;Genetic algorithms;Intrusion detection;hybrid method;binary classification;C4.5;k-nearest neighbors},
 month = {},
 number = {},
 pages = {12060-12073},
 title = {An Effective Two-Step Intrusion Detection Approach Based on Binary Classification and $k$ -NN},
 volume = {6},
 year = {2018}
}

@article{8283694,
 abstract = {The upcoming fifth-generation (5G) mobile technology, which includes advanced communication features, is posing new challenges on cybersecurity defense systems. Although innovative approaches have evolved in the last few years, 5G will make existing intrusion detection and defense procedures become obsolete, in case they are not adapted accordingly. In this sense, this paper proposes a novel 5G-oriented cyberdefense architecture to identify cyberthreats in 5G mobile networks efficient and quickly enough. For this, our architecture uses deep learning techniques to analyze network traffic by extracting features from network flows. Moreover, our proposal allows adapting, automatically, the configuration of the cyberdefense architecture in order to manage traffic fluctuation, aiming both to optimize the computing resources needed in each particular moment and to fine tune the behavior and the performance of analysis and detection processes. Experiments using a well-known botnet data set depict how a neural network model reaches a sufficient classification accuracy in our anomaly detection system. Extended experiments using diverse deep learning solutions analyze and determine their suitability and performance for different network traffic loads. The experimental results show how our architecture can self-adapt the anomaly detection system based on the volume of network flows gathered from 5G subscribers' user equipments in real-time and optimizing the resource consumption.},
 author = {Fernández Maimó, Lorenzo and Perales Gómez, Ángel Luis and García Clemente, Félix J. and Gil Pérez, Manuel and Martínez Pérez, Gregorio},
 doi = {10.1109/ACCESS.2018.2803446},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;5G mobile communication;Machine learning;Botnet;Computer architecture;Feature extraction;5G;anomaly detection;botnets;deep learning;performance evaluation},
 month = {},
 number = {},
 pages = {7700-7712},
 title = {A Self-Adaptive Deep Learning-Based System for Anomaly Detection in 5G Networks},
 volume = {6},
 year = {2018}
}

@article{8290925,
 abstract = {Machine learning is one of the most prevailing techniques in computer science, and it has been widely applied in image processing, natural language processing, pattern recognition, cybersecurity, and other fields. Regardless of successful applications of machine learning algorithms in many scenarios, e.g., facial recognition, malware detection, automatic driving, and intrusion detection, these algorithms and corresponding training data are vulnerable to a variety of security threats, inducing a significant performance decrease. Hence, it is vital to call for further attention regarding security threats and corresponding defensive techniques of machine learning, which motivates a comprehensive survey in this paper. Until now, researchers from academia and industry have found out many security threats against a variety of learning algorithms, including naive Bayes, logistic regression, decision tree, support vector machine (SVM), principle component analysis, clustering, and prevailing deep neural networks. Thus, we revisit existing security threats and give a systematic survey on them from two aspects, the training phase and the testing/inferring phase. After that, we categorize current defensive techniques of machine learning into four groups: security assessment mechanisms, countermeasures in the training phase, those in the testing or inferring phase, data security, and privacy. Finally, we provide five notable trends in the research on security threats and defensive techniques of machine learning, which are worth doing in-depth studies in future.},
 author = {Liu, Qiang and Li, Pan and Zhao, Wentao and Cai, Wei and Yu, Shui and Leung, Victor C. M.},
 doi = {10.1109/ACCESS.2018.2805680},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Training;Machine learning algorithms;Training data;Support vector machines;Testing;Taxonomy;Machine learning;adversarial samples;security threats;defensive techniques},
 month = {},
 number = {},
 pages = {12103-12117},
 title = {A Survey on Security Threats and Defensive Techniques of Machine Learning: A Data Driven View},
 volume = {6},
 year = {2018}
}

@article{8354788,
 abstract = {Many applications in the Internet use the reliable end-to-end Transmission Control Protocol (TCP) as a transport protocol due to practical considerations. There are many different TCP variants widely in use, and each variant uses a specific congestion control algorithm to avoid congestion, while also attempting to share the underlying network capacity equally among the competing users. This paper shows how an intermediate node (e.g., a network operator) can identify the transmission state of the TCP client associated with a TCP flow by passively monitoring the TCP traffic. Here, we present a robust, scalable and generic machine learning-based method which may be of interest for network operators that experimentally infers Congestion Window (cwnd) and the underlying variant of loss-based TCP algorithms within a flow from passive traffic measurements collected at an intermediate node. The method can also be extended to predict other TCP transmission states of the client. We believe that our study also has a potential benefit and opportunity for researchers and scientists in the networking community from both academia and industry who want to assess the characteristics of TCP transmission states related to network congestion. We validate the robustness and scalability approach of our prediction model through a large number of controlled experiments. It turns out, surprisingly enough, that the learned prediction model performs reasonably well by leveraging knowledge from the emulated network when it is applied on a real-life scenario setting. Thus, our prediction model is general bearing similarity to the concept of transfer learning in the machine learning community. The accuracy of our experimental results both in an emulated network, realistic and combined scenario settings and across multiple TCP congestion control variants demonstrate that our model is reasonably effective and has considerable potential.},
 author = {Hagos, Desta Haileselassie and Engelstad, Paal E. and Yazidi, Anis and Kure, Øivind},
 doi = {10.1109/ACCESS.2018.2833107},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Predictive models;Machine learning;Internet;Prediction algorithms;Robustness;Loss measurement;Network protocols;TCP;congestion control;passive measurement;machine learning;transfer learning;convolutional filtering;deep learning},
 month = {},
 number = {},
 pages = {28372-28387},
 title = {General TCP State Inference Model From Passive Measurements Using Machine Learning Techniques},
 volume = {6},
 year = {2018}
}

@article{8359287,
 abstract = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.},
 author = {Xin, Yang and Kong, Lingshuang and Liu, Zhi and Chen, Yuling and Li, Yanmiao and Zhu, Hongliang and Gao, Mingcheng and Hou, Haixia and Wang, Chunhua},
 doi = {10.1109/ACCESS.2018.2836950},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning;Intrusion detection;Feature extraction;Machine learning algorithms;Computer security;Cybersecurity;intrusion detection;deep learning;machine learning},
 month = {},
 number = {},
 pages = {35365-35381},
 title = {Machine Learning and Deep Learning Methods for Cybersecurity},
 volume = {6},
 year = {2018}
}

@article{8373695,
 abstract = {Despite the popularity of wireless sensor networks (WSNs) in a wide range of applications, security problems associated with them have not been completely resolved. Middleware is generally introduced as an intermediate layer between WSNs and the end user to resolve some limitations, but most of the existing middleware is unable to protect data from malicious and unknown attacks during transmission. This paper introduces a secure wireless sensor network middleware (SWSNM) based on an unsupervised learning technique called generative adversarial network algorithm. SWSNM consists of two networks: a generator (G) network and a discriminator (D) network. The G creates fake data that are similar to the real sample and combines it with real data from the sensors to confuse the attacker. The D contains multi-layers that have the ability to differentiate between real and fake data. The output intended for this algorithm shows an actual interpretation of the data that is securely communicated through the WSN. The framework is implemented in Python with experiments performed using Keras. Results illustrate that SWSNM algorithm improves the accuracy of the data and enhances its security by protecting data from adversaries. In addition, the SWSNM algorithm consumes significantly less energy, has higher throughput, and lower end-to-end delay when compared with a similar conventional approach.},
 author = {Alshinina, Remah A. and Elleithy, Khaled M.},
 doi = {10.1109/ACCESS.2018.2844255},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Middleware;Security;Sensors;Machine learning algorithms;Machine learning;Support vector machines;Middleware;unsupervised learning;WSNs;generator;discriminator;visualization;confusion matrix;security;GANs;energy consumption;delay},
 month = {},
 number = {},
 pages = {29885-29898},
 title = {A Highly Accurate Deep Learning Based Approach for Developing Wireless Sensor Network Middleware},
 volume = {6},
 year = {2018}
}

@article{8386760,
 abstract = {Anomaly detection has a wide range of applications in security area such as network monitoring and smart city/campus construction. It has become an active research issue of great concern in recent years. However, most algorithms of the existing studies are powerless for large-scale and high-dimensional data, and the intermediate data extracted by some methods that can handle high-dimensional data will consume lots of storage space. In this paper, we propose a novel sparse representation framework that learns dictionaries based on the latent space of variational auto-encoder. For large-scale data sets, it can play the role of dimensionality reduction to obtain hidden information, and extract more high-level features than hand-crafted features. At the same time, for the storage of normal information, the space cost can be greatly reduced. To verify the versatility and performance of the proposed learning algorithm, we have experimented on different types of anomaly detection tasks, including KDD-CUP data set for network intrusion detection, Mnist data set for image anomaly detection, and UCSD pedestrian's data set for abnormal event detection in surveillance videos. The experimental results demonstrate that the proposed algorithm outperforms competing algorithms in all kinds of anomaly detection tasks.},
 author = {Sun, Jiayu and Wang, Xinzhou and Xiong, Naixue and Shao, Jie},
 doi = {10.1109/ACCESS.2018.2848210},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Feature extraction;Machine learning;Dictionaries;Data models;Monitoring;Anomaly detection;campus surveillance video;dictionary learning},
 month = {},
 number = {},
 pages = {33353-33361},
 title = {Learning Sparse Representation With Variational Auto-Encoder for Anomaly Detection},
 volume = {6},
 year = {2018}
}

@article{8387883,
 abstract = {Phishing is one of the most harmful social engineering techniques to subdue end users where threat actors find a chance to gain access to critical information systems. A common approach in phishing is through the use of e-mail communication with an embedded hyperlink. The detection and mitigation of phishing attacks are a grand challenge due to the complexity of current phishing attacks. Existing techniques are often too time consuming to be used in the real world in terms of detection and mitigation time. Likewise, they employ static detection rules that are not effective in the real world due to the dynamics of phishing attacks. In this paper, we present PhishLimiter, a new detection and mitigation approach, where we first propose a new technique for deep packet inspection (DPI) and then leverage it with software-defined networking (SDN) to identify phishing activities through e-mail and web-based communication. The proposed DPI approach consists of two components: phishing signature classification and real-time DPI. Based on the programmability of SDN, we develop the store and forward mode and the forward and inspect mode to the direct network traffic by using an artificial neural network model to classify phishing attack signatures and design the real-time DPI so that PhishLimiter can flexibly address the dynamics of phishing attacks in the real world. PhishLimiter also provides better network traffic management for containing phishing attacks since it has the global view of a network through SDN. Furthermore, we evaluate PhishLimiter using a real-world testbed environment and data sets consisting of real-world email with embedded links. Our extensive experimental study shows that PhishLimiter provides an effective and efficient solution to deter malicious activities.},
 author = {Chin, Tommy and Xiong, Kaiqi and Hu, Chengbin},
 doi = {10.1109/ACCESS.2018.2837889},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Phishing;Electronic mail;Inspection;Organizations;IP networks;Neural networks;Artificial neural network (ANN);phishing;software-defined networking (SDN);security},
 month = {},
 number = {},
 pages = {42516-42531},
 title = {Phishlimiter: A Phishing Detection and Mitigation Approach Using Software-Defined Networking},
 volume = {6},
 year = {2018}
}

@article{8408779,
 abstract = {Deep neural networks have demonstrated their effectiveness in most machine learning tasks, with intrusion detection included. Unfortunately, recent research found that deep neural networks are vulnerable to adversarial examples in the image classification domain, i.e., they leave some opportunities for an attacker to fool the networks into misclassification by introducing imperceptible changes to the original pixels in an image. The vulnerability raises some concerns in applying deep neural networks in security-critical areas, such as intrusion detection. In this paper, we investigate the performances of the state-of-the-art attack algorithms against deep learning-based intrusion detection on the NSL-KDD data set. The vulnerabilities of neural networks employed by the intrusion detection systems are experimentally validated. The roles of individual features in generating adversarial examples are explored. Based on our findings, the feasibility and applicability of the attack methodologies are discussed.},
 author = {Wang, Zheng},
 doi = {10.1109/ACCESS.2018.2854599},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning;Neural networks;Intrusion detection;Feature extraction;Perturbation methods;Measurement;Task analysis;Intrusion detection;neural networks;classification algorithms;data security},
 month = {},
 number = {},
 pages = {38367-38384},
 title = {Deep Learning-Based Intrusion Detection With Adversaries},
 volume = {6},
 year = {2018}
}

@article{8409455,
 abstract = {Diabetic patients use therapy from the insulin pump, a type of implantable medical device, for the infusion of insulin to control blood glucose level. While these devices offer many clinical benefits, there has been a recent increase in the number of cases, wherein, the wireless communication channel of such devices has been compromised. This not only causes the device to malfunction but also potentially threatens the patient's life. In this paper, a neural networks-based multi-layer perceptron model was designed for real-time medical device security. Machine learning algorithms are among the most effective and broadly utilized systems for classification, identification, and segmentation. Although they are effective, they are both computationally and memory intensive, making them hard to be deployed on low-power embedded frameworks. In this paper, we present an on-chip neural system network for securing diabetic treatment. The model achieved 98.1% accuracy in classifying fake versus genuine glucose measurements. The proposed model was comparatively evaluated with a linear support vector machine which achieved only 90.17% accuracy with negligible precision and recall. Moreover, the proposal estimates the reliability of the framework through the use of the Bayesian network. The proposed approach enhances the reliability of the overall framework by 18% when only one device is secured, and over 90% when all devices are secured.},
 author = {Rathore, Heena and Wenzel, Lothar and Al-Ali, Abdulla Khalid and Mohamed, Amr and Du, Xiaojiang and Guizani, Mohsen},
 doi = {10.1109/ACCESS.2018.2854822},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Sugar;Insulin pumps;Security;Wireless communication;Blood;Communication system security;Field programmable gate arrays;Security;machine learning;insulin pumps;deep learning;implantable medical devices},
 month = {},
 number = {},
 pages = {44718-44730},
 title = {Multi-Layer Perceptron Model on Chip for Secure Diabetic Treatment},
 volume = {6},
 year = {2018}
}

@article{8418451,
 abstract = {Classification features are crucial for an intrusion detection system (IDS), and the detection performance of IDS will change dramatically when providing different input features. Moreover, the large number of network traffic and their high-dimensional features will result in a very lengthy classification process. Recently, there is an increasing interest in the application of deep learning approaches for classification and learn feature representations. So, in this paper, we propose using the stacked sparse autoencoder (SSAE), an instance of a deep learning strategy, to extract high-level feature representations of intrusive behavior information. The original classification features are introduced into SSAE to learn the deep sparse features automatically for the first time. Then, the low-dimensional sparse features are used to build different basic classifiers. We compare SSAE with other feature extraction methods proposed by previous researchers. The experimental results both in binary classification and multiclass classification indicate the following: 1) the high-dimensional sparse features learned by SSAE are more discriminative for intrusion behaviors compared to previous methods and 2) the classification process of basic classifiers is significantly accelerated by using high-dimensional sparse features. In summary, it is shown that the SSAE is a feasible and efficient feature extraction method and provides a new research method for intrusion detection.},
 author = {Yan, Binghao and Han, Guodong},
 doi = {10.1109/ACCESS.2018.2858277},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Machine learning;Machine learning algorithms;Anomaly detection;Intrusion detection;deep learning;machine learning;SSAE;feature extraction},
 month = {},
 number = {},
 pages = {41238-41248},
 title = {Effective Feature Extraction via Stacked Sparse Autoencoder to Improve Intrusion Detection System},
 volume = {6},
 year = {2018}
}

@article{8438865,
 abstract = {Due to the monumental growth of Internet applications in the last decade, the need for security of information network has increased manifolds. As a primary defense of network infrastructure, an intrusion detection system is expected to adapt to dynamically changing threat landscape. Many supervised and unsupervised techniques have been devised by researchers from the discipline of machine learning and data mining to achieve reliable detection of anomalies. Deep learning is an area of machine learning which applies neuron-like structure for learning tasks. Deep learning has profoundly changed the way we approach learning tasks by delivering monumental progress in different disciplines like speech processing, computer vision, and natural language processing to name a few. It is only relevant that this new technology must be investigated for information security applications. The aim of this paper is to investigate the suitability of deep learning approaches for anomaly-based intrusion detection system. For this research, we developed anomaly detection models based on different deep neural network structures, including convolutional neural networks, autoencoders, and recurrent neural networks. These deep models were trained on NSLKDD training data set and evaluated on both test data sets provided by NSLKDD, namely NSLKDDTest+ and NSLKDDTest21. All experiments in this paper are performed by authors on a GPU-based test bed. Conventional machine learning-based intrusion detection models were implemented using well-known classification techniques, including extreme learning machine, nearest neighbor, decision-tree, random-forest, support vector machine, naive-bays, and quadratic discriminant analysis. Both deep and conventional machine learning models were evaluated using well-known classification metrics, including receiver operating characteristics, area under curve, precision-recall curve, mean average precision and accuracy of classification. Experimental results of deep IDS models showed promising results for real-world application in anomaly detection systems.},
 author = {Naseer, Sheraz and Saleem, Yasir and Khalid, Shehzad and Bashir, Muhammad Khawar and Han, Jihun and Iqbal, Muhammad Munwar and Han, Kijun},
 doi = {10.1109/ACCESS.2018.2863036},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Machine learning;Training;Intrusion detection;Measurement;Neural networks;Deep learning;convolutional neural networks;autoencoders;LSTM;k_NN;decision_tree;intrusion detection;convnets;information security},
 month = {},
 number = {},
 pages = {48231-48246},
 title = {Enhanced Network Anomaly Detection Based on Deep Neural Networks},
 volume = {6},
 year = {2018}
}

@article{8439941,
 abstract = {Deep neural networks (DNNs) are widely used for image recognition, speech recognition, pattern analysis, and intrusion detection. Recently, the adversarial example attack, in which the input data are only slightly modified, although not an issue for human interpretation, is a serious threat to a DNN as an attack as it causes the machine to misinterpret the data. The adversarial example attack has been receiving considerable attention owing to its potential threat to machine learning. It is divided into two categories: targeted adversarial example and untargeted adversarial example. The untargeted adversarial example happens when machines misclassify an object into an incorrect class. In contrast, the targeted adversarial example attack causes machines to misinterpret the image as the attacker’s desired class. Thus, the latter is a more elaborate and powerful attack than the former. The existing targeted adversarial example is a single targeted attack that allows only one class to be recognized. However, in some cases, a multi-targeted adversarial example can be useful for an attacker to make multiple models recognize a single original image as different classes. For example, an attacker can use a single road sign generated by a multi-targeted adversarial example scheme to make model A recognize it as a stop sign and model B recognize it as a left turn, whereas a human might recognize it as a right turn. Therefore, in this paper, we propose a multi-targeted adversarial example that attacks multiple models within each target class with a single modified image. To produce such examples, we carried out a transformation to maximize the probability of different target classes by multiple models. We used the MNIST datasets and TensorFlow library for our experiment. The experimental results showed that the proposed scheme for generating a multi-targeted adversarial example achieved a 100% attack success rate.},
 author = {Kwon, Hyun and Kim, Yongchul and Park, Ki-Woong and Yoon, Hyunsoo and Choi, Daeseon},
 doi = {10.1109/ACCESS.2018.2866197},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Target recognition;Distortion;Machine learning;Training;Neural networks;Image recognition;Perturbation methods;Deep neural network (DNN);evasion attack;adversarial example;machine learning},
 month = {},
 number = {},
 pages = {46084-46096},
 title = {Multi-Targeted Adversarial Example in Evasion Attack on Deep Neural Network},
 volume = {6},
 year = {2018}
}

@article{8449272,
 abstract = {To improve the performance of network intrusion detection systems (IDS), we applied deep learning theory to intrusion detection and developed a deep network model with automatic feature extraction. In this paper, we consider the characteristics of the time-related intrusion and propose a novel IDS that consists of a recurrent neural network with gated recurrent units (GRU), multilayer perceptron (MLP), and softmax module. Experiments on the well-known KDD 99 and NSL-KDD data sets show that the system has leading performance. The overall detection rate was 99.42% using KDD 99 and 99.31% using NSL-KDD with false positive rates as low as 0.05% and 0.84%, respectively. In particular, for detecting the denial of service attacks, the system achieved detection rates of 99.98% and 99.55%, respectively. Comparative experiments showed that the GRU is more suitable as a memory unit for IDS than LSTM, and proved that it is an effective simplification and improvement of LSTM. Moreover, the bidirectional GRU can reach the best performance compared with the recently published methods.},
 author = {Xu, Congyuan and Shen, Jizhong and Du, Xin and Zhang, Fan},
 doi = {10.1109/ACCESS.2018.2867564},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Machine learning;Support vector machines;Recurrent neural networks;Logic gates;Intrusion detection;deep learning;recurrent neural network;gated recurrent unit},
 month = {},
 number = {},
 pages = {48697-48707},
 title = {An Intrusion Detection System Using a Deep Neural Network With Gated Recurrent Units},
 volume = {6},
 year = {2018}
}

@article{8456507,
 abstract = {More and more network traffic data have brought great challenge to traditional intrusion detection system. The detection performance is tightly related to selected features and classifiers, but traditional feature selection algorithms and classification algorithms can't perform well in massive data environment. Also the raw traffic data are imbalanced, which has a serious impact on the classification results. In this paper, we propose a novel network intrusion detection model utilizing convolutional neural networks (CNNs). We use CNN to select traffic features from raw data set automatically, and we set the cost function weight coefficient of each class based on its numbers to solve the imbalanced data set problem. The model not only reduces the false alarm rate (FAR) but also improves the accuracy of the class with small numbers. To reduce the calculation cost further, we convert the raw traffic vector format into image format. We use the standard NSL-KDD data set to evaluate the performance of the proposed CNN model. The experimental results show that the accuracy, FAR, and calculation cost of the proposed model perform better than traditional standard algorithms. It is an effective and reliable solution for the intrusion detection of a massive network.},
 author = {Wu, Kehe and Chen, Zuge and Li, Wei},
 doi = {10.1109/ACCESS.2018.2868993},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Training;Data models;Data preprocessing;Convolutional neural networks;Network intrusion detection;convolutional neural networks;image data format conversion;cost function weight;imbalanced dataset},
 month = {},
 number = {},
 pages = {50850-50859},
 title = {A Novel Intrusion Detection Model for a Massive Network Using Convolutional Neural Networks},
 volume = {6},
 year = {2018}
}

@article{8463474,
 abstract = {Network intrusion detection systems (NIDSs) provide a better solution to network security than other traditional network defense technologies, such as firewall systems. The success of NIDS is highly dependent on the performance of the algorithms and improvement methods used to increase the classification accuracy and decrease the training and testing times of the algorithms. We propose an effective deep learning approach, self-taught learning (STL)-IDS, based on the STL framework. The proposed approach is used for feature learning and dimensionality reduction. It reduces training and testing time considerably and effectively improves the prediction accuracy of support vector machines (SVM) with regard to attacks. The proposed model is built using the sparse autoencoder mechanism, which is an effective learning algorithm for reconstructing a new feature representation in an unsupervised manner. After the pre-training stage, the new features are fed into the SVM algorithm to improve its detection capability for intrusion and classification accuracy. Moreover, the efficiency of the approach in binary and multiclass classification is studied and compared with that of shallow classification methods, such as J48, naive Bayesian, random forest, and SVM. Results show that our approach has accelerated SVM training and testing times and performed better than most of the previous approaches in terms of performance metrics in binary and multiclass classification. The proposed STL-IDS approach improves network intrusion detection and provides a new research method for intrusion detection.},
 author = {Al-Qatf, Majjed and Lasheng, Yu and Al-Habib, Mohammed and Al-Sabahi, Kamal},
 doi = {10.1109/ACCESS.2018.2869577},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Support vector machines;Machine learning;Intrusion detection;Feature extraction;Training;Computational modeling;Classification algorithms;Network security;network intrusion detection system;deep learning;sparse autoencoder;SVM;self-taught learning;NSL-KDD},
 month = {},
 number = {},
 pages = {52843-52856},
 title = {Deep Learning Approach Combining Sparse Autoencoder With SVM for Network Intrusion Detection},
 volume = {6},
 year = {2018}
}

@article{8464069,
 abstract = {Cyber physical systems (CPSs) are rapidly developing, with increasing scale, complexity, and heterogeneity. However, testing CPSs systematically to ensure that they operate with high reliability remains a big challenge. Therefore, it is necessary to summarize existing works and technologies systematically, with the aim of inspiring new inventions for more efficient CPS testing. Accordingly, this paper first investigated the advances in CPS testing methods from ten aspects, including different testing paradigms, technologies, and some non-functional testing methods (including security testing, robust testing, and fragility testing). Then, we further elaborate on the infrastructures of CPS testbeds from the perspectives of their architecture and the corresponding function analyses. Finally, challenges and future research directions are identified and discussed. It can be concluded that future CPS testing should focus more on the combination of different paradigms and technologies for multi-objective by integrating more emerging cutting-edge technologies such as Internet of things, big data, cloud computing, and AI.},
 author = {Zhou, Xin and Gou, Xiaodong and Huang, Tingting and Yang, Shunkun},
 doi = {10.1109/ACCESS.2018.2869834},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Testing;Unified modeling language;Security;Mathematical model;Data models;Monitoring;Analytical models;Cyber-physical system;non-functional testing;robust testing;security testing;testing method;testbed},
 month = {},
 number = {},
 pages = {52179-52194},
 title = {Review on Testing of Cyber Physical Systems: Methods and Testbeds},
 volume = {6},
 year = {2018}
}

@article{8486946,
 abstract = {The emergence of Internet connectivity has led to a significant increase in the volume and complexity of cyber attacks. Abnormal behavior detection systems are valuable tools for ensuring the security in computer networks. However, due to the huge amount and ever increasing diversity of the intrusions, the existing intrusion detection systems, which use machine learning techniques to learn a classifier based on a handcrafted feature vector, are not robust enough to detect sophisticated attacks which cause a high false alarm rate. Therefore, building a flexible in-depth defense system to detect abnormal behavior requires an ability to automatically learn powerful features and analyze large amounts of network traffic. To address these concerns, this paper proposes a novel distributed approach for the detection of abnormal behavior in largescale networks. The developed model discovers the abnormal behavior from large-scale network traffic data using a combination of a deep feature extraction and multi-layer ensemble support vector machines (SVMs) in a distributed way. First, we perform a non-linear dimensionality reduction, achieved through a distributed deep belief networks on large-scale network traffic data. Then, the obtained features are fed to the multi-layer ensemble SVM. The construction of the ensemble is accomplished through the iterative reduce paradigm based on Spark. Empirical results show a promising gain in performance compared with other existing models.},
 author = {Marir, Naila and Wang, Huiqiang and Feng, Guangsheng and Li, Bingyang and Jia, Meijuan},
 doi = {10.1109/ACCESS.2018.2875045},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Support vector machines;Feature extraction;Intrusion detection;Big Data;Distributed databases;Dimensionality reduction;Abnormal behavior detection;big data;deep belief networks;deep learning;ensemble classifier},
 month = {},
 number = {},
 pages = {59657-59671},
 title = {Distributed Abnormal Behavior Detection Approach Based on Deep Belief Network and Ensemble SVM Using Spark},
 volume = {6},
 year = {2018}
}

@article{8548545,
 abstract = {Computers and other smart gadgets have become of a paramount importance in today’s transactions. Connected to the Internet, those devices offer the possibility to benefit from a myriad of electronic services, including social networking, banking, trade marketing, education and so on. Such activities are producing huge volume of information transiting with high velocity each day. Parallel to that, we have witnessed an epidemic increase in the number and the sophistication of cyberattacks, as they became more persistent and highly structured. In this context, modern intrusion detection systems are to be modeled so as to issue high detection rates in a tiny period of time in order to mitigate the risks. This paper is built on recurrent neural network with multilayered echo-state machine (ML-ESM) to model an intrusion detection. We assess our model on three publicly available data sets, namely, the DARPA KDD’99, NSL-KDD a reformed version of the latter, and UNSW NB 15. Performance metrics for both binary classification and multilabel classification are calculated and compared with those of some existing machine learning techniques and the recent state-of-the-art intrusion detection systems. Results indicate that the ML-ESM wins the challenge in both achieving a higher accuracy and considerably optimizing the processing time.},
 author = {Ait Tchakoucht, Taha and Ezziyyani, Mostafa},
 doi = {10.1109/ACCESS.2018.2867345},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Training;Reservoirs;Support vector machines;Feature extraction;Computational modeling;Recurrent neural networks;Intrusion detection;recurrent neural networks;multilayered echo-state machine},
 month = {},
 number = {},
 pages = {72458-72468},
 title = {Multilayered Echo-State Machine: A Novel Architecture for Efficient Intrusion Detection},
 volume = {6},
 year = {2018}
}

@article{8574884,
 abstract = {The smart campus is becoming a reality with the advancement of information and communication technologies. For energy efficiency, it is essential to detect abnormal energy consumption in a smart campus, which is important for a “smart” campus. However, the obtained data are usually continuously generated by ubiquitous sensing devices, and the abnormal patterns hidden in the data are usually unknown, which makes detecting anomalies in such a context more challenging. Moreover, evaluating the quality of anomaly detection algorithms is difficult without labeled datasets. If the data are annotated well, classical criteria such as the receiver operating characteristic or precision recall curves can be used to compare the performance of different anomaly detection algorithms. In a smart campus environment, it is difficult to acquire labeled data to train a model due to the limited capabilities of the sensing devices. Therefore, distributed intelligence is preferred. In this paper, we present a multi-agent-based unsupervised anomaly detection method. We tackle these challenges in two stages with this method. First, we label the data using ensemble models. Second, we propose a method based on deep learning techniques to detect anomalies in an unsupervised fashion. The result of the first stage is used to evaluate the performance of the proposed method. We validate the proposed method with several datasets, and the experimental results demonstrate the effectiveness of our method.},
 author = {Weng, Yu and Zhang, Ning and Xia, Chunlei},
 doi = {10.1109/ACCESS.2018.2886583},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Data models;Energy consumption;Sensors;Gaussian distribution;Neural networks;Anomaly detection and evaluation;energy consumption;multi-agent;smart campus},
 month = {},
 number = {},
 pages = {2169-2178},
 title = {Multi-Agent-Based Unsupervised Detection of Energy Consumption Anomalies on Smart Campus},
 volume = {7},
 year = {2019}
}

@article{8581420,
 abstract = {Energy is a vital resource in wireless computing systems. Despite the increasing popularity of wireless local area networks (WLANs), one of the most important outstanding issues remains the power consumption caused by wireless network interface controller. To save this energy and reduce the overall power consumption of wireless devices, most approaches proposed to-date are focused on static and adaptive power saving modes. Existing literature has highlighted several issues and limitations in regards to their power consumption and performance degradation, warranting the need for further enhancements. In this paper, we propose a novel context-aware network traffic classification approach based on machine learning (ML) classifiers for optimizing WLAN power saving. The levels of traffic interaction in the background are contextually exploited for application of ML classifiers. Finally, the classified output traffic is used to optimize our proposed context-aware listen interval power saving modes. A real-world dataset is recorded, based on nine smartphone applications’ network traffic, reflecting different types of network behavior and interaction. This is used to evaluate the performance of eight ML classifiers in this initial study. The comparative results show that more than 99% of accuracy can be achieved. This paper indicates that ML classifiers are suited for classifying smartphone applications’ network traffic based on the levels of interaction in the background.},
 author = {Saeed, Ahmed and Kolberg, Mario},
 doi = {10.1109/ACCESS.2018.2888813},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless communication;Wireless sensor networks;Telecommunication traffic;Machine learning;Power demand;Wireless LAN;MIMO communication;802.11;energy consumption;machine learning (ML);power save mode (PSM);traffic classification;WLAN},
 month = {},
 number = {},
 pages = {3122-3135},
 title = {Towards Optimizing WLANs Power Saving: Novel Context-Aware Network Traffic Classification Based on a Machine Learning Approach},
 volume = {7},
 year = {2019}
}

@article{8606923,
 abstract = {The Internet of Things (IoT) is a ubiquitous system connecting many different devices - the things - which can be accessed from the distance. The cyber-physical systems (CPSs) monitor and control the things from the distance. As a result, the concepts of dependability and security get deeply intertwined. The increasing level of dynamicity, heterogeneity, and complexity adds to the system's vulnerability, and challenges its ability to react to faults. This paper summarizes the state of the art of existing work on anomaly detection, fault-tolerance, and self-healing, and adds a number of other methods applicable to achieve resilience in an IoT. We particularly focus on non-intrusive methods ensuring data integrity in the network. Furthermore, this paper presents the main challenges in building a resilient IoT for the CPS, which is crucial in the era of smart CPS with enhanced connectivity (an excellent example of such a system is connected autonomous vehicles). It further summarizes our solutions, work-in-progress and future work to this topic to enable “Trustworthy IoT for CPS”. Finally, this framework is illustrated on a selected use case: a smart sensor infrastructure in the transport domain.},
 author = {Ratasich, Denise and Khalid, Faiq and Geissler, Florian and Grosu, Radu and Shafique, Muhammad and Bartocci, Ezio},
 doi = {10.1109/ACCESS.2019.2891969},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Resilience;Security;Internet of Things;Cyber-physical systems;Robustness;Safety;Monitoring;Anomaly detection;cyber-physical systems (CPS);Internet of Things (IoT);monitoring;resilience;long-term dependability and security;self-adaptation;self-healing},
 month = {},
 number = {},
 pages = {13260-13283},
 title = {A Roadmap Toward the Resilient Internet of Things for Cyber-Physical Systems},
 volume = {7},
 year = {2019}
}

@article{8620986,
 abstract = {The intrusion detection systems (IDSs) are essential elements when it comes to the protection of an ICT infrastructure. A misuse IDS is a stable method that can achieve high attack detection rates (ADR) while keeping false alarm rates under acceptable levels. However, the misuse IDSs suffer from the lack of agility, as they are unqualified to adapt to new and “unknown” environments. That is, such an IDS puts the security administrator into an intensive engineering task for keeping the IDS up-to-date every time it faces efficiency drops. Considering the extended size of modern networks and the complexity of big network traffic data, the problem exceeds the substantial limits of human managing capabilities. In this regard, we propose a novel methodology which combines the benefits of self-taught learning and MAPE-K frameworks to deliver a scalable, self-adaptive, and autonomous misuse IDS. Our methodology enables the misuse IDS to sustain high ADR, even if it is imposed on consecutive and drastic environmental changes. Through the utilization of deep-learning based methods, the IDS is able to grasp an attack's nature based on the generalized feature reconstructions stemming directly from the unknown environment and its unlabeled data. The experimental results reveal that our methodology can breathe new life into the IDS without the constant need for manually refreshing its training set. We evaluate our proposal under several classification metrics and demonstrate that the ADR of the IDS increases up to 73.37% in critical situations where a statically trained IDS is rendered totally ineffective.},
 author = {Papamartzivanos, Dimitrios and Gómez Mármol, Félix and Kambourakis, Georgios},
 doi = {10.1109/ACCESS.2019.2893871},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Task analysis;Deep learning;Training;Engines;Adaptive systems;Adaptive intrusion detection systems;artificial neural networks;deep learning;information systems security;MAPE-K;sparse auto encoders},
 month = {},
 number = {},
 pages = {13546-13560},
 title = {Introducing Deep Learning Self-Adaptive Misuse Network Intrusion Detection Systems},
 volume = {7},
 year = {2019}
}

@article{8643036,
 abstract = {The network intrusion detection system is an important tool for protecting computer networks against threats and malicious attacks. Many techniques have recently been proposed; however, these face significant challenges due to the continuous emergence of new threats that are not recognized by existing systems. In this paper, we propose a novel two-stage deep learning (TSDL) model, based on a stacked auto-encoder with a soft-max classifier, for efficient network intrusion detection. The model comprises two decision stages: an initial stage responsible for classifying network traffic as normal or abnormal, using a probability score value. This is then used in the final decision stage as an additional feature, for detecting the normal state and other classes of attacks. The proposed model is able to learn useful feature representations from large amounts of unlabeled data and classifies them automatically and efficiently. To evaluate its effectiveness, several experiments are conducted on two public datasets, specifically the benchmark KDD99 and UNSW-NB15 datasets. Comparative simulation results demonstrate that our proposed model significantly outperforms existing approaches, achieving high recognition rates, up to 99.996% and 89.134%, for the KDD99 and UNSW-NB15 datasets respectively. We conclude that our model has the potential to serve as a future benchmark for the deep learning and network security research communities.},
 author = {Khan, Farrukh Aslam and Gumaei, Abdu and Derhab, Abdelouahid and Hussain, Amir},
 doi = {10.1109/ACCESS.2019.2899721},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Feature extraction;Computational modeling;Benchmark testing;Neural networks;Tools;Computational intelligence;two-stage deep learning model;feature representation;network intrusion detection;stacked auto-encoder},
 month = {},
 number = {},
 pages = {30373-30385},
 title = {A Novel Two-Stage Deep Learning Model for Efficient Network Intrusion Detection},
 volume = {7},
 year = {2019}
}

@article{8662673,
 abstract = {With the advent of the Internet of Things (IoT), the security of the network layer in the IoT is getting more and more attention. The traditional intrusion detection technologies cannot be well adapted in the complex Internet environment of IoT. For the deep learning algorithm of intrusion detection, a neural network structure may have fine detection accuracy for one kind of attack, but it may not have a good detection effect when facing other attacks. Therefore, it is urgent to design a self-adaptive model to change the network structure for different attack types. This paper presents an intrusion detection model based on improved genetic algorithm (GA) and deep belief network (DBN). Facing different types of attacks, through multiple iterations of the GA, the optimal number of hidden layers and number of neurons in each layer are generated adaptively, so that the intrusion detection model based on the DBN achieves a high detection rate with a compact structure. Finally, the NSL-KDD dataset was used to simulate and evaluate the model and algorithms. The experimental results show that the improved intrusion detection model combined with DBN can effectively improve the recognition rate of intrusion attacks and reduce the complexity of the neural network structure.},
 author = {Zhang, Ying and Li, Peisong and Wang, Xinheng},
 doi = {10.1109/ACCESS.2019.2903723},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Neurons;Genetic algorithms;Neural networks;Internet of Things;Deep learning;Internet of Things security;intrusion detection;deep belief network;genetic algorithm},
 month = {},
 number = {},
 pages = {31711-31722},
 title = {Intrusion Detection for IoT Based on Improved Genetic Algorithm and Deep Belief Network},
 volume = {7},
 year = {2019}
}

@article{8668403,
 abstract = {In recent years, the increased use of wireless networks for the transmission of large volumes of information has generated a myriad of security threats and privacy concerns; consequently, there has been the development of a number of preventive and protective measures including intrusion detection systems (IDS). Intrusion detection mechanisms play a pivotal role in securing computer and network systems; however, for various IDS, the performance remains a major issue. Moreover, the accuracy of existing methodologies for IDS using machine learning is heavily affected when the feature space grows. In this paper, we propose a IDS based on deep learning using feed forward deep neural networks (FFDNNs) coupled with a filter-based feature selection algorithm. The FFDNN-IDS is evaluated using the well-known NSL-knowledge discovery and data mining (NSL-KDD) dataset and it is compared to the following existing machine learning methods: support vectors machines, decision tree, K-Nearest Neighbor, and Naïve Bayes. The experimental results prove that the FFDNN-IDS achieves an increase in accuracy in comparison to other methods.},
 author = {Kasongo, Sydney Mambwe and Sun, Yanxia},
 doi = {10.1109/ACCESS.2019.2905633},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Support vector machines;Deep learning;Wireless networks;Communication system security;Deep learning;feature extraction;intrusion detection;machine learning;wireless networks},
 month = {},
 number = {},
 pages = {38597-38607},
 title = {A Deep Learning Method With Filter Based Feature Engineering for Wireless Intrusion Detection System},
 volume = {7},
 year = {2019}
}

@article{8671689,
 abstract = {Wireless communication has changed and improved people's lives and society, especially with the arrival of the Internet of Things (IoT) era. Despite the maturity of wireless communication, the security issue of communication remains the most stubborn and troublesome problem due to the increasingly complex and large amounts of data. An intrusion detection system is the guarantee of secure communication. However, variable protocols and drastic growth in data volume make intrusion detection a difficult task. In this paper, we proposed a framework of anomaly-based network intrusion detection system to finish the detection job. First, UNSW-NB15 is selected as the research object. Based on this new dataset, we built a detection model combining a deep learning method and a shallow learning approach. The former one is a deep auto-encoder used for feature learning, which can discover important representations of data and accelerate detection. The latter one is a powerful support vector machine (SVM), where the artificial bee colony (ABC) algorithm is used to find optimal parameters for SVM with five-fold cross validation (5FCV). Various experiments are conducted and the simulation results prove that the proposed method performs quite better than some of state-of-the-art intrusion detection approaches, including the method based on the principal component analysis (PCA) and some other machine learning strategies.},
 author = {Tian, Qiao and Li, Jingmei and Liu, Haibo},
 doi = {10.1109/ACCESS.2019.2905754},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Support vector machines;Intrusion detection;Wireless communication;Kernel;Internet of Things;Data mining;Wireless communication;big data;intrusion detection system;deep auto-encoder},
 month = {},
 number = {},
 pages = {38688-38695},
 title = {A Method for Guaranteeing Wireless Communication Based on a Combination of Deep and Shallow Learning},
 volume = {7},
 year = {2019}
}

@article{8672138,
 abstract = {Network intrusion detection plays a very important role in protecting computer network security. The abnormal traffic detection and analysis by extracting the statistical features of flow is the main analysis method in the field of network intrusion detection. However, these features need to be designed and extracted manually, which often loses the original information of the flow and leads to poor detection efficiency. In this paper, we do not manually design the features of the flow but directly extract the raw data information of the flow for analysis. In addition, we first proposed a new network intrusion detection model named the deep hierarchical network, which integrates the improved LeNet-5 and LSTM neural network structures, while learning the spatial and temporal features of flow. By designing a reasonable network cascading method, we can train our proposed hierarchical network at the same time instead of training two networks separately. In this paper, we use the CICIDS2017 dataset and the CTU dataset. The number and types of flow in these two datasets are large, and the attack types are relatively new. The experimental results show that the performance of the proposed hierarchical network model is significantly better than other network intrusion detection models, which can achieve the best detection accuracy. Finally, we also present an analysis method for traffic features which has an important contribution to abnormal traffic detection and gives the actual meanings of these important features.},
 author = {Zhang, Yong and Chen, Xu and Jin, Lei and Wang, Xiaojuan and Guo, Da},
 doi = {10.1109/ACCESS.2019.2905041},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Data mining;Intrusion detection;Data models;Machine learning algorithms;Neural networks;Inspection;Network intrusion detection;deep hierarchical network;raw feature;feature importance},
 month = {},
 number = {},
 pages = {37004-37016},
 title = {Network Intrusion Detection: Based on Deep Hierarchical Network and Original Flow Data},
 volume = {7},
 year = {2019}
}

@article{8673741,
 abstract = {Feature-based (FB) algorithms for automatic modulation recognition of radar signals have received much attention since they are usually simple to realize. However, existing FB approaches usually focus on several specific modulations and fail when applied to various modulations. To overcome this issue, we propose a simple and effective FB algorithm based on Manhattan distance-based features (MDBFs) in this paper. MDBFs are new features for radar signals that can be applied for recognition of different modulations. The main contributions of this paper are as follows. First, radar signals are represented as wavelet ridges, which includes important information that can distinguish different modulations, and the piecewise aggregate approximation algorithm is introduced to reduce signal dimensions. Then, the dynamic time warping averaging is employed instead of the traditional k-means algorithm to extract realistic centroids for each class. Finally, the Manhattan distances between each data sample and each centroid are used to construct MDBFs, and decisions are made using the k-nearest neighbor. In addition, we prove that MDBFs have better class separability power than the Euclidean-based features. MDBFs contain information about the correlations between different classes, which means that these features suitable for discriminating various modulations when their class distributions do not overlap badly in representation space. The extensive experiments on a synthetic dataset demonstrate the outstanding performance of our proposed method and are hardly affected by the pulse width of the signal. Thus, the proposed method with the effectiveness and robustness could be a promising modulation recognition method of the radar signal.},
 author = {Huang, Yingkun and Jin, Weidong and Li, Bing and Ge, Peng and Wu, Yunpu},
 doi = {10.1109/ACCESS.2019.2907159},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Modulation;Feature extraction;Radar;Time-frequency analysis;Support vector machines;Classification algorithms;Deep learning;Modulation recognition;Manhattan distance-based feature;wavelet ridge;dynamic time warping averaging;class centroid},
 month = {},
 number = {},
 pages = {41193-41204},
 title = {Automatic Modulation Recognition of Radar Signals Based on Manhattan Distance-Based Features},
 volume = {7},
 year = {2019}
}

@article{8678865,
 abstract = {With the rapid evolution of network traffic diversity, the understanding of network traffic has become more pivotal and more formidable. Previously, traffic classification and intrusion detection require a burdensome analyzing of various traffic features and attack-related characteristics by experts, and even, private information might be required. However, due to the outdated features labeling and privacy protocols, the existing approaches may not fit with the characteristics of the changing network environment anymore. In this paper, we present a light-weight framework with the aid of deep learning for encrypted traffic classification and intrusion detection, termed as deep-full-range (DFR). Thanks to deep learning, DFR is able to learn from raw traffic without manual intervention and private information. In such a framework, our proposed algorithms are compared with other state-of-the-art methods using two public datasets. The experimental results show that our framework not only can outperform the state-of-the-art methods by averaging 13.49% on encrypted traffic classification’s  $F1$  score and by averaging 12.15% on intrusion detection’s  $F1$  score but also require much lesser storage resource requirement.},
 author = {Zeng, Yi and Gu, Huaxi and Wei, Wenting and Guo, Yantao},
 doi = {10.1109/ACCESS.2019.2908225},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cryptography;Intrusion detection;Deep learning;Data preprocessing;Feature extraction;Privacy;Protocols;Encrypted traffic classification;network intrusion detection;deep learning;end-to-end},
 month = {},
 number = {},
 pages = {45182-45190},
 title = { $Deep-Full-Range$ : A Deep Learning Based Network Encrypted Traffic Classification and Intrusion Detection Framework},
 volume = {7},
 year = {2019}
}

@article{8681044,
 abstract = {Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01-0.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks.},
 author = {Vinayakumar, R. and Alazab, Mamoun and Soman, K. P. and Poornachandran, Prabaharan and Al-Nemrat, Ameer and Venkatraman, Sitalakshmi},
 doi = {10.1109/ACCESS.2019.2895334},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computer security;Deep learning;Malware;Benchmark testing;Cyber security;intrusion detection;malware;big data;machine learning;deep learning;deep neural networks;cyberattacks;cybercrime},
 month = {},
 number = {},
 pages = {41525-41550},
 title = {Deep Learning Approach for Intelligent Intrusion Detection System},
 volume = {7},
 year = {2019}
}

@article{8713986,
 abstract = {The constant miniaturization of hardware and an increase in power efficiency, have made possible the integration of intelligence into ordinary devices. This trend of augmenting so-called non-intelligent everyday devices with computational capabilities has led to the emergence of the Internet of Things (IoT) domain. With a wide variety of applications, such as home automation, smart grids/cities, and critical infrastructure management, the IoT systems make compelling targets for cyber-attacks. In order to effectively compromise these systems, adversaries employ different advanced persistent threat (APT) methods, with one such sophisticated method, being botnets. By employing a plethora of infected machines (bots), attackers manage to compromise the IoT systems and exploit them. Prior to the appearance of the IoT domain, specialized digital forensics mechanisms were developed, in order to investigate Botnet activities in small-scale systems. Since IoT enabled botnets are scalable, technologically diverse and make use of current high-speed networks, developing forensic mechanisms capable of investigating the IoT Botnet activities has become an important challenge in the cyber-security field. Various studies have proposed, deep learning as a viable solution for handling the IoT generated data, as it was designed to handle diverse data in large volumes, requiring near real-time processing. In this study, we provide a review of forensics and deep learning mechanisms employed to investigate botnets and their applicability in the IoT environments. We provide a new definition for the IoT, in addition to a taxonomy of network forensic solutions, that were developed for both conventional, as well as, the IoT settings. Furthermore, we investigate the applicability of deep learning in network forensics, the inherent challenges of applying network forensics techniques to the IoT, and provide future direction for research in this field.},
 author = {Koroniotis, Nickolaos and Moustafa, Nour and Sitnikova, Elena},
 doi = {10.1109/ACCESS.2019.2916717},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Forensics;Internet of Things;Malware;Security;Deep learning;Internet of Things;IoT;nework forensics;botnets;deep learning},
 month = {},
 number = {},
 pages = {61764-61785},
 title = {Forensics and Deep Learning Mechanisms for Botnets in Internet of Things: A Survey of Challenges and Solutions},
 volume = {7},
 year = {2019}
}

@article{8713992,
 abstract = {While machine learning and artificial intelligence have long been applied in networking research, the bulk of such works has focused on supervised learning. Recently, there has been a rising trend of employing unsupervised machine learning using unstructured raw network data to improve network performance and provide services, such as traffic engineering, anomaly detection, Internet traffic classification, and quality of service optimization. The growing interest in applying unsupervised learning techniques in networking stems from their great success in other fields, such as computer vision, natural language processing, speech recognition, and optimal control (e.g., for developing autonomous self-driving cars). In addition, unsupervised learning can unconstrain us from the need for labeled data and manual handcrafted feature engineering, thereby facilitating flexible, general, and automated methods of machine learning. The focus of this survey paper is to provide an overview of applications of unsupervised learning in the domain of networking. We provide a comprehensive survey highlighting recent advancements in unsupervised learning techniques, and describe their applications in various learning tasks, in the context of networking. We also provide a discussion on future directions and open research issues, while identifying potential pitfalls. While a few survey papers focusing on applications of machine learning in networking have previously been published, a survey of similar scope and breadth is missing in the literature. Through this timely review, we aim to advance the current state of knowledge, by carefully synthesizing insights from previous survey papers, while providing contemporary coverage of the recent advances and innovations.},
 author = {Usama, Muhammad and Qadir, Junaid and Raza, Aunn and Arif, Hunain and Yau, Kok-lim Alvin and Elkhatib, Yehia and Hussain, Amir and Al-Fuqaha, Ala},
 doi = {10.1109/ACCESS.2019.2916648},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Unsupervised learning;Deep learning;Anomaly detection;Internet of Things;Quality of service;Machine learning;deep learning;unsupervised learning;computer networks},
 month = {},
 number = {},
 pages = {65579-65615},
 title = {Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges},
 volume = {7},
 year = {2019}
}

@article{8717998,
 abstract = {The diversification of wireless network traffic attack characteristics has led to the problems what traditional intrusion detection technology with high false positive rate, low detection efficiency, and poor generalization ability. In order to enhance the security and improve the detection ability of malicious intrusion behavior in a wireless network, this paper proposes a wireless network intrusion detection method based on improved convolutional neural network (ICNN). First, the network traffic data is characterized and preprocessed, then modeled the network intrusion traffic data by ICNN. The low-level intrusion traffic data is abstractly represented as advanced features by CNN, which extracted autonomously the sample features, and optimizing network parameters by stochastic gradient descent algorithm to converge the model. Finally, we conducted a sample test to detect the intrusion behavior of the network. The simulation results show that the method proposed in our paper has higher detection accuracy and true positive rate together with a lower false positive rate. The test results on the test set KDDTest + in our paper show that compared with the traditional models, the detection accuracy is 8.82% and 0.51% higher than that of LeNet-5 and DBN, respectively, and the recall rate is 4.24% and 1.16% higher than that of LeNet-5 and RNN, respectively, while the false positive rate is lower than the other three types of models. It also has a big advantage compared to the IDABCNN and NIDMBCNN methods.},
 author = {Yang, Hongyu and Wang, Fengyan},
 doi = {10.1109/ACCESS.2019.2917299},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Training;Convolutional neural networks;Feature extraction;Wireless networks;Convolution;Backpropagation;Wireless network intrusion detection;security;convolutional neural network},
 month = {},
 number = {},
 pages = {64366-64374},
 title = {Wireless Network Intrusion Detection Based on Improved Convolutional Neural Network},
 volume = {7},
 year = {2019}
}

@article{8736331,
 abstract = {Due to the complex and time-varying network environments, traditional methods are difficult to extract accurate features of intrusion behavior from the high-dimensional data samples and process the high-volume of these data efficiently. Even worse, the network intrusion samples are submerged into a large number of normal data packets, which leads to insufficient samples for model training; therefore it is accompanied by high false detection rates. To address the challenge of unbalanced positive and negative learning samples, we propose using deep convolutional generative adversarial networks (DCGAN), which allows features to be extracted directly from the rawdata, and then generates new training-sets by learning from the rawdata. Given the fact that the attack samples are usually intra-dependent time sequence data, we apply long short-term memory (LSTM) to automatically learn the features of network intrusion behaviors. However, it is hard to parallelize the learning/training of the LSTM network, since the LSTM algorithm depends on the result of the previous moment. To remove such dependency and enable intrusion detection in real time, we propose a simple recurrent unit based (SRU)-based model. The proposed model was verified by extensive experiments on the benchmark datasets KDD’99 and NSL-KDD, which effectively identifies normal and abnormal network activities. It achieves 99.73% accuracy on the KDD’99 dataset and 99.62% on the NSL-KDD dataset.},
 author = {Yang, Jin and Li, Tao and Liang, Gang and He, Wenbo and Zhao, Yue},
 doi = {10.1109/ACCESS.2019.2922692},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Deep learning;Training;Logic gates;Malware;Computer architecture;Network security;deep learning;intrusion detection system (IDS);simple recurrent unit;deep convolutional generative adversarial networks},
 month = {},
 number = {},
 pages = {83286-83296},
 title = {A Simple Recurrent Unit Model Based Intrusion Detection System With DCGAN},
 volume = {7},
 year = {2019}
}

@article{8740873,
 abstract = {In order to effectively detect wireless network intrusion behavior, a combined wireless network intrusion detection model based on deep learning was proposed. First, a feature database was generated by feature mapping, one-hot encoding, and normalization processing. Then, we built a deep belief network (DBN) with the multi-restricted Boltzmann machine (RBM) and the back propagation (BP) network. The BP network layer was connected as an auxiliary layer to the end of the RBM. The back-propagation algorithm was used to fine-tune the weight of the multi-restricted Boltzmann machine. Finally, the support vector machine (SVM) was used to train the detection method. After training, the intrusion detection model, which had the DBN-SVM detection method, was determined. The experimental results show that the detection model has good intrusion detection performance.},
 author = {Yang, Hongyu and Qin, Geng and Ye, Li},
 doi = {10.1109/ACCESS.2019.2923814},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Support vector machines;Wireless networks;Training;Databases;Deep learning;Feature extraction;Intrusion detection;information security;wireless network;deep belief network;support vector machine},
 month = {},
 number = {},
 pages = {82624-82632},
 title = {Combined Wireless Network Intrusion Detection Model Based on Deep Learning},
 volume = {7},
 year = {2019}
}

@article{8740962,
 abstract = {In recent years, advanced threat attacks are increasing, but the traditional network intrusion detection system based on feature filtering has some drawbacks which make it difficult to find new attacks in time. This paper takes NSL-KDD data set as the research object, analyses the latest progress and existing problems in the field of intrusion detection technology, and proposes an adaptive ensemble learning model. By adjusting the proportion of training data and setting up multiple decision trees, we construct a MultiTree algorithm. In order to improve the overall detection effect, we choose several base classifiers, including decision tree, random forest, kNN, DNN, and design an ensemble adaptive voting algorithm. We use NSL-KDD Test+ to verify our approach, the accuracy of the MultiTree algorithm is 84.2%, while the final accuracy of the adaptive voting algorithm reaches 85.2%. Compared with other research papers, it is proved that our ensemble model effectively improves detection accuracy. In addition, through the analysis of data, it is found that the quality of data features is an important factor to determine the detection effect. In the future, we should optimize the feature selection and preprocessing of intrusion detection data to achieve better results.},
 author = {Gao, Xianwei and Shan, Chun and Hu, Changzhen and Niu, Zequn and Liu, Zhen},
 doi = {10.1109/ACCESS.2019.2923640},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Classification algorithms;Adaptation models;Machine learning algorithms;Neural networks;Prediction algorithms;Intrusion detection;ensemble learning;deep neural network;voting;MultiTree;NSL-KDD},
 month = {},
 number = {},
 pages = {82512-82521},
 title = {An Adaptive Ensemble Machine Learning Model for Intrusion Detection},
 volume = {7},
 year = {2019}
}

@article{8742593,
 abstract = {A DDoS attack is one of the most serious threats to the current Internet. The Router throttling is a popular method to response against DDoS attacks. Currently, coordinated team learning (CTL) has adopted tile coding for continuous state representation and strategy learning. It is suitable for this distributed challenge but lacks robustness. Our first contribution is that we adapt deep network as function approximation for continuous state representation, as a deep reinforcement learning approach is robust in many different Atari games with a little modification of the learning architecture. Furthermore, current multiagent router throttling methods only consider traffic-reading information. Therefore, for a homogeneous team scenario, all agents can share parameters with the same deep network. However, for heterogeneous team scenarios, if all agents still share one deep network, the learning policy may not be sufficiently ideal. Our second contribution is that we add team structure information so that all agents can still share one deep network. However, deep reinforcement learning is a considerably time-consuming task. Transfer learning is an appropriate method because learning policy in a simple scenario allows us to transfer the policy to other different and even complex scenarios. For transfer learning regarding the DDoS control problem, we propose a progressive transfer learning approach, which is our third contribution. Therefore, we can learn a better policy with less time consumption. Moreover, with progressive transfer learning, we can promote our method in a more complex environment. The experimental results validate that our three contributions truly achieve better performance than the existing methods.},
 author = {Xia, Shi-Ming and Zhang, Lei and Bai, Wei and Zhou, Xing-Yu and Pan, Zhi-Song},
 doi = {10.1109/ACCESS.2019.2923993},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Servers;Reinforcement learning;Task analysis;Games;Encoding;Aggregates;Distributed denial of service;router throttling;deep network;team structure information;multiagent reinforcement learning;progressive transfer learning},
 month = {},
 number = {},
 pages = {81481-81493},
 title = {DDoS Traffic Control Using Transfer Learning DQN With Structure Information},
 volume = {7},
 year = {2019}
}

@article{8744218,
 abstract = {In the studies of cybersecurity, malicious traffic detection is attracting more and more attention for its capability of detecting attacks. Almost all of the intrusion detection methods based on deep learning have poor data processing capacity with the increase in the data length. Most intrusion detection methods can only handle the header part of the traffic and omit valuable information from the payload, so they cannot detect the malicious traffic when the hacker hides the attack behavior in the payload. In this paper, we propose an attention model that can process network traffic flow with adjustable length to detect the payload-based attacks. Furthermore, we design a Flow Wasserstein GAN model to generate new network traffic data from the original data sets to enhance the network packet data and protect the user's privacy. Our model has a hierarchical structure to build the representations of bytes and packets on two levels. Moreover, two levels of attention mechanisms enable the model to pay attention to more important content when constructing the flow representation. The experiments based on the ISCX-2012 and ISCX-2017 datasets prove that the proposed model has higher performance in accuracy and true positive rate (TPR) than four state-of-the-art deep learning methods. The experiment shows that our model outperforms the existing HSAT-IDS in the detection of the generated packets.},
 author = {Han, Luchao and Sheng, Yiqiang and Zeng, Xuewen},
 doi = {10.1109/ACCESS.2019.2924492},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Logic gates;Deep learning;Intrusion detection;Computer security;Task analysis;Malware;Malicious traffic detection;deep learning;cybersecurity},
 month = {},
 number = {},
 pages = {82913-82926},
 title = {A Packet-Length-Adjustable Attention Model Based on Bytes Embedding Using Flow-WGAN for Smart Cybersecurity},
 volume = {7},
 year = {2019}
}

@article{8751965,
 abstract = {The rapid development and popularization of the network have brought many problems to network security. Intrusion detection technology is often used as an effective security technology to protect the network. The deep belief network (DBN), as a classic model of deep learning, has good classification performance and is often used in the field of intrusion detection. However, the network structure of DBN is generally set through practical experience. For the optimization problem of the DBN-based intrusion detection classification model (DBN-IDS), this paper proposes a new joint optimization algorithm to optimize the DBN's network structure. First, we design a particle swarm optimization (PSO) based on the adaptive inertia weight and learning factor. Second, we use the fish swarm behavior of cluster, foraging, and other behaviors to optimize the PSO to find the initial optimization solution. Then, based on the initial optimization solution, we use the genetic operators with self-adjusting crossover probability and mutation probability to optimize the PSO to search the global optimization solution. Finally, the global optimization solution constructed by the above-mentioned joint optimization algorithm is used as the network structure of the intrusion detection classification model. The experimental results show that compared with other DBN-IDS optimization algorithms, our algorithm shortens the average detection time by at least 24.69% on the premise of increasing the average training time by 6.9%; compared with the tested classification algorithms, our DBN-IDS improves the average classification accuracy by at least 1.3% and up to 14.80% in the five-category classification, which is proved to be an efficient DBN-IDS optimization method.},
 author = {Wei, Peng and Li, Yufeng and Zhang, Zhen and Hu, Tao and Li, Ziyong and Liu, Diyang},
 doi = {10.1109/ACCESS.2019.2925828},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Optimization methods;Particle swarm optimization;Biological neural networks;Machine learning algorithms;Intrusion detection;deep belief network;particle swarm optimization;artificial fish swarm algorithm;genetic algorithm},
 month = {},
 number = {},
 pages = {87593-87605},
 title = {An Optimization Method for Intrusion Detection Classification Model Based on Deep Belief Network},
 volume = {7},
 year = {2019}
}

@article{8758106,
 abstract = {Accurate detection of network-based attacks is crucial to prevent security breaches of information systems. The recent application of deep learning approaches for network intrusion detection has shown promising. However, the challenges remain on how to deal with imbalance data and small samples as well as reducing false alarm rate (FAR). To address these issues, this work has proposed a multiple-layer representation learning model for accurate end-to-end network intrusion detection by combining deep convolutional neural networks (CNN) with gcForest. The contributions of this work lie in 1) a new data encoding scheme based on P-Zigzag to encode network traffic data into two-dimensional gray-scale images for representation learning without loss of original information; 2) The combination of gcForest and CNN allows accurate detection on imbalanced data and small scale data with fewer hyperparamters comparing to most existing deep learning models, which increase computational efficiency. The proposed approach is based on a multiple-layer approach consisting of a coarse layer and a fine layer, in which the coarse layer with the improved CNN model (GoogLeNetNP) focuses on identification of N abnormal classes and a normal class. While in the fine layer, an improved model based on gcForest (caXGBoost) further classifies the abnormal classes into N-1 subclasses. This ensures fine-grained detection of various attacks. The proposed framework has been compared with the existing deep learning models using three real datasets (a new dataset NBC, a combination of UNSW-NB15 and CICIDS2017 consisting of 101 classes). The experimental results show that our proposed method outperforms other single deep learning methods (i.e., AlexNet, VGG19, GoogleNet, InceptionV3, ResNet18) in terms of accuracy, detection rate, and FAR, which demonstrates its effectiveness in detecting fine-grained attacks and handling imbalanced datasets with high-precision and low FAR.},
 author = {Zhang, Xueqin and Chen, Jiahao and Zhou, Yue and Han, Liangxiu and Lin, Jiajun},
 doi = {10.1109/ACCESS.2019.2927465},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Forestry;Deep learning;Data models;Network intrusion detection;convolutional neural networks;deep random forests;representation learning},
 month = {},
 number = {},
 pages = {91992-92008},
 title = {A Multiple-Layer Representation Learning Model for Network-Based Attack Detection},
 volume = {7},
 year = {2019}
}

@article{8762138,
 abstract = {The main task of future networks is to build, as much as possible, intelligent networking architectures for intellectualization, activation, and customization. Software-defined networking (SDN) technology breaks the tight coupling between the control plane and the data plane in the traditional network architecture, making the controllability, security, and economy of network resources into a reality. As one of the important actualization methods of artificial intelligence (AI), machine learning (ML), combined with SDN architecture will have great potential in areas, such as network resource management, route planning, traffic scheduling, fault diagnosis, and network security. This paper presents the network applications combined with SDN concepts based on ML from two perspectives, namely the perspective of ML algorithms and SDN network applications. From the perspective of ML algorithms, this paper focuses on the applications of classical ML algorithms in SDN-based networks, after a characteristic analysis of algorithms. From the other perspective, after classifying the existing network applications based on the SDN architecture, the related ML solutions are introduced. Finally, the future development of the ML algorithms and SDN concepts is discussed and analyzed. This paper occupies the intersection of the AI, big data, computer networking, and other disciplines; the AI itself is a new and complex interdisciplinary field, which causes the researchers in this field to often have different professional backgrounds and, sometimes, divergent research purposes. This paper is necessary and helpful for researchers from different fields to accurately master the key issues.},
 author = {Zhao, Yanling and Li, Ye and Zhang, Xinchang and Geng, Guanggang and Zhang, Wei and Sun, Yanjie},
 doi = {10.1109/ACCESS.2019.2928564},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Numerical models;Software defined networking;Machine learning;Computer architecture;Prediction algorithms;Artificial intelligence;machine learning;network management;software-defined networking},
 month = {},
 number = {},
 pages = {95397-95417},
 title = {A Survey of Networking Applications Applying the Software Defined Networking Concept Based on Machine Learning},
 volume = {7},
 year = {2019}
}

@article{8787567,
 abstract = {Network attack behavior detection using deep learning is an important research topic in the field of network security. Currently, there are still many challenges in detecting multi-class imbalanced abnormal traffic data. This paper proposed a new intrusion detection network based on deep learning, named parallel cross convolutional neural network (PCCN), to improve the detection performance of imbalanced abnormal flows. By fusing the flow features learned from the two branch convolutional neural networks (CNN), PCCN can better learn the flow features with fewer samples, to improve the detection results of the imbalanced abnormal flows. We proposed an improved feature extraction method of the original flow to extract multi-class flow features at the same time. The proposed algorithm not only reduces the number of useless elements for network learning, but also accelerates network convergence. In addition, we proposed four improved versions of the PCCN network structure to meet the real-time requirements of network intrusion detection in the current big data computing. These networks can achieve almost the same detection results as the PCCN, but greatly reduce the detection time of data. Through the analysis of high-order evaluation metrics, the proposed PCCN algorithm is significantly better than the traditional machine learning algorithms. Compared with the current hierarchical network model, PCCN can also achieve better performance in term of overall accuracy.},
 author = {Zhang, Yong and Chen, Xu and Guo, Da and Song, Mei and Teng, Yinglei and Wang, Xiaojuan},
 doi = {10.1109/ACCESS.2019.2933165},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Big Data;Measurement;Deep learning;Machine learning algorithms;Data models;Network intrusion detection;cross network;deep learning;feature fusion},
 month = {},
 number = {},
 pages = {119904-119916},
 title = {PCCN: Parallel Cross Convolutional Neural Network for Abnormal Network Traffic Flows Detection in Multi-Class Imbalanced Network Traffic Flows},
 volume = {7},
 year = {2019}
}

@article{8793124,
 abstract = {In this paper, we investigate the security threats in mobile edge computing (MEC) of Internet of things, and propose a deep-learning (DL)-based physical (PHY) layer authentication scheme which exploits channel state information (CSI) to enhance the security of MEC system via detecting spoofing attacks in wireless networks. Moreover, three gradient descent algorithms are adopted to accelerate the training of deep neural networks, which enables smaller computation overheads and lower energy consumptions. In addition, the maximum likelihood function of multi-user authentication method is derived, which explains why cross entropy is chosen as the loss function. The vectorization cost function is also derived. The mini batch scheme and ℓ2 regularization are adopted to improve training accuracy and avoid over-fitting, respectively. Moreover, the simulation and experimental results show that the DL-based PHY-layer authentication approaches can distinguish multiple legitimate edge nodes from malicious nodes and attacker by CSIs, effectively. Our proposed method supports a better performance compared with the traditional hypothesis test based method.},
 author = {Liao, Run-Fa and Wen, Hong and Wu, Jinsong and Pan, Fei and Xu, Aidong and Song, Huanhuan and Xie, Feiyi and Jiang, Yixin and Cao, Minggui},
 doi = {10.1109/ACCESS.2019.2934122},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Authentication;Servers;Edge computing;Wireless communication;Physical layer;Internet of Things;Mobile edge computing (MEC);the Internet of things (IoT);PHY-layer authentication;deep neural network (DNN);multi-user},
 month = {},
 number = {},
 pages = {116390-116401},
 title = {Security Enhancement for Mobile Edge Computing Through Physical Layer Authentication},
 volume = {7},
 year = {2019}
}

@article{8834820,
 abstract = {The wirelessly connected intelligent robot swarms are more vulnerable to be attacked due to their unstable network connection and limited resources, and the consequences of being attacked are more serious than other systems. Therefore, the quantitative assessment of wireless connected intelligent robot swarms network security situation is very important. Factors determining the state of wireless connected intelligent robot swarms network security have characteristics such as mass and diversity, which constantly evolve with time. In fact, network security measurement has multi-level, multi-dimensional, and multi-granularity characteristics. Therefore, properly selecting wireless connected intelligent robot swarms network security measurement parameters and reducing and converging them to quantitative values such that they can enable a true and objective reflection of the network security state is a very challenging problem. However, deep learning is a novel solution to the abovementioned problems; its algorithm gets rid of the dependence on feature engineering and automatically builds a quantitative assessment model of a network security situation with dynamic adjustment as well as self-adaptive and self-learning characteristics. In this study, we propose a quantitative assessment method of wireless connected intelligent robot swarms network security situation based on a convolutional neural network (CNN). Generally, the convolutional layer is used to locally detect and deeply extract features, and the pooling layer is used to rapidly shrink the network scale and highlight the summary features. Using the deep network structure of several hidden layers, the results of quantitative assessment of the network security situation are highly consistent with expert experience. Experimental results show that the quantitative assessment of wireless connected intelligent robot swarms network security situation can be realized by combining the characteristics of a network security index system and CNN. Note that the accuracy rate is 95%, and the calculation results are better than those of other deep learning models.},
 author = {Han, Weihong and Tian, Zhihong and Huang, Zizhong and Huang, Dongqiu and Jia, Yan},
 doi = {10.1109/ACCESS.2019.2940822},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Communication networks;Indexes;Intelligent robots;Communication system security;Wireless communication;Feature extraction;Network security;index system;convolutional neural networks;deep learning},
 month = {},
 number = {},
 pages = {134293-134300},
 title = {Quantitative Assessment of Wireless Connected Intelligent Robot Swarms Network Security Situation},
 volume = {7},
 year = {2019}
}

@article{8835902,
 abstract = {Code Injection attacks such as SQL Injection and Cross-Site Scripting (XSS) are among the major threats for today's web applications and systems. This paper proposes CODDLE, a deep learning-based intrusion detection systems against web-based code injection attacks. CODDLE's main novelty consists in adopting a Convolutional Deep Neural Network and in improving its effectiveness via a tailored pre-processing stage which encodes SQL/XSS-related symbols into type/value pairs. Numerical experiments performed on real-world datasets for both SQL and XSS attacks show that, with an identical training and with a same neural network shape, CODDLE's type/value encoding improves the detection rate from a baseline of about 75% up to 95% accuracy, 99% precision, and a 92% recall value.},
 author = {Abaimov, Stanislav and Bianchi, Giuseppe},
 doi = {10.1109/ACCESS.2019.2939870},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Structured Query Language;SQL injection;Training;Neural networks;Deep learning;Databases;Tools;Deep learning;code injection;intrusion detection;supervised learning;SQL injection;XSS;JavaScript},
 month = {},
 number = {},
 pages = {128617-128627},
 title = {CODDLE: Code-Injection Detection With Deep Learning},
 volume = {7},
 year = {2019}
}

@article{8846674,
 abstract = {Deep learning has been widely studied in many technical domains such as image analysis and speech recognition, with its benefits that effectively deal with complex and high-dimensional data. Our preliminary experiments show a high degree of non-linearity from the network connection data, which explains why it is hard to improve the performance of identifying network anomalies by using conventional learning methods (e.g., Adaboosting, SVM, and Random Forest). In this study, we design and examine deep learning models constructed based on Fully Connected Networks (FCNs), Variational AutoEncoder (VAE), and Sequence-to-Sequence (Seq2Seq) structures. For the extensive evaluation, we employ a broad range of the public datasets with unique characteristics. Our experimental results confirm the feasibility of deep learning-based network anomaly detection, with the improved performance compared to the conventional learning techniques. In particular, the detection model based on Seq2Seq with LSTM is highly promising, consistently yielding over 99% of accuracy to identify network anomalies from the entire datasets employed in the evaluation.},
 author = {Malaiya, Ritesh K. and Kwon, Donghwoon and Suh, Sang C. and Kim, Hyunjoo and Kim, Ikkyun and Kim, Jinoh},
 doi = {10.1109/ACCESS.2019.2943249},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Anomaly detection;Support vector machines;Neural networks;Security;Learning systems;Training;Network anomaly detection;traffic analysis;deep learning;neural networks;sequence-to-sequence;performance evaluation},
 month = {},
 number = {},
 pages = {140806-140817},
 title = {An Empirical Evaluation of Deep Learning for Network Anomaly Detection},
 volume = {7},
 year = {2019}
}

@article{8854182,
 abstract = {Injection attack is the first of the top 10 security threats announced by the OWASP. Meanwhile, SQL injection is one of the most important types among the injection attacks. Because of its various types and fast variations, SQL injection can cause great harm to the network, resulting in data leakage and website paralysis. Due to the heterogeneity of attack load, the diversity of attack methods and the variety of attack modes, SQL injection detection is still a challenging problem. How to defense SQL injection attack effectively becomes the focus and frontier of web security nowadays. Therefore, this paper proposes an adaptive deep forest-based method to detect the complex SQL injection attacks. Firstly, the structure of deep forest is optimized in our paper, the input of each layer is concatenated by the raw feature vector and average of previous outputs. Experiments show that our proposed method effectively solves the problem that the original features of deep forests are degraded with the increasing number of layers. Then, we introduce an AdaBoost algorithm based deep forest model which utilizes error rate to update the weights of features on each layer. That is, in the process of training, different features are assigned with different weights based on their influence on the result. Our model can automatically adjust the structure of the tree model and deal with multi-dimensional fine-grained features to avoid over-fitting problem effectively. The experimental results show that the proposed method has a better performance than classical machine learning methods and deep learning methods.},
 author = {Li, Qi and Li, Weishi and Wang, Junfeng and Cheng, Mingyu},
 doi = {10.1109/ACCESS.2019.2944951},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {SQL injection;Forestry;Structured Query Language;Training;Feature extraction;Adaptation models;Machine learning;SQL injection detection;adaptive deep forest;Web security;AdaBoost},
 month = {},
 number = {},
 pages = {145385-145394},
 title = {A SQL Injection Detection Method Based on Adaptive Deep Forest},
 volume = {7},
 year = {2019}
}

@article{8879591,
 abstract = {The advancement of the Internet of Things (IoT) has allowed for unprecedented data collection, automation, and remote sensing and actuation, transforming autonomous systems and bringing smart command and control into numerous cyber physical systems (CPS) that our daily lives depend on. Simultaneously, dramatic improvements in machine learning and deep neural network architectures have enabled unprecedented analytical capabilities, which we see in increasingly common applications and production technologies, such as self-driving vehicles and intelligent mobile applications. Predictably, these technologies have seen rapid adoption, which has left many implementations vulnerable to threats unforeseen or undefended against. Moreover, such technologies can be used by malicious actors, and the potential for cyber threats, attacks, intrusions, and obfuscation that are only just being considered, applied, and countered. In this paper, we consider the good, the bad, and the ugly use of machine learning for cybersecurity and CPS/IoT. In detail, we consider the numerous benefits (good use) that machine learning has brought, both in general, and specifically for security and CPS/IoT, such as the improvement of intrusion detection mechanisms and decision accuracy in CPS/IoT. More pressing, we consider the vulnerabilities of machine learning (bad use) from the perspectives of security and CPS/IoT, including the ways in which machine learning systems can be compromised, misled, and subverted at all stages of the machine learning life-cycle (data collection, pre-processing, training, validation, implementation, etc.). Finally, the most concerning, a growing trend has been the utilization of machine learning in the execution of cyberattacks and intrusions (ugly use). Thus, we consider existing mechanisms with the potential to improve target acquisition and existing threat patterns, as well as those that can enable novel attacks yet to be seen.},
 author = {Liang, Fan and Hatcher, William Grant and Liao, Weixian and Gao, Weichao and Yu, Wei},
 doi = {10.1109/ACCESS.2019.2948912},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning;Computer security;Internet of Things;Training;Data collection;Security;machine learning;cyber physical systems;Internet of Things;applications;distributed environments},
 month = {},
 number = {},
 pages = {158126-158147},
 title = {Machine Learning for Security and the Internet of Things: The Good, the Bad, and the Ugly},
 volume = {7},
 year = {2019}
}

@article{8896978,
 abstract = {One of the major challenges in cybersecurity is the provision of an automated and effective cyber-threats detection technique. In this paper, we present an AI technique for cyber-threats detection, based on artificial neural networks. The proposed technique converts multitude of collected security events to individual event profiles and use a deep learning-based detection method for enhanced cyber-threat detection. For this work, we developed an AI-SIEM system based on a combination of event profiling for data preprocessing and different artificial neural network methods, including FCNN, CNN, and LSTM. The system focuses on discriminating between true positive and false positive alerts, thus helping security analysts to rapidly respond to cyber threats. All experiments in this study are performed by authors using two benchmark datasets (NSLKDD and CICIDS2017) and two datasets collected in the real world. To evaluate the performance comparison with existing methods, we conducted experiments using the five conventional machine-learning methods (SVM, k-NN, RF, NB, and DT). Consequently, the experimental results of this study ensure that our proposed methods are capable of being employed as learning-based models for network intrusion-detection, and show that although it is employed in the real world, the performance outperforms the conventional machine-learning methods.},
 author = {Lee, Jonghoon and Kim, Jonghyun and Kim, Ikkyun and Han, Kijun},
 doi = {10.1109/ACCESS.2019.2953095},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {IP networks;Machine learning;Benchmark testing;Network intrusion;Data models;Communication networks;Cyber security;intrusion detection;network security;artificial intelligence;deep neural networks},
 month = {},
 number = {},
 pages = {165607-165626},
 title = {Cyber Threat Detection Based on Artificial Neural Networks Using Event Profiles},
 volume = {7},
 year = {2019}
}

@article{8902008,
 abstract = {Most active research in Host and Network Intrusion Detection Systems are only able to detect attacks on the computer systems and at the network layer, which are not sufficient to counteract SOAP/REST or XML/JSON-related attacks. In dealing with the problem of anomaly detection in web service message datasets, this paper proposes an anomaly detection system called the Online Adaptive Deep-Packet Inspector (O-ADPI) for web service message attacks classification. The proposed approach relies on multiple statistical methods which use Unigram-based Weighting Scheme (UWS) that combines text mining techniques with a set of different statistical criteria for Feature Selection Engine (FSE) to effectively and efficiently explore optimal subspaces in detecting anomalies embedded deep in the high dimensional feature subspaces. We utilize a supervised intrusion detection algorithm based on Mahalanobis Distance Map classifier. As web service attacks can be classified into anomaly and normal, the task of anomaly detection can be modeled as a classification problem. The O-ADPI model was assessed for F-value, true positive rate (TPR), and false positive rate (FPR) in order to evaluate the detection performance of O-ADPI against different type of feature selections engines with corresponding PCs for each message-specific service. The experiments were performed using the REST-IDS Dataset 2015 and the results demonstrated that the proposed O-ADPI model achieved the best results in each message-specific service.},
 author = {Kakavand, Mohsen and Mustapha, Aida and Tan, Zhiyuan and Yazdani, Sepideh Foroozan and Arulsamy, Lingges},
 doi = {10.1109/ACCESS.2019.2953791},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Payloads;XML;Feature extraction;Anomaly detection;Simple object access protocol;Security;Anomaly detection;feature selection engine;Mahalanobis distance map;web service attacks},
 month = {},
 number = {},
 pages = {167141-167156},
 title = {O-ADPI: Online Adaptive Deep-Packet Inspector Using Mahalanobis Distance Map for Web Service Attacks Classification},
 volume = {7},
 year = {2019}
}

@article{8926464,
 abstract = {Vehicular Ad-Hoc Networks (VANETs) have received a great attention recently due to their potential and various applications. However, the initial phase of the VANET has many research challenges that need to be addressed, such as the issues of security and privacy protection caused by the openness of wireless communication networks among the city-wide applied regions. Specially, anomaly detection for a VANET has become a challenging problem, due to the changes in the scenario of VANETs comparing with traditional wireless networks. Motivated by this issue, we focus on the problem of anomaly detection in VANETs, and propose an effective anomaly detection approach based on the convolutional neural network in this paper. The proposed approach takes into account the spatio-temporal and sparse features of VANET traffic, and it uses a convolutional neural network architecture and a loss function based on Mahalanobis distance to extract and estimate the traffic matrix. Then, reinforcement learning is used to implement anomaly detection. Furthermore, a comprehensive assessment is provided to validate the proposed approach, which illustrates the effectiveness of this approach.},
 author = {Nie, Laisen and Wu, Yixuan and Wang, Huizhi and li, yongkang},
 doi = {10.1109/ACCESS.2019.2958068},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Feature extraction;Vehicular ad hoc networks;Security;Learning (artificial intelligence);Convolutional neural networks;Anomaly detection;VANET;intelligent transportation systems;network security},
 month = {},
 number = {},
 pages = {177954-177964},
 title = {Anomaly Detection Based on Spatio-Temporal and Sparse Features of Network Traffic in VANETs},
 volume = {7},
 year = {2019}
}

@article{8926471,
 abstract = {In recent decades, Industrial Control Systems (ICS) have been affected by heterogeneous cyberattacks that have a huge impact on the physical world and the people's safety. Nowadays, the techniques achieving the best performance in the detection of cyber anomalies are based on Machine Learning and, more recently, Deep Learning. Due to the incipient stage of cybersecurity research in ICS, the availability of datasets enabling the evaluation of anomaly detection techniques is insufficient. In this paper, we propose a methodology to generate reliable anomaly detection datasets in ICS that consists of four steps: attacks selection, attacks deployment, traffic capture and features computation. The proposed methodology has been used to generate the Electra Dataset, whose main goal is the evaluation of cybersecurity techniques in an electric traction substation used in the railway industry. Using the Electra dataset, we train several Machine Learning and Deep Learning models to detect anomalies in ICS and the performed experiments show that the models have high precision and, therefore, demonstrate the suitability of our dataset for use in production systems.},
 author = {Perales Gómez, Ángel Luis and Fernández Maimó, Lorenzo and Huertas Celdrán, Alberto and García Clemente, Félix J. and Cadenas Sarmiento, Cristian and Del Canto Masa, Carlos Javier and Méndez Nistal, Rubén},
 doi = {10.1109/ACCESS.2019.2958284},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Feature extraction;Industrial control;Protocols;Machine learning;Integrated circuit modeling;Anomaly detection;critical infrastructures;industrial control;industrial control systems;industry applications;machine learning},
 month = {},
 number = {},
 pages = {177460-177473},
 title = {On the Generation of Anomaly Detection Datasets in Industrial Control Systems},
 volume = {7},
 year = {2019}
}

@article{8931585,
 abstract = {Network intrusion detection systems (NIDS) are essential tools in ensuring network information security, and neural networks have become an increasingly popular solution for NIDS. However, with the gradual complexity of the network environment, the existing solutions using the conventional neural network cannot make full use of the rich information in the network traffic data due to its single structure. More importantly, this will lead to the existing NIDS have incomplete knowledge of the intrusion detection domain, and making it unable to achieve a high detection rate and good stability in the new environment. In this paper, we take a step forward and extract the different level features from the network connection, rather than a long feature vector used in the traditional approach, which can process feature information separately more efficiently. And further, we propose multimodal-sequential intrusion detection approach with special structure of hierarchical progressive network, which is supported by multimodal deep auto encoder (MDAE) and LSTM technologies. By design the special structure of hierarchical progressive network, our approach can efficiently integrate the different level features information within a network connection and automatically learn temporal information between adjacent network connections at the same time. Based on the three benchmark datasets from 1999 to 2017, including NSL-KDD, UNSW-NB15, and CICIDS 2017, we investigated the performance of our proposed approach on the task of detecting attacks within modern network. The experimental results show that the average accuracy of this method is 94% in binary classification and 88% in multi-class classification, which is at least 2% and 4% super than other methods respectively, and demonstrated that our model has excellent stability. Moreover, we further explore the multimodality and complementarity in traffic data, the experimental results show that the performance of detection model can be further improved in the range 2% to 5% when using our MDAE model to process the features of traffic data.},
 author = {He, Haitao and Sun, Xiaobing and He, Hongdou and Zhao, Guyu and He, Ligang and Ren, Jiadong},
 doi = {10.1109/ACCESS.2019.2959131},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Deep learning;Network intrusion detection;Anomaly detection;Neural networks;Data models;Network anomaly detection;hierarchical progressive network;multimodal deep learning},
 month = {},
 number = {},
 pages = {183207-183221},
 title = {A Novel Multimodal-Sequential Approach Based on Multi-View Features for Network Intrusion Detection},
 volume = {7},
 year = {2019}
}

@article{8935217,
 abstract = {The advancement in Information and Communications Technology (ICT) has changed the entire paradigm of computing. Because of such advancement, we have new types of computing and communication environments, for example, Internet of Things (IoT) that is a collection of smart IoT devices. The Internet of Medical Things (IoMT) is a specific type of IoT communication environment which deals with communication through the smart healthcare (medical) devices. Though IoT communication environment facilitates and supports our day-to-day activities, but at the same time it has also certain drawbacks as it suffers from several security and privacy issues, such as replay, man-in-the-middle, impersonation, privileged-insider, remote hijacking, password guessing and denial of service (DoS) attacks, and malware attacks. Among these attacks, the attacks which are performed through the malware botnet (i.e., Mirai) are the malignant attacks. The existence of malware botnets leads to attacks on confidentiality, integrity, authenticity and availability of the data and other resources of the system. In presence of such attacks, the sensitive data of IoT communication may be disclosed, altered or even may not be available to the authorized users. Therefore, it becomes essential to protect the IoT/IoMT environment from malware attacks. In this review paper, we first perform the study of various types of malware attacks, and their symptoms. We also discuss some architectures of IoT environment along with their applications. Next, a taxonomy of security protocols in IoT environment is provided. Moreover, we conduct a comparative study on various existing schemes for malware detection and prevention in IoT environment. Finally, some future research challenges and directions of malware detection in IoT/IoMT environment are highlighted.},
 author = {Wazid, Mohammad and Das, Ashok Kumar and Rodrigues, Joel J. P. C. and Shetty, Sachin and Park, Youngho},
 doi = {10.1109/ACCESS.2019.2960412},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Computer architecture;Security;Internet of Things;Servers;Medical services;Smart homes;Internet of Things (IoT);Internet of Medical Things (IoMT);security;IoT malware;malware detection},
 month = {},
 number = {},
 pages = {182459-182476},
 title = {IoMT Malware Detection Approaches: Analysis and Research Challenges},
 volume = {7},
 year = {2019}
}

@article{8938741,
 abstract = {In recent years, the emergence of blockchain technology (BT) has become a unique, most disruptive, and trending technology. The decentralized database in BT emphasizes data security and privacy. Also, the consensus mechanism in it makes sure that data is secured and legitimate. Still, it raises new security issues such as majority attack and double-spending. To handle the aforementioned issues, data analytics is required on blockchain based secure data. Analytics on these data raises the importance of arisen technology Machine Learning (ML). ML involves the rational amount of data to make precise decisions. Data reliability and its sharing are very crucial in ML to improve the accuracy of results. The combination of these two technologies (ML and BT) can provide highly precise results. In this paper, we present a detailed study on ML adoption for making BT-based smart applications more resilient against attacks. There are various traditional ML techniques, for instance, Support Vector Machines (SVM), clustering, bagging, and Deep Learning (DL) algorithms such as Convolutional Neural Network (CNN) and Long short-term memory (LSTM) can be used to analyse the attacks on a blockchain-based network. Further, we include how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities. Then, future research issues and challenges are explored. At last, a case study is presented with a conclusion.},
 author = {Tanwar, Sudeep and Bhatia, Qasim and Patel, Pruthvi and Kumari, Aparna and Singh, Pradeep Kumar and Hong, Wei-Chiang},
 doi = {10.1109/ACCESS.2019.2961372},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchain;Security;Machine learning;Taxonomy;Databases;Prediction algorithms;Malware;Blockchain;machine learning;smart grid;data security and privacy;data analytics;smart applications},
 month = {},
 number = {},
 pages = {474-488},
 title = {Machine Learning Adoption in Blockchain-Based Smart Applications: The Challenges, and a Way Forward},
 volume = {8},
 year = {2020}
}

@article{8941140,
 abstract = {Network traffic classification serves as a building block for important tasks such as security and quality of service management. The field has been studied for a long time, with many techniques such as classical machine learning and deep learning methods currently available. However, the emergence of stronger encryption protocols has led to the rise of new challenges. One of the challenges is capturing and labeling a large amount of encrypted traffic data especially for training deep learning classifiers, as current techniques rely on deep packet inspection tools (DPI) which perform poorly on encrypted traffic. In this paper, we propose a semi-supervised learning approach using Deep Convolutional Generative Adversarial Network (DCGAN). The basic idea is to utilize the samples generated by DCGAN generators as well as unlabeled data to improve the performance of a classifier trained on a few labeled samples. Thus, alleviating the difficulties associated with large dataset collecting and labeling. To demonstrate the efficacy of our approach, we evaluated our model using a self-collected dataset of the recently established QUIC protocol as well as publicly available ISCX VPN-NonVPN dataset. Our approach is able to achieve 89% and 78% accuracy with a very small number of labeled samples (just 10% of the dataset) on both QUIC and ISCX VPN-NonVPN datasets respectively.},
 author = {Iliyasu, Auwal Sani and Deng, Huifang},
 doi = {10.1109/ACCESS.2019.2962106},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Generative adversarial networks;Deep learning;Generators;Payloads;Protocols;Encryption;Deep convolutional generative adversarial network;encrypted traffic classification;semi-supervised learning},
 month = {},
 number = {},
 pages = {118-126},
 title = {Semi-Supervised Encrypted Traffic Classification With Deep Convolutional Generative Adversarial Networks},
 volume = {8},
 year = {2020}
}

@article{8949457,
 abstract = {Figuring the network's hidden abnormal behavior can reduce network vulnerability. This paper presents a detailed architecture in which the collected log data of the network can be processed and analyzed. We process and integrate on-campus network information from every router and store the integrated NetFlow log data. Ceph is used as an open-source distributed storage platform that offers high efficiency, high reliability, scalability, and preliminary preprocessing of raw data with Python, removing redundant areas and unification. In the subanalysis, we discover the anomaly event and absolute flow by three times of standard deviation rule. Keras has been used to classify in-time data collected via a cyber-attack and to construct an automatic identifier template through the Recurring Neural Network (RNN) test. The identification accuracy of the optimization model is around 98% in attack detection. Finally, in the MySQL server, the results of the real-time evaluation can be obtained, and the results of the assessment can be displayed via ECharts.},
 author = {Yang, Chao-Tung and Liu, Jung-Chun and Kristiani, Endah and Liu, Ming-Lun and You, Ilsun and Pau, Giovanni},
 doi = {10.1109/ACCESS.2019.2963716},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Computer architecture;Logic gates;Cyberattack;Monitoring;Neural networks;Feature extraction;Data storage;ceph;deep learning;cyberattack;netflow log},
 month = {},
 number = {},
 pages = {7842-7850},
 title = {NetFlow Monitoring and Cyberattack Detection Using Deep Learning With Ceph},
 volume = {8},
 year = {2020}
}

@article{8954698,
 abstract = {Models based on deep learning are prone to misjudging the results when faced with adversarial examples. In this paper, we propose an MCTS-T algorithm for generating adversarial examples of cross-site scripting (XSS) attacks based on Monte Carlo tree search (MCTS) algorithm. The MCTS algorithm enables the generation model to provide a reward value that reflects the probability of generative examples bypassing the detector. To guarantee the antagonism and feasibility of the generative adversarial examples, the bypassing rules are restricted. The experimental results indicate that the missed detection rate of adversarial examples is significantly improved after the MCTS-T generation algorithm. Additionally, we construct a generative adversarial network (GAN) to optimize the detector and improve the detection rate when dealing with adversarial examples. After several epochs of adversarial training, the accuracy of detecting adversarial examples is significantly improved.},
 author = {Zhang, Xueqin and Zhou, Yue and Pei, Songwen and Zhuge, Jingjing and Chen, Jiahao},
 doi = {10.1109/ACCESS.2020.2965184},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Training;Feature extraction;Gallium nitride;Encoding;Detectors;Malware;Network intrusion detection;generative adversarial network;Monte Carlo tree;convolutional neural networks},
 month = {},
 number = {},
 pages = {10989-10996},
 title = {Adversarial Examples Detection for XSS Attacks Based on Generative Adversarial Networks},
 volume = {8},
 year = {2020}
}

@article{8960303,
 abstract = {Cryptographic technology has been commonly used in malware for hiding their static characteristics and malicious behaviors to avoid the detection of anti-virus engines and counter the reverse analysis from security researchers. The detection of cryptographic functions in an effective way in malware has vital significance for malicious code detection and deep analysis. Many efforts have been made to solve this issue, while existing methods suffer from some issues, such as unable to achieve promising results in accuracy, limited by prior knowledge, and have a high overhead. In this paper, we draw on the idea of text classification in the field of natural language processing and propose a novel neural network to detect the type of cryptographic functions. The new network is an end-2-end model which includes two important modules: Instruction-2-vec and K-Max-CNN-Attention. The Instruction-2-vec model extracts the “words” of assembly instructions and transfers them into continuous vectors. The K-Max-CNN-Attention is used to encode the instruction vectors and generate the representation of the function. And we designed a softmax classifier to predict the categories of the functions. Extensive experiments were conducted on a collected dataset which contains 15 common types of cryptographic functions extracted from malware, to assess the validity of the proposed approach. The experiment results showed that the proposed approach archives a better performance than the recent embedding network SAFE with the Precision, Recall and F1-score of 0.9349, 0.8933 and 0.9020, respectively. We also compared it with four widely-used tools, the results demonstrated that our approach is much better in accuracy and effectiveness than all of them.},
 author = {Jia, Li and Zhou, Anmin and Jia, Peng and Liu, Luping and Wang, Yan and Liu, Liang},
 doi = {10.1109/ACCESS.2020.2966860},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cryptography;Malware;Heuristic algorithms;Neural networks;Feature extraction;Binary codes;Semantics;Cryptographic function detection;neural network;function embedding;binary analysis},
 month = {},
 number = {},
 pages = {23506-23521},
 title = {A Neural Network-Based Approach for Cryptographic Function Detection in Malware},
 volume = {8},
 year = {2020}
}

@article{8963730,
 abstract = {Cybersecurity is a fast-evolving discipline that is always in the news over the last decade, as the number of threats rises and cybercriminals constantly endeavor to stay a step ahead of law enforcement. Over the years, although the original motives for carrying out cyberattacks largely remain unchanged, cybercriminals have become increasingly sophisticated with their techniques. Traditional cybersecurity solutions are becoming inadequate at detecting and mitigating emerging cyberattacks. Advances in cryptographic and Artificial Intelligence (AI) techniques (in particular, machine learning and deep learning) show promise in enabling cybersecurity experts to counter the ever-evolving threat posed by adversaries. Here, we explore AI's potential in improving cybersecurity solutions, by identifying both its strengths and weaknesses. We also discuss future research opportunities associated with the development of AI techniques in the cybersecurity field across a range of application domains.},
 author = {Zeadally, Sherali and Adi, Erwin and Baig, Zubair and Khan, Imran A.},
 doi = {10.1109/ACCESS.2020.2968045},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Machine learning;Malware;Artificial intelligence;cybersecurity;cyberattacks;machine learning},
 month = {},
 number = {},
 pages = {23817-23837},
 title = {Harnessing Artificial Intelligence Capabilities to Improve Cybersecurity},
 volume = {8},
 year = {2020}
}

@article{8966259,
 abstract = {The work presented in this paper deals with a proactive network monitoring for security and protection of computing infrastructures. We provide an exploitation of an intelligent module, in the form of a as a machine learning application using deep learning modeling, in order to enhance functionality of intrusion detection system supervising network traffic flows. Currently, intrusion detection systems work well for network monitoring in near real-time and they effectively deal with threats in a reactive way. Deep learning is the emerging generation of artificial intelligence techniques and one of the most promising candidates for intelligence integration into traditional solutions leading to quality improvement of the original solutions. The work presented in this paper faces the challenge of cooperation between deep learning techniques and large-scale data processing. The outcomes obtained from extensive and careful experiments show the applicability and feasibility of simultaneously modelled multiple monitoring channels using deep learning techniques. The proper joining of deep learning modelling with scalable data preprocessing ensures high quality and stability of model performance in dynamic and fast-changing environments such as network traffic flow monitoring.},
 author = {Nguyen, Giang and Dlugolinsky, Stefan and Tran, Viet and López García, Álvaro},
 doi = {10.1109/ACCESS.2020.2968718},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Deep learning;Forecasting;Real-time systems;Time series analysis;Intrusion detection;Deep learning;proactive forecasting;network monitoring;cyber security;anomaly detection;neural machine translation},
 month = {},
 number = {},
 pages = {19696-19716},
 title = {Deep Learning for Proactive Network Monitoring and Security Protection},
 volume = {8},
 year = {2020}
}

@article{8979381,
 abstract = {In communications, innovative paradigm shifts have emerged in integrating various devices into the network to provide advanced and intelligent services. However, various security threats may occur that may not always be detected using traditional cryptographic techniques. Secure authentication is of paramount importance in modern wireless systems. This paper focusses on robust authentication in a time-varying communication environment where conventional authentication mechanisms are severely limited. We propose an Adaptive Neural Network (ANN) as an intelligent authentication process to improve detection accuracy. Specifically, a Data-Adaptive Matrix (DAM) is designed to track time-varying channel features. By utilizing a convolutional neural network as an intelligent authenticator, the proposed approach integrates deep feature extraction and attack detection, hence, leading to effective physical layer security. To evaluate the system, the ANN is prototyped on a universal software radio peripheral (USRP) and its authentication performance is evaluated in a conference room environment. Experimental results show that the ANN is effective in tackling the challenges of physical layer authentication under interference conditions, and is effective in time-varying environments.},
 author = {Qiu, Xiaoying and Dai, Jianmei and Hayes, Monson},
 doi = {10.1109/ACCESS.2020.2971260},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Authentication;Wireless communication;Physical layer security;Communication system security;Feature extraction;Convolutional neural network;physical layer security;intrusion detection;machine learning},
 month = {},
 number = {},
 pages = {26139-26149},
 title = {A Learning Approach for Physical Layer Authentication Using Adaptive Neural Network},
 volume = {8},
 year = {2020}
}

@article{8981962,
 abstract = {A Web attack protection system is extremely essential in today's information age. Classifier ensembles have been considered for anomaly-based intrusion detection in Web traffic. However, they suffer from an unsatisfactory performance due to a poor ensemble design. This paper proposes a stacked ensemble for anomaly-based intrusion detection systems in a Web application. Unlike a conventional stacking, where some single weak learners are prevalently used, the proposed stacked ensemble is an ensemble architecture, yet its base learners are other ensembles learners, i.e. random forest, gradient boosting machine, and XGBoost. To prove the generalizability of the proposed model, two datasets that are specifically used for attack detection in a Web application, i.e. CSIC-2010v2 and CICIDS-2017 are used in the experiment. Furthermore, the proposed model significantly surpasses existing Web attack detection techniques concerning the accuracy and false positive rate metrics. Validation result on the CICIDS-2017, NSL-KDD, and UNSW-NB15 dataset also ameliorate the ones obtained by some recent techniques. Finally, the performance of all classification algorithms in terms of a two-step statistical significance test is further discussed, providing a value-added contribution to the current literature.},
 author = {Tama, Bayu Adhi and Nkenyereye, Lewis and Islam, S.M. Riazul and Kwak, Kyung-Sup},
 doi = {10.1109/ACCESS.2020.2969428},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Intrusion detection;Boosting;Organizations;Internet;Radio frequency;Random forest;gradient boosting machine;Web attack;performance benchmark;anomaly-based IDSs;significance tests},
 month = {},
 number = {},
 pages = {24120-24134},
 title = {An Enhanced Anomaly Detection in Web Traffic Using a Stack of Classifier Ensemble},
 volume = {8},
 year = {2020}
}

@article{8988230,
 abstract = {Intrusion detection can identify unknown attacks from network traffics and has been an effective means of network security. Nowadays, existing methods for network anomaly detection are usually based on traditional machine learning models, such as KNN, SVM, etc. Although these methods can obtain some outstanding features, they get a relatively low accuracy and rely heavily on manual design of traffic features, which has been obsolete in the age of big data. To solve the problems of low accuracy and feature engineering in intrusion detection, a traffic anomaly detection model BAT is proposed. The BAT model combines BLSTM (Bidirectional Long Short-term memory) and attention mechanism. Attention mechanism is used to screen the network flow vector composed of packet vectors generated by the BLSTM model, which can obtain the key features for network traffic classification. In addition, we adopt multiple convolutional layers to capture the local features of traffic data. As multiple convolutional layers are used to process data samples, we refer BAT model as BAT-MC. The softmax classifier is used for network traffic classification. The proposed end-to-end model does not use any feature engineering skills and can automatically learn the key features of the hierarchy. It can well describe the network traffic behavior and improve the ability of anomaly detection effectively. We test our model on a public benchmark dataset, and the experimental results demonstrate our model has better performance than other comparison methods.},
 author = {Su, Tongtong and Sun, Huazhi and Zhu, Jinqi and Wang, Sheng and Li, Yabo},
 doi = {10.1109/ACCESS.2020.2972627},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Deep learning;Anomaly detection;Machine learning algorithms;Pattern matching;Network traffic;intrusion detection;deep learning;BLSTM;attention mechanism},
 month = {},
 number = {},
 pages = {29575-29585},
 title = {BAT: Deep Learning Methods on Network Intrusion Detection Using NSL-KDD Dataset},
 volume = {8},
 year = {2020}
}

@article{8993711,
 abstract = {In recent years, due to the extensive use of the Internet, the number of networked computers has been increasing in our daily lives. Weaknesses of the servers enable hackers to intrude on computers by using not only known but also new attack-types, which are more sophisticated and harder to detect. To protect the computers from them, Intrusion Detection System (IDS), which is trained with some machine learning techniques by using a pre-collected dataset, is one of the most preferred protection mechanisms. The used datasets were collected during a limited period in some specific networks and generally don't contain up-to-date data. Additionally, they are imbalanced and cannot hold sufficient data for all types of attacks. These imbalanced and outdated datasets decrease the efficiency of current IDSs, especially for rarely encountered attack types. In this paper, we propose six machine-learning-based IDSs by using K Nearest Neighbor, Random Forest, Gradient Boosting, Adaboost, Decision Tree, and Linear Discriminant Analysis algorithms. To implement a more realistic IDS, an up-to-date security dataset, CSE-CIC-IDS2018, is used instead of older and mostly worked datasets. The selected dataset is also imbalanced. Therefore, to increase the efficiency of the system depending on attack types and to decrease missed intrusions and false alarms, the imbalance ratio is reduced by using a synthetic data generation model called Synthetic Minority Oversampling TEchnique (SMOTE). Data generation is performed for minor classes, and their numbers are increased to the average data size via this technique. Experimental results demonstrated that the proposed approach considerably increases the detection rate for rarely encountered intrusions.},
 author = {Karatas, Gozde and Demir, Onder and Sahingoz, Ozgur Koray},
 doi = {10.1109/ACCESS.2020.2973219},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Support vector machines;Intrusion detection;Random forests;Computer hacking;Servers;IDS;intrusion detection;SMOTE;machine learning;CSE-CIC-IDS2018;imbalanced dataset},
 month = {},
 number = {},
 pages = {32150-32162},
 title = {Increasing the Performance of Machine Learning-Based IDSs on an Imbalanced and Up-to-Date Dataset},
 volume = {8},
 year = {2020}
}

@article{8998253,
 abstract = {Intrusion detection system (IDS) plays an important role in network security by discovering and preventing malicious activities. Due to the complex and time-varying network environment, the network intrusion samples are submerged into a large number of normal samples, which leads to insufficient samples for model training and detection results with a high false detection rate. According to the problem of data imbalance, we propose a network intrusion detection algorithm combined hybrid sampling with deep hierarchical network. Firstly, we use the one-side selection (OSS) to reduce the noise samples in majority category, and then increase the minority samples by Synthetic Minority Over-sampling Technique (SMOTE). In this way, a balanced dataset can be established to make the model fully learn the features of minority samples and greatly reduce the model training time. Secondly, we use convolution neural network (CNN) to extract spatial features and Bi-directional long short-term memory (BiLSTM) to extract temporal features, which forms a deep hierarchical network model. The proposed network intrusion detection algorithm was verified by experiments on the NSL-KDD and UNSW-NB15 dataset, and the classification accuracy can achieve 83.58% and 77.16%, respectively.},
 author = {Jiang, Kaiyuan and Wang, Wenya and Wang, Aili and Wu, Haibin},
 doi = {10.1109/ACCESS.2020.2973730},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Data models;Support vector machines;Telecommunication traffic;Training;Classification algorithms;Network intrusion detection;hybrid sampling;deep hierarchical network;convolution neural network;bi-directional long short-term memory},
 month = {},
 number = {},
 pages = {32464-32476},
 title = {Network Intrusion Detection Combined Hybrid Sampling With Deep Hierarchical Network},
 volume = {8},
 year = {2020}
}

@article{9016053,
 abstract = {As novel technologies continue to reshape the digital era, cyberattacks are also increasingly becoming more commonplace and sophisticated. Distributed denial of service (DDoS) attacks are, perhaps, the most prevalent and exponentially-growing attack, targeting the varied and emerging computational network infrastructures across the globe. This necessitates the design of an efficient and early detection of large-scale sophisticated DDoS attacks. Software defined networks (SDN) point to a promising solution, as a network paradigm which decouples the centralized control intelligence from the forwarding logic. In this work, a deep convolutional neural network (CNN) ensemble framework for efficient DDoS attack detection in SDNs is proposed. The proposed framework is evaluated on a current state-of-the-art Flow-based dataset under established benchmarks. Improved accuracy is demonstrated against existing related detection approaches.},
 author = {Haider, Shahzeb and Akhunzada, Adnan and Mustafa, Iqra and Patel, Tanil Bharat and Fernandez, Amanda and Choo, Kim-Kwang Raymond and Iqbal, Javed},
 doi = {10.1109/ACCESS.2020.2976908},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Machine learning;Software;Anomaly detection;Feature extraction;Benchmark testing;Computer architecture;Software defined network (SDN);anomaly detection;distributed denial of service (DDoS);deep learning;deep convolutional neural network (CNN)},
 month = {},
 number = {},
 pages = {53972-53983},
 title = {A Deep CNN Ensemble Framework for Efficient DDoS Attack Detection in Software Defined Networks},
 volume = {8},
 year = {2020}
}

@article{9016201,
 abstract = {Existing intrusion detection and defense models for CPSS (Cyber-Physical-Social Systems) are based on analyzing the static intrusion characteristics, which cannot effectively detect large-scale Low-Rate Denial-of-Service (LR-DDoS) attacks, especially in the edge environment. In this paper, we firstly explore and enhance Mirai botnet to a sophisticated multi-targets low-rate TCP attack network, which makes edge LR-DDoS more powerful and obfuscates their activity. And then, we develop a novel intrusion detection and defense hybrid method for above CPSS LR-DDoS scenario in edge environment, which takes advantage of locality sensitive features extraction and Deep Convolution Neural Network (DCNN) to auto learn the optimal features of the original data distribution and employs deep reinforcement learning Q-network as the powerful decision maker to defend attacks. The experimental results in detection phase prove the proposed method can distinguish abnormal network attack flows with higher detection accuracy and faster response time than kinds of Support Vector Machines (SVM), K-means and Surface Learning Neural Network etc. Even more, it has a certain detection rate for unknown new attacks, which means the method is effective and suitable for the actual network environment. The experimental results in defense phase prove it can defense LR-DDoS attacks smoothly.},
 author = {Liu, Zengguang and Yin, Xiaochun and Hu, Yuemei},
 doi = {10.1109/ACCESS.2020.2976706},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Image edge detection;Computer crime;Edge computing;Machine learning;Feature extraction;Botnet;Neural networks;Deep convolution neural network;Q learning;deep reinforcement learning;edge computing;LR-DDoS;CPSS},
 month = {},
 number = {},
 pages = {42120-42130},
 title = {CPSS LR-DDoS Detection and Defense in Edge Computing Utilizing DCNN Q-Learning},
 volume = {8},
 year = {2020}
}

@article{9017945,
 abstract = {To explore the advantages of adversarial learning and deep learning, we propose a novel network intrusion detection model called SAVAER-DNN, which can not only detect known and unknown attacks but also improve the detection rate of low-frequent attacks. SAVAER is a supervised variational auto-encoder with regularization, which uses WGAN-GP instead of the vanilla GAN to learn the latent distribution of the original data. SAVAER's decoder is used to synthesize samples of low-frequent and unknown attacks, thereby increasing the diversity of training samples and balancing the training data set. SAVAER's encoder is used to initialize the weights of the hidden layers of the DNN and explore high-level feature representations of the original samples. The benchmark NSL-KDD (KDDTest+), NSL-KDD (KDDTest-21) and UNSW-NB15 datasets are used to evaluate the performance of the proposed model. The experimental results show that the proposed SAVAER-DNN is more suitable for data augmentation than the other three well-known data oversampling methods. Moreover, the proposed SAVAER-DNN outperforms eight well-known classification models in detection performance and is more effective in detecting low-frequent and unknown attacks. Furthermore, compared with other state-of-the-art intrusion detection models reported in the IDS literature, the proposed SAVAER-DNN offers better performance in terms of overall accuracy, detection rate, F1 score, and false positive rate.},
 author = {Yang, Yanqing and Zheng, Kangfeng and Wu, Bin and Yang, Yixian and Wang, Xiujuan},
 doi = {10.1109/ACCESS.2020.2977007},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Feature extraction;Training;Gallium nitride;Neural networks;Intrusion detection;supervised adversarial variational auto-encoder;regularization;WGAN-GP;deep learning},
 month = {},
 number = {},
 pages = {42169-42184},
 title = {Network Intrusion Detection Based on Supervised Adversarial Variational Auto-Encoder With Regularization},
 volume = {8},
 year = {2020}
}

@article{9032126,
 abstract = {Network intrusion detection is an essential means to ensure the security of the network information system. In the real network, abnormal behaviors occur much less frequently than normal behaviors, resulting in scarcity of abnormal samples. We proposed an intrusion detection method based on Few-Shot Learning (FSL), which only used less than 1% of NSL-KDD KDDTrain+ dataset for training, and achieved high accuracy of 92.34% for KDD-Test+ and 85.75% for KDD-Test-21, while other methods, such as J48, Naive Bayes(NB), Random Forest(RF), Support Vector Machine(SVM), recurrent neural network(RNN) and Channel boosted and residual learning based deep convolutional neural network (CBR-CNN), used 20% of KDDTrain+ dataset for training, and achieved relatively low accuracy (less than 89.41% for KDD-Test+ and less than 80.36% for KDD-Test-21). The experiment on dataset of UNSW- NB15 showed a similar result. The detection rates for Dos, U2R, R2L and U2R are improved by our method too, especially for U2R and R2L, which only take up a small proportion of the dataset, the detection rates are increased from 13% to 81.50% and 44.41% to 75.93%, respectively.},
 author = {Yu, Yingwei and Bian, Naizheng},
 doi = {10.1109/ACCESS.2020.2980136},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Intrusion detection;Machine learning;Measurement;Feature extraction;Neural networks;Testing;Few-shot learning;intrusion detection;deep learning;data scarcity},
 month = {},
 number = {},
 pages = {49730-49740},
 title = {An Intrusion Detection Method Using Few-Shot Learning},
 volume = {8},
 year = {2020}
}

@article{9036935,
 abstract = {Networks had an increasing impact on modern life since network cybersecurity has become an important research field. Several machine learning techniques have been developed to build network intrusion detection systems for correctly detecting unforeseen cyber-attacks at the network-level. For example, deep artificial neural network architectures have recently achieved state-of-the-art results. In this paper a novel deep neural network architecture is defined, in order to learn flexible and effective intrusion detection models, by combining an unsupervised stage for multi-channel feature learning with a supervised one exploiting feature dependencies on cross channels. The aim is to investigate whether class-specific features of the network flows could be learned and added to the original ones in order to increase the model accuracy. In particular, in the unsupervised stage, two autoencoders are separately learned on normal and attack flows, respectively. As the top layer in the decoder of these autoencoders reconstructs samples in the same space as the input one, they could be used to define two new feature vectors allowing the representation of each network flow as a multi-channel sample. In the supervised stage, a multi-channel parametric convolution is adopted, in order to learn the effect of each channel on the others. In particular, as the samples belong to two different distributions (normal and attack flows), the samples labelled as normal should be more similar to the representation reconstructed with the normal autoencoder than that of the attack one, and viceversa. This expected dependency will be exploited to better disentangle the differences between normal and attack flows. The proposed neural network architecture leads to better predictive accuracy when compared to competitive intrusion detection architectures on three benchmark datasets.},
 author = {Andresini, Giuseppina and Appice, Annalisa and Mauro, Nicola Di and Loglisci, Corrado and Malerba, Donato},
 doi = {10.1109/ACCESS.2020.2980937},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Deep learning;Neural networks;Computer architecture;Decoding;Cybersecurity;intrusion detection;machine learning;computer security},
 month = {},
 number = {},
 pages = {53346-53359},
 title = {Multi-Channel Deep Feature Learning for Intrusion Detection},
 volume = {8},
 year = {2020}
}

@article{9044370,
 abstract = {Network intrusion detection system (NIDS) is a commonly used tool to detect attacks and protect networks, while one of its general limitations is the false positive issue. On the basis of our comparative experiments and analysis for the characteristics of the particle swarm optimization (PSO) and Xgboost, this paper proposes the PSO-Xgboost model given its overall higher classification accuracy than other alternative models such like Xgboost, Random Forest, Bagging and Adaboost. Firstly, a classification model based on Xgboost is constructed, and then PSO is used to adaptively search for the optimal structure of Xgboost. The benchmark NSL-KDD dataset is used to evaluate the proposed model. Our experimental results demonstrate that PSO-Xgboost model outperforms other comparative models in precision, recall, macro-average (macro) and mean average precision (mAP), especially when identifying minority groups of attacks like U2R and R2L. This work also provides experimental arguments for the application of swarm intelligence in NIDS.},
 author = {Jiang, Hui and He, Zheng and Ye, Gang and Zhang, Huyin},
 doi = {10.1109/ACCESS.2020.2982418},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Adaptation models;Network intrusion detection;Particle swarm optimization;Machine learning algorithms;Machine learning;Support vector machines;Optimization;Intrusion detection;PSO-Xgboost;ensemble learning;particle swarm optimization},
 month = {},
 number = {},
 pages = {58392-58401},
 title = {Network Intrusion Detection Based on PSO-Xgboost Model},
 volume = {8},
 year = {2020}
}

@article{9044377,
 abstract = {We propose a neural network architecture for detecting intrusions on the controller area network (CAN). The latter is the standard communication method between the electronic control units (ECUs) of automobiles. However, CAN lacks security mechanisms and it has recently been shown that it can be attacked remotely. Hence, it is desirable to monitor CAN traffic to detect intrusions. In order to find both, known and unknown intrusion scenarios, we consider a novel unsupervised learning approach which we call CANet. To our knowledge, this is the first deep learning based intrusion detection system (IDS) that naturally handles the data structure of the high dimensional CAN bus, where different message types are sent at different times. Our method is evaluated on real and synthetic CAN data. A comparison with previous machine learning based methods shows that CANet outperforms them by a significant margin. For reproducibility of the method, our synthetic data is publicly available.},
 author = {Hanselmann, Markus and Strauss, Thilo and Dormann, Katharina and Ulmer, Holger},
 doi = {10.1109/ACCESS.2020.2982544},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Neural networks;Payloads;Intrusion detection;Standards;Automobiles;Deep learning;Network architecture;CAN bus;deep learning;intrusion detection},
 month = {},
 number = {},
 pages = {58194-58205},
 title = {CANet: An Unsupervised Intrusion Detection System for High Dimensional CAN Bus Data},
 volume = {8},
 year = {2020}
}

@article{9050476,
 abstract = {With the continuous development of network technology, cyberattack detection mechanisms play a vital role in ensuring the security of computers and network systems. However, with the rapid growth of network traffic, traditional intrusion detection systems (IDSs) are far from being able to quickly and accurately identify complex and diverse network attacks, especially those related to low-frequency attacks. To enhance the overall security of the Internet, an IDS based on hierarchical long short-term memory (HLSTM) networks is proposed. With the introduction of HLSTM, the network can learn across multiple levels of temporal hierarchy over complex network traffic sequences. The system is evaluated on the well-known benchmark data set NSL-KDD for comparison with other existing methods. The experimental results demonstrate that compared with existing start-of-the-art methods, our system has better detection performance for different types of cyberattacks. In addition, the low-frequency network attack types have higher classification accuracy and a lower false detection rate.},
 author = {Hou, Haixia and Xu, Yingying and Chen, Menghan and Liu, Zhi and Guo, Wei and Gao, Mingcheng and Xin, Yang and Cui, Lizhen},
 doi = {10.1109/ACCESS.2020.2983953},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Cyberattack;Training;Deep learning;Data models;Data preprocessing;HLSTM;cyberattack detection;NSL-KDD data set;intrusion detection system},
 month = {},
 number = {},
 pages = {90907-90913},
 title = {Hierarchical Long Short-Term Memory Network for Cyberattack Detection},
 volume = {8},
 year = {2020}
}

@article{9050562,
 abstract = {Network security has always been a hot topic as security and reliability are vital to software and hardware. Network intrusion detection system (NIDS) is an effective solution to the identification of attacks in computer and communication systems. A necessary condition for high-quality intrusion detection is the gathering of useful and precise intrusion information. Machine learning, particularly deep learning, has achieved a lot of success in various fields of industry and academic due to its good ability of feature representation and extraction. In this paper, deep learning methods are integrated into the NIDS. The intrusion activity is regarded as a time-series event and a bidirectional gated recurrent unit (GRU) based network intrusion detection model with hierarchical attention mechanism is presented. The influence of different lengths of previous traffic on the performance is then studied. Some experiments are performed on the dataset UNSW-NB15, in which the proposed hierarchical attention model achieves satisfactory detection accuracy of more than 98.76% and a false alarm rate (FAR) of lower than 1.2%. An attention probability map to reflect the importance of features is then visualized using the attention mechanism. The visualization ability assists in providing an understanding of the varied importance of the same features for different traffic classes and to determine feature selection in the future.},
 author = {Liu, Chang and Liu, Yang and Yan, Yu and Wang, Ji},
 doi = {10.1109/ACCESS.2020.2983568},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Network intrusion detection;Deep learning;Recurrent neural networks;Intrusion detection system;recurrent neural network;attention mechanism;visualization},
 month = {},
 number = {},
 pages = {67542-67554},
 title = {An Intrusion Detection Model With Hierarchical Attention Mechanism},
 volume = {8},
 year = {2020}
}

@article{9055368,
 abstract = {An ever-increasing number of computing devices interconnected through wireless networks encapsulated in the cyber-physical-social systems and a significant amount of sensitive network data transmitted among them have raised security and privacy concerns. Intrusion detection system (IDS) is known as an effective defence mechanism and most recently machine learning (ML) methods are used for its development. However, Internet of Things (IoT) devices often have limited computational resources such as limited energy source, computational power and memory, thus, traditional ML-based IDS that require extensive computational resources are not suitable for running on such devices. This study thus is to design and develop a lightweight ML-based IDS tailored for the resource-constrained devices. Specifically, the study proposes a lightweight ML-based IDS model namely IMPACT (IMPersonation Attack deteCTion using deep auto-encoder and feature abstraction). This is based on deep feature learning with gradient-based linear Support Vector Machine (SVM) to deploy and run on resource-constrained devices by reducing the number of features through feature extraction and selection using a stacked autoencoder (SAE), mutual information (MI) and C4.8 wrapper. The IMPACT is trained on Aegean Wi-Fi Intrusion Dataset (AWID) to detect impersonation attack. Numerical results show that the proposed IMPACT achieved 98.22% accuracy with 97.64% detection rate and 1.20% false alarm rate and outperformed existing state-of-the-art benchmark models. Another key contribution of this study is the investigation of the features in AWID dataset for its usability for further development of IDS.},
 author = {Lee, Seo Jin and Yoo, Paul D. and Asyhari, A. Taufiq and Jhi, Yoonchan and Chermak, Lounis and Yeun, Chan Yeob and Taha, Kamal},
 doi = {10.1109/ACCESS.2020.2985089},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Training;Neurons;Security;Edge computing;Computational modeling;Image edge detection;IoT security;intrusion detection;feature engineering;mutual information;machine learning;edge computing},
 month = {},
 number = {},
 pages = {65520-65529},
 title = {IMPACT: Impersonation Attack Detection via Edge Computing Using Deep Autoencoder and Feature Abstraction},
 volume = {8},
 year = {2020}
}

@article{9057526,
 abstract = {Browser-based cloud storage services are still broadly used in enterprises for online sharing and collaboration. However, sensitive information in images or documents may be easily leaked outside trusted enterprise on-premises due to such cloud services. Existing solutions to prevent data leakage in cloud storage services either limit many functionalities of cloud applications or are difficult to be scaled to various cloud applications. In this paper, we propose CloudDLP, a transparent and scalable approach for enterprises to automatically sanitize sensitive data in images and documents with various browser-based cloud applications. CloudDLP is deployed as an internet gateway within the premises of an enterprise using JavaScript injecting techniques and deep learning methods to sanitize sensitive premise data. It neither compromises the user experience nor significantly affects application functionalities in browser-based cloud storage services. We have evaluated CloudDLP with a number of real-world cloud applications. Our experimental results show that it can achieve automatic data sanitization with cloud storage services while preserving most functionalities of cloud applications.},
 author = {Han, Peiyi and Liu, Chuanyi and Cao, Jiahao and Duan, Shaoming and Pan, Hezhong and Cao, Zekun and Fang, Binxing},
 doi = {10.1109/ACCESS.2020.2985870},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing;Storage management;Trusted computing;Data security;Data loss prevention;data sanitization;data security;cloud storage},
 month = {},
 number = {},
 pages = {68449-68459},
 title = {CloudDLP: Transparent and Scalable Data Sanitization for Browser-Based Cloud Storage},
 volume = {8},
 year = {2020}
}

@article{9057709,
 abstract = {The Internet of Things (IoT) has lately developed into an innovation for developing smart environments. Security and privacy are viewed as main problems in any technology's dependence on the IoT model. Privacy and security issues arise due to the different possible attacks caused by intruders. Thus, there is an essential need to develop an intrusion detection system for attack and anomaly identification in the IoT system. In this work, we have proposed a deep learning-based method Deep Belief Network (DBN) algorithm model for the intrusion detection system. Regarding the attacks and anomaly detection, the CICIDS 2017 dataset is utilized for the performance analysis of the present IDS model. The proposed method produced better results in all the parameters in relation to accuracy, recall, precision, F1-score, and detection rate. The proposed method has achieved 99.37% accuracy for normal class, 97.93% for Botnet class, 97.71% for Brute Force class, 96.67% for Dos/DDoS class, 96.37% for Infiltration class, 97.71% for Ports can class and 98.37% for Web attack, and these results were compared with various classifiers as shown in the results.},
 author = {Manimurugan, S. and Al-Mutairi, Saad and Aborokbah, Majed Mohammed and Chilamkurti, Naveen and Ganesan, Subramaniam and Patan, Rizwan},
 doi = {10.1109/ACCESS.2020.2986013},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Data models;Mathematical model;Training;Anomaly detection;Internet of Things;IoT;deep learning;anomaly detection;intrusion detection;DBN},
 month = {},
 number = {},
 pages = {77396-77404},
 title = {Effective Attack Detection in Internet of Medical Things Smart Environment Using a Deep Belief Neural Network},
 volume = {8},
 year = {2020}
}

@article{9063416,
 abstract = {Deep Learning has been widely applied to problems in detecting various network attacks. However, no cases on network security have shown applications of various deep learning algorithms in real-time services beyond experimental conditions. Moreover, owing to the integration of high-performance computing, it is necessary to apply systems that can handle large-scale traffic. Given the rapid evolution of web-attacks, we implemented and applied our Artificial Intelligence-based Intrusion Detection System (AI-IDS). We propose an optimal convolutional neural network and long short-term memory network (CNN-LSTM) model, normalized UTF-8 character encoding for Spatial Feature Learning (SFL) to adequately extract the characteristics of real-time HTTP traffic without encryption, calculating entropy, and compression. We demonstrated its excellence through repeated experiments on two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. By training payloads that analyzed true or false positives with a labeling tool, AI-IDS distinguishes sophisticated attacks, such as unknown patterns, encoded or obfuscated attacks from benign traffic. It is a flexible and scalable system that is implemented based on Docker images, separating user-defined functions by independent images. It also helps to write and improve Snort rules for signature-based IDS based on newly identified patterns. As the model calculates the malicious probability by continuous training, it could accurately analyze unknown web-attacks.},
 author = {Kim, Aechan and Park, Mohyun and Lee, Dong Hoon},
 doi = {10.1109/ACCESS.2020.2986882},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Machine learning;Real-time systems;Wireless sensor networks;Payloads;Computer networks;intrusion detection;neural networks;large-scale systems;intelligent systems;real time systems;security;CNN-LSTM},
 month = {},
 number = {},
 pages = {70245-70261},
 title = {AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection},
 volume = {8},
 year = {2020}
}

@article{9064510,
 abstract = {Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.},
 author = {Xue, Mingfu and Yuan, Chengxiang and Wu, Heyi and Zhang, Yushu and Liu, Weiqiang},
 doi = {10.1109/ACCESS.2020.2987435},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning;Security;Data models;Machine learning algorithms;Training;Training data;Prediction algorithms;Artificial intelligence security;poisoning attacks;backdoor attacks;adversarial examples;privacy-preserving machine learning},
 month = {},
 number = {},
 pages = {74720-74742},
 title = {Machine Learning Security: Threats, Countermeasures, and Evaluations},
 volume = {8},
 year = {2020}
}

@article{9069273,
 abstract = {In recent years, machine learning-based intrusion detection systems (IDSs) have proven to be effective; especially, deep neural networks improve the detection rates of intrusion detection models. However, as models become more and more complex, people can hardly get the explanations behind their decisions. At the same time, most of the works about model interpretation focuses on other fields like computer vision, natural language processing, and biology. This leads to the fact that in practical use, cybersecurity experts can hardly optimize their decisions according to the judgments of the model. To solve these issues, a framework is proposed in this paper to give an explanation for IDSs. This framework uses SHapley Additive exPlanations (SHAP), and combines local and global explanations to improve the interpretation of IDSs. The local explanations give the reasons why the model makes certain decisions on the specific input. The global explanations give the important features extracted from IDSs, present the relationships between the feature values and different types of attacks. At the same time, the interpretations between two different classifiers, one-vs-all classifier and multiclass classifier, are compared. NSL-KDD dataset is used to test the feasibility of the framework. The framework proposed in this paper leads to improve the transparency of any IDS, and helps the cybersecurity staff have a better understanding of IDSs' judgments. Furthermore, the different interpretations between different kinds of classifiers can also help security experts better design the structures of the IDSs. More importantly, this work is unique in the intrusion detection field, presenting the first use of the SHAP method to give explanations for IDSs.},
 author = {Wang, Maonan and Zheng, Kangfeng and Yang, Yanqing and Wang, Xiujuan},
 doi = {10.1109/ACCESS.2020.2988359},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Computational modeling;Predictive models;Machine learning;Biological system modeling;Feature extraction;Intrusion detection system;Shapley value;SHapley Additive exPlanations;model interpretation;machine learning},
 month = {},
 number = {},
 pages = {73127-73141},
 title = {An Explainable Machine Learning Framework for Intrusion Detection Systems},
 volume = {8},
 year = {2020}
}

@article{9072151,
 abstract = {The number of cyber-attacks and data breaches has immensely increased across different enterprises, companies, and industries as a result of the exploitation of the weaknesses in securing Internet of Things (IoT) devices. The increasing number of various devices connected to IoT and their different protocols has led to growing volume of zero-day attacks. Deep learning (DL) has demonstrated its superiority in big data fields and cyber-security. Recently, DL has been used in cyber-attacks detection because of its capability of extracting and learning deep features of known attacks and detecting unknown attacks without the need for manual feature engineering. However, DL cannot be implemented on IoT devices with limited resources because it requires extensive computation, strong power and storage capabilities. This paper presents a comprehensive attack detection framework of a distributed, robust, and high detection rate to detect several IoT cyber-attacks using DL. The proposed framework implements an attack detector on fog nodes because of its distributed nature, high computational capacity and proximity to edge devices. Six DL models are compared to identify the DL model with the best performance. All DL models are evaluated using five different datasets, each of which involves various attacks. Experiments show that the long short-term memory model outperforms the five other DL models. The proposed framework is effective in terms of response time and detection accuracy and can detect several types of cyber-attacks with 99.97% detection rate and 99.96% detection accuracy in binary classification and 99.65% detection accuracy in multi-class classification.},
 author = {Samy, Ahmed and Yu, Haining and Zhang, Hongli},
 doi = {10.1109/ACCESS.2020.2988854},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computational modeling;Feature extraction;Edge computing;Image edge detection;Security;Internet of Things;Machine learning;Attack detection;cybersecurity;deep learning;fog computing;long short term memory;Internet of Things},
 month = {},
 number = {},
 pages = {74571-74585},
 title = {Fog-Based Attack Detection Framework for Internet of Things Using Deep Learning},
 volume = {8},
 year = {2020}
}

@article{9076063,
 abstract = {Intrusion detection technology, as an active and effective dynamic network defense technology, has rapidly become a hot research topic in the field of network security since it was proposed. However, current intrusion detection still faces some problems and challenges that affect its detection performance. Especially with the rapid development of the current network, the volume and dimension of network data are increasing day by day, and the network is full of a large number of unlabeled data, which brings great pressure on the data processing methods of IDS. In view of the tremendous pressure of intrusion detection brought by the current complex and high-dimensional network environment, this paper provides a feasible solution. Firstly, this paper briefly outlines the necessity of feature learning, the shortcomings of traditional feature learning methods and the new breakthroughs brought by deep belief network in feature learning, and focuses on the principle and working mechanism of deep belief network and Principal Component Analysis (PCA). Then, it constructs the intrusion detection model based on PCA-BP and DBN respectively. And through the experimental evaluation of the two detection models, a comparative experiment between deep belief network and principal component analysis is constructed. The experimental results show that deep belief network has unique advantages and good performance in feature learning. Therefore, deep belief network can be applied in the field of intrusion detection to extract effective features from the current high-dimensional and redundant network data, thereby improving the detection performance of IDS and its adaptability to the current complex and high-dimensional network environment.},
 author = {Duan, Tao and Tian, Youhui and Zhang, Hanrui and Liu, Yaozong and Li, Qianmu and Jiang, Jian and Shi, Zongsheng},
 doi = {10.1109/ACCESS.2020.2989498},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Principal component analysis;Biological neural networks;Data processing;Data models;Analytical models;Intrusion detection;data mining;deep belief network},
 month = {},
 number = {},
 pages = {78330-78342},
 title = {Intelligent Processing of Intrusion Detection Data},
 volume = {8},
 year = {2020}
}

@article{9079479,
 abstract = {Intrusion detection plays a critical role in cyber-security domain since malicious attacks cause irreparable damages to cyber-systems. In this work, we propose the I2SP prototype, which is a novel Information Sharing Platform, able to gather, pre-process, model, and distribute network-traffic information. Within the I2SP prototype we build several challenging deep feature learning models for network-traffic intrusion detection. The learnt representations will be utilized for classifying each new network measurement into its corresponding threat level. We evaluate our prototype's performance by conducting case studies using cyber-security data extracted from the Malware Information Sharing Platform (MISP)-API. To the best of our knowledge, we are the first that combine the MISP-API in order to construct an information sharing mechanism that supports multiple novel deep feature learning architectures for intrusion detection. Experimental results justify that the proposed deep feature learning techniques are able to predict accurately MISP threat-levels.},
 author = {Fotiadou, Konstantina and Velivassaki, Terpsichori-Helen and Voulkidis, Artemis and Railis, Konstantinos and Trakadas, Panagiotis and Zahariadis, Theodore},
 doi = {10.1109/OJCOMS.2020.2989925},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Anomaly detection;Malware;Prototypes;Intrusion detection;Computer architecture;Feature extraction;Malware information sharing platform;network intrusion detection, anomaly detection;deep feature learning;convolutional neural networks;long-short memory neural networks;stacked-sparse autoencoders},
 month = {},
 number = {},
 pages = {593-605},
 title = {Incidents Information Sharing Platform for Distributed Attack Detection},
 volume = {1},
 year = {2020}
}

@article{9085352,
 abstract = {Computer networks become complex and dynamic structures. As a result of this fact, the configuration and the managing of this whole structure is a challenging activity. Software-Defined Networks(SDN) is a new network paradigm that, through an abstraction of network plans, seeks to separate the control plane and data plane, and tends as an objective to overcome the limitations in terms of network infrastructure configuration. As in the traditional network environment, the SDN environment is also liable to security vulnerabilities. This work presents a system of detection and mitigation of Distributed Denial of Service (DDoS) attacks and Portscan attacks in SDN environments (LSTM-FUZZY). The LSTM-FUZZY system presented in this work has three distinct phases: characterization, anomaly detection, and mitigation. The system was tested in two scenarios. In the first scenario, we applied IP flows collected from the SDN Floodlight controllers through emulation on Mininet. On the other hand, in the second scenario, the CICDDoS 2019 dataset was applied. The results gained show that the efficiency of the system to assist in network management, detect and mitigate the occurrence of the attacks.},
 author = {Novaes, Matheus P. and Carvalho, Luiz F. and Lloret, Jaime and Proença, Mario Lemes},
 doi = {10.1109/ACCESS.2020.2992044},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Computer crime;Denial-of-service attack;Deep learning;Fuzzy logic;IP networks;DDoS;deep learning;fuzzy;LSTM;portscan;SDN},
 month = {},
 number = {},
 pages = {83765-83781},
 title = {Long Short-Term Memory and Fuzzy Logic for Anomaly Detection and Mitigation in Software-Defined Network Environment},
 volume = {8},
 year = {2020}
}

@article{9086038,
 abstract = {The integration of communication networks and the Internet of Things (IoT) in Industrial Control Systems (ICSs) increases their vulnerability towards cyber-attacks, causing devastating outcomes. Traditional Intrusion Detection Systems (IDSs), which are mainly developed to support information technology systems, count vastly on predefined models and are trained mostly on specific cyber-attacks. Besides, most IDSs do not consider the imbalanced nature of ICS datasets, thereby suffering from low accuracy and high false-positive when being put to use. In this paper, we propose a deep learning model to construct new balanced representations of the imbalanced datasets. The new representations are fed into an ensemble deep learning attack detection model specifically designed for an ICS environment. The proposed attack detection model leverages Deep Neural Network (DNN) and Decision Tree (DT) classifiers to detect cyber-attacks from the new representations. The performance of the proposed model is evaluated based on 10-fold cross-validation on two real ICS datasets. The results show that the proposed method outperforms conventional classifiers, including Random Forest (RF), DNN, and AdaBoost, as well as recent existing models in the literature. The proposed approach is a generalized technique, which can be implemented in existing ICS infrastructures with minimum effort.},
 author = {Al-Abassi, Abdulrahman and Karimipour, Hadis and Dehghantanha, Ali and Parizi, Reza M.},
 doi = {10.1109/ACCESS.2020.2992249},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Integrated circuit modeling;Deep learning;Critical infrastructure;Security;Industrial control;Internet of Things;Cyber-attacks;critical infrastructure;industrial control system;integrity attack;operation technology;information technology;deep learning;neural network},
 month = {},
 number = {},
 pages = {83965-83973},
 title = {An Ensemble Deep Learning-Based Cyber-Attack Detection in Industrial Control System},
 volume = {8},
 year = {2020}
}

@article{9094066,
 abstract = {In a large-scale data environment, the “curse of dimensionality” of high-dimensional feature spaces and the large amount of noisy data make the efficiency and accuracy of intrusion detection systems (IDSs) significantly decrease. To address these challenges, the underlying algorithm can not only reduce dimensionality, but also remove some redundant and irrelevant noise data from the massive data. Accordingly, herein, an IDS combining deep belief network (DBN) with feature-weighted support vector machines (WSVM) is proposed. First, an adaptive learning rate strategy is applied to promote the training performance of the IDBN, which is used for learning deep features from raw data for reducing dimensionality. Second, the particle swarm optimization algorithm is used to optimize the SVM, followed by the determination of the weights of deep features and the best parameters of the Gaussian kernel, resulting in WSVM which can remove weakly related and redundant features from all IDBN-extracted features. The NSL-KDD dataset was used to validate the IDBN-WSVM model. In particular, the model performance was studied and compared to a model comprising a non-weighted SVM and other machine learning methods. Experimental results demonstrate that IDBN-WSVM is well-suited for designing high-precision classification models. The proposed improved model achieves accuracies of 85.73% and 82.36% in binary- and five-category classification experiments, respectively, which is better than or near state-of-the-art method. The IDBN-WSVM model not only saves training time and testing time on large-scale datasets, but also is more robust and has better performance of generalization than traditional methods, which provides a new research method that achieves high accuracy in intrusion detection tasks.},
 author = {Wu, Yukun and Lee, Wei William and Xu, Zhicheng and Ni, Minya},
 doi = {10.1109/ACCESS.2020.2994947},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Support vector machines;Feature extraction;Training;Mathematical model;Machine learning;Computational modeling;Intrusion detection;feature redundancy;deep belief network;feature extraction;NSL-KDD},
 month = {},
 number = {},
 pages = {98600-98611},
 title = {Large-Scale and Robust Intrusion Detection Model Combining Improved Deep Belief Network With Feature-Weighted SVM},
 volume = {8},
 year = {2020}
}

@article{9112664,
 abstract = {Security issues have resulted in severe damage to the cloud computing environment, adversely affecting the healthy and sustainable development of cloud computing. Intrusion detection is one of the technologies for protecting the cloud computing environment from malicious attacks. However, network traffic in the cloud computing environment is characterized by large scale, high dimensionality, and high redundancy, these characteristics pose serious challenges to the development of cloud intrusion detection systems. Deep learning technology has shown considerable potential for intrusion detection. Therefore, this study aims to use deep learning to extract essential feature representations automatically and realize high detection performance efficiently. An effective stacked contractive autoencoder (SCAE) method is presented for unsupervised feature extraction. By using the SCAE method, better and robust low-dimensional features can be automatically learned from raw network traffic. A novel cloud intrusion detection system is designed on the basis of the SCAE and support vector machine (SVM) classification algorithm. The SCAE+SVM approach combines both deep and shallow learning techniques, and it fully exploits their advantages to significantly reduce the analytical overhead. Experiments show that the proposed SCAE+SVM method achieves higher detection performance compared to three other state-of-the-art methods on two well-known intrusion detection evaluation datasets, namely KDD Cup 99 and NSL-KDD.},
 author = {Wang, Wenjuan and Du, Xuehui and Shan, Dibin and Qin, Ruoxi and Wang, Na},
 doi = {10.1109/TCC.2020.3001017},
 issn = {2168-7161},
 journal = {IEEE Transactions on Cloud Computing},
 keywords = {Cloud computing;Feature extraction;Intrusion detection;Telecommunication traffic;Support vector machines;Deep learning;Dimensionality reduction;Cloud computing;intrusion detection system (IDS);feature extraction;deep learning;contractive auto-encoder;support vector machine},
 month = {July},
 number = {3},
 pages = {1634-1646},
 title = {Cloud Intrusion Detection Method Based on Stacked Contractive Auto-Encoder and Support Vector Machine},
 volume = {10},
 year = {2022}
}

@article{9113298,
 abstract = {The rapid increase in network traffic has recently led to the importance of flow-based intrusion detection systems processing a small amount of traffic data. Furthermore, anomaly-based methods, which can identify unknown attacks are also integrated into these systems. In this study, the focus is concentrated on the detection of anomalous network traffic (or intrusions) from flow-based data using unsupervised deep learning methods with semi-supervised learning approach. More specifically, Autoencoder and Variational Autoencoder methods were employed to identify unknown attacks using flow features. In the experiments carried out, the flow-based features extracted out of network traffic data, including typical and different types of attacks, were used. The Receiver Operating Characteristics (ROC) and the area under ROC curve, resulting from these methods were calculated and compared with One-Class Support Vector Machine. The ROC curves were examined in detail to analyze the performance of the methods in various threshold values. The experimental results show that Variational Autoencoder performs, for the most part, better than Autoencoder and One-Class Support Vector Machine.},
 author = {Zavrak, Sultan and İskefiyeli, Murat},
 doi = {10.1109/ACCESS.2020.3001350},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Feature extraction;Telecommunication traffic;Deep learning;Support vector machines;Anomaly detection;Computer hacking;Flow anomaly detection;intrusion detection;deep learning;variational autoencoder;semi-supervised learning},
 month = {},
 number = {},
 pages = {108346-108358},
 title = {Anomaly-Based Intrusion Detection From Network Flow Features Using Variational Autoencoder},
 volume = {8},
 year = {2020}
}

@article{9116984,
 abstract = {A fault diagnosis method based on deep belief network (DBN) is to solve the high fault rate of a submersible reciprocating pumping unit, and to address the difficulties in measurement of downhole operation parameters. The running current of the submersible motor is obtained directly through the ground equipment. The running current is used as the characteristic parameter of the operation status of the submersible reciprocating pumping unit. The vector that is extracted from the running current is used as the input data for the fault diagnosis model. The DBN is firstly trained by the original currents, and then the fault feature's gradual extraction is realized through the multi-layered structure, thereby allowing the fault diagnosis of the submersible reciprocating pumping unit. In the experiment, the fault diagnosis model is tested by simulation samples. Results show that the model can extract the fault feature from the running currents of the submersible motor and implement the fault diagnosis effectively.},
 author = {Yu, Deliang and Zhang, Huibo},
 doi = {10.1109/ACCESS.2020.3002376},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Underwater vehicles;Visualization;Fault diagnosis;Pumps;Oils;Circuit faults;Submersible reciprocating pumping unit;deep belief network;original current;fault diagnose;feature extraction},
 month = {},
 number = {},
 pages = {109940-109948},
 title = {Fault Diagnosis Method for Submersible Reciprocating Pumping Unit Based on Deep Belief Network},
 volume = {8},
 year = {2020}
}

@article{9117020,
 abstract = {Software Defined Network (SDN) is a flexible paradigm that provides support for a variety of data-intensive applications with real-world smart Internet of Things (IoT) devices. This emerging architecture updates with the managing ability and network control. Still, the benefits are challenging to achieve due to the presence of intruder flow into the network. The research topic of intrusion detection and prevention system (IDPS) has grasped the attention to reduce the effect of intruders. Distributed Denial of Service (DDoS) is a targeted attack that develops malicious traffic is flooded into a particular network device. These intruders also involve even with legitimate network devices, the authenticated device will be compromised to inject malicious traffic. In this paper, we investigate the involvement of intruders in three-Tier IDPS with regard to user validation, packet validation and flow validation. Not all the authentication users can be legitimate, since they are compromised, so that the major contribution is to identify all the compromised devices by knee analysis of the packets. Routers are the edge devices employed in first tier which is responsible to validate the IoT user with RFID tag and encrypted signature. Then the authenticated user's packets are submitted into second tier with switches that validates the packets using type-II fuzzy filtering. Then the key features are extracted from packets and they are classified into normal, suspicious and malicious. The mismatched packets are analyzed in controllers which maintain two queues as suspicious and normal. Then suspicious queue packets are classified and predicted using deep learning method. The proposed work is experimented in OMNeT++ environment and the performances are evaluated in terms of intruder Detection Rate, Failure Rate, Delay, Throughput and Traffic Load.},
 author = {Ali, Amir and Yousaf, Muhammad Murtaza},
 doi = {10.1109/ACCESS.2020.3002333},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Software defined networking;Machine learning algorithms;Support vector machines;Computer architecture;SDN security;IoT;intrusion prevention system;RFID;packet classification},
 month = {},
 number = {},
 pages = {109662-109676},
 title = {Novel Three-Tier Intrusion Detection and Prevention System in Software Defined Network},
 volume = {8},
 year = {2020}
}

@article{9121208,
 abstract = {Increasing use of renewable energy sources, liberalized energy markets and most importantly, the integrations of various monitoring, measuring and communication infrastructures into modern power system network offer the opportunity to build a resilient and efficient grid. However, it also brings about various threats of instabilities and security concerns in form of cyberattack, voltage instability, power quality (PQ) disturbance among others to the complex network. The need for efficient methodologies for quicker identification and detection of these problems have always been a priority to energy stakeholders over the years. In recent times, machine learning techniques (MLTs) have proven to be effective in numerous applications including power system studies. In the literature, various MLTs such as artificial neural networks (ANN), Decision Tree (DT), support vector machines (SVM) have been proposed, resulting in effective decision making and control actions in the secured and stable operations of the power system. Given this growing trend, this paper presents a comprehensive review on the most recent studies whereby MLTs were developed for power system security and stability especially in cyberattack detections, PQ disturbance studies and dynamic security assessment studies. The aim is to highlight the methodologies, achievements and more importantly the limitations in the classifier(s) design, dataset and test systems employed in the reviewed publications. A brief review of reinforcement learning (RL) and deep reinforcement learning (DRL) approaches to transient stability assessment is also presented. Finally, we highlighted some challenges and directions for future studies.},
 author = {Alimi, Oyeniyi Akeem and Ouahada, Khmaies and Abu-Mahfouz, Adnan M.},
 doi = {10.1109/ACCESS.2020.3003568},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Power system stability;Power system security;Stability criteria;Machine learning;Power quality;Classifiers;cyberattacks;deep reinforcement learning;intruder detection system;machine learning techniques;power quality disturbance;power system;reinforcement learning;test systems;transient stability assessment;voltage stability},
 month = {},
 number = {},
 pages = {113512-113531},
 title = {A Review of Machine Learning Approaches to Power System Security and Stability},
 volume = {8},
 year = {2020}
}

@article{9125902,
 abstract = {Wireless technology and the latest developments in a mobile object, has led to a Mobile Ad Hoc network (MANET), which is a collection of mobile nodes that are communicating with each other without requiring any fixed infrastructure. Due to the dynamic nature with a decentralized system, these networks are susceptible to different attacks such as Black Hole Attack (BHA), Gray Hole Attack (GHA), Sink Hole Attack (SHA) and many more. Several researchers have worked for the detection and mitigation of individual attacks, either GHA or BHA nodes. But the protection of MANET against a dual-threat is scarce. In this paper, the protection against dual attacks has been presented for BHA and GHA by using the concept of Artificial Neural Network (ANN) as a deep learning algorithm along with the swarm-based Artificial Bee Colony (ABC) optimization technique. The performance of the system has been increased by the selection of appropriate and best nodes for data packets transmission which is explained in the result section of this paper. For the network designing and simulation purposes, MATLAB software is used with communication and neural network toolboxes. The examined results show that the presented protocol performs better in contrast to the existing work under black hole as well as gray hole attack condition. A mobile ad hoc network (MANET) is a collection of mobile nodes that dynamically form a temporary network without using any existing network infrastructure.},
 author = {Rani, Pooja and Kavita and Verma, Sahil and Nguyen, Gia Nhu},
 doi = {10.1109/ACCESS.2020.3004692},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Mobile ad hoc networks;Routing protocols;Routing;Data communication;Optimization;Delays;ABC;ANN;AODV;black hole attack;gray hole attack;MANET},
 month = {},
 number = {},
 pages = {121755-121764},
 title = {Mitigation of Black Hole and Gray Hole Attack Using Swarm Inspired Algorithm With Artificial Neural Network},
 volume = {8},
 year = {2020}
}

@article{9134764,
 abstract = {Correct and timely responses to abnormal conditions in the power systems are crucial to their sound operation. In order for the operator or the automated response system to take prompt measures during system contingencies, it is critical to facilitate an accurate mechanism for the classification of the events and disturbances in the power grid. The massive amount of time-synchronized data recorded by the phasor measurement units can be combined with logs from other components in the power grid to create datasets for event and intrusion detection. This paper presents the results of applying deep learning techniques on open datasets recorded from a power system testbed to classify contingencies and cyber-attacks. Three different designs of recurrent neural networks (RNN) are investigated and tested for discriminating binary and multiclass events. Experiment results show 100% and 99.99% accuracy when applying the proposed classifiers on large scale binary and multiclass datasets respectively. It is also shown that one can improve the efficiency of the scheme by selectively eliminating 75% of the features in the dataset while maintaining as high as 99.96% accuracy in classifying multiclass events. Additionally, the feasibility of the design is validated by the low classification latency recorded on the low-end embedded system Jetson Nano. These promising results demonstrate the potential of employing RNN techniques in developing event and intrusion detection systems for power grids.},
 author = {Hong, Wei-Chih and Huang, Ding-Ray and Chen, Chih-Lung and Lee, Jung-San},
 doi = {10.1109/ACCESS.2020.3007609},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Phasor measurement units;Smart grids;Intrusion detection;Recurrent neural networks;Computational modeling;Intrusion detection;recurrent neural networks;smart grids;phasor measurement units},
 month = {},
 number = {},
 pages = {123297-123309},
 title = {Towards Accurate and Efficient Classification of Power System Contingencies and Cyber-Attacks Using Recurrent Neural Networks},
 volume = {8},
 year = {2020}
}

@article{9138418,
 abstract = {Machine learning algorithms are widely utilized in cybersecurity. However, recent studies show that machine learning algorithms are vulnerable to adversarial examples. This poses new threats to the security-critical applications in cybersecurity. Currently, there is still a short of study on adversarial examples in the domain of cybersecurity. In this paper, we propose a new method known as the brute-force attack method to better evaluate the robustness of the machine learning classifiers in cybersecurity against adversarial examples. The proposed method, which works in a black-box way and covers some shortages of the existing adversarial attack methods based on generative adversarial networks, is simple to implement and only needs the output of the target classifiers to generate adversarial examples. To have a comprehensive evaluation of the attack performance of the proposed method, we use our method to generate adversarial examples against the common machine learning based security systems in cybersecurity including host intrusion detection systems, Android malware detection systems, and network intrusion detection systems. We compare the attack performance of the proposed method against these security systems with that of state-of-the-art adversarial attack methods based on generative adversarial networks. The preliminary experimental results show that the proposed method, which is more efficient in computation and outperforms the state-of-the-art attack methods based on generative adversarial networks, can be used to evaluate the robustness of various machine learning based systems in cybersecurity against adversarial examples.},
 author = {Zhang, Sicong and Xie, Xiaoyao and Xu, Yang},
 doi = {10.1109/ACCESS.2020.3008433},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer security;Machine learning;Malware;Intrusion detection;Machine learning algorithms;Generative adversarial networks;Adversarial examples;machine learning;deep learning;intrusion detection;malware detection;neural networks;black-box method},
 month = {},
 number = {},
 pages = {128250-128263},
 title = {A Brute-Force Black-Box Method to Attack Machine Learning-Based Systems in Cybersecurity},
 volume = {8},
 year = {2020}
}

@article{9139918,
 abstract = {Human identity identification based on channel state information (CSI) using commercial WiFi devices has drawn increasingly attention, and it can be used in many applications such as smart home, intrusion detection, building monitoring, activity recognition, etc. However, most of the existing identity identification approaches are sensitive to the influence of random noise derived from indoor environments, and thus their identification accuracies are far from satisfactory. In the present paper, a device-free CSI based human identity identification approach using deep learning (Wihi) is proposed. Wihi mainly utilizes three key techniques to identify different people. Firstly, to eliminate the influence of the random noise, discrete wavelet transform (DWT) strategy is introduced to denoise raw CSI data by leveraging signal decomposition. Secondly, in order to characterize human’s gaits profoundly, several representative features are exploited from different statistical profiles, including channel power distribution in time domain (CPD), time-frequency analysis (TFA), and energy distribution in different frequency bands (ED). Thirdly, a recurrent neural network (RNN) model with long short-term memory (LSTM) blocks is employed to learn the representative gait features extracted above and encode temporal information for realizing human identity identification. The proof-of-concept prototype of the proposed Wihi approach is implemented on a set of commercial WiFi devices, and multiple comprehensive experiments have been carried out to evaluate the performance of identity identification. The experimental results confirm that the proposed Wihi can achieve a satisfactory performance compared with some state-of-the-art approaches.},
 author = {Ding, Jianyang and Wang, Yong and Fu, Xiangcong},
 doi = {10.1109/ACCESS.2020.3009123},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless fidelity;Object recognition;Feature extraction;Fingerprint recognition;Indoor environments;Iris recognition;Recurrent neural networks;Human identity identification;commercial wifi devices;channel state information (CSI);recurrent neural network (RNN)},
 month = {},
 number = {},
 pages = {129246-129262},
 title = {Wihi: WiFi Based Human Identity Identification Using Deep Learning},
 volume = {8},
 year = {2020}
}

@article{9142203,
 abstract = {Software defined network (SDN) centralized control intelligence and network abstraction aims to facilitate applications, service deployment, programmability, innovation and ease in configuration management of the underlying networks. However, the centralized control intelligence and programmability is primarily a potential target for the evolving cyber threats and attacks to throw the entire network into chaos. The authors propose a control plane-based orchestration for varied sophisticated threats and attacks. The proposed mechanism comprises of a hybrid Cuda-enabled DL-driven architecture that utilizes the predictive power of Long short-term memory (LSTM) and Convolutional Neural Network (CNN) for an efficient and timely detection of multi-vector threats and attacks. A current state of the art dataset CICIDS2017 and standard performance evaluation metrics have been employed to thoroughly evaluate the proposed mechanism. We rigorously compared our proposed technique with our constructed hybrid DL-architectures and current benchmark algorithms. Our analysis shows that the proposed approach out-performs in terms of detection accuracy with a trivial trade-off speed efficiency. We also performed a 10-fold cross validation to explicitly show unbiased results.},
 author = {Malik, Jahanzaib and Akhunzada, Adnan and Bibi, Iram and Imran, Muhammad and Musaddiq, Arslan and Kim, Sung Won},
 doi = {10.1109/ACCESS.2020.3009849},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer architecture;Intrusion detection;Feature extraction;Machine learning;Software;Computer crime;Anomaly detection;Security;hybrid deep learning model;software defined networks;long short-term memory;convolutional neural network},
 month = {},
 number = {},
 pages = {134695-134706},
 title = {Hybrid Deep Learning: An Efficient Reconnaissance and Surveillance Detection Mechanism in SDN},
 volume = {8},
 year = {2020}
}

@article{9144212,
 abstract = {Deep Learning (DL) is vulnerable to out-of-distribution and adversarial examples resulting in incorrect outputs. To make DL more robust, several posthoc (or runtime) anomaly detection techniques to detect (and discard) these anomalous samples have been proposed in the recent past. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection for DL based applications. We provide a taxonomy for existing techniques based on their underlying assumptions and adopted approaches. We discuss various techniques in each of the categories and provide the relative strengths and weaknesses of the approaches. Our goal in this survey is to provide an easier yet better understanding of the techniques belonging to different categories in which research has been done on this topic. Finally, we highlight the unsolved research challenges while applying anomaly detection techniques in DL systems and present some high-impact future research directions.},
 author = {Bulusu, Saikiran and Kailkhura, Bhavya and Li, Bo and Varshney, Pramod K. and Song, Dawn},
 doi = {10.1109/ACCESS.2020.3010274},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Machine learning;Training data;Data models;Training;Neural networks;Anomaly detection;out-of-distribution;adversarial examples;deep learning;neural network},
 month = {},
 number = {},
 pages = {132330-132347},
 title = {Anomalous Example Detection in Deep Learning: A Survey},
 volume = {8},
 year = {2020}
}

@article{9146148,
 abstract = {Cybercrimes are cases of indictable offences and misdemeanors that involve computers or communication tools as targets and commission instruments or are associated with the prevalence of computer technology. Common forms of cybercrimes are child pornography, cyberstalking, identity theft, cyber laundering, credit card theft, cyber terrorism, drug sale, data leakage, sexually explicit content, phishing, and other forms of cyber hacking. They mostly lead to a privacy breach, security violation, business loss, financial fraud, or damage in public and government properties. Thus, this study intensively reviews cybercrime detection and prevention techniques. It first explores the different types of cybercrimes and discusses their threats against privacy and security in computer systems. Then, it describes the strategies that cybercriminals may utilize in committing these crimes against individuals, organizations, and societies. It also reviews the existing techniques of cybercrime detection and prevention. It objectively discusses the strengths and critically analyzes the vulnerabilities of each technique. Finally, it provides recommendations for the development of a cybercrime detection model that can detect cybercrimes effectively compared with the existing techniques.},
 author = {Al-Khater, Wadha Abdullah and Al-Maadeed, Somaya and Ahmed, Abdulghani Ali and Sadiq, Ali Safaa and Khan, Muhammad Khurram},
 doi = {10.1109/ACCESS.2020.3011259},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Phishing;Cyber terrorism;Government;Tools;Companies;Security;cybercrime detection techniques;neural network;fuzzy logic;machine learning;data mining},
 month = {},
 number = {},
 pages = {137293-137311},
 title = {Comprehensive Review of Cybercrime Detection Techniques},
 volume = {8},
 year = {2020}
}

@article{9151152,
 abstract = {Intrusion detection is an important and challenging problem that has a major impact on quality and reliability of smart city services. To this extent, replay attacks have been one of the most common threats on smart city infrastructure, which compromises authentication in a smart city network. For example, a replay attack may physically damage smart city infrastructure resulting in loss of sensitive data, incurring considerable financial damages. Therefore, towards securing smart cities from reply attacks, intrusion detection systems and frameworks based on deep learning have been proposed in the recent literature. However, the absence of the time dimension of these proposals is a major limitation. Therefore, we have developed a deep learning-based model for replay attack detection in smart cities. The novelty of the proposed methodology resides in the adoption of deep learning based models as an application for detecting replay attacks to improve detection accuracy. The performance of this model is evaluated by applying it to a real life smart city dataset, where replay attacks were simulated. Our results show that the proposed model is capable of distinguishing between normal and attack behaviours with relatively high accuracy. In addition, according to the results, our proposed model outperforms traditional classification and deep learning models. Last but not least, as an additional contribution, this paper presents a real life smart city data set with simulated replay attacks for future research.},
 author = {Elsaeidy, Asmaa A. and Jagannath, Nishant and Sanchis, Adrian Garrido and Jamalipour, Abbas and Munasinghe, Kumudu S.},
 doi = {10.1109/ACCESS.2020.3012411},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart cities;Machine learning;Intrusion detection;Authentication;Convolution;Time series analysis;Australia;Smart cities;intrusion detection;replay attack;deep learning;convolutional neural networks},
 month = {},
 number = {},
 pages = {137825-137837},
 title = {Replay Attack Detection in Smart Cities Using Deep Learning},
 volume = {8},
 year = {2020}
}

@article{9162012,
 abstract = {With the increasing use of resource-constrained IoT devices, the number of IoT Botnets has exploded with many variations and ways of penetration. Nowadays, studies based on machine learning and deep learning have focused on dealing with IoT Botnet with many successes, and these studies have required relevant data during malware execution. For this, the sandbox environment and behavior collection tools play an essential role. However, the existing sandboxes do not provide adequate behavior data of IoT botnet such as the C&C server communication, shared libraries requirements. Moreover, these sandboxes do not support a wide range of CPU architectures, data is not exhaustively collected during executable file runtime. In this paper, we present a new practical sandbox, named V-Sandbox, for dynamic analysis of the IoT Botnet. This sandbox is an ideal environment for IoT Botnet samples that exhibit all of their malicious behavior. It supports the C&C servers connection, shared libraries for dynamic files, and a wide range of CPU architectures. Experimental results on the 6141 IoT Botnet samples in our dataset have demonstrated the effectiveness of the proposed sandbox, compared to existing ones. The contribution of this paper is specific to the development of a usable, efficient sandbox for dynamic analysis of resource-constrained IoT devices.},
 author = {Le, Hai-Viet and Ngo, Quoc-Dung},
 doi = {10.1109/ACCESS.2020.3014891},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Malware;Servers;Machine learning;IP networks;Libraries;Buildings;Sandbox;dynamic analysis;IoT botnet;machine learning},
 month = {},
 number = {},
 pages = {145768-145786},
 title = {V-Sandbox for Dynamic Analysis IoT Botnet},
 volume = {8},
 year = {2020}
}

@article{9164974,
 abstract = {Intelligent capabilities are of utmost importance in future wireless communication systems. For optimum resource utilization, wireless communication systems require knowledge of the prevalent situation in a frequency band through learning. To learn appropriately, it is imperative for practitioners to select the right parameters for building robust data-driven learning models as well as use the appropriate algorithms and performance evaluation methods. In this paper, we evaluate the performance of deep learning models against the performance of other machine learning methods for wireless communication systems. We explore the different wireless communication scenarios in which deep learning can be used given Radio Frequency (RF) data, and evaluate its performance in various scenarios. Furthermore, we express it as a distribution alignment problem in which deep learning models do not perform well when learning from RF data of a particular distribution and evaluating on RF data from a different distribution. We also discuss our results in the light of how signal quality affects deep learning model leveraging on the knowledge from computer vision domain. The effect of Signal-to-Noise Ratio (SNR) selection for training on the model performance as it relates to practical implementation of deep learning in communications systems is also discussed. From our analysis, we conclude that the design and use of RF spectrum learning must be tailored to each specific scenario being considered in practice.},
 author = {Adesina, Damilola and Bassey, Joshua and Qian, Lijun},
 doi = {10.1109/ACCESS.2020.3015939},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Radio frequency;Machine learning;Wireless communication;Signal to noise ratio;Robustness;Data models;Training;Radio frequency learning;signal-to-noise ratio;training and testing strategy;spectrum data;convolutional neural network},
 month = {},
 number = {},
 pages = {148528-148540},
 title = {Robust Deep Radio Frequency Spectrum Learning for Future Wireless Communications Systems},
 volume = {8},
 year = {2020}
}

@article{9172062,
 abstract = {Through three development routes of authentication, communication, and computing, the Internet of Things (IoT) has become a variety of innovative integrated solutions for specific applications. However, due to the openness, extensiveness and resource constraints of IoT, each layer of the three-tier IoT architecture suffers from a variety of security threats. In this work, we systematically review the particularity and complexity of IoT security protection, and then find that Artificial Intelligence (AI) methods such as Machine Learning (ML) and Deep Learning (DL) can provide new powerful capabilities to meet the security requirements of IoT. We analyze the technical feasibility of AI in solving IoT security problems and summarize a general process of AI solutions for IoT security. For four serious IoT security threats: device authentication, Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks defense, intrusion detection and malware detection, we summarize representative AI solutions and compare the different algorithms and technologies used by various solutions. It should be noted that although AI provides many new capabilities for the security protection of IoT, it also brings new potential challenges and possible negative effects to IoT in terms of data, algorithm and architecture. In the future, how to solve these challenges can serve as potential research directions.},
 author = {Wu, Hui and Han, Haiting and Wang, Xiao and Sun, Shengli},
 doi = {10.1109/ACCESS.2020.3018170},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Artificial intelligence;Authentication;Computer architecture;Software;Computer crime;Artificial intelligence;deep learning;Internet of Things;machine learning;security},
 month = {},
 number = {},
 pages = {153826-153848},
 title = {Research on Artificial Intelligence Enhancing Internet of Things Security: A Survey},
 volume = {8},
 year = {2020}
}

@article{9177002,
 abstract = {While there have been extensive studies of denial of service (DoS) attacks and DDoS attack mitigation, such attacks remain challenging to mitigate. For example, Low-Rate DDoS (LR-DDoS) attacks are known to be difficult to detect, particularly in a software-defined network (SDN). Hence, in this paper we present a flexible modular architecture that allows the identification and mitigation of LR-DDoS attacks in SDN settings. Specifically, we train the intrusion detection system (IDS) in our architecture using six machine learning (ML) models (i.e., J48, Random Tree, REP Tree, Random Forest, Multi-Layer Perceptron (MLP), and Support Vector Machines (SVM)) and evaluate their performance using the Canadian Institute of Cybersecurity (CIC) DoS dataset. The findings from the evaluation demonstrate that our approach achieves a detection rate of 95%, despite the difficulty in detecting LR-DoS attacks. We also remark that in our deployment, we use the open network operating system (ONOS) controller running on Mininet virtual machine in order for our simulated environment to be as close to real-world production networks as possible. In our testing topology, the intrusion prevention detection system mitigates all attacks previously detected by the IDS system. This demonstrates the utility of our architecture in identifying and mitigating LR-DDoS attacks.},
 author = {Pérez-Díaz, Jesús Arturo and Valdovinos, Ismael Amezcua and Choo, Kim-Kwang Raymond and Zhu, Dakai},
 doi = {10.1109/ACCESS.2020.3019330},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Computer architecture;Machine learning;Vegetation;Support vector machines;Control systems;IP networks;DDoS attack mitigation;low-rate DDoS (LR-DDoS) attacks;machine learning;software-defined network (SDN)},
 month = {},
 number = {},
 pages = {155859-155872},
 title = {A Flexible SDN-Based Architecture for Identifying and Mitigating Low-Rate DDoS Attacks Using Machine Learning},
 volume = {8},
 year = {2020}
}

@article{9177119,
 abstract = {In modern railway systems, video surveillance and machine vision analysis have been widely used to detect perimeter intrusions. For pan-tilt-zoom (PTZ) cameras, the machine vision system needs to detect adjustments in PTZ cameras and then automatically determine the new alarm region in real time. In this paper, we propose a deep multi-task learning based algorithm for simultaneous vanishing point (VP) detection and rail segmentation, which can identify camera adjustment from changes in VP, and then automatically determine the alarm region from segmented rails. The multi-task based neural network consists of a feature extraction base network and three sub-task networks. The first sub-task network is a convolution regression network for VP detection. The second sub-task network utilizes an encoder-decoder structure for vanishing region (VR, a fixed region centered on VP) segmentation. The third sub-task network shares the encoder-decoder structure with the VR segmentation task and is used for rail segmentation. The VR segmentation task is activated only at the training stage, serving as an auxiliary task to enhance feature learning ability and increase VP detection accuracy. To further improve the accuracies of VP detection and rail segmentation, low-level features is modulated by high-level semantic information before feeding to the decoder stage. With the help of shared feature extraction and auxiliary training, the proposed VP prediction method needs very small training dataset and outperforms other methods in both efficiency and accuracy.},
 author = {Li, Xingxin and Zhu, Liqiang and Yu, Zujun and Guo, Baoqing and Wan, Yanqin},
 doi = {10.1109/ACCESS.2020.3019318},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Task analysis;Rail transportation;Rails;Feature extraction;Object segmentation;Training;Cameras;Vanishing point detection;rail segmentation;intrusion detection;multi-task learning;deep learning},
 month = {},
 number = {},
 pages = {163015-163025},
 title = {Vanishing Point Detection and Rail Segmentation Based on Deep Multi-Task Learning},
 volume = {8},
 year = {2020}
}

@article{9178792,
 abstract = {With the development of the wireless network techniques, the number of cyber-attack increases significantly, which has seriously threat the security of Wireless Local Area Network (WLAN). The traditional intrusion detection technology is a prevalent area of study for numerous years, but it may not have a good detection performance in a real-time way. Therefore, it is urgent to design a detection mechanism to detect the attacks timely. In this paper, we exploit a CDBN (Conditional Deep Belief Network)-based intrusion detection mechanism to recognize the attack features and perform the wireless network intrusion detection in real time. To avoid the impact of the imbalanced dataset and the data redundancy on the detection accuracy, a window-based instance selection algorithm “SamSelect” is adopted to undersample the majority class data samples, and a Stacked Contractive Auto-Encoder (SCAE) algorithm is proposed to reduce the dimension of the data samples. By doing so, our proposed mechanism can effectively detect the potential attack and achieve high accuracy. The experiment results show that CDBN can be effectively combined with “SamSelect” and SCAE, and the proposed mechanism has a high detection speed and accuracy, with the average detection time 1.14 ms and the detection accuracy 0.974.},
 author = {Yang, Liqun and Li, Jianqiang and Yin, Liang and Sun, Zhonghao and Zhao, Yufei and Li, Zhoujun},
 doi = {10.1109/ACCESS.2020.3019973},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Training;Dimensionality reduction;Real-time systems;Wireless networks;Wireless LAN;Intrusion detection;conditional deep belief network;Samselect algorithm;stacked contractive auto-encoder;real-time detection},
 month = {},
 number = {},
 pages = {170128-170139},
 title = {Real-Time Intrusion Detection in Wireless Network: A Deep Learning-Based Intelligent Mechanism},
 volume = {8},
 year = {2020}
}

@article{9178801,
 abstract = {Internet evolution produced a connected world with a massive amount of data. This connectivity advantage came with the price of more complex and advanced attacks. Intrusion Detection System (IDS) is an essential component for security in modern networks. The IDS methodology is either signature-based detection or anomaly behavior detection. Recently, researchers adopted Deep Learning (DL) because it has a better performance than traditional machine learning algorithms. The use of DL to produce a model for the IDS may take a long time because of computation complexity and a large number of hyperparameters. Different DL models for IDS on Apache Spark have been implemented in this article. This article uses the famous Network Security Lab - Knowledge Discovery and Data Mining (NSL-KDD) dataset and presents a computation delay comparison between Apache Spark and regular implementation. Moreover, an enhanced model is used to improve attack detection accuracy.},
 author = {Haggag, Mohamed and Tantawy, Mohsen M. and El-Soudani, Magdy M. S.},
 doi = {10.1109/ACCESS.2020.3019931},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Machine learning;Sparks;Computational modeling;Intrusion detection;Support vector machines;Intrusion detection;bigdata;Hadoop;apache spark;deep learning},
 month = {},
 number = {},
 pages = {163660-163672},
 title = {Implementing a Deep Learning Model for Intrusion Detection on Apache Spark Platform},
 volume = {8},
 year = {2020}
}

@article{9187597,
 abstract = {Abnormal traffic detection is an important network security technology to protect computer systems from malicious attacks. Existing detection methods are usually based on traditional machine learning, such as Support Vector Machine (SVM), Naive Bayes, etc. They rely heavily on manual design of traffic features and usually shallow feature learning, which get a low accuracy for high-dimensional traffic. Although the method based on Long Short-Term Memory (LSTM) has an excellent ability to detect abnormal traffic. The sequence-dependent structure of LSTM cannot realize parallel computation, which leads to slow model training and limits its applicability. To address the above problem, we propose an efficient Bidirectional Simple Recurrent Unit (BiSRU) combined with feature dimensionality reduction for abnormal traffic detection. Specifically, in order to perform feature dimensionality reduction on the original high-dimensional network traffic, we design a stack Sparse Autoencoder (sSAE) to extract the compressed high-level features. For the purpose of realizing efficient parallel computation and accurate feature extraction, a BiSRU is utilized to extract the bidirectional structural features of the traffic. Finally, the experimental results show that our proposed method significantly outperforms existing methods in terms of accuracy and training time. The method we propose can timely and accurately detect various abnormal traffic and achieve effective network security protection.},
 author = {Ding, Pengpeng and Li, Jinguo and Wen, Mi and Wang, Liangliang and Li, Hongjiao},
 doi = {10.1109/ACCESS.2020.3022355},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Dimensionality reduction;Neurons;Training;Intrusion detection;Abnormal traffic detection;dimensionality reduction;sSAE;BiSRU},
 month = {},
 number = {},
 pages = {164414-164427},
 title = {Efficient BiSRU Combined With Feature Dimensionality Reduction for Abnormal Traffic Detection},
 volume = {8},
 year = {2020}
}

@article{9187856,
 abstract = {Today, with the continuous promotion and development of IoT and 5G technology, Cyberspace has become an important pillar of economic and social development, and also a foundational domain of national security. Cyberspace security is attracting more and more attention. Therefore, detecting malware and its variants is of great significance to Cyberspace. However, the increasing sophistication of malicious variants, such as encryption, polymorphism and obfuscation, makes it more difficult to identified malware effectively. In this article, a malware detection method of code texture visualization based on an improved Faster RCNN (Region-Convolutional Neural Networks) combining transfer learning is proposed. We utilize visualization technology to map malicious code into corresponding images with typical texture features, and realize the classification of malware. Firstly, in order to quickly acquire and locate the representative texture of malware, we adopt CNN to extract the global and deeper features of malicious code images. Then with RPN (Region Proposal Network) we generate the target image frame, which is used to locate the core texture of malware file (.text file), to realize the accurate positioning of malicious features. Secondly, we preprocess and train Faster RCNN model with ImageNet set, and then transfer the model to the malware classification model to accelerate the convergence of the first model and promote generation performance. Thirdly, we construct an improved objective function in which a novel multi-label of classification proportion is added to solve the problem that the texture change of “.text” section and other sections in malicious code image is not obvious after transfer learning. We collect code samples of six malware families from Kaggle platform, and compared the experimental results before and after transfer. The results show that the novel method can accelerate the convergence of loss function, and obtain higher accuracy (92.8%), lower FPR (6.8%) and better P-R (precision-recall) curve.},
 author = {Zhao, Yuntao and Cui, Wenjie and Geng, Shengnan and Bo, Bo and Feng, Yongxin and Zhang, Wenbo},
 doi = {10.1109/ACCESS.2020.3022722},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Machine learning;Data mining;Cyberspace;Acceleration;Convergence;Cyberspace security;faster RCNN;malware detection;code classification;transfer model},
 month = {},
 number = {},
 pages = {166630-166641},
 title = {A Malware Detection Method of Code Texture Visualization Based on an Improved Faster RCNN Combining Transfer Learning},
 volume = {8},
 year = {2020}
}

@article{9189760,
 abstract = {Although the Internet of Things (IoT) can increase efficiency and productivity through intelligent and remote management, it also increases the risk of cyber-attacks. The potential threats to IoT applications and the need to reduce risk have recently become an interesting research topic. It is crucial that effective Intrusion Detection Systems (IDSs) tailored to IoT applications be developed. Such IDSs require an updated and representative IoT dataset for training and evaluation. However, there is a lack of benchmark IoT and IIoT datasets for assessing IDSs-enabled IoT systems. This paper addresses this issue and proposes a new data-driven IoT/IIoT dataset with the ground truth that incorporates a label feature indicating normal and attack classes, as well as a type feature indicating the sub-classes of attacks targeting IoT/IIoT applications for multi-classification problems. The proposed dataset, which is named TON_IoT, includes Telemetry data of IoT/IIoT services, as well as Operating Systems logs and Network traffic of IoT network, collected from a realistic representation of a medium-scale network at the Cyber Range and IoT Labs at the UNSW Canberra (Australia). This paper also describes the proposed dataset of the Telemetry data of IoT/IIoT services and their characteristics. TON_IoT has various advantages that are currently lacking in the state-of-the-art datasets: i) it has various normal and attack events for different IoT/IIoT services, and ii) it includes heterogeneous data sources. We evaluated the performance of several popular Machine Learning (ML) methods and a Deep Learning model in both binary and multi-class classification problems for intrusion detection purposes using the proposed Telemetry dataset.},
 author = {Alsaedi, Abdullah and Moustafa, Nour and Tari, Zahir and Mahmood, Abdun and Anwar, Adnan},
 doi = {10.1109/ACCESS.2020.3022862},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Telemetry;Sensors;Internet of Things;Machine learning;Australia;Internet of Things (IoT);Industrial Internet of Things (IIoT);cybersecurity;intrusion detection systems (IDSs);dataset},
 month = {},
 number = {},
 pages = {165130-165150},
 title = {TON_IoT Telemetry Dataset: A New Generation Dataset of IoT and IIoT for Data-Driven Intrusion Detection Systems},
 volume = {8},
 year = {2020}
}

@article{9189883,
 abstract = {Fog Computing has emerged as an extension to cloud computing by providing an efficient infrastructure to support IoT. Fog computing acting as a mediator provides local processing of the end-users' requests and reduced delays in communication between the end-users and the cloud via fog devices. Therefore, the authenticity of incoming network traffic on the fog devices is of immense importance. These devices are vulnerable to malicious attacks. All kinds of information, especially financial and health information travel through these devices. Attackers target these devices by sending malicious data packets. It is imperative to detect these intrusions to provide secure and reliable service to the user. So, an effective Intrusion Detection System (IDS) is essential for the secure functioning of fog without compromising efficiency. In this paper, we propose a method (Auto-IF) for intrusion detection based on deep learning approach using Autoencoder (AE) and Isolation Forest (IF) for the fog environment. This approach targets only binary classification of the incoming packets as fog devices are more concerned about differentiating attack from normal packets in real-time. We validate the proposed method on the benchmark NSL-KDD dataset. Our technique of intrusion detection achieves a high accuracy rate of 95.4% as compared to many other state-of-art intrusion detection methods.},
 author = {Sadaf, Kishwar and Sultana, Jabeen},
 doi = {10.1109/ACCESS.2020.3022855},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Cloud computing;Edge computing;Forestry;Support vector machines;Autoencoder;fog computing;intrusion detection;isolation forest},
 month = {},
 number = {},
 pages = {167059-167068},
 title = {Intrusion Detection Based on Autoencoder and Isolation Forest in Fog Computing},
 volume = {8},
 year = {2020}
}

@article{9204675,
 abstract = {The development of computer and network technology has provided convenience to our daily life, however, attack and intrusion in network emerge endlessly. Intrusion Detection System (IDS) has been developed to confront network attacks. As a result, the research of IDS is one of the most popular fields in recent years. This paper proposes a Gradient Boosting Decision Tree (GBDT)-paralleled quadratic ensemble learning method for intrusion detection system. We use GBDT to deal with the spatial part of traffic data and use Gated Recurrent Unit (GRU) model with special modification for network traffic to deal with temporal data. Then, in order to combine the spatial feature and temporal feature, we fuse GBDT model and GRU model to make a quadratic ensemble model as our final intrusion detection system. The experimental results based on CICIDS2017 dataset show that the advanced spatial-temporal intrusion detection system based on ensemble learning achieves better accuracy, recall, precision and F1 score than the state-of-the-art methods. The accuracies of detecting benign, port scan, Distributed Denial of Service (DDoS), infiltration and web attack traffic are up to 99.9%, 99.9%, 99.9%, 99.9%, and 99.9%, respectively. We also use our method in Information-Centric Networking (ICN) dataset and the results show our method achieves much better performance compared with existing methods.},
 author = {Yang, Jun and Sheng, Yiqiang and Wang, Jinlin},
 doi = {10.1109/ACCESS.2020.3026044},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Intrusion detection;Feature extraction;Machine learning;IP networks;Intrusion detection;deep learning;ensemble learning;model fusion},
 month = {},
 number = {},
 pages = {175467-175482},
 title = {A GBDT-Paralleled Quadratic Ensemble Learning for Intrusion Detection System},
 volume = {8},
 year = {2020}
}

@article{9204699,
 abstract = {Fraud detection systems support advanced detection techniques based on complex rules, statistical modelling and machine learning. However, alerts triggered by these systems still require expert judgement to either confirm a fraud case or discard a false positive. Reducing the number of false positives that fraud analysts investigate, by automating their detection with computer-assisted techniques, can lead to significant cost efficiencies. Alert reduction has been achieved with different techniques in related fields like intrusion detection. Furthermore, deep learning has been used to accomplish this task in other fields. In our paper, a set of deep neural networks have been tested to measure their ability to detect false positives, by processing alerts triggered by a fraud detection system. The performance achieved by each neural network setting is presented and discussed. The optimal setting allowed to capture 91.79% of total fraud cases with 35.16% less alerts. Obtained alert reduction rate would entail a significant reduction in cost of human labor, because alerts classified as false positives by the neural network wouldn't require human inspection.},
 author = {San Miguel Carrasco, Rafael and Sicilia-Urbán, Miguel-Ángel},
 doi = {10.1109/ACCESS.2020.3026222},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Neural networks;Machine learning;Credit cards;Support vector machines;Decision trees;Forestry;Feature extraction;Neural networks;deep learning;fraud detection;alert reduction},
 month = {},
 number = {},
 pages = {186421-186432},
 title = {Evaluation of Deep Neural Networks for Reduction of Credit Card Fraud Alerts},
 volume = {8},
 year = {2020}
}

@article{9204732,
 abstract = {With the development of smart phones, malicious applications for the Android platform have increased dramatically. The existing Android malicious code analysis methods majorly focus on detection based on signatures, inter-component communication, and other configuration information features. Such methods ignore the effect of the semantic features of the malicious code. Even a few such studies that exist are based on the statistical features of the code for malicious code detection. To address these shortcomings, we (1) use the code semantic structure features to reflect deep semantic information, (2) propose a preprocessing method of APK files to generate graphics that reflect the code semantic features, and (3) introduce the advanced graphical semantics for a graph convolutional network (GCN) model to automatically identify and learn semantics and extract features for malicious code detection. Experiments on a dataset confirm that the proposed method can achieve 95.8% detection accuracy. Compared with the existing methods that adopt configuration information features or statistical features of codes, our method shows higher accuracy.},
 author = {Zhang, Yu and Li, Binglong},
 doi = {10.1109/ACCESS.2020.3026052},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Malware;Semantics;Smart phones;Data mining;Machine learning;Convolutional codes;Deep learning;malicious code detection;semantic features},
 month = {},
 number = {},
 pages = {176728-176737},
 title = {Malicious Code Detection Based on Code Semantic Features},
 volume = {8},
 year = {2020}
}

@article{9212425,
 abstract = {Cloud computing has very attractive features like elastic, on demand and fully managed computer system resources and services. However, due to its distributed and dynamic nature as well as vulnerabilities in virtualization implementation, the cloud environment is prone to various cyber-attacks and security issues related to cloud model. Some of them are inability to access data coming to and from cloud service, theft and misuse of data hosted, no control over sensitive data access, advance threats like malware injection attack, wrapping attacks, virtual machine escape, distributed denial of service attack (DDoS) etc. DDoS is one of the notorious attack. Despite a number of available potential solutions for the detection of DDoS attacks, the increasing frequency and potency of recent attacks and the constantly evolving attack vectors, necessitate the development of improved detection approaches. This article proposes a novel architecture that combines a well posed stacked sparse AutoEncoder (AE) for feature learning with a Deep Neural Network (DNN) for classification of network traffic into benign traffic and DDoS attack traffic. AE and DNN are optimized for detection of DDoS attacks by tuning the parameters using appropriately designed techniques. The improvements suggested in this article lead to low reconstruction error, prevent exploding and vanishing gradients, and lead to smaller network which avoids overfitting. A comparative analysis of the proposed approach with ten state-of-the-art approaches using performance metrics-detection accuracy, precision, recall and F1-Score, has been conducted. Experiments have been performed on CICIDS2017 and NSL-KDD standard datasets for validation. Proposed approach outperforms existing approaches over the NSL-KDD dataset and yields competitive results over the CICIDS2017 dataset.},
 author = {Bhardwaj, Aanshi and Mangat, Veenu and Vig, Renu},
 doi = {10.1109/ACCESS.2020.3028690},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Cloud computing;Computer crime;Feature extraction;Radio frequency;Support vector machines;Standards;Machine learning;intrusion detection;artificial neural network;cloud computing;distributed denial of service attack},
 month = {},
 number = {},
 pages = {181916-181929},
 title = {Hyperband Tuned Deep Neural Network With Well Posed Stacked Sparse AutoEncoder for Detection of DDoS Attacks in Cloud},
 volume = {8},
 year = {2020}
}

@article{9216166,
 abstract = {The modern automobile is a complex piece of technology that uses the Controller Area Network (CAN) bus system as a central system for managing the communication between the electronic control units (ECUs). Despite its central importance, the CAN bus system does not support authentication and authorization mechanisms, i.e., CAN messages are broadcast without basic security features. As a result, it is easy for attackers to launch attacks at the CAN bus network system. Attackers can compromise the CAN bus system in several ways including Denial of Service (DoS), Fuzzing and Spoofing attacks. It is imperative to devise methodologies to protect modern cars against the aforementioned attacks. In this paper, we propose a Long Short-Term Memory (LSTM)-based Intrusion Detection System (IDS) to detect and mitigate the CAN bus network attacks. We generate our own dataset by first extracting attack-free data from our experimental car and by injecting attacks into the latter and collecting the dataset. We use the dataset for testing and training our model. With our selected hyper-parameter values, our results demonstrate that our classifier is efficient in detecting the CAN bus network attacks, we achieved an overall detection accuracy of 99.995%. We also compare the proposed LSTM method with the Survival Analysis for automobile IDS dataset which is developed by the Hacking and Countermeasure Research Lab, Korea. Our proposed LSTM model achieves a higher detection rate than the Survival Analysis method.},
 author = {Hossain, Md Delwar and Inoue, Hiroyuki and Ochiai, Hideya and Fall, Doudou and Kadobayashi, Youki},
 doi = {10.1109/ACCESS.2020.3029307},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Automobiles;Fuzzing;Protocols;Intrusion detection;Machine learning;Computer crime;Modern car security;controller area network;deep learning;LSTM;intrusion detection system},
 month = {},
 number = {},
 pages = {185489-185502},
 title = {LSTM-Based Intrusion Detection System for In-Vehicle Can Bus Communications},
 volume = {8},
 year = {2020}
}

@article{9220971,
 abstract = {In today's cyber world, worms pose a great threat to the global network infrastructure. In this paper, we propose a worm detection system based on deep learning. It includes two main modules: one worm detection module based on a convolutional neural network (CNN) and one automatic worm signature generation module based on a deep neural network (DNN). In the CNN-based worm detection module, we propose three kinds of data preprocessing methods: frequency processing, frequency weighted processing, and difference processing, and use CNN to train the model for worm detection. In the DNN-based worm signature generation module, there are two phrase: DNN is firstly utilized for training the model with worm payloads and their corresponding signatures as input in the training phrase. After worm payloads are fed into the trained DNN model in the test phrase, worm signatures are generated by our proposed Signature Beam Search algorithm. In the experiment, we firstly analyzed the impact of different data preprocessing methods and the number of convolution-pooling layers in the CNN model on the worm detection performance. Then we analyzed the effects of different signatures in the DNN algorithm on the automatic generation of worm signatures. Experiments show that the generated signatures have a good detection performance.},
 author = {Zhou, Hanxun and Hu, Yeshuai and Yang, Xinlin and Pan, Hong and Guo, Wei and Zou, Cliff C.},
 doi = {10.1109/ACCESS.2020.3023434},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Grippers;Payloads;Deep learning;Feature extraction;Malware;Intrusion detection;Data collection;Network security;worm detection;worm signature automatic generation;deep learning},
 month = {},
 number = {},
 pages = {205444-205454},
 title = {A Worm Detection System Based on Deep Learning},
 volume = {8},
 year = {2020}
}

@article{9229088,
 abstract = {In the field of intrusion detection, there is often a problem of data imbalance, and more and more unknown types of attacks make detection difficult. To resolve above issues, this article proposes a network intrusion detection model called CWGAN-CSSAE, which combines improved conditional Wasserstein Generative Adversarial Network (CWGAN) and cost-sensitive stacked autoencoders (CSSAE). First of all, the CWGAN network that introduces gradient penalty and L2 regularization is used to generate specified minority attack samples to reduce the class imbalance of the training dataset. Secondly, the stacked autoencoder is used to intelligently extract the deep abstract features of the network data. Finally, a cost-sensitive loss function is constructed to give a large misclassification cost to a minority of attack samples. Thus, effective detection of network intrusion attacks can be realized. The experimental results based on KDDTest+, KDDTest-21, and UNSW-NB15 datasets show that the CWGAN-CSSAE network intrusion detection model improves the detection accuracy of minority attacks and unknown attacks. In addition, the method in this article is compared with other existing intrusion detection methods, excellent results have been achieved in performance indicators such as accuracy and F1 score. The accuracy on the above datasets reached 90.34%, 80.78% and 93.27% respectively. The accuracy of U2R on the KDDTest+ and KDDTest-21 datasets both reached 42.50%. The accuracy of R2L on the KDDTest+ and KDDTest-21 datasets reached 54.39% and 52.51%, respectively. And the F1 score on the above datasets reached 91.01%, 87.18% and 93.99% respectively.},
 author = {Zhang, Guoling and Wang, Xiaodan and Li, Rui and Song, Yafei and He, Jiaxing and Lai, Jie},
 doi = {10.1109/ACCESS.2020.3031892},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Network intrusion detection;Deep learning;Data models;Generative adversarial networks;Training;Intrusion detection;conditional Wasserstein GAN;stacked autoencoder;imbalanced classification;cost-sensitive;regularization;deep learning},
 month = {},
 number = {},
 pages = {190431-190447},
 title = {Network Intrusion Detection Based on Conditional Wasserstein Generative Adversarial Network and Cost-Sensitive Stacked Autoencoder},
 volume = {8},
 year = {2020}
}

@article{9229453,
 abstract = {Distributed Denial of Service (DDoS) attacks are one of the most challenging security threats, since a single victim is attacked by several compromised malicious nodes. As a consequence, legitimate end users can be prevented to access network resources. This letter proposes a noise-robust multilayer perceptron (MLP) architecture for DDoS attack detection trained with corrupted data. In the proposed approach, the average value of the common features among dataset instances is iteratively filtered out by applying Higher Order Singular Value Decomposition (HOSVD) based techniques. The effectiveness of the proposed architecture is validated through comparison with state-of-the-art methods.},
 author = {Maranhão, João Paulo A. and Costa, João Paulo C. L. da and de Freitas, Edison Pignaton and Javidi, Elnaz and de Sousa, Rafael T.},
 doi = {10.1109/LCOMM.2020.3032170},
 issn = {1558-2558},
 journal = {IEEE Communications Letters},
 keywords = {Tensors;Training;Testing;Feature extraction;Denial-of-service attack;Computer crime;Machine learning;Tensor decomposition;machine learning;supervised classification;neural networks},
 month = {Feb},
 number = {2},
 pages = {402-406},
 title = {Noise-Robust Multilayer Perceptron Architecture for Distributed Denial of Service Attack Detection},
 volume = {25},
 year = {2021}
}

@article{9239385,
 abstract = {In recent years, due to the frequent occurrence of network intrusions, more and more researchers have begun to focus on network intrusion detection. However, it is still a challenge to detect unknown attacks. Currently, there are two main methods of unknown attack detection: clustering and honeypot. But they still have unsolved problems such as difficulty in collecting unknown attack samples and failure to detect on time. Zero-Shot learning is proposed to deal with the problem in this article, which can recognize unknown attacks by learning the mapping relations between feature space and semantic space (such as attribute space). When the semantic descriptions of all attacks (including known and unknown attacks) are provided, the classifier built by Zero-Shot learning can extract common semantic information among all attacks and construct connections between known and unknown attacks. The classifier then utilizes the connections to classify unknown attacks although there are no samples for unknown attacks. In this article, we first propose to use Zero-Shot learning to overcome the challenge of unknown attack detection and illustrate the feasibility of this method. Secondly, we then propose a novel method of Zero-Shot learning based on sparse autoencoder for unknown attack detection. This method maps the feature of known attacks to the semantic space, and restores the semantic space to the feature space by constrains of reconstruction error, and establishes the feature to semantic mapping, which is used to detect unknown attacks. Verification tests have been carried out by using the public dataset NSL_KDD. From the experiments conducted in this work, the results show that the average accuracy reaches 88.3%, which performs better than other methods.},
 author = {Zhang, Zhun and Liu, Qihe and Qiu, Shilin and Zhou, Shijie and Zhang, Cheng},
 doi = {10.1109/ACCESS.2020.3033494},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Semantics;Feature extraction;Neural networks;Training;Network intrusion detection;Data mining;Zero-shot learning;network intrusion;unknown attack detection;sparse semantic autoencoder},
 month = {},
 number = {},
 pages = {193981-193991},
 title = {Unknown Attack Detection Based on Zero-Shot Learning},
 volume = {8},
 year = {2020}
}

@article{9239970,
 abstract = {The diversity of network attacks poses severe challenges to intrusion detection systems (IDSs). Traditional attack recognition methods usually adopt mining data associations to identify anomalies, which has the disadvantages of a high false alarm rate (FAR), low recognition accuracy (ACC) and poor generalization ability. To ameliorate the comprehensive capabilities of IDS and strengthen network security, we propose a novel intrusion detection method based on the adaptive synthetic sampling (ADASYN) algorithm and an improved convolutional neural network (CNN). First, we use the ADASYN method to balance the sample distribution, which can effectively prevent the model from being sensitive to large samples and ignore small samples. Second, the improved CNN is based on the split convolution module (SPC-CNN), which can increase the diversity of features and eliminate the impact of interchannel information redundancy on model training. Then, an AS-CNN model mixed with ADASYN and SPC-CNN is used for intrusion detection tasks. Finally, the standard NSL-KDD dataset is selected to test AS-CNN. The simulation illustrates that the accuracy is 4.60% and 2.79% higher than that of the traditional CNN and RNN models, and the detection rate (DR) increased by 11.34% and 10.27%, respectively. Additionally, the FAR decreased by 15.58% and 14.57%, respectively, compared with the two models.},
 author = {Hu, Zhiquan and Wang, Liejun and Qi, Lei and Li, Yongming and Yang, Wenzhong},
 doi = {10.1109/ACCESS.2020.3034015},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Classification algorithms;Task analysis;Redundancy;Machine learning algorithms;Data models;Intrusion detection;adaptive synthetic sampling;AS-CNN;NSL-KDD},
 month = {},
 number = {},
 pages = {195741-195751},
 title = {A Novel Wireless Network Intrusion Detection Method Based on Adaptive Synthetic Sampling and an Improved Convolutional Neural Network},
 volume = {8},
 year = {2020}
}

@article{9247957,
 abstract = {Cancer is a second foremost life-threatening disease next to cardiovascular diseases. In particular, brain cancer holds the least rate of survival than all other cancer types. The categorization of a brain tumor depends upon the various factors such as texture, shape and location. The medical experts have preferred the appropriate treatment to the patients, based on the accurate identification of tumor type. The process of segmenting the Magnetic Resonance Imaging (MRI) has high complicacy during the analysis of brain tumor, owing to its variable shape, location, size, and texture. The physicians and radiologists can easily detect and categorize the tumors if there exists a system by combining Computer Assisted Diagnosis (CAD) as well as Artificial Intelligence (AI). An approach of automated segmentation has proposed in this paper, which enables the segmentation of tumor out of MRI images, besides enhances the efficiency of segmentation and classification. The initial functions of this approach include preprocessing and segmentation processes for segmenting tumor or tissue of benign and malignant by expanding a range of data and clustering. A modern learning-based approach has suggested in this study, in order to process the automated segmentation in multimodal MRI images to identify brain tumor, hence the clustering algorithm of Bat Algorithm with Fuzzy C-Ordered Means (BAFCOM) has recommended segmenting the tumor. The Bat Algorithm calculates the initial centroids and distance within the pixels in the clustering algorithm of BAFCOM, which also acquires the tumor through determining the distance among tumor Region of Interest (RoI) and non-tumor RoI. Afterwards, the MRI image has analyzed by the Enhanced Capsule Networks (ECN) method to categorize it as normal and brain tumor. Ultimately, the algorithm of ECN has assessed the performance of proposed approach by distinguishing the two categories of the tumor over MRI images, besides the suggested ECN classifier has assessed by the measurement factors of accuracy, precision, recall, and F1-score. In addition, the genetic algorithm has applied to process the automatic tumor stage classification, which in turn classification accuracy enhanced.},
 author = {Alhassan, Afnan M. and Zainon, Wan Mohd Nazmee Wan},
 doi = {10.1109/ACCESS.2020.3035803},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Tumors;Clustering algorithms;Image segmentation;Magnetic resonance imaging;Cancer;Shape;Brain modeling;Machine learning;enhanced capsule networks (ECN);brain tumor;bat algorithm with fuzzy c-ordered means (BAFCOM);magnetic resonance imaging (MRI) images},
 month = {},
 number = {},
 pages = {201741-201751},
 title = {BAT Algorithm With fuzzy C-Ordered Means (BAFCOM) Clustering Segmentation and Enhanced Capsule Networks (ECN) for Brain Cancer MRI Images Classification},
 volume = {8},
 year = {2020}
}

@article{9247978,
 abstract = {As an essential part of the network-based intrusion detection systems (IDS), malicious traffic detection using deep learning methods has become a research focus in network intrusion detection. However, even the most advanced IDS available are challenging to satisfy real-time detection because they usually need to accumulate the packets into particular flows and then extract the features, causing processing delays. In this paper, using the deep learning approach, we propose a deep hierarchical network for malicious traffic detection at the packet-level, capable of learning the features of traffic from raw packet data. It used the one-dimensional convolutional layer to extract the spatial features of raw packets and Gated Recurrent Units (GRU) structure to extract the temporal features. To evaluate the performance of our approach, experiments were conducted to examine the efficiency of the proposed deep hierarchical network based on the ISCX2012 dataset, USTC-TFC2016 dataset and CICIDS2017 dataset, respectively. Accuracy (ACC), detection rate (DR) and false alarm rate (FAR) are the metrics for evaluation. In the ISCX2012 dataset, our approach achieved 99.42%, 99.74%, 1.77% on ACC, DR and FAR, respectively. In USTC-TFC2016, there were 99.94%, 99.99%, 0.99%. In CICIDS2017, there were 100%, 100%, 0%. Furthermore, we discussed the impact of data balanced on classification performance and the time efficiency between the Long Short-Term Memory (LSTM) model and the GRU model. Experiments show that our approach can effectively detect malicious traffic and outperform sout s many other state-of-the-art methods in terms of ACC and DR.},
 author = {Wang, Bo and Su, Yang and Zhang, Mingshu and Nie, Junke},
 doi = {10.1109/ACCESS.2020.3035967},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Logic gates;Brain modeling;Deep learning;Data models;Biological neural networks;Protocols;Network intrusion detection;deep learning;neural networks;malicious traffic detection},
 month = {},
 number = {},
 pages = {201728-201740},
 title = {A Deep Hierarchical Network for Packet-Level Malicious Traffic Detection},
 volume = {8},
 year = {2020}
}

@article{9252856,
 abstract = {Advances in the Internet of Things (IoT) and aviation sector have resulted in the emergence of smart airports. Services and systems powered by the IoT enable smart airports to have enhanced robustness, efficiency and control, governed by real-time monitoring and analytics. Smart sensors control the environmental conditions inside the airport, automate passenger-related actions and support airport security. However, these augmentations and automation introduce security threats to network systems of smart airports. Cyber-attackers demonstrated the susceptibility of IoT systems and networks to Advanced Persistent Threats (APT), due to hardware constraints, software flaws or IoT misconfigurations. With the increasing complexity of attacks, it is imperative to safeguard IoT networks of smart airports and ensure reliability of services, as cyber-attacks can have tremendous consequences such as disrupting networks, cancelling travel, or stealing sensitive information. There is a need to adopt and develop new Artificial Intelligence (AI)-enabled cyber-defence techniques for smart airports, which will address the challenges brought about by the incorporation of IoT systems to the airport business processes, and the constantly evolving nature of contemporary cyber-attacks. In this study, we present a holistic review of existing smart airport applications and services enabled by IoT sensors and systems. Additionally, we investigate several types of cyber defence tools including AI and data mining techniques, and analyse their strengths and weaknesses in the context of smart airports. Furthermore, we provide a classification of smart airport sub-systems based on their purpose and criticality and address cyber threats that can affect the security of smart airport's networks.},
 author = {Koroniotis, Nickolaos and Moustafa, Nour and Schiliro, Francesco and Gauravaram, Praveen and Janicke, Helge},
 doi = {10.1109/ACCESS.2020.3036728},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Tools;Airports;Software reliability;Internet of Things;Artificial intelligence;Task analysis;Intelligent sensors;Cyber security;artificial intelligence;smart airport;Industry 4.0;Internet of Things (IoT)},
 month = {},
 number = {},
 pages = {209802-209834},
 title = {A Holistic Review of Cybersecurity and Reliability Perspectives in Smart Airports},
 volume = {8},
 year = {2020}
}

@article{9256206,
 abstract = {Deep neural networks (DNNs) have achieved great success in various applications due to their strong expressive power. However, recent studies have shown that DNNs are vulnerable to adversarial examples, and these manipulated instances can mislead DNN into making false predictions. The existing methods of generating adversarial examples include pixel-level perturbation or spatial transformation of images, which cannot consider concurrently with the semantic quality of adversarial examples or success rate of attack. These methods are computationally bulky and slow to generate the adversarial examples. To solve this kind of issue, a two-stage generative adversarial networks (TSGAN) with semantic content constraints is proposed in this paper. The first-stage uses the original example dataset to train generator  $G$ , which can help the generator learn the distribution of real examples. Then, the example semantic quality constraint loss function, the adversarial loss function and the distance loss function are adopted in the second-stage, so that the generator  $G$  can continue to learn to search the distribution of the adversarial examples, and train the new generator  $G_{adv} $ . The adversarial examples generated by generator  $G_{adv} $  are better fit the distribution of real examples, and have targeted black-box attack capability. The experiments show that the adversarial examples generated by TSGAN can achieve the success rate of attack at 98.40% in target model, 29.40% success rate in defense-oriented model. And 77.58% success rate is obtained in the transfer test attack. The results show that the adversarial examples generated by the proposed model, which has a highly attack success rate and more difficult to defense. Meanwhile, the improved adversarial examples have stronger transfer ability than the existing models. The proposed model can effectively reduce the expression of target category features of the adversarial examples, and the generated adversarial examples have better semantic quality than others.},
 author = {Liu, Jianyi and Tian, Yu and Zhang, Ru and Sun, Youqiang and Wang, Chan},
 doi = {10.1109/ACCESS.2020.3037329},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Generators;Feature extraction;Semantics;Generative adversarial networks;Gallium nitride;Perturbation methods;Generative adversarial networks;adversarial example attack;semantic content},
 month = {},
 number = {},
 pages = {205766-205777},
 title = {A Two-Stage Generative Adversarial Networks With Semantic Content Constraints for Adversarial Example Generation},
 volume = {8},
 year = {2020}
}

@article{9262847,
 abstract = {A masquerader is an attacker who gains illegitimate access to a user’s account. Masquerade detection is one of the key problems of intrusion detection systems. Deep learning models that obtained state-of-the-art results in masquerade detection have failed to exhibit very high detection performance when data samples contain limited information. Alternatively, computationally cheaper and more memory-efficient traditional machine learning models suffer from less robust features, which hinders them in achieving high detection performance. The contributions of this article are as follows: we introduce new features of variable-length UNIX command sequences (i.e., weighted occurrence frequencies of different orders) and integrate these features into an extended Markov-chain-based variable-length model. The detection performance of our model is evaluated on three publicly available and free datasets: Schonlau (SEA), Purdue (PU), and Greenberg. The results demonstrate that our model significantly improves the true positive rate (TPR), false positive rate, receiver operator characteristic, and threshold variance compared to the baselines (other Markov-chain-based variable-length models). Furthermore, in terms of the TPR, the proposed method is superior to a state-of-the-art deep learning model that uses a convolutional neural network on the PU and Greenberg datasets and a state-of-the-art sequence-alignment-hidden Markov model on the SEA dataset. Moreover, the proposed method is much more lightweight than the state-of-the-art models in terms of computational and memory complexity, and thus more suitable for real-time masquerade detection.},
 author = {Barseghyan, Ghazaros and Yuan, Yuyu and Anakpa, Manawa},
 doi = {10.1109/ACCESS.2020.3039166},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Hidden Markov models;Computational modeling;Data models;Markov processes;Feature extraction;Memory management;Anomaly detection;Anomaly detection;intrusion detection;machine learning (ML);Markov chain;masquerade detection;UNIX commands},
 month = {},
 number = {},
 pages = {210140-210157},
 title = {Model for Detection of Masquerade Attacks Based on Variable-Length Sequences},
 volume = {8},
 year = {2020}
}

@article{9272378,
 abstract = {In this paper, an intrusion detection system is introduced that uses data mining and machine learning concepts to detect network intrusion patterns. In the proposed method, an artificial neural network (ANN) is used as a learning technique in intrusion detection. The metaheuristic algorithm with the swarm-based approach is used to reduce intrusion detection errors. In the proposed method, the Grasshopper Optimization Algorithm (GOA) is used for better and more accurate learning of ANNs to reduce intrusion detection error rate. The role of the GOAMLP algorithm is to minimize the intrusion detection error in the neural network by selecting useful parameters such as weight and bias. Our implementation in MATLAB software and using the KDD and UNSW datasets show that the proposed method detects abnormal, malicious traffic and attacks with high accuracy. The GOAMLP method outperforms and is more accurate than the existing state-of-the-art techniques such as RF, XGBoost, and embedded learning of ANN with BOA, HHO, and BWO algorithms in network intrusion detection.},
 author = {Moghanian, Shadi and Saravi, Farshid Bagheri and Javidi, Giti and Sheybani, Ehsan O.},
 doi = {10.1109/ACCESS.2020.3040740},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Optimization;Mathematical model;Machine learning algorithms;Multilayer perceptrons;Genetic algorithms;Computer hacking;Network intrusion detection;data mining;machine learning;artificial neural network;multilayer perceptron;swarm-based algorithm},
 month = {},
 number = {},
 pages = {215202-215213},
 title = {GOAMLP: Network Intrusion Detection With Multilayer Perceptron and Grasshopper Optimization Algorithm},
 volume = {8},
 year = {2020}
}

@article{9274356,
 abstract = {The Internet has been evolving from a traditional mechanism to a modern service-oriented architecture, such as quality-of-service (QoS) policies, to meet users’ various requirements for high service quality. An instant and effective network traffic classification method is indispensable to identify network services to enforce QoS policies on the corresponding service. Network managers can easily flexibly deploy traffic classification modules and configure the network policies with the help of the emerging software-defined networking. However, most existing traffic classification solutions, such as port-based methods or deep packet inspection, cannot handle real-time and encrypted traffic classification. In this research, a Convolutional Autoencoder Packet Classifier (CAPC) has been proposed to immediately classify incoming packets in fine-grained and coarse-grained manners, that is, classifying a service to a single application and a rough genre, respectively. The CAPC is a packet-based deep learning model consisting of a 1D convolutional neural network and an autoencoder, which can handle dynamic-port and encrypted traffic and even cluster similar applications. This classifier is verified on not only the private self-captured traffic but also a public VPN dataset to demonstrate its performance. Moreover, the CAPC classifies different types of service traffic with an accuracy of over 99.9% on the private dataset of 16 services and over 97% on the public dataset of 24 services, thereby outperforming other deep learning classifiers. Experimental results also show other performance metrics, including stability, average precision, and recall and the highest F1-score values of 15 and 18 services on the private and public datasets, respectively.},
 author = {Chiu, Kai-Cheng and Liu, Chien-Chang and Chou, Li-Der},
 doi = {10.1109/ACCESS.2020.3041806},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Deep learning;Cryptography;Virtual private networks;Data models;Feature extraction;Payloads;Neural networks;Autoencoder;deep learning;one-dimensional convolutional neural network;packet-based traffic classification},
 month = {},
 number = {},
 pages = {218081-218094},
 title = {CAPC: Packet-Based Network Service Classifier With Convolutional Autoencoder},
 volume = {8},
 year = {2020}
}

@article{9274426,
 abstract = {The existing satellite-terrestrial integrated networks (STINs) suffer from security and privacy concerns due to the limited resources, poor attack resistance and high privacy requirements of satellite networks. Network Intrusion Detection System (NIDS) is intended to provide a high level of protection for modern network environments, but how to implement distributed NIDS on STINs has not been widely discussed. At the same time, satellite networks have always lacked real and effective security data sets as references. To solve these problems, we propose a distributed NIDS using Federal Learning (FL) in STIN to properly allocate resources in each domain to analyze and block malicious traffic, especially distributed denial-of-service (DDoS) attacks. Specifically, we first design a typical STIN topology, on the basis of which we collect and design security data sets adapted to satellite and terrestrial networks in STIN, respectively. To address the problem of poor attack resistance of satellite networks, we propose a satellite network topology optimization algorithm to reduce the difficulty in tracing malicious packets due to frequent link switching. In order to solve the problem of limited resources and high privacy requirements of satellite networks, we propose an algorithm for FL adaptation to STIN, and build a distributed NIDS using FL in STIN. Finally, we deploy the designed distributed NIDS in a prototype system and evaluate our proposed distributed NIDS with a large number of simulations of randomly generated malicious traffic. Related results demonstrate that the performance of our approach is better than traditional deep learning and intrusion detection methods in terms of malicious traffic recognition rate, packet loss rate, and CPU utilization.},
 author = {Li, Kun and Zhou, Huachun and Tu, Zhe and Wang, Weilin and Zhang, Hongke},
 doi = {10.1109/ACCESS.2020.3041641},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Satellites;Security;Distributed databases;Prototypes;Denial-of-service attack;Privacy;Network topology;Satellite-terrestrial integrated network;distributed NIDS;security data set;federated learning},
 month = {},
 number = {},
 pages = {214852-214865},
 title = {Distributed Network Intrusion Detection System in Satellite-Terrestrial Integrated Networks Using Federated Learning},
 volume = {8},
 year = {2020}
}

@article{9277523,
 abstract = {Pervasive growth and usage of the Internet and mobile applications have expanded cyberspace. The cyberspace has become more vulnerable to automated and prolonged cyberattacks. Cyber security techniques provide enhancements in security measures to detect and react against cyberattacks. The previously used security systems are no longer sufficient because cybercriminals are smart enough to evade conventional security systems. Conventional security systems lack efficiency in detecting previously unseen and polymorphic security attacks. Machine learning (ML) techniques are playing a vital role in numerous applications of cyber security. However, despite the ongoing success, there are significant challenges in ensuring the trustworthiness of ML systems. There are incentivized malicious adversaries present in the cyberspace that are willing to game and exploit such ML vulnerabilities. This paper aims to provide a comprehensive overview of the challenges that ML techniques face in protecting cyberspace against attacks, by presenting a literature on ML techniques for cyber security including intrusion detection, spam detection, and malware detection on computer networks and mobile networks in the last decade. It also provides brief descriptions of each ML method, frequently used security datasets, essential ML tools, and evaluation metrics to evaluate a classification model. It finally discusses the challenges of using ML techniques in cyber security. This paper provides the latest extensive bibliography and the current trends of ML in cyber security.},
 author = {Shaukat, Kamran and Luo, Suhuai and Varadharajan, Vijay and Hameed, Ibrahim A. and Xu, Min},
 doi = {10.1109/ACCESS.2020.3041951},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Machine learning;Internet;Deep learning;Market research;Malware;Intrusion detection;Cyber security;deep learning;intrusion detection;malware;machine learning;spam},
 month = {},
 number = {},
 pages = {222310-222354},
 title = {A Survey on Machine Learning Techniques for Cyber Security in the Last Decade},
 volume = {8},
 year = {2020}
}

@article{9294026,
 abstract = {Deep Learning (DL) algorithms based on artificial neural networks have achieved remarkable success and are being extensively applied in a variety of application domains, ranging from image classification, automatic driving, natural language processing to medical diagnosis, credit risk assessment, intrusion detection. However, the privacy and security issues of DL have been revealed that the DL model can be stolen or reverse engineered, sensitive training data can be inferred, even a recognizable face image of the victim can be recovered. Besides, the recent works have found that the DL model is vulnerable to adversarial examples perturbed by imperceptible noised, which can lead the DL model to predict wrongly with high confidence. In this paper, we first briefly introduces the four types of attacks and privacy-preserving techniques in DL. We then review and summarize the attack and defense methods associated with DL privacy and security in recent years. To demonstrate that security threats really exist in the real world, we also reviewed the adversarial attacks under the physical condition. Finally, we discuss current challenges and open problems regarding privacy and security issues in DL.},
 author = {Liu, Ximeng and Xie, Lehui and Wang, Yaopeng and Zou, Jian and Xiong, Jinbo and Ying, Zuobin and Vasilakos, Athanasios V.},
 doi = {10.1109/ACCESS.2020.3045078},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Computational modeling;Privacy;Data models;Training;Training data;Face recognition;Deep learning;DL privacy;DL security;model extraction attack;model inversion attack;adversarial attack;poisoning attack;adversarial defense;privacy-preserving},
 month = {},
 number = {},
 pages = {4566-4593},
 title = {Privacy and Security Issues in Deep Learning: A Survey},
 volume = {9},
 year = {2021}
}

@article{9296578,
 abstract = {Predominant network intrusion detection systems (NIDS) aim to identify malicious traffic patterns based on a handcrafted dataset of rules. Recently, the application of machine learning in NIDS helps alleviate the enormous effort of human observation. Federated learning (FL) is a collaborative learning scheme concerning distributed data. Instead of sharing raw data, it allows a participant to share only a trained local model. Despite the success of existing FL solutions, in NIDS, a network’s traffic data distribution does not always fit into the single global model of FL; some networks have similarities with each other but other networks do not. We propose Segmented-Federated Learning (Segmented-FL), where by employing periodic local model evaluation and network segmentation, we aim to bring similar network environments to the same group. A comparison between FL and our method was conducted against a range of metrics including the weighted precision, recall, and F1 score, using a collected dataset from 20 massively distributed networks within 60 days. By studying the optimized hyperparameters of Segmented-FL and employing three evaluation methods, it shows that Segmented-FL has better performance in all three types of intrusion detection tasks, achieving validation weighted F1 scores of 0.964, 0.803, and 0.912 with Method A, Method B, and Method C respectively. For each method, this scheme shows a gain of 0.1%, 4.0% and 1.1% in performance compared with FL.},
 author = {Sun, Yuwei and Esaki, Hiroshi and Ochiai, Hideya},
 doi = {10.1109/OJCOMS.2020.3044323},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Operating systems;Traffic control;Telecommunication traffic;Intrusion detection;Cybersecurity;deep learning;intrusion detection;segmented-federated learning;LAN;convolutional neural network},
 month = {},
 number = {},
 pages = {102-112},
 title = {Adaptive Intrusion Detection in the Networking of Large-Scale LANs With Segmented Federated Learning},
 volume = {2},
 year = {2021}
}

@article{9310178,
 abstract = {Nowadays, Intrusion Detection System (IDS) is an active research topic with machine learning nature. A single-hidden layer feedforward neural network (SLFN) trained on the approach of extreme learning machine (ELM) is used for (IDS). The encouraging factors for its usage are its fast learning and supportability of sequential learning in its online sequential extreme learning machine (OSELM) variant. An issue with OSELM that has been addressed by researchers is its random weights nature of the input-hidden layer. Most approaches use the concept of metaheuristic optimisation for determining the optimal weights of OSELM and resolve the random weight. However, metaheuristic approaches require many trials to determine the optimal one. Hence, there is concern about the convergence aspect and speed. This article proposes a novel approach for finding the optimal weights of the input-hidden layer. This article presents an approach for an integration between OSELM and back-propagation designated as (OSELM-BP). After integration, BP changes the random weights iteratively and uses an iterated evaluation of the generated error for feedback correction of the weights. The approach is evaluated based on various scenarios of activation functions for OSELM on the one hand and the number of iterations for BP on the other. An extensive evaluation of the approach and comparison with the original OSELM reveal a superiority of OSELM-BP in reaching optimal accuracy with a small number of iterations.},
 author = {Ahmad Hamdi Qaiwmchi, Nedhal and Amintoosi, Haleh and Mohajerzadeh, Amirhossein},
 doi = {10.1109/ACCESS.2020.3047933},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Intrusion detection;Optimization;Classification algorithms;Prediction algorithms;Neurons;Power system stability;Online sequential extreme learning machine (OSELM);intrusion detection system (IDS);back-propagation (BP);activation function},
 month = {},
 number = {},
 pages = {4983-4999},
 title = {Intrusion Detection System Based on Gradient Corrected Online Sequential Extreme Learning Machine},
 volume = {9},
 year = {2021}
}

@article{9311173,
 abstract = {In imbalanced network traffic, malicious cyber-attacks can often hide in large amounts of normal data. It exhibits a high degree of stealth and obfuscation in cyberspace, making it difficult for Network Intrusion Detection System(NIDS) to ensure the accuracy and timeliness of detection. This paper researches machine learning and deep learning for intrusion detection in imbalanced network traffic. It proposes a novel Difficult Set Sampling Technique(DSSTE) algorithm to tackle the class imbalance problem. First, use the Edited Nearest Neighbor(ENN) algorithm to divide the imbalanced training set into the difficult set and the easy set. Next, use the KMeans algorithm to compress the majority samples in the difficult set to reduce the majority. Zoom in and out the minority samples' continuous attributes in the difficult set synthesize new samples to increase the minority number. Finally, the easy set, the compressed set of majority in the difficult, and the minority in the difficult set are combined with its augmentation samples to make up a new training set. The algorithm reduces the imbalance of the original training set and provides targeted data augment for the minority class that needs to learn. It enables the classifier to learn the differences in the training stage better and improve classification performance. To verify the proposed method, we conduct experiments on the classic intrusion dataset NSL-KDD and the newer and comprehensive intrusion dataset CSE-CIC-IDS2018. We use classical classification models: random forest(RF), Support Vector Machine(SVM), XGBoost, Long and Short-term Memory(LSTM), AlexNet, Mini-VGGNet. We compare the other 24 methods; the experimental results demonstrate that our proposed DSSTE algorithm outperforms the other methods.},
 author = {Liu, Lan and Wang, Pengcheng and Lin, Jun and Liu, Langzhou},
 doi = {10.1109/ACCESS.2020.3048198},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Machine learning;Deep learning;Machine learning algorithms;Data models;Support vector machines;Feature extraction;IDS;imbalanced network traffic;machine learning;deep learning;CSE-CIC-IDS2018},
 month = {},
 number = {},
 pages = {7550-7563},
 title = {Intrusion Detection of Imbalanced Network Traffic Based on Machine Learning and Deep Learning},
 volume = {9},
 year = {2021}
}

@article{9311723,
 abstract = {Traffic classification is widely used in various network functions such as software-defined networking and network intrusion detection systems. Many traffic classification methods have been proposed for classifying encrypted traffic by utilizing a deep learning model without inspecting the packet payload. However, they have an important challenge in that the mechanism of deep learning is inexplicable. A malfunction of the deep learning model may occur if the training dataset includes malicious or erroneous data. Explainable artificial intelligence (XAI) can give some insight for improving the deep learning model by explaining the cause of the malfunction. In this paper, we propose a method for explaining the working mechanism of deep-learning-based traffic classification as a method of XAI based on a genetic algorithm. We describe the mechanism of the deep-learning-based traffic classifier by quantifying the importance of each feature. In addition, we leverage the genetic algorithm to generate a feature selection mask that selects important features in the entire feature set. To demonstrate the proposed explanation method, we implemented a deep-learning-based traffic classifier with an accuracy of approximately 97.24%. In addition, we present the importance of each feature derived from the proposed explanation method by defining the dominance rate.},
 author = {Ahn, Seyoung and Kim, Jeehyeong and Park, Soo Young and Cho, Sunghyun},
 doi = {10.1109/ACCESS.2020.3048348},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Deep learning;Machine learning;Quality of service;Payloads;Genetic algorithms;Data models;Traffic classification;deep learning;explainable artificial intelligence (XAI);genetic algorithm},
 month = {},
 number = {},
 pages = {4738-4751},
 title = {Explaining Deep Learning-Based Traffic Classification Using a Genetic Algorithm},
 volume = {9},
 year = {2021}
}

@article{9311786,
 abstract = {With the increasing population of Industry 4.0, both AI and smart techniques have been applied and become hotly discussed topics in industrial cyber-physical systems (CPS). Intelligent anomaly detection for identifying cyber-physical attacks to guarantee the work efficiency and safety is still a challenging issue, especially when dealing with few labeled data for cyber-physical security protection. In this article, we propose a few-shot learning model with Siamese convolutional neural network (FSL-SCNN), to alleviate the over-fitting issue and enhance the accuracy for intelligent anomaly detection in industrial CPS. A Siamese CNN encoding network is constructed to measure distances of input samples based on their optimized feature representations. A robust cost function design including three specific losses is then proposed to enhance the efficiency of training process. An intelligent anomaly detection algorithm is developed finally. Experiment results based on a fully labeled public dataset and a few labeled dataset demonstrate that our proposed FSL-SCNN can significantly improve false alarm rate (FAR) and F1 scores when detecting intrusion signals for industrial CPS security protection.},
 author = {Zhou, Xiaokang and Liang, Wei and Shimizu, Shohei and Ma, Jianhua and Jin, Qun},
 doi = {10.1109/TII.2020.3047675},
 issn = {1941-0050},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Anomaly detection;Security;Training;Task analysis;Feature extraction;Analytical models;Object recognition;Anomaly detection;convolutional neural network (CNN);few-shot learning;industrial cyber-physical systems (CPS);Siamese network},
 month = {Aug},
 number = {8},
 pages = {5790-5798},
 title = {Siamese Neural Network Based Few-Shot Learning for Anomaly Detection in Industrial Cyber-Physical Systems},
 volume = {17},
 year = {2021}
}

@article{9312605,
 abstract = {A network intrusion detection system (NIDS) is an important technology for cyber security. Recently, machine learning based NIDSs are being actively researched as various machine learning techniques are proposed. However, existing NIDSs have limitation in terms of generality because they have been designed based on specific characteristics obtained from analyzing some partial datasets. Moreover, in reality, the NIDS datasets have a significantly imbalanced ratio between normal and abnormal data. It causes the minority class problem, which needs to be addressed for developing robust and reliable NIDSs working in various environments. This paper proposes a novel technique using service-aware dataset partitioning, which provides high scalability to handle huge and rapidly growing network data flexibly, and helps the classifier to improve the classification performance in terms of accuracy and speed. We evaluated our approach with the Kyoto2016 dataset, which is a well-known dataset for highly imbalanced data, using various classification algorithms and parameters for achieving the best performance and compared it with existing state-of-the-art approaches. Our experimental results indicated that our approach can classify network traffics rapidly and accurately with huge imbalanced datasets. We conclude that it can relieve serious existing issues of imbalanced datasets for modern machine learning based NIDS solutions.},
 author = {Uhm, Yeongje and Pak, Wooguil},
 doi = {10.1109/ACCESS.2020.3048900},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Machine learning algorithms;Machine learning;Partitioning algorithms;Support vector machines;Heuristic algorithms;Scalability;Network intrusion detection;service based partitioning;imbalanced data;machine learning;minority class problem},
 month = {},
 number = {},
 pages = {6608-6622},
 title = {Service-Aware Two-Level Partitioning for Machine Learning-Based Network Intrusion Detection With High Performance and High Scalability},
 volume = {9},
 year = {2021}
}

@article{9319853,
 abstract = {Deep learning has become a research hotspot in the field of network intrusion detection. In order to further improve the detection accuracy and performance, we proposed an intrusion detection model based on improved deep belief network (DBN). Traditional neural network training methods, like Back Propagation (BP), start to train a model with preset parameters such as the randomly initialized weights and thresholds, which may bring some issues, e.g., attracting the model to the local optimal solutions, or requiring a long training period. We use the Kernel-based Extreme Learning Machine (KELM) with the supervised learning ability to replace the BP algorithm in DBN in a bid to ameliorate the situation. Considering the problem of poor classification performance usually caused by randomly initializing kernel parameters with KELM, an enhanced grey wolf optimizer (EGWO) is designed to optimize the parameters of KELM. In order to improve the search ability and optimization ability of the traditional grey wolf optimizer algorithm, a novel optimization strategy combining the inner and outer hunting is introduced. Experiments on KDDCup99, NSL-KDD, UNSW-NB15 and CICIDS2017 datasets show that the proposed DBN-EGWO-KELM algorithm has greater advantages in terms of its accuracy, precision, true positive rate, false positive rate and other evaluation indices compared with BP, RBF, SVM, KELM, LIBSVM, CNN, DBN-KELM and other intrusion detection models, and can effectively meet the requirements of intrusion detection of complex networks.},
 author = {Wang, Zhendong and Zeng, Yong and Liu, Yaodi and Li, Dahai},
 doi = {10.1109/ACCESS.2021.3051074},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Classification algorithms;Neural networks;Data models;Deep learning;Network intrusion detection;Extreme learning machines;Intrusion detection;deep belief network;kernel-based extreme learning machine;grey wolf optimizer},
 month = {},
 number = {},
 pages = {16062-16091},
 title = {Deep Belief Network Integrating Improved Kernel-Based Extreme Learning Machine for Network Intrusion Detection},
 volume = {9},
 year = {2021}
}

@article{9320588,
 abstract = {As a tremendous amount of service being streamed online to their users along with massive digital privacy information transmitted in recent years, the internet has become the backbone of most people's everyday workflow. The extending usage of the internet, however, also expands the attack surface for cyberattacks. If no effective protection mechanism is implemented, the internet will only be much vulnerable and this will raise the risk of data getting leaked or hacked. The focus of this paper is to propose an Intrusion Detection System (IDS) based on the Convolutional Neural Network (CNN) to reinforce the security of the internet. The proposed IDS model is aimed at detecting network intrusions by classifying all the packet traffic in the network as benign or malicious classes. The Canadian Institute for Cybersecurity Intrusion Detection System (CICIDS2017) dataset has been used to train and validate the proposed model. The model has been evaluated in terms of the overall accuracy, attack detection rate, false alarm rate, and training overhead. A comparative study of the proposed model's performance against nine other well-known classifiers has been presented.},
 author = {Ho, Samson and Jufout, Saleh Al and Dajani, Khalil and Mozumdar, Mohammad},
 doi = {10.1109/OJCS.2021.3050917},
 issn = {2644-1268},
 journal = {IEEE Open Journal of the Computer Society},
 keywords = {Mathematical model;Intrusion detection;Databases;Computational modeling;Deep learning;Convolutional neural networks;Machine learning;CICIDS2017;Convolutional neural network;Cybersecurity;Deep learning;Intrusion detection system},
 month = {},
 number = {},
 pages = {14-25},
 title = {A Novel Intrusion Detection Model for Detecting Known and Innovative Cyberattacks Using Convolutional Neural Network},
 volume = {2},
 year = {2021}
}

@article{9321332,
 abstract = {Existing techniques for incremental learning are computationally expensive and produce duplicate features leading to higher false positive and true negative rates. We propose a novel privacy-preserving intrusion detection pipeline for distributed incremental learning. Our pre-processing technique eliminates redundancies and selects unique features by following innovative extraction techniques. We use autoencoders with non-negativity constraints, which help us extract less redundant features. More importantly, the distributed intrusion detection model reduces the burden on the edge classifier and distributes the load among IoT and edge devices. Theoretical analysis and numerical experiments have shown lower space and time costs than state of the art techniques, with comparable classification accuracy. Extensive experiments with standard data sets and real-time streaming IoT traffic give encouraging results.},
 author = {Tabassum, Aliya and Erbad, Aiman and Mohamed, Amr and Guizani, Mohsen},
 doi = {10.1109/ACCESS.2021.3051530},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Deep learning;Security;Real-time systems;Intrusion detection;Data models;Task analysis;Deep learning;internet of things (IoT);intrusion detection system (IDS);incremental learning;pre-processing},
 month = {},
 number = {},
 pages = {14271-14283},
 title = {Privacy-Preserving Distributed IDS Using Incremental Learning for IoT Health Systems},
 volume = {9},
 year = {2021}
}

@article{9334988,
 abstract = {The popularity and usage of Cloud computing is increasing rapidly. Several companies are investing in this field either for their own use or to provide it as a service for others. One of the results of Cloud development is the emergence of various security problems for both industry and consumer. One of the ways to secure Cloud is by using Machine Learning (ML). ML techniques have been used in various ways to prevent or detect attacks and security gaps on the Cloud. In this paper, we provide a Systematic Literature Review (SLR) of ML and Cloud security methodologies and techniques. We analyzed 63 relevant studies and the results of the SLR are categorized into three main research areas: (i) the different types of Cloud security threats, (ii) ML techniques used, and (iii) the performance outcomes. We have defined 11 Cloud security areas. Moreover, distributed denial-of-service (DDoS) and data privacy are the most common Cloud security areas, with a 16% level of use and 14%respectively. On the other hand, we found 30 ML techniques used, some used hybrid and others as standalone. The most popular ML used is SVM in both hybrid and standalone models. Furthermore, 60% of the papers compared their models with other models to prove the efficiency of their proposed model. Moreover, 13 different evaluation metrics were enumerated. The most applied metric is true positive rate and least used is training time. Lastly, from 20 datasets found, KDD and KDD CUP'99 are the most used among relevant studies.},
 author = {Nassif, Ali Bou and Talib, Manar Abu and Nasir, Qassim and Albadani, Halah and Dakalbab, Fatima Mohamad},
 doi = {10.1109/ACCESS.2021.3054129},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cloud computing security;Security;Machine learning;Systematics;Computational modeling;Machine learning algorithms;Bibliographies;Cloud security;machine learning;DDos;privacy;security},
 month = {},
 number = {},
 pages = {20717-20735},
 title = {Machine Learning for Cloud Security: A Systematic Review},
 volume = {9},
 year = {2021}
}

@article{9335932,
 abstract = {Network Intrusion Detection is one of the most researched topics in the field of computer security. Hacktivists use sophisticated tools to launch numerous attacks that hamper the confidentiality, integrity and availability of computer resources. There is an incessant need to safeguard these resources to avoid further damage. In the proposed study, we have presented a meta-classification approach using decision jungle to perform both binary and multiclass classification. We have established the robustness of our approach by configuring an optimal set of hyper-parameters coupled with relevant feature subsets using a production-ready environment namely Azure machine learning. We have validated the efficiency of the proposed design using three contemporary datasets namely UNSW NB-15, CICIDS 2017, and CICDDOS 2019. We could achieve an accuracy of 99.8% pertaining to UNSW NB-15 whereas the accuracy in the case of CICIDS 2017 and CICDDOS 2019 datasets has been 98% and 97% respectively. A distinctive ability of the proposed model lies in its finesse to detect thirty-three modern attack types considerably well. Unlike conventional stacking ensembles, the proposed solution relies on a train-test ratio of 40:60 to establish the legitimacy of predictions. We also conducted statistical significance tests to compare the performance of classifiers involved in the study. To extend the functionalities further, we have automated the proposed model that can be a reliable candidate for real-time network intrusion detection.},
 author = {Rajagopal, Smitha and Kundapur, Poornima Panduranga and K. S., Hareesha},
 doi = {10.1109/ACCESS.2021.3054688},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning;Machine learning algorithms;Automation;Stacking;Network intrusion detection;Classification algorithms;Support vector machines;Azure;Bayes point machine;Decision jungle;Fisher score;locally deep SVM;meta-classification;mutual information;Spearman correlation coefficient;stacking;significance tests},
 month = {},
 number = {},
 pages = {19723-19742},
 title = {Towards Effective Network Intrusion Detection: From Concept to Creation on Azure Cloud},
 volume = {9},
 year = {2021}
}

@article{9343860,
 abstract = {Internet of Things (IoT) enables a myriad of applications by interconnecting software to physical objects. The objects range from wireless sensors to robots and include surveillance cameras. The applications are often critical (e.g. physical intrusion detection, fire fighting) and latency-sensitive. On the one hand, such applications rely on specific protocols (e.g. MQTT, COAP) and the network to communicate with the objects under very tight timeframe. On the other hand, anomalies (e.g. communication noise, sensors' failures, security attacks) are likely to occur in open IoT systems and can result by sending false alerts or the failure to properly detect critical events. To address that, IoT systems have to be equipped with anomaly detection processing in addition to the required event detection capability. This is a key feature that enables reliability and efficiency in IoT. However, anomaly detection systems can be themselves object of failures and attacks, and then can easily fall short to accomplish their mission. This paper introduces a Reliable Event and Anomaly Detection Framework for the Internet of Things (READ-IoT for short). The designed framework integrates events and anomalies detection into a single and common system that centralizes the management of both concepts. To enforce its reliability, the system relies on a reputation-aware provisioning of detection capabilities that takes into account the vulnerability of the deployment hosts. As for validation, READ-IoT was implemented and evaluated using two real life applications, i.e. a fire detection and an unauthorized person detection applications. Several scenarios of anomalies and events were conducted using NSL-KDD public dataset, as well as, generated data to simulate routing attacks. The obtained results and performance measurements show the efficiency of READ-IoT in terms of event detection accuracy and real-time processing.},
 author = {Yahyaoui, Aymen and Abdellatif, Takoua and Yangui, Sami and Attia, Rabah},
 doi = {10.1109/ACCESS.2021.3056149},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Cloud computing;Reliability;Surveillance;Anomaly detection;Sensors;Real-time systems;Anomaly detection;cloud computing;event detection;fog computing;Internet of Things;intrusion detection;trust;reputation},
 month = {},
 number = {},
 pages = {24168-24186},
 title = {READ-IoT: Reliable Event and Anomaly Detection Framework for the Internet of Things},
 volume = {9},
 year = {2021}
}

@article{9345704,
 abstract = {An intrusion detection system (IDS) is an important protection instrument for detecting complex network attacks. Various machine learning (ML) or deep learning (DL) algorithms have been proposed for implementing anomaly-based IDS (AIDS). Our review of the AIDS literature identifies some issues in related work, including the randomness of the selected algorithms, parameters, and testing criteria, the application of old datasets, or shallow analyses and validation of the results. This paper comprehensively reviews previous studies on AIDS by using a set of criteria with different datasets and types of attacks to set benchmarking outcomes that can reveal the suitable AIDS algorithms, parameters, and testing criteria. Specifically, this paper applies 10 popular supervised and unsupervised ML algorithms for identifying effective and efficient ML-AIDS of networks and computers. These supervised ML algorithms include the artificial neural network (ANN), decision tree (DT), k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) algorithms, whereas the unsupervised ML algorithms include the expectation-maximization (EM), k-means, and self-organizing maps (SOM) algorithms. Several models of these algorithms are introduced, and the turning and training parameters of each algorithm are examined to achieve an optimal classifier evaluation. Unlike previous studies, this study evaluates the performance of AIDS by measuring the true positive and negative rates, accuracy, precision, recall, and F-Score of 31 ML-AIDS models. The training and testing time for ML-AIDS models are also considered in measuring their performance efficiency given that time complexity is an important factor in AIDSs. The ML-AIDS models are tested by using a recent and highly unbalanced multiclass CICIDS2017 dataset that involves real-world network attacks. In general, the k-NN-AIDS, DT-AIDS, and NB-AIDS models obtain the best results and show a greater capability in detecting web attacks compared with other models that demonstrate irregular and inferior results.},
 author = {Maseer, Ziadoon Kamil and Yusof, Robiah and Bahaman, Nazrulazhar and Mostafa, Salama A. and Foozy, Cik Feresa Mohd},
 doi = {10.1109/ACCESS.2021.3056614},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Feature extraction;Training;Benchmark testing;Support vector machines;Self-organizing feature maps;Radio frequency;Cyberattacks;intrusion detection system;machine learning;supervised and unsupervised learning},
 month = {},
 number = {},
 pages = {22351-22370},
 title = {Benchmarking of Machine Learning for Anomaly Based Intrusion Detection Systems in the CICIDS2017 Dataset},
 volume = {9},
 year = {2021}
}

@article{9349442,
 abstract = {Industrial Internet of Things (IIoTs) are the extensions of the Internet of Things (IoTs) and have paved the way towards the industry revolution 4.0. IIoT accelerates the industry automation of internal and external working process including transport, manufacturing, and marketing units with a number of connected devices. Being the extension of IoT, it inherits the insecurities of the technology; however, this sensor-configured infrastructure of IIoT needs some extra effort to customize the existing security solutions. In spite of the reconstructions of security models, the scope of improved developments is open to detect unknown attacks. The present study helps the researchers to understand the cause for intrusion by classifying and comparing various attacks of each IIoT layers. The main focus of this survey is to analyze various security issues faced by IIoT and provide a comparative analysis on the available solutions to enhance the industrial IoTs’ protection systems. This study also notifies some open research problems for academia, technologists, and researchers to flourish the IIoT domain and its security aspects.},
 author = {Jayalaxmi, Pls and Saha, Rahul and Kumar, Gulshan and Kumar, Neeraj and Kim, Tai-Hoon},
 doi = {10.1109/ACCESS.2021.3057766},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Security;Computer architecture;Monitoring;Software;Industries;Production systems;Security;industrial;IoT;Internet;intrusion;detection},
 month = {},
 number = {},
 pages = {25344-25359},
 title = {A Taxonomy of Security Issues in Industrial Internet-of-Things: Scoping Review for Existing Solutions, Future Implications, and Research Challenges},
 volume = {9},
 year = {2021}
}

@article{9352796,
 abstract = {In the last decade, many ransomware attacks had the ability to spread within local networks or even outside them. At the same time, software defined networking (SDN) has provided a major boost to networks by transferring intelligence from network devices to a programmable logically centralised controller. The latter can be programmed to be compatible with the requirements of a wide range of networks and environments in a straightforward manner. This has motivated researchers to design SDN-based security solutions against threats targeting traditional networks and systems. This article investigates the use of SDN to detect and mitigate the risk of self-propagating ransomware. The infamous BadRabbit ransomware has been used for the proof of concept. To achieve this, an extensive analysis of BadRabbit was performed to identify its characteristics and understand its behaviour at both the infected device level and at the network level. As a result, several unique artifacts were extracted from BadRabbit, which could facilitate its detection. These artifacts were relied upon to design an SDN-based intrusion detection and prevention system. Our system comprises five modules, namely deep packet inspection, ARP scanning detection, packet header inspection, honeypot, and SMB checker. The first two modules have been inspired by other works and have been included for comparison with the existing solutions. Three other modules rely on novel SDN-based methods for ransomware detection. We have also evaluated the efficiency and the performance of our system in terms of detection time, CPU utilisation, as well as TCP and ping latency. Finally, the proposed approach has also been tested for other ransomware families, such as WannaCry and NotPetya. Our experimental results show that the system is effective in terms of detecting self-propagating ransomware and outperforms other proposed approaches.},
 author = {Alotaibi, Fahad M. and Vassilakis, Vassilios G.},
 doi = {10.1109/ACCESS.2021.3058897},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Ransomware;Inspection;Performance evaluation;Internet;Grippers;Blacklisting;Feature extraction;Self-propagating ransomware;intrusion detection and prevention;SDN security;BadRabbit detection},
 month = {},
 number = {},
 pages = {28039-28058},
 title = {SDN-Based Detection of Self-Propagating Ransomware: The Case of BadRabbit},
 volume = {9},
 year = {2021}
}

@article{9366480,
 abstract = {A distributed denial of service (DDoS) attack represents a major threat to service providers. More specifically, a DDoS attack aims to disrupt and deny services to legitimate users by overwhelming the target with a massive number of malicious requests. A cyberattack of this kind is likely to result in tremendous economic losses for businesses and service providers due to increasing both operating and financial costs. In recent years, machine learning (ML) techniques have been widely used to prevent DDoS attacks. Indeed, many defense systems have been transformed into smart and intelligent systems through the use of ML techniques, which allow them to defeat DDoS attacks. This paper analyzes recent studies concerning DDoS detection methods that have adapted single and hybrid ML approaches in modern networking environments. Additionally, the paper discusses different DDoS defense systems based on ML techniques that make use of a virtualized environment, including cloud computing, software-defined network, and network functions virtualization environments. As the development of the Internet of Things (IoT) has been the subject of significant research attention in recent years, the paper also discusses ML approaches as security solutions against DDoS attacks in IoT environments. Furthermore, the paper recommends a number of directions for future research. This paper is intended to assist the research community with the design and development of effective defense systems capable of overcoming different types of DDoS attacks.},
 author = {Aljuhani, Ahamed},
 doi = {10.1109/ACCESS.2021.3062909},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Cloud computing;Internet of Things;Cyberattack;Network function virtualization;Floods;Machine learning;DDoS attacks and detection;Internet of Things (IoT);machine learning (ML);network functions virtualization (NFV);software-defined network (SDN)},
 month = {},
 number = {},
 pages = {42236-42264},
 title = {Machine Learning Approaches for Combating Distributed Denial of Service Attacks in Modern Networking Environments},
 volume = {9},
 year = {2021}
}

@article{9373407,
 abstract = {Nowadays, most cyber attackers exploit secure communication channels to hide malicious activities and imitate the behaviors of a legitimate user. These attacks over a secure channel make networked systems more vulnerable to new threats and increase the possibility of significant damage to other end users. Traditional TCP/IP-level traffic inspections do not suffice in investigating a secure sockets layer (SSL) conversation because the SSL conversation data is encrypted by a public key system and the SSL uses its own data unit of an SSL record. In this paper, we propose a novel malicious SSL traffic detection method, which reassembles SSL records from captured IP packets and inspects the characteristics of SSL records using a deep learning method. After an SSL record is reassembled from a single or multiple IP packets, the proposed method extracts unencrypted contents of the reassembled record and generates a sequence of unencrypted data from successive SSL records for deep learning-based classification. The sequences of SSL records are encoded using a long short-term memory autoencoder, and then an encoded feature map is generated for each SSL flow. These feature maps are forwarded to the convolutional neural network-based classifier to determine whether the SSL flow is malicious or not. The experiment shows that our proposed approach has a great separability between benign and malicious traffic flows on an encrypted SSL channel.},
 author = {Yang, Jiwon and Lim, Hyuk},
 doi = {10.1109/ACCESS.2021.3064561},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Cryptography;Inspection;Protocols;Deep learning;Payloads;Feature extraction;Computer crime;Cryptographic protocols;deep learning;intrusion detection;network security},
 month = {},
 number = {},
 pages = {39229-39244},
 title = {Deep Learning Approach for Detecting Malicious Activities Over Encrypted Secure Channels},
 volume = {9},
 year = {2021}
}

@article{9374403,
 abstract = {Rolling bearings, as the main components of the large industrial rotating equipment, usually work under complex conditions and are prone to break down. It can provide a certain theoretical basis for identifying the sub-health state of the industrial equipment by the analysis from the incipient weak signals. Thus, a sub-health recognition offline algorithm based on Refined Composite Multiscale Dispersion Entropy (RCMDE) and Deep Belief Network-Extreme Learning Machine (DBN-ELM) optimized by Improved Firework Algorithm (IFWA) is proposed. First of all, in light of the drawbacks that it is easy to fall into local optima and cross the boundary for exploding fireworks in Firework Algorithm (FWA), Cauchy mutation and adaptive dynamic explosion radius factor coefficient is introduced into IFWA. Secondly, Maximum Correlation Kurtosis Deconvolution (MCKD) optimized by the improved parameters is used to process the incipient vibration signals with nonlinearity, nonstationary, and IFWA is used to adaptively adjust to the period T and the filter length L in MCKD(IFWA-MCKD). Then, each sequence of signals is further extracted the feature-RCMDE to rich sample diversity. Finally, combining the powerful unsupervised learning capability from DBN and the generalization capability from ELM, DBN-ELM can be established. What's more, in order to avoid the interference of human on the parameters, IFWA is used to optimize the number of hidden nodes in DBN-ELM, and the IFWA-DBN-ELM is established. It shows that the algorithm has the higher sub-health recognition accuracy, better robustness and generalization, which has a better industrial application prospect.},
 author = {Luo, Hao and He, Chao and Zhou, Jianing and Zhang, Li},
 doi = {10.1109/ACCESS.2021.3064962},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Rolling bearings;Fireworks algorithm;Feature extraction;Entropy;Deconvolution;Vibrations;Sociology;Sub-health recognition;DBN;MCKD;RCMDE;improved firework algorithm},
 month = {},
 number = {},
 pages = {42013-42026},
 title = {Rolling Bearing Sub-Health Recognition via Extreme Learning Machine Based on Deep Belief Network Optimized by Improved Fireworks},
 volume = {9},
 year = {2021}
}

@article{9374442,
 abstract = {This paper presents an overview of device identification techniques and the Manufacturer Usage Description (MUD) standard used for the Internet of things to reduce the IoT attack surface. The ongoing diversity and the sheer increase in the number of connected IoT devices have crumpled security efforts. There is a need to reconsider and redesign the underlying concept of developing security systems to resolve IoT security challenges. In this backdrop, device profiling and identification have emerged as an exciting technique that helps to reduce IoT device attack surface. One of the known approaches for device identification is to fingerprint a device. There are many ways to fingerprint the device, mostly using device network flows or device local attributes. The device identification ensures the authenticity of the device attached to the network, like user authentication. Since IoT devices mostly work using machine-to-machine (M2M) communication, this requires identifying each device properly. But there is no unified approach for device identification for the ever-growing world of IoT devices and applications. One of the major steps forward in this direction is the development of the Manufacturer Usage Description (MUD) standard that defines the role of a device within the network. It limits the device to execute the primary task only, which will help to reduce the attack surface. Since the inception of MUD, many security frameworks use this standard for IoT security. However, there is a need to scrutinize the security frameworks based on the MUD, to find out the claimed effectiveness of the standard in IoT security. This paper initially identifies and classifies the potential vulnerabilities in IoT devices. Then, the study provides an overview of the research that focuses on device identification techniques and analyzes their role in IoT security. Finally, the research presents an overview of MUD technology, its implementation scenarios, the limitation of the latest MUD standard, and its applications in the industry. The prime aim of this work is to examine the MUD benefits in IoT security along with the weaknesses and challenges while implementing this standard along with future directions.},
 author = {Mazhar, Noman and Salleh, Rosli and Zeeshan, Muhammad and Hameed, M. Muzaffar},
 doi = {10.1109/ACCESS.2021.3065123},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Multiuser detection;Security;Internet of Things;Standards;Industries;Cryptography;Password;Manufacturer usage description (MUD);Internet of Things (IoT);device identification (DI);software defined network (SDN);machine learning (ML);deep learning (DL)},
 month = {},
 number = {},
 pages = {41757-41786},
 title = {Role of Device Identification and Manufacturer Usage Description in IoT Security: A Survey},
 volume = {9},
 year = {2021}
}

@article{9382796,
 abstract = {The Social Internet of Things (SIoT) now penetrates our daily lives. As a strategy to alleviate the escalation of resource congestion, collaborative edge computing (CEC) has become a new paradigm for solving the needs of the Internet of Things (IoT). CEC can provide computing, storage, and network connection resources for remote devices. Because the edge network is closer to the connected devices, it involves a large amount of users’ privacy. This also makes edge networks face more and more security issues, such as Denial-of-Service (DoS) attacks, unauthorized access, packet sniffing, and man-in-the-middle attacks. To combat these issues and enhance the security of edge networks, we propose a deep learning-based intrusion detection algorithm. Based on the generative adversarial network (GAN), we designed a powerful intrusion detection method. Our intrusion detection method includes three phases. First, we use the feature selection module to process the collaborative edge network traffic. Second, a deep learning architecture based on GAN is designed for intrusion detection aiming at a single attack. Finally, we propose a new intrusion detection model by combining several intrusion detection models that aim at a single attack. Intrusion detection aiming at multiple attacks is realized through the designed GAN-based deep learning architecture. Besides, we provide a comprehensive evaluation to verify the effectiveness of the proposed method.},
 author = {Nie, Laisen and Wu, Yixuan and Wang, Xiaojie and Guo, Lei and Wang, Guoyin and Gao, Xinbo and Li, Shengtao},
 doi = {10.1109/TCSS.2021.3063538},
 issn = {2329-924X},
 journal = {IEEE Transactions on Computational Social Systems},
 keywords = {Intrusion detection;Feature extraction;Gallium nitride;Image edge detection;Generative adversarial networks;Deep learning;Internet of Things;Collaborative edge computing (CEC);generative adversarial network (GAN);intrusion detection;social internet of things (SIoT)},
 month = {Feb},
 number = {1},
 pages = {134-145},
 title = {Intrusion Detection for Secure Social Internet of Things Based on Collaborative Edge Computing: A Generative Adversarial Network-Based Approach},
 volume = {9},
 year = {2022}
}

@article{9385142,
 abstract = {Intrusion detection system (IDS) and deep packet inspection (DPI) are widely used to detect network attacks and anomalies, thereby enhancing cyber-security. Conventional traffic analyzers such as IDS have fixed locations and a limited capacity to perform DPI on large volumes of network traffic. Nowadays, software-defined networking (SDN) technology, which provides flexibility, elasticity, and programmability by decoupling the network control and data planes, makes it possible to capture entire or a certain portion of data traffic flows on SDN-capable switches and steer the captured network traffic to one of the traffic analyzers on the network. Therefore, how to sample network traffic and where to steer the sampled traffic among multiple traffic analyzers are critical problems facing cyber-security. Since there is a possibility that potentially useful information will be lost in not-captured traffic, deciding the sampling points and sampling rates of network traffic remains important. Additionally, after determining the sampling points and rates, sampled traffic must be sent to one of the multiple traffic analyzers for traffic inspection, which may incur additional network delivery overheads. We propose a less-intrusive traffic sampling mechanism for multiple traffic analyzers on an SDN-capable network using a deep deterministic policy gradient (DDPG), which is a representative deep reinforcement learning (DRL) algorithm for continuous action control. The proposed system learns sampling resource allocation policy under the uncertainty of flow distribution according to sampled traffic inspection results obtained from multiple traffic analyzers. Through extensive simulations and the SDN-based testbed experiments, we demonstrate that the proposed approach has a high probability of capturing malicious flows while maintaining a balanced load of multiple traffic analyzers and reducing flow monitoring overheads.},
 author = {Kim, Sunghwan and Yoon, Seunghyun and Lim, Hyuk},
 doi = {10.1109/ACCESS.2021.3068459},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Monitoring;Inspection;Malware;Control systems;Protocols;Reinforcement learning;Internet;Cyber-security;network traffic monitoring;intrusion detection system;software-defined networking;deep reinforcement learning},
 month = {},
 number = {},
 pages = {47815-47827},
 title = {Deep Reinforcement Learning-Based Traffic Sampling for Multiple Traffic Analyzers on Software-Defined Networks},
 volume = {9},
 year = {2021}
}

@article{9388670,
 abstract = {Communication networks are expanding rapidly and becoming increasingly complex. As a consequence, the conventional rule-based algorithms or protocols may no longer perform at their best efficiencies in these networks. Machine learning (ML) has recently been applied to solve complex problems in many fields, including finance, health care, and business. ML algorithms can offer computational models that can solve complex communication network problems and consequently improve performance. This paper reviews the recent trends in the application of ML models in communication networks for prediction, intrusion detection, route and path assignment, Quality of Service improvement, and resource management. A review of the recent literature reveals extensive opportunities for researchers to exploit the advantages of ML in solving complex performance issues in a network, especially with the advancement of software-defined networks and 5G.},
 author = {Ridwan, M. A. and Radzi, N. A. M. and Abdullah, F. and Jalil, Y. E.},
 doi = {10.1109/ACCESS.2021.3069210},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Prediction algorithms;Deep learning;Machine learning algorithms;Routing;Quality of service;Wireless sensor networks;Data models;Machine learning algorithms;communication network;intrusion detection;routing;quality of service},
 month = {},
 number = {},
 pages = {52523-52556},
 title = {Applications of Machine Learning in Networking: A Survey of Current Issues and Future Challenges},
 volume = {9},
 year = {2021}
}

@article{9395457,
 abstract = {Intrusion detection systems (IDS) are commonly categorized into misuse based, anomaly based and specification based IDS. Both misuse based IDS and anomaly based IDS are extensively researched in academia and industry. However, as critical infrastructures including smart grids (SG) may often face sophisticated unknown attacks in the near future, misuse based attack detection techniques will mostly miss their targets. Despite the fact that anomaly based IDS can detect novel attacks, they are not often deployed in industry, mainly owing to high false positive rate and lack of interpretability of trained models. With misuse based IDS' inability to detect unknown attacks and requirement for frequently manually crafting and updating signatures and with anomaly based IDS' bad reputation for high false alarm rate, specification based IDS can be regarded as the most suitable detection engine for cyber-physical systems (CPS) including SG. We argue that specification based IDS especially using rule learning could prove to be the most promising IDS for SG. Intrusion detection rules are learned through rule learning techniques and periodically automatically updated to accommodate dynamic system behaviors in SG. Fortunately, rule learning based IDS can not only detect previously unknown attacks but also achieve higher interpretability, due to symbolic representation of learned rules. It can thus be considered more “trustworthy” from human perspective and further assist human in the loop security operation. The present work provides a systematic and deep analysis of rule learning techniques and their suitability for IDS in SG. Besides, it concludes the most important criteria for learning intrusion detection rules and assessing their quality. This work serves not only as a guide to a number of important rule learning techniques but also as the first survey on their applications in IDS, which indicates their potential opportunities in SG security.},
 author = {Liu, Qi and Hagenmeyer, Veit and Keller, Hubert B.},
 doi = {10.1109/ACCESS.2021.3071263},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Protocols;Systematics;Smart grids;Deep learning;Cyber-physical systems;Intrusion detection;interpretable machine learning;rule learning;data mining;smart grid},
 month = {},
 number = {},
 pages = {57542-57564},
 title = {A Review of Rule Learning-Based Intrusion Detection Systems and Their Prospects in Smart Grids},
 volume = {9},
 year = {2021}
}

@article{9399085,
 abstract = {The Industrial Internet of Things (IIoT) refers to the use of traditional Internet of Things (IoT) concepts in industrial sectors and applications. IIoT has several applications in smart homes, smart cities, smart grids, connected cars, and supply chain management. However, these systems are being more frequently targeted by cybercriminals. Deep learning and big data analytics have great potential in designing and developing robust security mechanisms for IIoT networks. In this paper, a novel hybrid deep random neural network (HDRaNN) for cyberattack detection in the IIoT is presented. The HDRaNN combines a deep random neural network and a multilayer perceptron with dropout regularization. The proposed technique is evaluated using two IIoT security-related datasets: (i) DS2OS and (ii) UNSW-NB15. The performance of the proposed scheme is analyzed through a number of performance metrics such as accuracy, precision, recall, F1 score, log loss, Region of Convergence (ROC), and Area Under the Curve (AUC). The HDRaNN classified 16 different types of cyberattacks using with higher accuracy of 98% and 99% for DS2OS and UNSW-NB15, respectively. To measure the effectiveness of the proposed scheme, the performance metrics are also compared with several state-of-the-art attack detection algorithms. The findings of HDRaNN proved its superior performance over other DL-based schemes. The deployment perspective of the proposed work is also highlighted in this work.},
 author = {Huma, Zil E. and Latif, Shahid and Ahmad, Jawad and Idrees, Zeba and Ibrar, Anas and Zou, Zhuo and Alqahtani, Fehaid and Baothman, Fatmah},
 doi = {10.1109/ACCESS.2021.3071766},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Industries;Performance evaluation;Servers;Malware;Deep learning;Feature extraction;Attack detection;cybersecurity;deep learning;Industrial Internet of Things;random neural network},
 month = {},
 number = {},
 pages = {55595-55605},
 title = {A Hybrid Deep Random Neural Network for Cyberattack Detection in the Industrial Internet of Things},
 volume = {9},
 year = {2021}
}

@article{9399440,
 abstract = {Deep generative models have increasingly become popular in different domains such as image processing, though, they hardly appear in the cybersecurity arena. While the main application of these models is dimensionality reduction, marginally they have been utilized for overcoming challenges such as data generalization and overfitting issues inherited from feature selection methods. To solve the mentioned challenges, we propose a combined architecture comprising a Conditional Variational AutoEncoder (CVAE) and a Random Forest (RF) classifier to automatically learn similarity among input features, provide data distribution in order to extract discriminative features from original features, and finally classify various types of attacks. CVAE introduces the labels of traffic packets into a latent space in order to better learn the changes of input samples and distinguish the data characteristics of each class. It avoids the confusion between classes while learning the whole data distribution. Compared with feature selection mechanisms such as Support Vector Machine Online (SVMo) by considering various evaluation metrics, the proposed architecture demonstrates considerable improvement in terms of performance. To verify the versatility of the proposed architecture, two publicly available datasets have been used in experiments.},
 author = {Monshizadeh, Mehrnoosh and Khatri, Vikramajeet and Gamdou, Marah and Kantola, Raimo and Yan, Zheng},
 doi = {10.1109/ACCESS.2021.3072126},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Random forests;Classification algorithms;Telecommunication traffic;Anomaly detection;Measurement;Vegetation;Anomaly detection;data mining;feature selection;machine learning;security},
 month = {},
 number = {},
 pages = {56893-56907},
 title = {Improving Data Generalization With Variational Autoencoders for Network Traffic Anomaly Detection},
 volume = {9},
 year = {2021}
}

@article{9405669,
 abstract = {Internet of Things (IoT) technology is prospering and entering every part of our lives, be it education, home, vehicles, or healthcare. With the increase in the number of connected devices, several challenges are also coming up with IoT technology: heterogeneity, scalability, quality of service, security requirements, and many more. Security management takes a back seat in IoT because of cost, size, and power. It poses a significant risk as lack of security makes users skeptical towards using IoT devices. This, in turn, makes IoT vulnerable to security attacks, ultimately causing enormous financial and reputational losses. It makes up for an urgent need to assess present security risks and discuss the upcoming challenges to be ready to face the same. The undertaken study is a multi-fold survey of different security issues present in IoT layers: perception layer, network layer, support layer, application layer, with further focus on Distributed Denial of Service (DDoS) attacks. DDoS attacks are significant threats for the cyber world because of their potential to bring down the victims. Different types of DDoS attacks, DDoS attacks in IoT devices, impacts of DDoS attacks, and solutions for mitigation are discussed in detail. The presented review work compares Intrusion Detection and Prevention models for mitigating DDoS attacks and focuses on Intrusion Detection models. Furthermore, the classification of Intrusion Detection Systems, different anomaly detection techniques, different Intrusion Detection System models based on datasets, various machine learning and deep learning techniques for data pre-processing and malware detection has been discussed. In the end, a broader perspective has been envisioned while discussing research challenges, its proposed solutions, and future visions.},
 author = {Mishra, Nivedita and Pandya, Sharnil},
 doi = {10.1109/ACCESS.2021.3073408},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Intrusion detection;Denial-of-service attack;Systematics;Deep learning;Machine vision;Anomaly detection;DDoS attacks;deep learning;machine learning;Internet of Things;intrusion detection system},
 month = {},
 number = {},
 pages = {59353-59377},
 title = {Internet of Things Applications, Security Challenges, Attacks, Intrusion Detection, and Future Visions: A Systematic Review},
 volume = {9},
 year = {2021}
}

@article{9406576,
 abstract = {Nowadays, Information and Communication Technology (ICT) infrastructures play a crucial role for human beings, providing essential services at astonishing speed. Nevertheless, such a centrality of those infrastructures attracts the interest of ill-motivated actors that target such infrastructures with cyberattacks that are every day more sophisticated and more disruptive. In this alarming context, selecting the optimal set of countermeasures represents a primary need to react against the appearance of potentially dangerous threats effectively. With the motivation to contribute to develop ing faster and more effective response capabilities against them, the paper at hand introduces a novel cybersecurity reaction methodology based on Artificial Immune Systems (AIS), for which the evolutionary computing paradigm has been adopted. By leveraging the outstanding properties of these bio-inspired techniques, the selected countermeasures to defeat cyberthreats through cloning and mutation phases in an effort to improve the quality of the solution from a quantitative perspective, being able to adjust the risk to which the assets of the protected system are exposed. Exhaustive experiments demonstrate the feasibility of the proposed approach, reducing the risk in a more than acceptable time lapse.},
 author = {Nespoli, Pantaleone and Mármol, Félix Gómez and Vidal, Jorge Maestre},
 doi = {10.1109/ACCESS.2021.3074021},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Immune system;Computer crime;Standards;Proposals;Measurement;Ecosystems;Countermeasure selection;cyberattack countermeasures;intrusion reaction systems;artificial immune systems;bio-inspired reaction},
 month = {},
 number = {},
 pages = {60971-60996},
 title = {A Bio-Inspired Reaction Against Cyberattacks: AIS-Powered Optimal Countermeasures Selection},
 volume = {9},
 year = {2021}
}

@article{9409092,
 abstract = {This paper investigates the effect of data integrity attacks on the central control of the microgrids (MGs), which can lead to severe blackouts and load shedding. It assesses this cyber attack from the steady state and optimal scheduling point of view. In order to stop the cyber hacking, a new deep learning-based framework has been developed based on the generative adversarial networks (GANs). In this framework, two networks compete with each other, wherein the first network generates fake data, and the second one is responsible for the data classification. In order to get into the most optimal features, a new optimization method based on a modified teaching-learning based optimization (TLBO) algorithm is also devised to reinforce the GAN model and help a better matching training process. In addition, a new modification is introduced for TLBO to avoid premature convergence and provide high population diversity. To show the effectiveness of the proposed framework, a real dataset of several smart metering devices in a MG has been tested. Results illustrate the high performance of the proposed framework, comparing to the well-known conventional detection frameworks with hit rate of 93.11%, miss rate of 6.89%, false alarm rate of 7.76% and correct reject rate of 92.24%.},
 author = {Tang, Ziqiang and Lin, Yubin and Vosoogh, Mahdi and Parsa, Navid and Baziar, Aliasghar and Khan, Baseem},
 doi = {10.1109/ACCESS.2021.3074460},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Microgrids;Cyberattack;Smart meters;Data models;Gallium nitride;Data integrity;Decision making;Cyberattack;data injection;intrusion detection;prediction interval;smart meters},
 month = {},
 number = {},
 pages = {63377-63387},
 title = {Securing Microgrid Optimal Energy Management Using Deep Generative Model},
 volume = {9},
 year = {2021}
}

@article{9410227,
 abstract = {Currently, with the increasing number of devices connected to the Internet, search for network vulnerabilities to attackers has increased, and protection systems have become indispensable. There are prevalent security attacks, such as the Distributed Denial of Service (DDoS), which have been causing significant damage to companies. However, through security attacks, it is possible to extract characteristics that identify the type of attack. Thus, it is essential to have fast and effective security identification models. In this work, a novel Intrusion Detection System (IDS) based on the Tree-CNN hierarchical algorithm with the Soft-Root-Sign (SRS) activation function is proposed. The model reduces the training time of the generated model for detecting DDoS, Infiltration, Brute Force, and Web attacks. For performance assessment, the model is implemented in a medium-sized company, analyzing the level of complexity of the proposed solution. Experimental results demonstrate that the proposed hierarchical model achieves a significant reduction in execution time, around 36%, and an average detection accuracy of 0.98 considering all the analyzed attacks. Therefore, the results of performance evaluation show that the proposed classifier based on Tree-CNN is of low complexity and requires less processing time and computational resources, outperforming other current IDS based on machine learning algorithms.},
 author = {Mendonça, Robson V. and Teodoro, Arthur A. M. and Rosa, Renata L. and Saadi, Muhammad and Melgarejo, Dick Carrillo and Nardelli, Pedro H. J. and Rodríguez, Demóstenes Z.},
 doi = {10.1109/ACCESS.2021.3074664},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Machine learning algorithms;Neural networks;Support vector machines;Classification algorithms;Security;Computer crime;Activation function;deep learning;intrusion detection system;Tree-CNN},
 month = {},
 number = {},
 pages = {61024-61034},
 title = {Intrusion Detection System Based on Fast Hierarchical Deep Convolutional Neural Network},
 volume = {9},
 year = {2021}
}

@article{9410557,
 abstract = {Network Intrusion detection systems are essential for the protection of advanced communication networks. Originally, these systems were hard-coded to identify specific signatures, patterns and rule violations; now artificial intelligence and machine learning algorithms provide promising alternatives. However, in the literature, various outdated datasets as well as a plethora of different evaluation metrics are used to prove algorithm efficacy. To enable a global comparison, this study compiles algorithms for different configurations to create common ground and proposes two new evaluation metrics. These metrics, the detection score and the identification score, together reliably present the performance of a network intrusion detection system to allow for practical comparison on a large scale. Additionally, we present a workflow to process raw packet flows into input features for machine learning. This framework quickly implements different algorithms for the various datasets and allows systematic performance comparison between those algorithms. Our experimental results, matching and surpassing the state-of-the-art, indicate the potential of this approach. As raw traffic input features are much easier and cheaper to extract when compared to traditional features, they show promise for application in real-time deep learning-based systems.},
 author = {Le Jeune, Laurens and Goedemé, Toon and Mentens, Nele},
 doi = {10.1109/ACCESS.2021.3075066},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Network intrusion detection;Measurement;Anomaly detection;Machine learning algorithms;Feature extraction;Wireless sensor networks;Hidden Markov models;Intrusion detection;machine learning;neural networks;security},
 month = {},
 number = {},
 pages = {63995-64015},
 title = {Machine Learning for Misuse-Based Network Intrusion Detection: Overview, Unified Evaluation and Feature Choice Comparison Framework},
 volume = {9},
 year = {2021}
}

@article{9425573,
 abstract = {The interconnected and heterogeneous nature of the next-generation Electrical Grid (EG), widely known as Smart Grid (SG), bring severe cybersecurity and privacy risks that can also raise domino effects against other Critical Infrastructures (CIs). In this paper, we present an Intrusion Detection System (IDS) specially designed for the SG environments that use Modbus/Transmission Control Protocol (TCP) and Distributed Network Protocol 3 (DNP3) protocols. The proposed IDS called MENSA (anoMaly dEtection aNd claSsificAtion) adopts a novel Autoencoder-Generative Adversarial Network (GAN) architecture for (a) detecting operational anomalies and (b) classifying Modbus/TCP and DNP3 cyberattacks. In particular, MENSA combines the aforementioned Deep Neural Networks (DNNs) in a common architecture, taking into account the adversarial loss and the reconstruction difference. The proposed IDS is validated in four real SG evaluation environments, namely (a) SG lab, (b) substation, (c) hydropower plant and (d) power plant, solving successfully an outlier detection (i.e., anomaly detection) problem as well as a challenging multiclass classification problem consisting of 14 classes (13 Modbus/TCP cyberattacks and normal instances). Furthermore, MENSA can discriminate five cyberattacks against DNP3. The evaluation results demonstrate the efficiency of MENSA compared to other Machine Learning (ML) and Deep Learning (DL) methods in terms of Accuracy, False Positive Rate (FPR), True Positive Rate (TPR) and the F1 score.},
 author = {Siniosoglou, Ilias and Radoglou-Grammatikis, Panagiotis and Efstathopoulos, Georgios and Fouliras, Panagiotis and Sarigiannidis, Panagiotis},
 doi = {10.1109/TNSM.2021.3078381},
 issn = {1932-4537},
 journal = {IEEE Transactions on Network and Service Management},
 keywords = {Computer crime;Protocols;Intrusion detection;Anomaly detection;Substations;Engines;Decision trees;Anomaly detection;auto-encoder;cybersecurity;generative adversarial network;deep learning;machine learning;modbus;smart grid},
 month = {June},
 number = {2},
 pages = {1137-1151},
 title = {A Unified Deep Learning Anomaly Detection and Classification Approach for Smart Grid Environments},
 volume = {18},
 year = {2021}
}

@article{9430613,
 abstract = {The dramatic increase in Android-based smart devices has brought technological revolution to improve the overall quality of life and thus making it worth a billion-dollar market. Despite the huge hype surrounding Android market, the prevalent and potentially sophisticated malicious mobile malware has become a serious threat to the popular Android platform and an ideal target for varied cyber adversaries. Conversely, multivector malware efficient and timely detection is extremely challenging because it usually hides itself under legitimate third party software's and having the capability to be easily crafted on any executable file extension. To better streamline this complex issue of paramount concern, the authors propose a highly proficient hybrid deep learning (DL)-enabled intelligent multi-vector malware detection mechanism. The devised approach leverages Convolutional Neural Networks and Bidirectional Long Short-Term Memory (BiLSTM) to efficiently identify persistent malware. The proposed technique has been thoroughly evaluated with publicly available datasets, standard performance metrics, and state-of-the-art hybrid DL-driven architectures and benchmark DL algorithms. Besides, the proposed framework has been cross-validated and shows out performance both in terms of time efficiency and detection accuracy.},
 author = {Haq, Ikram Ul and Khan, Tamim Ahmed and Akhunzada, Adnan},
 doi = {10.1109/ACCESS.2021.3079370},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Convolutional neural networks;Computer architecture;Logic gates;Deep learning;Security;Android malwares;recurrent neural networks;hybrid models;deep learning (DL);hybrid deep learning models},
 month = {},
 number = {},
 pages = {74510-74521},
 title = {A Dynamic Robust DL-Based Model for Android Malware Detection},
 volume = {9},
 year = {2021}
}

@article{9432913,
 abstract = {The astonishing growth of sophisticated ever-evolving cyber threats and attacks throws the entire Internet-of-Things (IoT) infrastructure into chaos. As the IoT belongs to the infrastructure of interconnected devices, it brings along significant security challenges. Cyber threat analysis is an augmentation of a network security infrastructure that primarily emphasizes on detection and prevention of sophisticated network-based threats and attacks. Moreover, it requires the security of network by investigation and classification of malicious activities. In this study, we propose a DL-enabled malware detection scheme using a hybrid technique based on the combination of a Deep Neural Network(DNN) and Long Short-Term Memory(LSTM) for the efficient identification of multi-class malware families in IoT infrastructure. The proposed scheme utilizes latest 2018 dataset named as N_BaIoT. Furthermore, our proposed scheme is evaluated using standard performance metrics such as accuracy, recall, precision, F1-score, and so forth. The DL-based malware detection system achieves 99.96% detection accuracy for IoT based threats. Finally, we also compare our proposed work with other robust and state-of-the-art detection schemes.},
 author = {Qureshi, Sirajuddin and He, Jingsha and Tunio, Saima and Zhu, Nafei and Akhtar, Faheem and Ullah, Faheem and Nazir, Ahsan and Wajahat, Ahsan},
 doi = {10.1109/ACCESS.2021.3081069},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Malware;Security;Deep learning;Recurrent neural networks;Performance evaluation;Smart devices;Internet-of-Things;deep learning;long short-term memory;convolutional neural network;deep neural network},
 month = {},
 number = {},
 pages = {73938-73947},
 title = {A Hybrid DL-Based Detection Mechanism for Cyber Threats in Secure Networks},
 volume = {9},
 year = {2021}
}

@article{9436776,
 abstract = {As cyberattacks become more intelligent, the difficulty increases for traditional intrusion detection systems to detect advanced attacks that deviate from previously stored patterns. To solve this problem, a deep learning-based intrusion detection system model has emerged that analyzes intelligent attack patterns through data learning. However, deep learning models have the disadvantage of having to re-learn each time a new cyberattack method emerges. The time required to learn a large amount of data is not efficient. In this paper, an experiment was conducted using the Leipzig Intrusion Detection Data Set (LID-DS), which is a host-based intrusion detection data set released in 2018. In addition, in order to evaluate and improve the performance of the system, a host-based intrusion detection model consisting of pre-processing, vector-to-image processing, training and testing steps is proposed. In the training and testing steps, a Siamese Convolutional Neural Network (Siamese-CNN) is constructed using the few-shot learning method, which shows excellent performance by learning a small amount of data. Siamese-CNN determines whether the attack type is the same based on the similarity score of each cyberattack sample converted to an image. The accuracy was calculated using the few-shot learning technique. The performance of the Vanilla Convolutional Neural Network (Vanilla-CNN) and Siamese-CNN are compared to confirm the performance of Siamese-CNN. As a result of measuring the accuracy, precision, recall, and F1-score indicators, it was confirmed that the recall of the Siamese-CNN model proposed in this study increased by about 6% compared to the Vanilla-CNN model.},
 author = {Park, Daekyeong and Kim, Sangsoo and Kwon, Hyukjin and Shin, Dongil and Shin, Dongkyoo},
 doi = {10.1109/ACCESS.2021.3082160},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Data models;Computer crime;Malware;Machine learning algorithms;Convolutional neural networks;Machine learning;LID-DS;few-shot learning;siamese network;HIDS},
 month = {},
 number = {},
 pages = {76614-76623},
 title = {Host-Based Intrusion Detection Model Using Siamese Network},
 volume = {9},
 year = {2021}
}

@article{9437227,
 abstract = {Digital assets have come under various network security threats in the digital age. As a kind of security equipment to protect digital assets, intrusion detection system (IDS) is less efficient if the alert is not timely and IDS is useless if the accuracy cannot meet the requirements. Therefore, an intrusion detection model that combines machine learning with deep learning is proposed in this paper. The model uses the k-means and the random forest (RF) algorithms for the binary classification, and distributed computing of these algorithms is implemented on the Spark platform to quickly classify normal events and attack events. Then, by using the convolutional neural network (CNN), long short-term memory (LSTM), and other deep learning algorithms, the events judged as abnormal are further classified into different attack types finally. At this stage, adaptive synthetic sampling (ADASYN) is adopted to solve the unbalanced dataset. The NSL-KDD and CIS-IDS2017 datasets are used to evaluate the performance of the proposed model. The experimental results show that the proposed model has better TPR for most of attack events, faster data preprocessing speed, and potentially less training time. In particular, the accuracy of multi-target classification can reach as high as 85.24% in the NSL-KDD dataset and 99.91% in the CIC-IDS2017 dataset.},
 author = {Liu, Chao and Gu, Zhaojun and Wang, Jialiang},
 doi = {10.1109/ACCESS.2021.3082147},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning algorithms;Classification algorithms;Intrusion detection;Deep learning;Radio frequency;Sparks;Feature extraction;Intrusion detection system;machine learning algorithm;k-means;random forest;deep learning algorithm},
 month = {},
 number = {},
 pages = {75729-75740},
 title = {A Hybrid Intrusion Detection System Based on Scalable K-Means+ Random Forest and Deep Learning},
 volume = {9},
 year = {2021}
}

@article{9439459,
 abstract = {Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML models used in the identification of anomalies. Finally, we present 22 different datasets that are applied in experiments on anomaly detection, as well as many other general datasets. In addition, we observe that unsupervised anomaly detection has been adopted by researchers more than other classification anomaly detection systems. Detection of anomalies using ML models is a promising area of research, and there are a lot of ML models that have been implemented by researchers. Therefore, we provide researchers with recommendations and guidelines based on this review.},
 author = {Nassif, Ali Bou and Talib, Manar Abu and Nasir, Qassim and Dakalbab, Fatima Mohamad},
 doi = {10.1109/ACCESS.2021.3083060},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Machine learning;Intrusion detection;Systematics;Training;Bibliographies;Analytical models;Anomaly detection;machine learning;security and privacy protection},
 month = {},
 number = {},
 pages = {78658-78700},
 title = {Machine Learning for Anomaly Detection: A Systematic Review},
 volume = {9},
 year = {2021}
}

@article{9439890,
 abstract = {Machine learning (ML) based botnet detectors are no exception to traditional ML models when it comes to adversarial evasion attacks. The datasets used to train these models have also scarcity and imbalance issues. We propose a new technique named Botshot, based on generative adversarial networks (GANs) for addressing these issues and proactively making botnet detectors aware of adversarial evasions. Botshot is cost-effective as compared to the network emulation for botnet traffic data generation rendering the dedicated hardware resources unnecessary. First, we use the extended set of network flow and time-based features for three publicly available botnet datasets. Second, we utilize two GANs (vanilla, conditional) for generating realistic botnet traffic. We evaluate the generator performance using classifier two-sample test (C2ST) with 10-fold 70-30 train-test split and propose the use of 'recall' in contrast to 'accuracy' for proactively learning adversarial evasions. We then augment the train set with the generated data and test using the unchanged test set. Last, we compare our results with benchmark oversampling methods with augmentation of additional botnet traffic data in terms of average accuracy, precision, recall and F1 score over six different ML classifiers. The empirical results demonstrate the effectiveness of the GAN-based oversampling for learning in advance the adversarial evasion attacks on botnet detectors.},
 author = {Randhawa, Rizwan Hamid and Aslam, Nauman and Alauthman, Mohammad and Rafiq, Husnain and Comeau, Frank},
 doi = {10.1109/ACCESS.2021.3083421},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Generative adversarial networks;Detectors;Training;Generators;Biological system modeling;Feature extraction;Botnet detection;GANs;adversarial evasion attacks;unbalanced datasets},
 month = {},
 number = {},
 pages = {78276-78292},
 title = {Security Hardening of Botnet Detectors Using Generative Adversarial Networks},
 volume = {9},
 year = {2021}
}

@article{9452083,
 abstract = {The dynamics of computer networks have changed rapidly over the past few years due to a tremendous increase in the volume of the connected devices and the corresponding applications. This growth in the network's size and our dependence on it for all aspects of our life have therefore resulted in the generation of many attacks on the network by malicious parties that are either novel or the mutations of the older attacks. These attacks pose many challenges for network security personnel to protect the computer and network nodes and corresponding data from possible intrusions. A network intrusion detection system (NIDS) can act as one of the efficient security solutions by constantly monitoring the network traffic to secure the entry points of a network. Despite enormous efforts by researchers, NIDS still suffers from a high false alarm rate (FAR) in detecting novel attacks. In this paper, we propose a novel NIDS framework based on a deep convolution neural network that utilizes network spectrogram images generated using the short-time Fourier transform. To test the efficiency of our proposed solution, we evaluated it using the CIC-IDS2017 dataset. The experimental results have shown about 2.5% - 4% improvement in accurately detecting intrusions compared to other deep learning (DL) algorithms while at the same time reducing the FAR by 4.3%-6.7% considering binary classification scenario. We also observed its efficiency for a 7-class classification scenario by achieving almost 98.75% accuracy with 0.56% - 3.72% improvement compared to other DL methodologies.},
 author = {Khan, Adnan Shahid and Ahmad, Zeeshan and Abdullah, Johari and Ahmad, Farhan},
 doi = {10.1109/ACCESS.2021.3088149},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Spectrogram;Classification algorithms;Support vector machines;Security;Prediction algorithms;Arrays;Training;Convolutional neural network;deep learning;network intrusion detection system;spectrogram},
 month = {},
 number = {},
 pages = {87079-87093},
 title = {A Spectrogram Image-Based Network Anomaly Detection System Using Deep Convolutional Neural Network},
 volume = {9},
 year = {2021}
}

@article{9455368,
 abstract = {Recent technological developments in computer systems transfer human life from real to virtual environments. Covid-19 disease has accelerated this process. Cyber criminals' interest has shifted in a real to virtual life as well. This is because it is easier to commit a crime in cyberspace rather than regular life. Malicious software (malware) is unwanted software which is frequently used by cyber criminals to launch cyber-attacks. Malware variants are continuing to evolve by using advanced obfuscation and packing techniques. These concealing techniques make malware detection and classification significantly challenging. Novel methods which are quite different from traditional methods must be used to effectively combat with new malware variants. Traditional artificial intelligence (AI) specifically machine learning (ML) algorithms are no longer effective in detecting all new and complex malware variants. Deep learning (DL) approach which is quite different from traditional ML algorithms can be a promising solution to the problem of detecting all variants of malware. In this study, a novel deep-learning-based architecture is proposed which can classify malware variants based on a hybrid model. The main contribution of the study is to propose a new hybrid architecture which integrates two wide-ranging pre-trained network models in an optimized manner. This architecture consists of four main stages, namely: data acquisition, the design of deep neural network architecture, training of the proposed deep neural network architecture, and evaluation of the trained deep neural network. The proposed method tested on Malimg, Microsoft BIG 2015, and Malevis datasets. The experimental results show that the suggested method can effectively classify malware with high accuracy which outperforms the state of the art methods in the literature. When proposed method tested on Malimg dataset, 97.78% accuracy is obtained which is outperformed most of the ML-based malware detection method.},
 author = {Aslan, Ömer and Yilmaz, Abdullah Asim},
 doi = {10.1109/ACCESS.2021.3089586},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Deep learning;Computer architecture;Cloud computing;Classification algorithms;Static analysis;Malware;malware classification;malware detection;malware variants;deep neural networks;transfer learning;deep learning},
 month = {},
 number = {},
 pages = {87936-87951},
 title = {A New Malware Classification Framework Based on Deep Learning Algorithms},
 volume = {9},
 year = {2021}
}

@article{9456954,
 abstract = {The Internet of Things (IoT) has emerged as a technology capable of connecting heterogeneous nodes/objects, such as people, devices, infrastructure, and makes our daily lives simpler, safer, and fruitful. Being part of a large network of heterogeneous devices, these nodes are typically resource-constrained and became the weakest link to the cyber attacker. Classical encryption techniques have been employed to ensure the data security of the IoT network. However, high-level encryption techniques cannot be employed in IoT devices due to the limitation of resources. In addition, node security is still a challenge for network engineers. Thus, we need to explore a complete solution for IoT networks that can ensure nodes and data security. The rule-based approaches and shallow and deep machine learning algorithms- branches of Artificial Intelligence (AI)- can be employed as countermeasures along with the existing network security protocols. This paper presented a comprehensive layer-wise survey on IoT security threats, and the AI-based security models to impede security threats. Finally, open challenges and future research directions are addressed for the safeguard of the IoT network.},
 author = {Zaman, Shakila and Alhazmi, Khaled and Aseeri, Mohammed A. and Ahmed, Muhammad Raisuddin and Khan, Risala Tasin and Kaiser, M. Shamim and Mahmud, Mufti},
 doi = {10.1109/ACCESS.2021.3089681},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Encryption;Artificial intelligence;Cryptography;Protocols;Computer crime;Fuzzy logic;machine leaning;attack vector;IoT protocols;IoT applications},
 month = {},
 number = {},
 pages = {94668-94690},
 title = {Security Threats and Artificial Intelligence Based Countermeasures for Internet of Things Networks: A Comprehensive Survey},
 volume = {9},
 year = {2021}
}

@article{9459716,
 abstract = {Network security has become a growing concern within the popularity and development of the Internet. Malicious code is one of the main threats to network security. Different types of malicious code have different functions and cause different harms. Therefore, improving the detection efficiency and recognition accuracy of malicious code is becoming an urgent problem to be solved. While traditional machine learning methods for malicious code detection largely depend on hand-designed features with experts' knowledge of the domain or focus on the images which come from malicious code binary files. These methods spend too much time on feature extraction. With the emergence of a large amount of malicious code data, the efficiency of traditional machine learning algorithms is getting worse and worse. In this paper, a workflow based on deep learning is proposed to detect and classify malicious codes. This workflow adopts a convolutional neural network (CNN) and the regularization algorithms to classify malicious code with N_gram semantic feature as input of the model. The convolutional neural network can automatically extract the features of malicious code while avoiding the need for manual feature selection. Regularization algorithms not only speed up the training process of the deep model but also improve the generalization ability in the case of effective prevention of over-fitting of the model. The proposed method is compared with the state-of-the-art methods and other deep learning models. Experimental results show that our workflow can improve the accuracy and efficiency of malicious code classification.},
 author = {Wang, Haojun and Long, Haixia and Wang, Ailan and Liu, Tianyue and Fu, Haiyan},
 doi = {10.1109/ACCESS.2021.3090464},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Deep learning;Convolutional neural networks;Classification algorithms;Machine learning algorithms;Support vector machines;Malicious code classification;deep learning;convolutional neural networks;N-gram;regularization algorithm},
 month = {},
 number = {},
 pages = {91512-91523},
 title = {Deep Learning and Regularization Algorithms for Malicious Code Classification},
 volume = {9},
 year = {2021}
}

@article{9462110,
 abstract = {In recent years, the increase in non-Windows malware threats had turned the focus of the cybersecurity community. Research works on hunting Windows PE-based malwares are maturing, whereas the developments on Linux malware threat hunting are relatively scarce. With the advent of the Internet of Things (IoT) era, smart devices that are getting integrated into human life have become a hackers’ highway for their malicious activities. The IoT devices employ various Unix-based architectures that follow ELF (Executable and Linkable Format) as their standard binary file specification. This study aims at providing a comprehensive survey on the latest developments in cross-architectural IoT malware detection and classification approaches. Aided by a modern taxonomy, we discuss the feature representations, feature extraction techniques, and machine learning models employed in the surveyed works. We further provide more insights on the practical challenges involved in cross-architectural IoT malware threat hunting and discuss various avenues to instill potential future research.},
 author = {Raju, Anandharaju Durai and Abualhaol, Ibrahim Y. and Giagone, Ronnie Salvador and Zhou, Yang and Huang, Shengqiang},
 doi = {10.1109/ACCESS.2021.3091427},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Linux;Tools;Ground penetrating radar;Geophysical measurement techniques;Operating systems;Internet of Things;Cybersecurity;cross-architecture;IoT;elf;linux;survey;taxonomy;machine learning;malware classification;malware detection},
 month = {},
 number = {},
 pages = {91686-91709},
 title = {A Survey on Cross-Architectural IoT Malware Threat Hunting},
 volume = {9},
 year = {2021}
}

@article{9462940,
 abstract = {Fault diagnosis in telecommunication networks requires extensive expert knowledge and is key to efficient network operations and high service availability. Specifically, discovering and identifying new faults occurring in the network is a challenging task. Some dominant methods in industry are based on expert systems or Bayesian networks. Both of these methods require considerable expert knowledge and time resources to construct and maintain the diagnosis system. In this paper, we propose a data driven approach for the clustering and identification of new faults, based on existing knowledge, using neural networks and infinite mixture models. In our approach deep infinite mixture models are capable of extracting interesting features from labeled data, which are then leveraged in the clustering process to identify new relevant faults in unlabeled data. We apply our method to real operational data from Fiber-to-the Home services based on Gigabit-capable Passive Optical Networks. We show that our approach can be trained end-to-end, and allows to identify and interpret new faults.},
 author = {Echraibi, Amine and Flocon-Cholet, Joachim and Gosselin, Stéphane and Vaton, Sandrine},
 doi = {10.1109/ACCESS.2021.3091328},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Fault diagnosis;Feature extraction;Neural networks;Optical fiber networks;Bayes methods;Task analysis;Mixture models;Network fault diagnosis;deep learning;infinite mixture models;variational inference},
 month = {},
 number = {},
 pages = {90488-90499},
 title = {Deep Infinite Mixture Models for Fault Discovery in GPON-FTTH Networks},
 volume = {9},
 year = {2021}
}

@article{9464257,
 abstract = {The proliferation of Internet of Things (IoT) systems and smart digital devices, has perceived them targeted by network attacks. Botnets are vectors buttoned up which the attackers grapple the control of IoT systems and comportment venomous activities. To confront this challenge, efficient machine learning and deep learning with suitable feature engineering are suggested to detect and protect the network from such vulnerabilities in the future. For the efficient detection of cyber attacks, the representative dataset shall be well-structured for training the model and then validating the proposed system to develop an optimal security model. In this research, we used the UNSW-NB15, a new IoT-Botnet dataset (a noisy and imbalanced dataset) to classify cyber-attacks. K-Medoid sampling and scatter search-based feature engineering techniques are used to obtain a representative dataset with optimal feature subsets. To validate the proposed methodologies, three most recent machine learning (ML) methods including (i) JChaid*- a recent upgrade version to Chi-square automatic interaction detection (CHAID) decision tree-based, (ii) A2DE (a semi-naive Bayesian averaged two-dependence estimator), & (iii) HGC- a hybrid of Genetic algorithm with K-means clustering and two deep learning (DL) methods such as (i) Deep Multilayer perceptron (DMLP) & (ii) Convolutional neural network (CNN) based classifiers are employed. From the extensive experimental analysis, it is pronounced that scatter search-based DMLP classifier outperforms the other competing models in terms of (i) highest detection rate with100% accuracy, 100% macro-averaged precision, 100% macro-averaged recall & 100% macro-averaged F1-score and (ii) low computational complexity with the least training time of 4.7 seconds & testing time of 0.61 seconds.},
 author = {Panda, Mrutyunjaya and Mousa, Abd Allah A. and Hassanien, Aboul Ella},
 doi = {10.1109/ACCESS.2021.3092054},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Botnet;Convolutional neural networks;Training;Support vector machines;Malware;Network intrusions;IoT;botnet;K-Medoids;scatter search;DMLP;A2DE;JChaid*;CNN;K-means clustering;genetic algorithm;macro precision;macro recall;macro F1-score;UNSW-NB15 dataset},
 month = {},
 number = {},
 pages = {91038-91052},
 title = {Developing an Efficient Feature Engineering and Machine Learning Model for Detecting IoT-Botnet Cyber Attacks},
 volume = {9},
 year = {2021}
}

@article{9469900,
 abstract = {Artificial Intelligence (AI) techniques provide effective solutions for the detection of many aberrant network traffic patterns and attack flows. However, the validation of these techniques often relies on one training dataset. Recent results show that such training may fail in the face of dynamically-changing cyberattacks. Given the increased sophistication of cyberattacks nowadays, it is imperative to examine and improve the performance of such AI models. This paper proposes a defensive AI engine combined with a twofold feature selection technique and hyperparameter optimization of the AI model. In this work, we utilize the proposed system for binary attack flow identification and the AI models are trained and validated on the CICIDS2017 dataset. The system is then evaluated using synthesized atypical attack flows to mimic real-world scenarios. We demonstrate the effectiveness of the proposed atypical attack flow detection approach using several Deep Learning and Machine Learning models including DNN, Linear-SVC, and Stacked Decision Tree Classifier (S-DTC). Simulation results demonstrate that the proposed defensive AI engine significantly improves the True Positive Rate (TPR) of AI models on multiple atypical attacks.},
 author = {Sabeel, Ulya and Heydari, Shahram Shah and Elgazzar, Khalid and El-Khatib, Khalil},
 doi = {10.1109/ACCESS.2021.3093830},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Feature extraction;Training;Benchmark testing;Data models;Computer crime;Network intrusion detection;Artificial Intelligence (AI);atypical attacks;Denial of Service;feature profile;intrusion detection},
 month = {},
 number = {},
 pages = {94352-94370},
 title = {Building an Intrusion Detection System to Detect Atypical Cyberattack Flows},
 volume = {9},
 year = {2021}
}

@article{9469914,
 abstract = {The growing development of IoT (Internet of Things) devices creates a large attack surface for cybercriminals to conduct potentially more destructive cyberattacks; as a result, the security industry has seen an exponential increase in cyber-attacks. Many of these attacks have effectively accomplished their malicious goals because intruders conduct cyber-attacks using novel and innovative techniques. An anomaly-based IDS (Intrusion Detection System) uses machine learning techniques to detect and classify attacks in IoT networks. In the presence of unpredictable network technologies and various intrusion methods, traditional machine learning techniques appear inefficient. In many research areas, deep learning methods have shown their ability to identify anomalies accurately. Convolutional neural networks are an excellent alternative for anomaly detection and classification due to their ability to automatically categorize main characteristics in input data and their effectiveness in performing faster computations. In this paper, we design and develop a novel anomaly-based intrusion detection model for IoT networks. First, a convolutional neural network model is used to create a multiclass classification model. The proposed model is then implemented using convolutional neural networks in 1D, 2D, and 3D. The proposed convolutional neural network model is validated using the BoT-IoT, IoT Network Intrusion, MQTT-IoT-IDS2020, and IoT-23 intrusion detection datasets. Transfer learning is used to implement binary and multiclass classification using a convolutional neural network multiclass pre-trained model. Our proposed binary and multiclass classification models have achieved high accuracy, precision, recall, and F1 score compared to existing deep learning implementations.},
 author = {Ullah, Imtiaz and Mahmoud, Qusay H.},
 doi = {10.1109/ACCESS.2021.3094024},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Deep learning;Security;Intrusion detection;Convolutional neural networks;Computational modeling;Neural networks;Internet of Things;anomaly detection;IoT intrusion detection;machine learning;deep learning;transfer learning;network security;convolutional neural network},
 month = {},
 number = {},
 pages = {103906-103926},
 title = {Design and Development of a Deep Learning-Based Model for Anomaly Detection in IoT Networks},
 volume = {9},
 year = {2021}
}

@article{9483916,
 abstract = {Nowadays, the ever-increasing complication and severity of security attacks on computer networks have inspired security researchers to incorporate different machine learning methods to protect the organizations’ data and reputation. Deep learning is one of the exciting techniques which recently are vastly employed by the IDS or intrusion detection systems to increase their performance in securing the computer networks and hosts. This survey article focuses on the deep learning-based intrusion detection schemes and puts forward an in-depth survey and classification of these schemes. It first presents the primary background concepts about IDS architecture and various deep learning techniques. It then classifies these schemes according to the type of deep learning methods utilized in each of them. It describes how deep learning networks are utilized in the intrusion detection process to recognize intrusions accurately. Finally, a complete analysis of the investigated IDS frameworks is provided, and concluding remarks and future directions are highlighted.},
 author = {Lansky, Jan and Ali, Saqib and Mohammadi, Mokhtar and Majeed, Mohammed Kamal and Karim, Sarkhel H. Taher and Rashidi, Shima and Hosseinzadeh, Mehdi and Rahmani, Amir Masoud},
 doi = {10.1109/ACCESS.2021.3097247},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Deep learning;Feature extraction;Security;Machine learning;Anomaly detection;Recurrent neural networks;Intrusion detection;auto-encoder;recurrent neural network;Boltzmann machine;CNN},
 month = {},
 number = {},
 pages = {101574-101599},
 title = {Deep Learning-Based Intrusion Detection Systems: A Systematic Review},
 volume = {9},
 year = {2021}
}

@article{9496635,
 abstract = {In recent years, attacks on network environments continue to rapidly advance and are increasingly intelligent. Accordingly, it is evident that there are limitations in existing signature-based intrusion detection systems. In particular, for novel attacks such as Advanced Persistent Threat (APT), signature patterns have problems with poor generalization performance. Furthermore, in a network environment, attack samples are rarely collected compared to normal samples, creating the problem of imbalanced data. Anomaly detection using an autoencoder has been widely studied in this environment, and learning is through semi-supervised learning methods to overcome these problems. This approach is based on the assumption that reconstruction errors for samples that are not used for training will be large, but an autoencoder is often over-generalized and this assumption is often broken. In this paper, we propose a network intrusion detection method using a memory-augmented deep auto-encoder (MemAE) that can solve the over-generalization problem of autoencoders. The MemAE model is trained to reconstruct the input of an abnormal sample that is close to a normal sample, which solves the generalization problem for such abnormal samples. Experiments were conducted on the NSL-KDD, UNSW-NB15, and CICIDS 2017 datasets, and it was confirmed that the proposed method is better than other one-class models.},
 author = {Min, Byeongjun and Yoo, Jihoon and Kim, Sangsoo and Shin, Dongil and Shin, Dongkyoo},
 doi = {10.1109/ACCESS.2021.3100087},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Decoding;Anomaly detection;Network intrusion detection;Data models;Memory modules;Mathematical model;Machine learning;Network intrusion detection;autoencoder;anomaly detection;memory-augmented autoencoder},
 month = {},
 number = {},
 pages = {104695-104706},
 title = {Network Anomaly Detection Using Memory-Augmented Deep Autoencoder},
 volume = {9},
 year = {2021}
}

@article{9502698,
 abstract = {Distributed Denial of Service (DDoS) attacks represent the most common and critical attacks targeting conventional and new generation networks, such as the Internet of Things (IoT), cloud computing, and fifth-generation (5G) communication networks. In recent years, DDoS attacks have become not only massive but also sophisticated. Software-Defined Networking (SDN) technology has demonstrated effectiveness in counter-measuring complex attacks since it provides flexibility on global network monitoring and inline network configuration. Although several works have proposed to detect DDoS attacks, most of them did not use up-to-date datasets that contain the newest threats. Furthermore, only a few previous works assessed their solutions using simulated scenarios, easing the migration to production networks. This document presents the implementation of a modular and flexible SDN-based architecture to detect transport and application layer DDoS attacks using multiple Machine Learning (ML) and Deep Learning (DL) models. Exploring diverse ML/DL methods allowed us to resolve which methods perform better under different attack types and conditions. We tested the ML/DL models using two up-to-date security datasets, namely CICDoS2017 and CICDDoS2019 datasets, and they showed accuracy above 99% on classifying unseen traffic (testing set). We also deployed a simulated environment using the network emulator Mininet and the Open Network Operating System (ONOS) SDN controller. In this experimental setup, we demonstrated high detection rates, above 98% for transport DDoS attacks and up to 95% for application-layer DDoS attacks.},
 author = {Yungaicela-Naula, Noe Marcelo and Vargas-Rosales, Cesar and Perez-Diaz, Jesus Arturo},
 doi = {10.1109/ACCESS.2021.3101650},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Computer crime;Proposals;Support vector machines;Real-time systems;Internet of Things;Entropy;Software defined networking;deep learning;machine learning;DDoS attack;transport layer;application layer;slow-rate attacks},
 month = {},
 number = {},
 pages = {108495-108512},
 title = {SDN-Based Architecture for Transport and Application Layer DDoS Attack Detection by Using Machine and Deep Learning},
 volume = {9},
 year = {2021}
}

@article{9508433,
 abstract = {Recently, using artificial neural networks (ANNs) for network intrusion detection systems (NIDSs) has drawn much attention from security researchers. The capability of ANNs to learn patterns from numerous data helps detect attacks on networked systems. Moreover, to effectively monitor a newly emerging networked system consisting of distributed subsystems, such as edge, Internet of Things (IoT), and fog, recent studies have proposed an ANN-based distributed NIDS, where multiple ANNs are deployed to local gateways. To meet the incessant demand for high accuracy, ANN-based NIDSs have become complicated and heavy. With local gateways being small and low-end, such ANNs cannot be executed. Some researchers have proposed optimized algorithms to balance detection accuracy and runtime performance to solve this problem. For example, Kitsune empirically proved its efficiency, but a recent study reveals that Kitsune has limitations. In particular, Kitsune fails at identifying host-oriented attacks, which pretend to be benign during packet delivery but incur malicious behavior on destination devices. Panop is a novel ANN-based NIDS for a distributed network system that aims to detect malicious packets, including host-oriented attacks, while remaining sufficiently lightweight to be executed by low-end devices. Thus, the Panop ANN is designed to comprehensively learn network and device behaviors related to packet transactions in an IoT network. According to the experiments, Panop can detect host-oriented and other attacks with reasonably high accuracy with little degradation in runtime performance compared to the state-of-the-art NIDS for distributed network environments.},
 author = {Kim, Hyunjun and Ahn, Sunwoo and Ha, Whoi Ree and Kang, Hyunjae and Kim, Dong Seong and Kim, Huy Kang and Paek, Yunheung},
 doi = {10.1109/ACCESS.2021.3103015},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Logic gates;Internet of Things;Performance evaluation;Neural networks;Monitoring;Computational modeling;Anomaly detection;deep learning;Internet of Things;intrusion detection;machine learning;artificial neural networks},
 month = {},
 number = {},
 pages = {111853-111864},
 title = {Panop: Mimicry-Resistant ANN-Based Distributed NIDS for IoT Networks},
 volume = {9},
 year = {2021}
}

@article{9512278,
 abstract = {Vehicles are becoming increasingly autonomous and connected, leading to an increase in the types of security threats to vehicles. Controller Area Network (CAN) is a serial bus system that is used to connect sensors and controllers (Electronic Control Units - ECUs) within a vehicle. ECUs vary widely in processing power, storage, memory, and connectivity. There is a need for efficient security countermeasures for protecting the CAN from various attacks. In this paper, we present a novel process to efficiently design functions that can be used for anomaly detection. Our earlier work successfully demonstrated the use of Long Short-Term Memory (LSTM) Networks to perform anomaly detection. This paper focuses on the efficient design and testing of functions that are attack-resistant and can be used in our anomaly detection engine. Once trained, our system is capable of efficiently detecting anomalies in real-time. We report the results of our anomaly detection function design process. We also present the results of our overall anomaly detection engine that are used as inputs to our detection engine. Our function design process and anomaly detection engine have been tested on data from real automobiles. We present the results of our experiments and analyze our findings.},
 author = {Tanksale, Vinayak},
 doi = {10.1109/OJITS.2021.3104495},
 issn = {2687-7813},
 journal = {IEEE Open Journal of Intelligent Transportation Systems},
 keywords = {Engines;Anomaly detection;Security;Prediction algorithms;Logic gates;Intrusion detection;Intelligent transportation systems;Controller area network;long short-term memory;intrusion detection},
 month = {},
 number = {},
 pages = {312-321},
 title = {Design of Anomaly Detection Functions for Controller Area Networks},
 volume = {2},
 year = {2021}
}

@article{9513285,
 abstract = {Network intrusion discovery aims to detect the network attacks and abnormal network intrusion efficiently, that is an important protection implement in the field of cyber security. However, the traditional network intrusion discovery method are difficult to extract high-order features (such as spatial-temporal information) from network traffic data. In this paper, we proposed an improved method of network intrusion discovery based on convolutional long-short term memory network. This method implements the convolution operation in deep learning into the network structure of long-short term memory and improves the accuracy of network intrusion discovery. In the experimental section, we compared with other similar methods, the result shows that the proposed method has some advantages in the aspects of overall network intrusion discovery index, detection index of different types, and AUC evaluation index. In addition, we applied our method to the network intrusion discovery scenarios of video surveillance system (VSS). The result shows that the proposed method has advantages in accuracy, recall, precision, and other similar methods.},
 author = {Fan, Zhijie and Cao, Zhiwei},
 doi = {10.1109/ACCESS.2021.3104718},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Convolutional neural networks;Data models;Data mining;Logic gates;Recurrent neural networks;Network security;network intrusion discovery method;deep learning;convolutional long-short term memory network},
 month = {},
 number = {},
 pages = {122744-122753},
 title = {Method of Network Intrusion Discovery Based on Convolutional Long-Short Term Memory Network and Implementation in VSS},
 volume = {9},
 year = {2021}
}

@article{9525369,
 abstract = {The great advancements in communication, cloud computing, and the internet of things (IoT) have opened critical challenges in security. With these developments, cyberattacks are also rapidly growing since the current security mechanisms do not provide efficient solutions. Recently, various artificial intelligence (AI) based solutions have been proposed for different security applications, including intrusion detection. In this paper, we propose an efficient AI-based mechanism for intrusion detection systems (IDS) in IoT systems. We leverage the advancements of deep learnings and metaheuristics (MH) algorithms that approved their efficiency in solving complex engineering problems. We propose a feature extraction method using the convolutional neural networks (CNNs) to extract relevant features. Also, we develop a new feature selection method using a new variant of the transient search optimization (TSO) algorithm, called TSODE, using the operators of differential evolution (DE) algorithm. The proposed TSODE uses the DE to improve the process of balancing between exploitation and exploration phases. Furthermore, we use three public datasets, KDDCup-99, NSL-KDD, BoT-IoT, and CICIDS-2017 to assess the performance of the developed method, which achieved higher accuracy compared to several existing approaches.},
 author = {Fatani, Abdulaziz and Abd Elaziz, Mohamed and Dahou, Abdelghani and Al-Qaness, Mohammed A. A. and Lu, Songfeng},
 doi = {10.1109/ACCESS.2021.3109081},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Intrusion detection;Transient analysis;Deep learning;Convolutional neural networks;Cloud computing;Internet of Things;Internet of Things (IoT);security;cyberattack;intrusion detection system;feature selection;optimization algorithms},
 month = {},
 number = {},
 pages = {123448-123464},
 title = {IoT Intrusion Detection System Using Deep Learning and Enhanced Transient Search Optimization},
 volume = {9},
 year = {2021}
}

@article{9539167,
 abstract = {A network intrusion detection (NID) system plays a critical role in cybersecurity. However, the existing machine learning-based NID research has a vital issue that their experimental settings do not reflect real-world situations where unknown attacks are constantly emerging. In particular, their train and test sets are from a single data set, which inevitably overestimates the detection power since all test attack types are known in training, and test cases will have similar characteristics to the training data. This paper introduces a new strategy to constitute test data with updated traffic with attack types not included in training data. In the proposed setting, the prediction accuracy of the existing detectors is dropped by about 20% compared to what has been reported. Also, in- depth analysis of detection performance by attack types has revealed that the existing models have strength at certain attack types but struggle to detect the other attack types such as DoS, DDoS, web attack, and port scan. To overcome the issues, we propose a new neural detector, called MHSA, based on a multi-head self-attention mechanism whose architecture suits better to capture scattered pieces of evidence in network traffic. Our model improved the overall detection performance by 29% in false positive rate at the true positive rate of 0.9 and by 9% in AUC over the current state-of-the-art models, successfully detecting the attacks that are not well captured before. Furthermore, we show that our proposed MHSA model even outperforms the best ensemble detector constructed by joining the state-of-the-art classifiers.},
 author = {Seo, Seongyun and Han, Sungmin and Park, Janghyeon and Shim, Shinwoo and Ryu, Han-Eul and Cho, Byoungmo and Lee, Sangkyun},
 doi = {10.1109/ACCESS.2021.3113124},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Detectors;Convolutional neural networks;Training;Feature extraction;Support vector machines;Data models;Deep learning;Deep neural network;intrusion detection;multi-head attention;realistic prediction performance evaluation;self-attention},
 month = {},
 number = {},
 pages = {129635-129647},
 title = {Hunt for Unseen Intrusion: Multi-Head Self-Attention Neural Detector},
 volume = {9},
 year = {2021}
}

@article{9548896,
 abstract = {In recent years, adversarial attack methods have been deceived rather easily on deep neural networks (DNNs). In practice, adversarial patches cause misclassification that can be extremely effective. However, many existing adversarial patches are used for attacking DNNs, and only a few of them apply to both the DNN and its explanation model. In this paper, we present different adversarial patches that misguide the prediction of DNN models and change the cause of prediction results of interpretation models, such as gradient-weighted class activation mapping. The proposed adversarial patches have appropriate location and perturbation ratios, which comprise visible or less visible adversarial patches. In addition, image patches within small arrays are localized without covering or overlapping with any of the main objects in a natural image. In particular, we generate two adversarial patches that cover only 3% and 1.5% of the pixels in the original image, while they do not cover the main objects in the natural image. Our experiments are performed using four pre-trained DNN models and the ImageNet dataset. We also examine the inaccurate results of the interpretation models through mask and heatmap visualization. The proposed adversarial attack method could be a reference for developing robust network interpretation models that are more reliable for the decision-making process of pre-trained DNN models.},
 author = {Le, Thi-Thu-Huong and Kang, Hyoeun and Kim, Howon},
 doi = {10.1109/ACCESS.2021.3115764},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Perturbation methods;Predictive models;Heating systems;Detectors;Deep learning;Visualization;Training;AI security;explainable AI (XAI);gradient-weighted class activation mapping (Grad-CAM);adversarial patch;image classification;pre-trained model},
 month = {},
 number = {},
 pages = {133049-133061},
 title = {Robust Adversarial Attack Against Explainable Deep Classification Models Based on Adversarial Images With Different Patch Sizes and Perturbation Ratios},
 volume = {9},
 year = {2021}
}

@article{9551702,
 abstract = {Along with the popularity of the Internet of Things (IoT) techniques with several computational paradigms, such as cloud and edge computing, microservice has been viewed as a promising architecture in large-scale application design and deployment. Due to the limited computing ability of edge devices in distributed IoT, only a small scale of data can be used for model training. In addition, most of the machine-learning-based intrusion detection methods are insufficient when dealing with imbalanced dataset under limited computing resources. In this article, we propose an optimized intra/inter-class-structure-based variational few-shot learning (OICS-VFSL) model to overcome a specific out-of-distribution problem in imbalanced learning, and to improve the microservice-oriented intrusion detection in distributed IoT systems. Following a newly designed VFSL framework, an intra/inter-class optimization scheme is developed using reconstructed feature embeddings, in which the intra-class distance is optimized based on the approximation during a variation Bayesian process, while the inter-class distance is optimized based on the maximization of similarities during a feature concatenation process. An intelligent intrusion detection algorithm is, then, introduced to improve the multiclass classification via a nonlinear neural network. Evaluation experiments are conducted using two public datasets to demonstrate the effectiveness of our proposed model, especially in detecting novel attacks with extremely imbalanced data, compared with four baseline methods.},
 author = {Liang, Wei and Hu, Yiyong and Zhou, Xiaokang and Pan, Yi and Wang, Kevin I-Kai},
 doi = {10.1109/TII.2021.3116085},
 issn = {1941-0050},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Intrusion detection;Data models;Training;Feature extraction;Training data;Distributed databases;Deep learning;Distributed Internet of Things (IoT);few-shot learning;imbalanced data;intrusion detection;out-of-distribution;variational feature representation},
 month = {Aug},
 number = {8},
 pages = {5087-5095},
 title = {Variational Few-Shot Learning for Microservice-Oriented Intrusion Detection in Distributed Industrial IoT},
 volume = {18},
 year = {2022}
}

@article{9551879,
 abstract = {Background: Building an effective Intrusion detection system in a multi-attack classification environment is challenging due to the diversity of modern, sophisticated attacks. High-performance classification methods are needed for Intrusion Detection Systems as attackers can establish intrusive methods and easily evade the detection tools deployed in a computing environment. Moreover, it is challenging to use a single classifier to efficiently detect all kinds of attacks. Aims: To propose a unique ensemble framework that can effectively detect different attack categories. Method: The proposed approach is based on building an ensemble by ranking the detection ability of different base classifiers to identify various types of attacks. The F1-score of an algorithm is used to compute the rank matrix for different attack categories. For final prediction algorithm’s output for an attack is only considered if the algorithm has the highest F1-Score in the rank matrix for the particular attack category. This approach contrasts with the voting approach where the final classification is based on the voting of all classifiers in the ensemble irrespective of the fact if the algorithm is efficient enough to detect that attack or not. Results: With the proposed method, the final accuracy obtained is 96.97 %, a recall rate of 97.4%, and a better attack detection rate than the baseline classifiers and other existing approaches for different attack categories.},
 author = {Seth, Sugandh and Chahal, Kuljit Kaur and Singh, Gurvinder},
 doi = {10.1109/ACCESS.2021.3116219},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Classification algorithms;Machine learning algorithms;Deep learning;Random forests;Computer crime;Feature extraction;Intrusion detection system;machine learning;cybersecurity;ensemble learning;intrusion detection framework;CIC IDS 2018},
 month = {},
 number = {},
 pages = {138451-138467},
 title = {A Novel Ensemble Framework for an Intelligent Intrusion Detection System},
 volume = {9},
 year = {2021}
}

@article{9552882,
 abstract = {Network anomaly detection plays a crucial role as it provides an effective mechanism to block or stop cyberattacks. With the recent advancement of Artificial Intelligence (AI), there has been a number of Autoencoder (AE) based deep learning approaches for network anomaly detection to improve our posture towards network security. The performance of existing state-of-the-art AE models used for network anomaly detection varies without offering a holistic approach to understand the critical impacts of the core set of important performance indicators of AE models and the detection accuracy. In this study, we propose a novel 5-layer autoencoder (AE)-based model better suited for network anomaly detection tasks. Our proposal is based on the results we obtained through an extensive and rigorous investigation of several performance indicators involved in an AE model. In our proposed model, we use a new data pre-processing methodology that transforms and removes the most affected outliers from the input samples to reduce model bias caused by data imbalance across different data types in the feature set. Our proposed model utilizes the most effective reconstruction error function which plays an essential role for the model to decide whether a network traffic sample is normal or anomalous. These sets of innovative approaches and the optimal model architecture allow our model to be better equipped for feature learning and dimension reduction thus producing better detection accuracy as well as f1-score. We evaluated our proposed model on the NSL-KDD dataset which outperformed other similar methods by achieving the highest accuracy and f1-score at 90.61% and 92.26% respectively in detection.},
 author = {Xu, Wen and Jang-Jaccard, Julian and Singh, Amardeep and Wei, Yuanyuan and Sabrina, Fariza},
 doi = {10.1109/ACCESS.2021.3116612},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Data models;Training;Network security;Mathematical models;Encoding;Task analysis;Network security;intrusion detection systems;network-based IDSs;anomaly detection;NSL-KDD;artificial intelligence;machine learning;deep learning;autoencoders;unsupervised learning},
 month = {},
 number = {},
 pages = {140136-140146},
 title = {Improving Performance of Autoencoder-Based Network Anomaly Detection on NSL-KDD Dataset},
 volume = {9},
 year = {2021}
}

@article{9562531,
 abstract = {In this article, we present a comprehensive study with an experimental analysis of federated deep learning approaches for cyber security in the Internet of Things (IoT) applications. Specifically, we first provide a review of the federated learning-based security and privacy systems for several types of IoT applications, including, Industrial IoT, Edge Computing, Internet of Drones, Internet of Healthcare Things, Internet of Vehicles, etc. Second, the use of federated learning with blockchain and malware/intrusion detection systems for IoT applications is discussed. Then, we review the vulnerabilities in federated learning-based security and privacy systems. Finally, we provide an experimental analysis of federated deep learning with three deep learning approaches, namely, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). For each deep learning model, we study the performance of centralized and federated learning under three new real IoT traffic datasets, namely, the Bot-IoT dataset, the MQTTset dataset, and the TON_IoT dataset. The goal of this article is to provide important information on federated deep learning approaches with emerging technologies for cyber security. In addition, it demonstrates that federated deep learning approaches outperform the classic/centralized versions of machine learning (non-federated learning) in assuring the privacy of IoT device data and provide the higher accuracy in detecting attacks.},
 author = {Ferrag, Mohamed Amine and Friha, Othmane and Maglaras, Leandros and Janicke, Helge and Shu, Lei},
 doi = {10.1109/ACCESS.2021.3118642},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Collaborative work;Data models;Servers;Computer crime;Deep learning;Training;Federated learning;intrusion detection;deep learning;cyber security;the IoT;blockchain},
 month = {},
 number = {},
 pages = {138509-138542},
 title = {Federated Deep Learning for Cyber Security in the Internet of Things: Concepts, Applications, and Experimental Analysis},
 volume = {9},
 year = {2021}
}

@article{9562543,
 abstract = {Detecting intrusion in network traffic has remained a problematic task for years. Progress in the field of machine learning is paving the way for enhancing intrusion detection systems. Due to this progress intrusion detection has become an integral part of network security. Intrusion detection has achieved high detection accuracy with the help of supervised machine learning methods. A key factor in enhancing the performance of supervised classifiers is how data is augmented for training the classification model. Data in real-world networks or publicly available datasets are not always normally (Gaussian) distributed. Instead, the distributions of variables are more likely to be skewed. To achieve a high detection rate, data normalization or transformation plays an important role for machine learning-based intrusion detection systems. Several methods are available to normalize the attributes of the data before training a classification model. However, opting for the most suitable normalization technique is still a questionable task. In this paper, a statistical method is proposed that can identify the most suitable normalization method for the dataset. The normalization method identified by the proposed approach gives the highest accuracy for an intrusion detection system. To highlight the efficiency of the proposed method, five different datasets were used with two different feature selection methods. The datasets belong to both Internet of things and traditional network environments. The proposed method is also able to identify hybrid normalizations to achieve even improved intrusion detection results.},
 author = {Siddiqi, Murtaza Ahmed and Pak, Wooguil},
 doi = {10.1109/ACCESS.2021.3118361},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Mathematical models;Feature extraction;Training;Standards;Statistical analysis;Numerical models;Anomaly detection;Bot-IoT;CIC-IDS 2017;intrusion detection;IoT;ISCX-IDS 2012;normalization;NSL KDD;skewness;scaling;transformation;UNSW-NB15},
 month = {},
 number = {},
 pages = {137494-137513},
 title = {An Agile Approach to Identify Single and Hybrid Normalization for Enhancing Machine Learning-Based Network Intrusion Detection},
 volume = {9},
 year = {2021}
}

@article{9568902,
 abstract = {Enhanced metering infrastructure is a key component of the electrical system, offering many advantages, including load management and demand response. However, several additional energy theft channels are introduced by the automation of the metering system. With data analysis techniques, adapting the smart grid significantly reduces energy theft loss. In this article, we proposed deep learning methods for the identification of power theft. A three-stage technique has been devised, which includes selection, extraction, and classification of features. In the selection phase, the average hybrid feature importance determines the most important features and high priority. The feature extraction technique employs the ZFNET method to remove the unwanted features. For the detection of electric fraud, we have applied Long Short Term Memory method embedded in Convolutional Neural Network technique (CNN-LSTM). Meta-heuristic techniques, including Black Widow Optimization (BWO) and Blue Monkey Optimization (BMO), are used to calculate optimized values for the hyperparameters of CNN-LSTM. The tuning of hyperparameters of the classifier helps in better training on data. After extensive simulation, our proposed methods CNN-LSTM-BMO and CNN-LSTM-BWO achieved an accuracy of 91% and 93%. Our proposed methods outperform all the existing compared schemes. The performance of our models has attained high accuracy and low error rate. Furthermore, the statistical analysis also shows the superiority of the proposed methods.},
 author = {Almazroi, Abdulwahab Ali and Ayub, Nasir},
 doi = {10.1109/ACCESS.2021.3119575},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Meters;Support vector machines;Smart grids;Feature extraction;Convolutional neural networks;Smart meters;Optimization;Optimization techniques;smart grid;deep learning methods;ensembler;black widow optimizer;CNN},
 month = {},
 number = {},
 pages = {141154-141166},
 title = {A Novel Method CNN-LSTM Ensembler Based on Black Widow and Blue Monkey Optimizer for Electricity Theft Detection},
 volume = {9},
 year = {2021}
}

@article{9576688,
 abstract = {The network intrusion detection system is a core technology of network security that detects packets for malicious activities occurring in the network and is an essential element for stable services in extended network environments such as big data and IoT. These network intrusion detection systems have been studied together with machine learning and deep learning, but performance is not guaranteed in the actual environment or the class balance problem has not been solved. Therefore, in this study, we investigate the performance of a discretization preprocessing method with a CNN-based classifier on the class imbalance problem of network traffic data. The preprocessing method adds a discretization algorithm for continuous variables in the commonly used conventional preprocessing method and converts 1D network packet vectors into 2D image vectors to improve relational analysis and generalization performance. Since the convolution neural network has immutability to the input data, it improves statistical efficiency in learning network packets converted into images. To evaluate the proposed model, we compared the computational complexity and generalization performance using NSL-KDD and CSE-CIC-IDS 2018, which is a representative network packet data. As a result of the experiment, it was confirmed that in the case of computational complexity, training time and parameters were reduced compared to the model designed similarly to the proposed model, and accuracy and F1 score improved in generalization performance.},
 author = {Yoo, Jihoon and Min, Byeongjun and Kim, Sangsoo and Shin, Dongil and Shin, Dongkyoo},
 doi = {10.1109/ACCESS.2021.3120839},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Data models;Support vector machines;Analytical models;Classification algorithms;Training;Telecommunication traffic;Convolution neural network (CNN);CSE-CIC-IDS 2018;discretization;NSL-KDD;network intrusion detection system (NIDS)},
 month = {},
 number = {},
 pages = {142348-142361},
 title = {Study on Network Intrusion Detection Method Using Discrete Pre-Processing Method and Convolution Neural Network},
 volume = {9},
 year = {2021}
}

@article{9583228,
 abstract = {Anomaly detection in network traffic is one of the key techniques to ensure security in future networks. Today, the importance of this topic is even higher, since the network traffic is growing and there is a need to have smart algorithms, which can automatically adapt to new network conditions, detect threats and recognize the type of the possible network attack. Nowadays, there are a lot of different approaches, some of them have reached relatively sufficient accuracy. However, the majority of works are being tested on old datasets, which do not reflect current network conditions and it leads to overfitted results. This is caused by high redundancy of the data and because they fail to reflect the performance of the latest methods in the real-world anomaly detection applications. In this work, we applied a couple of new methods based on convolutional neural networks: U-Net based and Temporal convolutional network based for network attack classification. We trained and evaluated methods on the old dataset KDD99 and the modern large-scale one CSE-CIC-IDS2018. According to results, Temporal convolutional network with LSTM has achieved accuracy 92% and 97% on the KDD99 and the CSE-CIC-IDS2018 respectively, the U-Net model has accuracy 93% and 94% on the KDD99 and the CSE-CIC-IDS2018 respectively. Additionally, we utilized the focal loss function in the Temporal convolutional network with Long Short-Term Memory model, which has positive effect on class imbalance in time-series data. We showed, that the Temporal convolutional network in combination with Long Short-Term Memory network and U-Net model can give higher accuracy compared to other network architectures for network traffic classification. In this work we also proved, that methods trained on the old dataset can easily overfit during training and achieve relatively good results on the testing set, but at the same time, these methods are not so successful on more complex and actual data.},
 author = {Mezina, Anzhelika and Burget, Radim and Travieso-González, Carlos M.},
 doi = {10.1109/ACCESS.2021.3121998},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Task analysis;Training;Intrusion detection;Feature extraction;Data models;Testing;Convolutional neural network;deep learning;intrusion detection system;multi-class classification;security;imbalanced dataset},
 month = {},
 number = {},
 pages = {143608-143622},
 title = {Network Anomaly Detection With Temporal Convolutional Network and U-Net Model},
 volume = {9},
 year = {2021}
}

@article{9591559,
 abstract = {Distributed Denial-of-Service (DDoS) attacks are increasing as the demand for Internet connectivity massively grows in recent years. Conventional shallow machine learning-based techniques for DDoS attack classification tend to be ineffective when the volume and features of network traffic, potentially carry malicious DDoS payloads, increase exponentially as they cannot extract high importance features automatically. To address this concern, we propose a hybrid approach named AE-MLP that combines two deep learning-based models for effective DDoS attack detection and classification. The Autoencoder (AE) part of our proposed model provides an effective feature extraction that finds the most relevant feature sets automatically without human intervention (e.g., knowledge of cybersecurity professionals). The Multi-layer Perceptron Network (MLP) part of our proposed model uses the compressed and reduced feature sets produced by the AE as inputs and classifies the attacks into different DDoS attack types to overcome the performance overhead and bias associated with processing large feature sets with noise (i.e., unnecessary feature values). Our experimental results, obtained through comprehensive and extensive experiments on different aspects of performance on the CICDDoS2019 dataset, demonstrate both a very high and robust accuracy rate and F1-score that exceed 98% which also outperformed the performance of many similar methods. This shows that our proposed model can be used as an effective DDoS defense tool against the growing number of DDoS attacks.},
 author = {Wei, Yuanyuan and Jang-Jaccard, Julian and Sabrina, Fariza and Singh, Amardeep and Xu, Wen and Camtepe, Seyit},
 doi = {10.1109/ACCESS.2021.3123791},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Feature extraction;Computer crime;Random forests;Deep learning;Neurons;Electronic mail;Distributed denial of service;DDoS;deep learning;multi-class classification;autoencoder;MLP;CICDDoS2019},
 month = {},
 number = {},
 pages = {146810-146821},
 title = {AE-MLP: A Hybrid Deep Learning Approach for DDoS Detection and Classification},
 volume = {9},
 year = {2021}
}

@article{9605636,
 abstract = {Web applications are often exposed to attacks because of the critical information and valuable assets they host. In this study, Bi-LSTM based web application security models were developed in order to detect web attacks and classify them into binary or multiple classes using HTTP requests. A novel data augmentation technique based on the self-adapting noise adding method (DA-SANA) was developed. The DA-SANA method solves the low sensitivity problem caused by imbalanced data and the complex structure of multi-class classification in web attack detection. Experimental evaluations are carried out in detail using two benchmark web security datasets and a newly created dataset within the scope of the study. The achieved worst case detection rates are 98.34% and 93.91% for binary-class and multi-class classifications, respectively. The proposed DA-SANA technique provides an average of 6.52% improvement in multi-class classification for two datasets. These results revealed that the best classification performance values were achieved when compared with previous studies.},
 author = {Karacan, Hacer and Sevri, Mehmet},
 doi = {10.1109/ACCESS.2021.3125785},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Security;Deep learning;Payloads;Uniform resource locators;Mathematical models;Machine learning algorithms;Web security;anomaly detection;deep learning;Bi-LSTM;data augmentation},
 month = {},
 number = {},
 pages = {150781-150797},
 title = {A Novel Data Augmentation Technique and Deep Learning Model for Web Application Security},
 volume = {9},
 year = {2021}
}

@article{9612220,
 abstract = {Network intrusion detection focuses on classifying network traffic as either normal or attack carrier. The classification is based on information extracted from the network flow packets. This is a complex classification problem with unbalanced datasets and noisy data. This work extends the classic radial basis function (RBF) neural network by including it as a policy network in an offline reinforcement learning algorithm. With this approach, all parameters of the radial basis functions (along with the network weights) are learned end-to-end by gradient descent without external optimization. We further explore how additional dense hidden-layers, and the number of radial basis kernels influence the results. This novel approach is applied to five prominent intrusion detection datasets (NSL-KDD, UNSW-NB15, AWID, CICIDS2017 and CICDDOS2019) achieving better performance metrics than alternative state-of-the-art models. Each dataset provides different restrictions and challenges allowing a better validation of results. Analysis of the results shows that the proposed architectures are excellent candidates for designing classifiers with the constraints imposed by network intrusion detection. We discuss the importance of dataset imbalance and how the proposed methods may be critically important for unbalanced datasets.},
 author = {Lopez-Martin, Manuel and Sanchez-Esguevillas, Antonio and Arribas, Juan Ignacio and Carro, Belen},
 doi = {10.1109/ACCESS.2021.3127689},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Reinforcement learning;Training;Network intrusion detection;Optimization methods;Dispersion;Radial basis function networks;Particle swarm optimization;Communication system security;intrusion detection;neural networks;radial basis function networks},
 month = {},
 number = {},
 pages = {153153-153170},
 title = {Network Intrusion Detection Based on Extended RBF Neural Network With Offline Reinforcement Learning},
 volume = {9},
 year = {2021}
}

@article{9614112,
 abstract = {Machine learning has recently become a popular algorithm in building reliable intrusion detection systems (IDSs). However, most of the models are static and trained using datasets containing all targeted intrusions. If new intrusions emerge, these trained models must be retrained using old and new datasets to classify all intrusions accurately. In real-world situations, new threats continuously appear. Therefore, machine learning algorithms used for IDSs should have the ability to learn incrementally when these new intrusions emerge. To solve this issue, we propose T-DFNN. T-DFNN is an algorithm capable of learning new intrusions incrementally as they emerge. A T-DFNN model is composed of multiple deep feedforward neural network (DFNN) models connected in a tree-like structure. We examined our proposed algorithm using CICIDS2017, an open and widely used network intrusion dataset covering benign traffic and the most common network intrusions. The experimental results showed that the T-DFNN algorithm can incrementally learn new intrusions and reduce the catastrophic forgetting effect. The macro average of the F1-score of the T-DFNN model was over 0.85 for every retraining process. In addition, our proposed T-DFNN model has some advantages in several aspects compared to other models. Compared to the DFNN and Hoeffding tree models trained with a dataset containing only the latest targeted intrusions, our proposed T-DFNN model has higher F1-scores. Moreover, our proposed T-DFNN model has significantly shorter training times than a DFNN model trained using a dataset containing all targeted intrusions. Even though several factors can affect the duration of the training process, the T-DFNN algorithm shows promising results in solving the problem of ever-evolving network intrusion variants.},
 author = {Data, Mahendra and Aritsugi, Masayoshi},
 doi = {10.1109/ACCESS.2021.3127985},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Machine learning algorithms;Training;Computational modeling;Deep learning;Machine learning;Support vector machines;Task analysis;Network intrusion detection;incremental learning;catastrophic forgetting;deep learning;classification algorithm},
 month = {},
 number = {},
 pages = {154156-154171},
 title = {T-DFNN: An Incremental Learning Algorithm for Intrusion Detection Systems},
 volume = {9},
 year = {2021}
}

@article{9614187,
 abstract = {Aiming at unknown or variant ransomware attack encrypted with SSL (Secure Sockets Layer)/ TLS (Transport Layer Security) protocol, a detection framework named TGAN-IDS (Transferred Generating Adversarial Network-Intrusion Detection System) based on dual generative adversarial networks is presented in this paper. In this framework, DCGAN (Deep Convolutional Generative Adversarial Network) is adopted to train a generator which has good performance to generate adversarial sample, and is transferred to the generator of TGAN. A pre-training model named PreD is built based on CNN (Convolutional Neural Network), which has good performance to do binary classification, and is transferred to the discriminator of TGAN. The generator and discriminator of TGAN play games in training process until the discriminator has a strong ability to detection unknown attack, and then it is output as an anomaly detector. In order to suppress the deterioration of normal sample detection ability during adversarial training of TGAN, a reconstruction loss function is introduced into the target function of TGAN. Experiments on a mixed dataset which is constructed by CICIDS2017 and other ransomware datasets show comparing with other deep learning network, such as AlexNet, ResNet and DenseNet etc., TGAN-IDS performs well in the indicators of detection accuracy, recall or F1-score etc. Also experiments on KDD99, SWaT and WADI datasets show that TGAN-IDS is suitable for other unencrypted unknown network attack detection.},
 author = {Zhang, Xueqin and Wang, Jiyuan and Zhu, Shinan},
 doi = {10.1109/ACCESS.2021.3128024},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Ransomware;Generative adversarial networks;Anomaly detection;Training data;Protocols;Generators;Intrusion detection;Transfer learning;Encryption;Ransomware;encrypted traffic;anomaly detection;GAN;transfer learning},
 month = {},
 number = {},
 pages = {900-913},
 title = {Dual Generative Adversarial Networks Based Unknown Encryption Ransomware Attack Detection},
 volume = {10},
 year = {2022}
}

@article{9617591,
 abstract = {Today’s smart city infrastructure is predominantly dependant on Internet of Things (IoT) technologies. IoT technology essentially facilitates a platform for service automation through connections of heterogeneous objects via the Internet backbone. However, the security issues associated with IoT networks make smart city infrastructure vulnerable to cyber-attacks. For example, Distributed Denial of Service (DDoS) attack violates the authorization conditions in smart city infrastructure; whereas replay attack violates the authentication conditions in smart city infrastructure. Both attacks lead to physical disruption to smart city infrastructure, which may even lead to financial loss and/or loss of human lives. In this paper, a hybrid deep learning model is developed for detecting replay and DDoS attacks in a real life smart city platform. The performance of the proposed hybrid model is evaluated using real life smart city datasets (environmental, smart river and smart soil), where DDoS and replay attacks were simulated. The proposed model reported high accuracy rates: 98.37% for the environmental dataset, 98.13% for the smart river dataset, and 99.51% for the smart soil dataset. The results demonstrated an improved performance of the proposed model over other machine learning and deep learning models from the literature.},
 author = {Elsaeidy, Asmaa A. and Jamalipour, Abbas and Munasinghe, Kumudu S.},
 doi = {10.1109/ACCESS.2021.3128701},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Smart cities;Deep learning;Denial-of-service attack;Computer crime;Convolutional neural networks;Intrusion detection;Internet of Things;Intrusion detection;distributed denial of service (DDoS) attacks;replay attack;smart city;deep learning;Internet of Things (IoT)},
 month = {},
 number = {},
 pages = {154864-154875},
 title = {A Hybrid Deep Learning Approach for Replay and DDoS Attack Detection in a Smart City},
 volume = {9},
 year = {2021}
}

@article{9617609,
 abstract = {Information and communication technology (ICT) advancements have altered the entire computing paradigm. As a result of these improvements, numerous new channels of communication are being created, one of which is the Internet of Things (IoT). The IoT has recently emerged as cutting-edge technology for creating smart environments. The Internet of Medical Things (IoMT) is a subset of the IoT, in which medical equipment exchange information with each other to exchange sensitive information. These developments enable the healthcare business to maintain a higher level of touch and care for its patients. Security is seen as a significant challenge in whatsoever technology’s reliance based on the IoT. Security difficulties occur owing to the various potential attacks posed by attackers. There are numerous security concerns, such as remote hijacking, impersonation, denial of service attacks, password guessing, and man-in-the-middle. In the event of such attacks, critical data associated with IoT connectivity may be revealed, altered, or even rendered inaccessible to authorized users. As a result, it turns out to be critical to safeguard the IoT/IoMT ecosystem against malware assaults. The main goal of this study is to demonstrate how a deep recurrent neural network (DRNN) and supervised machine learning models (random forest, decision tree, KNN, and ridge classifier) can be utilized to develop an efficient and effective IDS in the IoMT environment for classifying and forecasting unexpected cyber threats. Preprocessing and normalization of network data are performed. Following that, we optimized features using a bio-inspired particle swarm algorithm. On the standard data for intrusion detection, a thorough evaluation of experiments in DRNN and other SML is performed. It was established through rigorous testing that the proposed SML model outperforms existing approaches with an accuracy of 99.76%.},
 author = {Saheed, Yakub Kayode and Arowolo, Micheal Olaolu},
 doi = {10.1109/ACCESS.2021.3128837},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Security;Internet of Things;Hospitals;Wireless sensor networks;Robot sensing systems;Privacy;Internet of Medical Things;cyber-attack;Internet of Things;particle swarm optimization;recurrent neural network;smart environment},
 month = {},
 number = {},
 pages = {161546-161554},
 title = {Efficient Cyber Attack Detection on the Internet of Medical Things-Smart Environment Based on Deep Recurrent Neural Network and Machine Learning Algorithms},
 volume = {9},
 year = {2021}
}

@article{9620099,
 abstract = {Effectively detecting intrusions in the computer networks still remains problematic. This is because cyber attackers are changing packet contents to disguise the intrusion detection system (IDS) recently. Besides, everyday a lot of new devices are added to the computer networks. These new devices are also raising security issues in the computer networks. To effectively manage the computer network flows and provide the security in advance; the components of the IDSs, the approaches and technologies that are used, the nature of the attacks, and the tools that are used needs to be examined deeply. This paper discusses intrusion detection technologies, methodologies, and approaches and also investigates new attack types, protection mechanisms, and recent scientific studies that have been made in this area. In addition, available datasets, well-known IDS tools, and advantages and disadvantages of particular IDSs are explained deeply. We believe that this scientific review study presents a road map for researchers and industry employees who focus on IDSs.},
 author = {Ozkan-Okay, Merve and Samet, Refik and Aslan, Ömer and Gupta, Deepti},
 doi = {10.1109/ACCESS.2021.3129336},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Security;Protocols;Tools;Computer networks;Computer hacking;Wireless communication;Intrusion detection system;IDS technologies;IDS methodologies;IDS approaches;datasets;IDS tools},
 month = {},
 number = {},
 pages = {157727-157760},
 title = {A Comprehensive Systematic Literature Review on Intrusion Detection Systems},
 volume = {9},
 year = {2021}
}

@article{9622260,
 abstract = {With the advancement of technology, the use of wireless media and devices are increasing every day. In particular, the use of wireless local area networks (WLAN) has increased rapidly in recent years and is expected to increase further. The current state of wireless local area network technologies makes the network vulnerable to attacks ranging from passive listening to active intervention. Intrusion detection systems (IDSs) are being developed against these kinds of attacks. The IDSs play an important role in WLAN security by detecting and preventing malicious activities. However, most techniques used in IDSs cannot cope with dynamic and complex attacks. The aim of this study is to reduce the deficiencies in present IDSs for WLANs and build a more effective system which can detect unknown and complex attack variants dynamically. In this context, a methodology has been proposed. The proposed methodology basically has two contributions. The first contribution is the Feature Selection Approach (FSAP) to increase the speed of attack detection by reducing the number of used features. The second contribution is the hybrid attack detection technique, SABADT (Signature and Anomaly Based Attack Detection Technique), which detects attacks fast with high accuracy. The proposed methodology is implemented on the KDD’99 and UNSW-NB15 datasets. The obtained results are compared with existing machine learning techniques. The detection model is created by using KDD’99 and UNSW-NB15 training datasets and tested on the KDD’99 and UNSW-NB15 test datasets. The obtained 99.65% and 99.17% accuracy rates are quite high when compared to leading methods in the literature. In addition, common tools were used to obtain a mix of normal activities and current attack behaviors in order to test on novel attacks within the scope of the study. The different types of attacks were captured with the Wireshark tool. Some of the captured attacks were used only in the testing phase. In this test case, the attacks were detected with an accuracy rate of 99.69%.},
 author = {Ozkan-Okay, Merve and Aslan, Ömer and Eryigit, Recep and Samet, Refik},
 doi = {10.1109/ACCESS.2021.3129600},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Wireless LAN;Machine learning;Intrusion detection;Classification algorithms;Wireless communication;Machine learning algorithms;Wireless LAN;intrusion detection system;hybrid model;signature based technique;anomaly based technique;machine learning;data analysis},
 month = {},
 number = {},
 pages = {157639-157653},
 title = {SABADT: Hybrid Intrusion Detection Approach for Cyber Attacks Identification in WLAN},
 volume = {9},
 year = {2021}
}

@article{9626144,
 abstract = {The advancement of Internet of Things (IoT) technologies leads to a wide penetration and large-scale deployment of IoT systems across an entire city or even country. While IoT systems are capable of providing intelligent services, the large amount of data collected and processed in IoT systems also raises serious security concerns. Many research efforts have been devoted to design intelligent network intrusion detection system (NIDS) to prevent misuse of IoT data across smart applications. However, existing approaches may suffer from the issue of limited and imbalanced attack data when training the detection model, which make the system vulnerable especially for those unknown type attacks. In this study, a novel hierarchical adversarial attack (HAA) generation method is introduced to realize the level-aware black-box adversarial attack strategy, targeting the graph neural network (GNN)-based intrusion detection in IoT systems with a limited budget. By constructing a shadow GNN model, an intelligent mechanism based on a saliency map technique is designed to generate adversarial examples by effectively identifying and modifying the critical feature elements with minimal perturbations. A hierarchical node selection algorithm based on random walk with restart (RWR) is developed to select a set of more vulnerable nodes with high attack priority, considering their structural features, and overall loss changes within the targeted IoT network. The proposed HAA generation method is evaluated using the open-source data set UNSW-SOSR2019 with three baseline methods. Comparison results demonstrate its ability in degrading the classification precision by more than 30% in the two state-of-the-art GNN models, GCN and JK-Net, respectively, for NIDS in IoT environments.},
 author = {Zhou, Xiaokang and Liang, Wei and Li, Weimin and Yan, Ke and Shimizu, Shohei and Wang, Kevin I-Kai},
 doi = {10.1109/JIOT.2021.3130434},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Internet of Things;Data models;Training;Deep learning;Feature extraction;Perturbation methods;Optimization;Adversarial attack;deep learning;graph neural network (GNN);Internet of Things (IoT);network intrusion detection},
 month = {June},
 number = {12},
 pages = {9310-9319},
 title = {Hierarchical Adversarial Attacks Against Graph-Neural-Network-Based IoT Network Intrusion Detection System},
 volume = {9},
 year = {2022}
}

@article{9626591,
 abstract = {The Internet of Things (IoT) devices, networks, and applications have become an integral part of modern societies. Despite their social, economic, and industrial benefits, these devices and networks are frequently targeted by cybercriminals. Hence, IoT applications and networks demand lightweight, fast, and flexible security solutions to overcome these challenges. In this regard, artificial-intelligence-based solutions with Big Data analytics can produce promising results in the field of cybersecurity. This article proposes a lightweight dense random neural network (DnRaNN) for intrusion detection in the IoT. The proposed scheme is well suited for implementation in resource-constrained IoT networks due to its inherent improved generalization capabilities and distributed nature. The suggested model was evaluated by conducting extensive experiments on a new generation IoT security dataset ToN_IoT. All the experiments were conducted under different hyperparameters and the efficiency of the proposed DnRaNN was evaluated through multiple performance metrics. The findings of the proposed study provide recommendations and insights in binary class and multiclass scenarios. The proposed DnRaNN model attained attack detection accuracy of 99.14% and 99.05% for binary class and multiclass classifications, respectively.},
 author = {Latif, Shahid and Huma, Zil e and Jamal, Sajjad Shaukat and Ahmed, Fawad and Ahmad, Jawad and Zahid, Adnan and Dashtipour, Kia and Aftab, Muhammad Umar and Ahmad, Muhammad and Abbasi, Qammer Hussain},
 doi = {10.1109/TII.2021.3130248},
 issn = {1941-0050},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Internet of Things;Security;Neurons;Mathematical models;Intrusion detection;Industries;Denial-of-service attack;Cybersecurity;deep learning;dense random neural network (DnRaNN);Internet of Things (IoT);intrusion detection},
 month = {Sep.},
 number = {9},
 pages = {6435-6444},
 title = {Intrusion Detection Framework for the Internet of Things Using a Dense Random Neural Network},
 volume = {18},
 year = {2022}
}

@article{9627525,
 abstract = {By violating semantic constraints that the control process impose, the semantic attack leads the Industry Control Systems (ICS) into an undesirable state or critical state. The spread of semantic attack has caused huge economic losses and casualties to critical infrastructure. Therefore, detecting semantic attack is referred to an urgent and critical task. However, few existing detecting techniques can achieve satisfactory effects in detecting semantic attack of ICS, due to the high requirements of complete critical state-based semantic behavior features description, joint detection on multivariate type state variables, and validity of field states datasets under semantic attacks. In an effort to deal with above challenges, We label device states databases with temporal characteristics and divide impacts on states of field devices under semantic attacks into three categories, including absent in states set, confused sequences, irregular frequency. On this basis, we establish a behavioral model based on secondary labeling of states-duration evolution graph (BMSLS), then implement an adaptive secure state-based semantic attack detection framework furtherly. Compared with the traditional Auto Regression (AR) algorithm, the newer time series correlation graph model, and other five deep learning algorithms, our proposed framework demonstrates the superior effect on the detection of semantic attack.},
 author = {Xu, Lijuan and Wang, Bailing and Wu, Xiaoming and Zhao, Dawei and Zhang, Lei and Wang, Zhen},
 doi = {10.1109/TNSE.2021.3130602},
 issn = {2327-4697},
 journal = {IEEE Transactions on Network Science and Engineering},
 keywords = {Semantics;Protocols;Process control;Integrated circuits;Intrusion detection;Valves;Support vector machines;Critical state;semantic attack;state-based duration evolation graph;supervisory control and data acquisition (SCADA)},
 month = {March},
 number = {2},
 pages = {703-715},
 title = {Detecting Semantic Attack in SCADA System: A Behavioral Model Based on Secondary Labeling of States-Duration Evolution Graph},
 volume = {9},
 year = {2022}
}

@article{9627657,
 abstract = {The botnet attack is a multi-stage and the most prevalent cyber-attack in the Internet of Things (IoT) environment that initiates with scanning activity and ends at the distributed denial of service (DDoS) attack. The existing studies mostly focus on detecting botnet attacks after the IoT devices get compromised, and start performing the DDoS attack. Similarly, the performance of most of the existing machine learning based botnet detection models is limited to a specific dataset on which they are trained. As a consequence, these solutions do not perform well on other datasets due to the diversity of attack patterns. Therefore, in this work, we first produce a generic scanning and DDoS attack dataset by generating 33 types of scan and 60 types of DDoS attacks. In addition, we partially integrated the scan and DDoS attack samples from three publicly-available datasets for maximum attack coverage to better train the machine learning algorithms. Afterwards, we propose a two-fold machine learning approach to prevent and detect IoT botnet attacks. In the first fold, we trained a state-of-the-art deep learning model, i.e., ResNet-18 to detect the scanning activity in the premature attack stage to prevent IoT botnet attacks. While, in the second fold, we trained another ResNet-18 model for DDoS attack identification to detect IoT botnet attacks. Overall, the proposed two-fold approach manifests 98.89% accuracy, 99.01% precision, 98.74% recall, and 98.87% f1-score to prevent and detect IoT botnet attacks. To demonstrate the effectiveness of the proposed two-fold approach, we trained three other ResNet-18 models over three different datasets for detecting scan and DDoS attacks and compared their performance with the proposed two-fold approach. The experimental results prove that the proposed two-fold approach can efficiently prevent and detect botnet attacks as compared to other trained models.},
 author = {Hussain, Faisal and Abbas, Syed Ghazanfar and Pires, Ivan Miguel and Tanveer, Sabeeha and Fayyaz, Ubaid U. and Garcia, Nuno M. and Shah, Ghalib A. and Shahzad, Farrukh},
 doi = {10.1109/ACCESS.2021.3131014},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Denial-of-service attack;Performance evaluation;Internet of Things;Computer crime;Protocols;Malware;Internet of Things;IoT botnet;botnet detection;IoT botnet attacks;IoT botnet DDoS attack;DDoS attack prevention;DDoS attack;IoT DDoS attack;botnet attack;botnet DDoS},
 month = {},
 number = {},
 pages = {163412-163430},
 title = {A Two-Fold Machine Learning Approach to Prevent and Detect IoT Botnet Attacks},
 volume = {9},
 year = {2021}
}

@article{9632806,
 abstract = {While anomaly detection and the related concept of intrusion detection are widely studied, detecting anomalies in new operating behavior in environments such as the Internet of Things (IoT) is an active field of research. Anomaly detection models trained on datasets that are likely imbalanced have poor results, but the ability of Generative Adversarial Networks (GANs) to emulate complex high-dimensional distributions seen in real-world data suggests that they can be effective for anomaly detection. This paper proposes a novel framework for detecting anomalies in IoT networks utilizing conditional GANs (cGANs) to build realistic distributions for a given feature set to overcome the issue of data imbalance. To this end, a one class cGAN (ocGAN) model was utilized to learn the minority data class to balance the dataset. Then, the binary class cGAN (bcGAN) model generates augmented data for the binary balance dataset. The performance of the ocGAN and bcGAN models in binary and multiclass classification environments were evaluated using a Feed Forward Neural Network (FFN) and tested on two network-based anomaly detection datasets and five IoT network-based anomaly detection datasets. The proposed models outperformed other anomaly detection models in the standard metrics of accuracy, precision, recall, and F1 score.},
 author = {Ullah, Imtiaz and Mahmoud, Qusay H.},
 doi = {10.1109/ACCESS.2021.3132127},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Measurement;Neural networks;Intrusion detection;Generative adversarial networks;Data models;Internet of Things;Security;Anomaly detection;Feature extraction;Internet of Things;generative adversarial networks (GANs);conditional GANs;feed-forward neural network;anomaly detection;deep learning;network security},
 month = {},
 number = {},
 pages = {165907-165931},
 title = {A Framework for Anomaly Detection in IoT Networks Using Conditional Generative Adversarial Networks},
 volume = {9},
 year = {2021}
}

@article{9654211,
 abstract = {The controller area network (CAN), which is still today the most used in-vehicle network, does not provide any security or authentication mechanism by design. Since current vehicles, which have numerous connectivity technologies, such as Bluetooth, Wi-Fi, and cellular radio, can be easily accessed from the exterior world, they can be easy targets of cyber-attacks. It is therefore urgently necessary to enhance vehicle security by detecting and stopping cyber-attacks. In this paper, we propose a novel unsupervised intrusion prevention system (IPS) for automotive CANs that detects and hinders attacks without modifying the architecture of the electronic control units (ECUs) or requiring information that is restricted to car manufacturers. We compare two machine learning algorithms’ ability to detect fuzzing and spoofing attacks, and evaluate which of them is most accurate with the fewest number of data bytes. The fewer data bytes required, the sooner detection can start and the sooner attacking frames can be detected. Experiment results show that our proposed detection mechanism achieves accuracy higher than 99%, F1-scores higher than 97%, and detection times shorter than  $80 ~\mu s$  for the types of attacks considered. Moreover, when compared to four state-of-the-art intrusion detection systems, it is the only solution that is capable of discarding attacking frames before damage occurs while being deployed on inexpensive Raspberry Pi. Such an inexpensive deployment is particularly desirable, as cost is one of the automotive industry’s primary concerns.},
 author = {Freitas De Araujo-Filho, Paulo and Pinheiro, Antônio J. and Kaddoum, Georges and Campelo, Divanilson R. and Soares, Fabio L.},
 doi = {10.1109/ACCESS.2021.3136147},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {IP networks;Hardware;Security;Machine learning algorithms;Intrusion detection;Automobiles;Timing;Intrusion detection system (IDS);intrusion prevention system (IPS);machine learning;controller area network (CAN)},
 month = {},
 number = {},
 pages = {166855-166869},
 title = {An Efficient Intrusion Prevention System for CAN: Hindering Cyber-Attacks With a Low-Cost Platform},
 volume = {9},
 year = {2021}
}

@article{9656911,
 abstract = {Since its inception, the Internet of Things (IoT) has witnessed mushroom growth as a breakthrough technology. In a nutshell, IoT is the integration of devices and data such that processes are automated and centralized to a certain extent. IoT is revolutionizing the way business is done and is transforming society as a whole. As this technology advances further, the need to exploit detection and weakness awareness increases to prevent unauthorized access to critical resources and business functions, thereby rendering the system unavailable. Denial of Service (DoS) and Distributed DoS attacks are all too common. In this paper, we propose a Protocol Based Deep Intrusion Detection (PB-DID) architecture, in which we created a data-set of packets from IoT traffic by comparing features from the UNSWNB15 and Bot-IoT data-sets based on flow and Transmission Control Protocol (TCP). We classify non-anomalous, DoS, and DDoS traffic uniquely by taking care of the problems like imbalanced and over-fitting. We have achieved a classification accuracy of 96.3% by using deep learning (DL) technique.},
 author = {Zeeshan, Muhammad and Riaz, Qaiser and Bilal, Muhammad Ahmad and Shahzad, Muhammad K. and Jabeen, Hajira and Haider, Syed Ali and Rahim, Azizur},
 doi = {10.1109/ACCESS.2021.3137201},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Deep learning;Support vector machines;Intrusion detection;Computer hacking;Computer crime;Training;Intrusion detection in IoT;deep learning for intrusion detection;DoS detection;DDoS detection},
 month = {},
 number = {},
 pages = {2269-2283},
 title = {Protocol-Based Deep Intrusion Detection for DoS and DDoS Attacks Using UNSW-NB15 and Bot-IoT Data-Sets},
 volume = {10},
 year = {2022}
}

@article{9658550,
 abstract = {Despite the superior performance in modeling complex patterns to address challenging problems, the black-box nature of Deep Learning (DL) methods impose limitations to their application in real-world critical domains. The lack of a smooth manner for enabling human reasoning about the black-box decisions hinder any preventive action to unexpected events, in which may lead to catastrophic consequences. To tackle the unclearness from black-box models, interpretability became a fundamental requirement in DL-based systems, leveraging trust and knowledge by providing ways to understand the model’s behavior. Although a current hot topic, further advances are still needed to overcome the existing limitations of the current interpretability methods in unsupervised DL-based models for Anomaly Detection (AD). Autoencoders (AE) are the core of unsupervised DL-based for AD applications, achieving best-in-class performance. However, due to their hybrid aspect to obtain the results (by requiring additional calculations out of network), only agnostic interpretable methods can be applied to AE-based AD. These agnostic methods are computationally expensive to process a large number of parameters. In this paper, we present the RXP (Residual eXPlainer), a new interpretability method to deal with the limitations for AE-based AD in large-scale systems. It stands out for its implementation simplicity, low computational cost and deterministic behavior, in which explanations are obtained through the deviation analysis of reconstructed input features. In an experiment using data from a real heavy-haul railway line, the proposed method achieved superior performance compared to SHAP, demonstrating its potential to support decision making in large scale critical systems.},
 author = {Oliveira, David F. N. and Vismari, Lucio F. and Nascimento, Alexandre M. and de Almeida, Jorge R. and Cugnasca, Paulo S. and Camargo, João B. and Almeida, Leandro and Gripp, Rafael and Neves, Marcelo},
 doi = {10.1109/ACCESS.2021.3137633},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Predictive models;Analytical models;Training;Data models;Computational modeling;Anomaly detection;Task analysis;Autoencoder;explainability;fault diagnosis;interpretability;safety},
 month = {},
 number = {},
 pages = {1401-1409},
 title = {A New Interpretable Unsupervised Anomaly Detection Method Based on Residual Explanation},
 volume = {10},
 year = {2022}
}

@article{9661375,
 abstract = {Machine Learning (ML) based Network Intrusion Systems (NIDSs) operate on flow features which are obtained from flow exporting protocols (<i>i.e.,</i> NetFlow). Recent success of ML and Deep Learning (DL) based NIDS solutions assume such flow information (<i>e.g.,</i> avg. packet size) is obtained from all packets of the flow. However, often in practice flow exporter is deployed on commodity devices where packet sampling is inevitable. As a result, applicability of such ML based NIDS solutions in the presence of sampling (<i>i.e.,</i> when flow information is obtained from sampled set of packets instead of full traffic) is an open question. In this study, we explore the impact of packet sampling on the performance and efficiency of ML-based NIDSs. Unlike previous work, our proposed evaluation procedure is immune to different settings of flow export stage. Hence, it can provide a robust evaluation of NIDS even in the presence of sampling. Through sampling experiments we established that malicious flows with shorter size (<i>i.e.,</i> number of packets) are likely to go unnoticed even with mild sampling rates such as 1/10 and 1/100. Next, using the proposed evaluation procedure we investigated the impact of various sampling techniques on NIDS detection rate and false alarm rate. Detection rate and false alarm rate is computed for three sampling rates (<i>i.e.,</i> 1/10, 1/100, 1/1000), for four different sampling techniques and for three (two tree-based, one deep learning based) classifiers. Experimental results show that systematic linear sampler - SketFlow performs better compared to non-linear samplers such as Sketch Guided and Fast Filtered sampling. We also found that random forest classifier with SketchFlow sampling was a better combination. The combination showed higher detection rate and lower false alarm rate across multiple sampling rates compared to other sampler-classifier combinations. Our results are consistent in multiple sampling rates, exceptional case is observed for Sketch Guided Sampling (SGS) as it caused a drastic performance drop when sampling rate was changed from 1/100 to 1/1000. Our results provide valuable insights for network practitioners and researchers regarding on how packet sampling effects ML-based NIDS performance. In this regard full source code for sampling and ML experiments has been released: github.com/Jumabek/sampledFlowMeter and github.com/Jumabek/nids-with-sampling},
 author = {Alikhanov, Jumabek and Jang, Rhongho and Abuhamad, Mohammed and Mohaisen, David and Nyang, Daehun and Noh, Youngtae},
 doi = {10.1109/ACCESS.2021.3137318},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Network intrusion detection;Monitoring;Deep learning;Convolutional neural networks;Computer science;Systematics;Switches;Flow information export;network traffic sampling;intrusion detection;machine learning;deep learning;CNN},
 month = {},
 number = {},
 pages = {5801-5823},
 title = {Investigating the Effect of Traffic Sampling on Machine Learning-Based Network Intrusion Detection Approaches},
 volume = {10},
 year = {2022}
}

@article{9667169,
 abstract = {Reinforcement learning (RL) is a promising approach for intelligent agents to protect a given system under highly hostile environments. RL allows the agent to adaptively make sequential defense decisions based on the perceived current state of system security aiming to achieve the maximum defense performance in terms of fast, efficient, and automated detection, threat analysis, and response to the threat. In this paper, we propose a deep reinforcement learning (DRL)-based adaptive traffic inspection and moving target defense countermeasure framework, called ‘DIVERGENCE,’ for building a secure networked system. The DIVERGENCE provides two main security services: (1) a DRL-based network traffic inspection mechanism to achieve scalable and intensive network traffic visibility for rapid threat detection; and (2) an address shuffling-based moving target defense (MTD) technique to defend against threats as a proactive intrusion prevention mechanism. Through extensive simulations and experiments, we demonstrate that the DIVERGENCE successfully caught malicious traffic flows while significantly reducing the vulnerability of the network through MTD.},
 author = {Kim, Sunghwan and Yoon, Seunghyun and Cho, Jin-Hee and Kim, Dong Seong and Moore, Terrence J. and Free-Nelson, Frederica and Lim, Hyuk},
 doi = {10.1109/TNSM.2021.3139928},
 issn = {1932-4537},
 journal = {IEEE Transactions on Network and Service Management},
 keywords = {Inspection;IP networks;Switches;Resource management;Monitoring;Uncertainty;Control systems;Traffic inspection;moving target defense;deep reinforcement learning;software-defined networking},
 month = {Dec},
 number = {4},
 pages = {4834-4846},
 title = {DIVERGENCE: Deep Reinforcement Learning-Based Adaptive Traffic Inspection and Moving Target Defense Countermeasure Framework},
 volume = {19},
 year = {2022}
}

@article{9667357,
 abstract = {The rapid growth of Internet of Things (IoT) is expected to add billions of IoT devices connected to the Internet. These devices represent a vast attack surface for cyberattacks. For example, these IoT devices can be infected with botnets to enable Distributed Denial of Service (DDoS) attacks. Signature-based intrusion detection systems are traditional countermeasures for such attacks. However, these methods rely on human experts and are time-consuming in terms of updates and may not exhaust all attack types especially zero-day attacks. Deep learning has shown some promise in intrusion detection. This paper shows that it is possible to use generative deep learning methods like Adversarial Autoencoders (AAE) and Bidirectional Generative Adversarial Networks (BiGAN) to detect intruders based on an analysis of the network data. The recently posted full IoT-23 dataset based on Somfy door lock, Philips Hue and Amazon Echo devices was used to train generative deep learning models to detect a variety of attacks like DDoS, and various botnets like Mirai, Okiruk and Torii. Over 1.8 million network flows were used to train the various models. The resulting generative models outperform traditional machine learning techniques like Random Forests. Both AAE and BiGAN-based models were able to achieve an F1-Score of 0.99. A BiGAN to detect unknown attacks was also trained to detect novel zero-day attacks with an F1-Score from 0.85 to 1.},
 author = {Abdalgawad, N. and Sajun, A. and Kaddoura, Y. and Zualkernan, I. A. and Aloul, F.},
 doi = {10.1109/ACCESS.2021.3140015},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Botnet;Computer crime;Internet of Things;Generative adversarial networks;Convolutional neural networks;Intrusion detection;Servers;Adversarial autoencoders;cyber security;generative adversarial networks;Internet of Things;intrusion detection systems},
 month = {},
 number = {},
 pages = {6430-6441},
 title = {Generative Deep Learning to Detect Cyberattacks for the IoT-23 Dataset},
 volume = {10},
 year = {2022}
}

@article{9673755,
 abstract = {The emergence of technological innovations brings sophisticated threats. Cyberattacks are increasing day by day aligned with these innovations and entails rapid solutions for defense mechanisms. These attacks may hinder enterprise operations or more importantly, interrupt critical infrastructure systems, that are essential to safety, security, and well-being of a society. Anomaly detection, as a protection step, is significant for ensuring a system security. Logs, which are accepted sources universally, are utilized in system health monitoring and intrusion detection systems. Recent developments in Natural Language Processing (NLP) studies show that contextual information decreases false-positives yield in detecting anomalous behaviors. Transformers and their adaptations to various language understanding tasks exemplify the enhanced ability to extract this information. Deep network based anomaly detection solutions use generally feature-based transfer learning methods. This type of learning presents a new set of weights for each log type. It is unfeasible and a redundant way considering various log sources. Also, a vague representation of model decisions prevents learning from threat data and improving model capability. In this paper, we propose AnomalyAdapters (AAs) which is an extensible multi-anomaly task detection model. It uses pretrained transformers’ variant to encode a log sequences and utilizes adapters to learn a log structure and anomaly types. Adapter-based approach collects contextual information, eliminates information loss in learning, and learns anomaly detection tasks from different log sources without overuse of parameters. Lastly, our work elucidates the decision making process of the proposed model on different log datasets to emphasize extraction of threat data via explainability experiments.},
 author = {Ünal, Uğur and Dağ, Hasan},
 doi = {10.1109/ACCESS.2022.3141161},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Task analysis;Anomaly detection;Adaptation models;Transformers;Security;Semantics;Monitoring;Anomaly detection;adapters;cyber threat intelligence;explainability;log;transfer learning},
 month = {},
 number = {},
 pages = {5635-5646},
 title = {AnomalyAdapters: Parameter-Efficient Multi-Anomaly Task Detection},
 volume = {10},
 year = {2022}
}

@article{9680704,
 abstract = {Federated learning (FL) has been facilitating privacy-preserving deep learning in many walks of life such as medical image classification, network intrusion detection, and so forth. Whereas it necessitates a central parameter server for model aggregation, which brings about delayed model communication and vulnerability to adversarial attacks. A fully decentralized architecture like Swarm Learning allows peer-to-peer communication among distributed nodes, without the central server. One of the most challenging issues in decentralized deep learning is that data owned by each node are usually non-independent and identically distributed (non-IID), causing time-consuming convergence of model training. To this end, we propose a decentralized learning model called Homogeneous Learning (HL) for tackling non-IID data with a self-attention mechanism. In HL, training performs on each round’s selected node, and the trained model of a node is sent to the next selected node at the end of each round. Notably, for the selection, the self-attention mechanism leverages reinforcement learning to observe a node’s inner state and its surrounding environment’s state, and find out which node should be selected to optimize the training. We evaluate our method with various scenarios for two different image classification tasks. The result suggests that HL can achieve a better performance compared with standalone learning and greatly reduce both the total training rounds by 50.8% and the communication cost by 74.6% for decentralized learning with non-IID data.},
 author = {Sun, Yuwei and Ochiai, Hideya},
 doi = {10.1109/ACCESS.2022.3142899},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Peer-to-peer computing;Training;Data models;Task analysis;Computer architecture;Computational modeling;Servers;Collective intelligence;distributed computing;knowledge transfer;multi-layer neural network;supervised learning},
 month = {},
 number = {},
 pages = {7695-7703},
 title = {Homogeneous Learning: Self-Attention Decentralized Deep Learning},
 volume = {10},
 year = {2022}
}

@article{9684419,
 abstract = {The development of an optimized deep learning intruder detection model that could be executed on IoT devices with limited hardware support has several advantages, such as the reduction of communication energy, lowering latency, and protecting data privacy. Motivated by these benefits, this research aims to design a lightweight autoencoder deep model that has a shallow architecture with a small number of input features and a few hidden neurons. To achieve this objective, an efficient two-layer optimizer is used to evolve a lightweight deep autoencoder model by performing simultaneous selection for the input features, the training instances, and the number of hidden neurons. The optimized deep model is constructed guided by both the accuracy of a K-nearest neighbor (KNN) classifier and the complexity of the autoencoder model. To evaluate the performance of the proposed optimized model, it has been applied for the N-baiot intrusion detection dataset. Reported results showed that the proposed model achieved anomaly detection accuracy of 99% with a lightweight autoencoder model with on average input features around 30 and output hidden neurons of 2 only. In addition, the proposed two-layers optimizer was able to outperform several optimizers such as Arithmetic Optimization Algorithm (AOA), Particle Swarm Optimization (PSO), and Reinforcement Learning-based Memetic Particle Swarm Optimization (RLMPSO).},
 author = {Lahasan, Badr and Samma, Hussein},
 doi = {10.1109/ACCESS.2022.3144208},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Convolutional neural networks;Floods;Deep learning;Data models;Optimization;Botnet;Anomaly detection;Deep learning;autoencoder;IoT;anomaly detection},
 month = {},
 number = {},
 pages = {8434-8448},
 title = {Optimized Deep Autoencoder Model for Internet of Things Intruder Detection},
 volume = {10},
 year = {2022}
}

@article{9687553,
 abstract = {Network Intrusion Detection Systems (NIDSs) using pattern matching have a fatal weakness in that they cannot detect new attacks because they only learn existing patterns and use them to detect those attacks. To solve this problem, a machine learning-based NIDS (ML-NIDS) that detects anomalies through ML algorithms by analyzing behaviors of protocols. However, the ML-NIDS learns the characteristics of attack traffic based on training data, so it, too, is inevitably vulnerable to attacks that have not been learned, just like pattern-matching machine learning. Therefore, in this study, by analyzing the characteristics of learning using representative features, we show that network intrusion outside the scope of the learned data in the feature space can bypass the ML-NIDS. To prevent this, designing the active session to be classified early, before it goes outside the detection range of the training dataset of the ML-NIDS, can effectively prevent bypassing the ML-NIDS. Various experiments confirmed that the proposed method can detect intrusion sessions early (before sessions terminate) significantly improving the robustness of the existing ML-NIDS. The proposed approach can provide more robust and more accurate classification with the same classification datasets compared to existing approaches, so we expect it will be used as one of feasible solutions to overcome weakness and limitation of existing ML-NIDSs.},
 author = {Kim, Taehoon and Pak, Wooguil},
 doi = {10.1109/ACCESS.2022.3145002},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Feature extraction;Robustness;Payloads;Machine learning;Data models;Training data;Network intrusion detection;early classification;robust classification;adversarial attack;machine-learning},
 month = {},
 number = {},
 pages = {10754-10767},
 title = {Robust Network Intrusion Detection System Based on Machine-Learning With Early Classification},
 volume = {10},
 year = {2022}
}

@article{9687591,
 abstract = {With recent advancements in the automotive world and the introduction of autonomous vehicles, automotive security has become a real and important issue. Modern vehicles have tens of Electronic Control Units (ECUs) connected to in-vehicle networks. As a de facto standard for in-vehicle network communication, the Controller Area Network (CAN) has become a target of cyber attacks. Anomaly-based Intrusion Detection System (IDS) is considered as an effective approach to secure CAN and detect malicious attacks. Currently, there are two primary approaches used for intrusion detection: rule-based and machine learning-based. Rule-based approach is efficient but limited in the detection accuracy while machine learning-based detection has comparably higher detection accuracy but higher computation cost at the same time. In this paper, we propose a novel hybrid IDS that combines the benefits of both rule-based and machine learning-based approaches. More specifically, we use machine learning methods to achieve a high detection rate while keeping the low computational requirement by offsetting the detection with a rule-based component. Our experiments with CAN traces collected from four different vehicle models demonstrate the effectiveness and efficiency of the proposed hybrid IDS.},
 author = {Zhang, Linxi and Ma, Di},
 doi = {10.1109/ACCESS.2022.3145007},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Automotive engineering;Entropy;Automobiles;Protocols;Hidden Markov models;Costs;Vehicle safety;Automotive security;in-vehicle network;controller area network (CAN);intrusion detection},
 month = {},
 number = {},
 pages = {10852-10866},
 title = {A Hybrid Approach Toward Efficient and Accurate Intrusion Detection for In-Vehicle Networks},
 volume = {10},
 year = {2022}
}

@article{9698218,
 abstract = {Software-Defined Networking is an innovative architecture approach in the networking field. This technology allows networks to be centrally and intelligently managed by unified applications such as traffic classification and security management. Traditional networks’ static nature has a minimal capacity to meet organisations business requirements. Software-Defined Networks (SDNs) are the emerging architectures that address a range of networking challenges with new solutions. Nevertheless, these centralised and programmable techniques face various challenges and issues that require contemporary security solutions such as Intrusion Detection Systems. Recently, the majority of this type of security solution has been developed using Machine Learning techniques. Deep Learning algorithms have recently been used to provide more accuracy and efficiency. This paper presents a new detection approach based on Convolutional Neural Network (CNN). The experiments proved that the proposed model could be successfully implemented in a Software-Defined Network controller to detect various attacks with 100% accuracy, achieved a low degradation rate of 2.3% throughput and 1.8% latency when executed in a large-scale network.},
 author = {Janabi, Ahmed H. and Kanakis, Triantafyllos and Johnson, Mark},
 doi = {10.1109/ACCESS.2022.3148134},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Real-time systems;Convolutional neural networks;Deep learning;Security;Computer crime;Training;Deep learning-early warning proactive system (DL-EWPS);convolutional neural network (CNN);software-defined networking (SDN);intrusion detection system (IDS);deep learning (DL);RGB image;InSDN dataset},
 month = {},
 number = {},
 pages = {14301-14310},
 title = {Convolutional Neural Network Based Algorithm for Early Warning Proactive System Security in Software Defined Networks},
 volume = {10},
 year = {2022}
}

@article{9712274,
 abstract = {The rapid evolution and growth of the internet through the last decades led to more concern about cyber-attacks that are continuously increasing and changing. As a result, an effective intrusion detection system was required to protect data, and the discovery of artificial intelligence’s sub-fields, machine learning, and deep learning, was one of the most successful ways to address this problem. This paper reviewed intrusion detection systems and discussed what types of learning algorithms machine learning and deep learning are using to protect data from malicious behavior. It discusses recent machine learning and deep learning work with various network implementations, applications, algorithms, learning approaches, and datasets to develop an operational intrusion detection system.},
 author = {Halbouni, Asmaa and Gunawan, Teddy Surya and Habaebi, Mohamed Hadi and Halbouni, Murad and Kartiwi, Mira and Ahmad, Robiah},
 doi = {10.1109/ACCESS.2022.3151248},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Machine learning;Deep learning;Computer security;Machine learning algorithms;Network security;Computer hacking;Cybersecurity;machine learning;deep learning;intrusion detection system},
 month = {},
 number = {},
 pages = {19572-19585},
 title = {Machine Learning and Deep Learning Approaches for CyberSecurity: A Review},
 volume = {10},
 year = {2022}
}

@article{9716094,
 abstract = {Distributed network attacks are referred to, usually, as Distributed Denial of Service (DDoS) attacks. These attacks take advantage of specific limitations that apply to any arrangement asset, such as the framework of the authorized organization’s site. In the existing research study, the author worked on an old KDD dataset. It is necessary to work with the latest dataset to identify the current state of DDoS attacks. This paper, used a machine learning approach for DDoS attack types classification and prediction. For this purpose, used Random Forest and XGBoost classification algorithms. To access the research proposed a complete framework for DDoS attacks prediction. For the proposed work, the UNWS-np-15 dataset was extracted from the GitHub repository and Python was used as a simulator. After applying the machine learning models, we generated a confusion matrix for identification of the model performance. In the first classification, the results showed that both Precision (PR) and Recall (RE) are  $\sim 89$ % for the Random Forest algorithm. The average Accuracy (AC) of our proposed model is ~89% which is superb and enough good. In the second classification, the results showed that both Precision (PR) and Recall (RE) are approximately 90% for the XGBoost algorithm. The average Accuracy (AC) of our suggested model is ~90%. By comparing our work to the existing research works, the accuracy of the defect determination was significantly improved which is approximately 85% and 79%, respectively.},
 author = {Ismail and Mohmand, Muhammad Ismail and Hussain, Hameed and Khan, Ayaz Ali and Ullah, Ubaid and Zakarya, Muhammad and Ahmed, Aftab and Raza, Mushtaq and Rahman, Izaz Ur and Haleem, Muhammad},
 doi = {10.1109/ACCESS.2022.3152577},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Denial-of-service attack;Machine learning algorithms;Random forests;Deep learning;Intrusion detection;Electronic mail;Convolutional neural networks;DDoS attacks;machine learning;random forest;XGBoost;prediction},
 month = {},
 number = {},
 pages = {21443-21454},
 title = {A Machine Learning-Based Classification and Prediction Technique for DDoS Attacks},
 volume = {10},
 year = {2022}
}

@article{9716113,
 abstract = {Phishing has become an increasing concern and captured the attention of end-users as well as security experts. Existing phishing detection techniques still suffer from the deficiency in performance accuracy and inability to detect unknown attacks despite decades of development and improvement. Motivated to solve these problems, many researchers in the cybersecurity domain have shifted their attention to phishing detection that capitalizes on machine learning techniques. Deep learning has emerged as a branch of machine learning that becomes a promising solution for phishing detection in recent years. As a result, this study proposes a taxonomy of deep learning algorithm for phishing detection by examining 81 selected papers using a systematic literature review approach. The paper first introduces the concept of phishing and deep learning in the context of cybersecurity. Then, taxonomies of phishing detection and deep learning algorithm are provided to classify the existing literature into various categories. Next, taking the proposed taxonomy as a baseline, this study comprehensively reviews the state-of-the-art deep learning techniques and analyzes their advantages as well as disadvantages. Subsequently, the paper discusses various issues that deep learning faces in phishing detection and proposes future research directions to overcome these challenges. Finally, an empirical analysis is conducted to evaluate the performance of various deep learning techniques in a practical context, and to highlight the related issues that motivate researchers in their future works. The results obtained from the empirical experiment showed that the common issues among most of the state-of-the-art deep learning algorithms are manual parameter-tuning, long training time, and deficient detection accuracy.},
 author = {Do, Nguyet Quang and Selamat, Ali and Krejcar, Ondrej and Herrera-Viedma, Enrique and Fujita, Hamido},
 doi = {10.1109/ACCESS.2022.3151903},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Phishing;Deep learning;Taxonomy;Feature extraction;Classification algorithms;Manuals;Systematics;Cybersecurity;deep learning;machine learning;phishing detection},
 month = {},
 number = {},
 pages = {36429-36463},
 title = {Deep Learning for Phishing Detection: Taxonomy, Current Challenges and Future Directions},
 volume = {10},
 year = {2022}
}

@article{9718242,
 abstract = {The Internet of Things (IoT) has established itself as a multibillion-dollar business in recent years. Despite its obvious advantages, the widespread nature of IoT renders it insecure and a potential target for cyber-attacks. Furthermore, these devices broad connectivity and dynamic heterogeneous nature can open up a new surface of attack for refined malware attacks. There is a critical need to protect the IoT environment from such attacks and malware. Therefore this research aims to propose an intelligent, SDN-enabled hybrid framework leveraging Cuda Long Short Term Memory Gated Recurrent Unit (cuLSTMGRU) for efficient threat detection in IoT environments. To properly assess the proposed system, a state-of-the-art IoT-based dataset and standard evaluation metrics were used. The proposed model achieved 99.23 % detection accuracy with a low false-positive rate. For further verification, we compare the proposed model results with two of our constructed models (i.e., cuBLSTM and cuGRUDNN) and current benchmark algorithms. The proposed model outclassed the other models regarding speed efficiency, detection accuracy, precision, and other standard evaluation metrics. Finally, the proposed work employed 10-fold cross-validation to ensure that the results were completely unbiased.},
 author = {Muthanna, Mohammed Saleh Ali and Alkanhel, Reem and Muthanna, Ammar and Rafiq, Ahsan and Abdullah, Wadhah Ahmed Muthanna},
 doi = {10.1109/ACCESS.2022.3153716},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Security;Internet of Things;Support vector machines;Protocols;Malware;Intrusion detection;Deep learning;Deep learning;network security;intrusion detection;software-defined network;IoT},
 month = {},
 number = {},
 pages = {22756-22768},
 title = {Towards SDN-Enabled, Intelligent Intrusion Detection System for Internet of Things (IoT)},
 volume = {10},
 year = {2022}
}

@article{9726814,
 abstract = {Advances in communication technologies and artificial intelligence are accelerating the paradigm of industrial Internet of Things (IIoT). With IIoT enabling continuous integration of sensors and controllers with the network, intelligent analysis of the generated Big Data is a critical requirement. Although IIoT is considered a subset of IoT, it has its own peculiarities in terms of higher levels of safety, security, and low-latency communication in an environment of critical real-time operations. Under these circumstances, discriminative deep learning (DL) algorithms are unsuitable due to their need for large amounts of labeled and balanced training data, uncertainty of inputs, etc. To overcome these issues, researchers have started using deep generative models (DGMs), which combine the flexibility of DL with the inference power of probabilistic modeling. In this article, we review the state of the art of DGMs and their applicability to IIoT, classifying the reviewed works into the IIoT application areas of anomaly detection, trust-boundary protection, network traffic prediction, and platform monitoring. Following an analysis of existing IIoT DGM implementations, we identify challenges (i.e., weak discriminative capability, insufficient interpretability, lack of generalization ability, generated data vulnerability, privacy concern, and data complexity) that need to be investigated in order to accelerate the adoption of DGMs in IIoT and also propose some potential research directions.},
 author = {De, Suparna and Bermudez-Edo, Maria and Xu, Honghui and Cai, Zhipeng},
 doi = {10.1109/TII.2022.3155656},
 issn = {1941-0050},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Industrial Internet of Things;Data models;Deep learning;Security;Hidden Markov models;Predictive models;Informatics;Deep generative model (DGM);generative adversarial networks (GANs);industrial Internet of Things (IIoT);survey},
 month = {Sep.},
 number = {9},
 pages = {5728-5737},
 title = {Deep Generative Models in the Industrial Internet of Things: A Survey},
 volume = {18},
 year = {2022}
}

@article{9734035,
 abstract = {As time series data with internal correlation, networks traffic data can be used for abnormal detection using Recurrent Neural Network (RNN) and its variants, but existing models are difficult to calculate in parallel, and gradient explosion or vanishing easily occurs. To address this problem, we propose a Bidirectional Independent Recurrent Neural Network (BiIndRNN) with parallel computation and adjustable gradient, which can extract the bidirectional structural features of networks traffic by forward and backward input and capture the spatial influence in the data flow. To establish the dependencies on the forward and backward moments of networks traffic, a model combining Global Attention (GA) with BiIndRNN is proposed to pay more attention to the moments containing essential information. Taking the UNSW-NB15 dataset as the object, the GA expression of the packets feature vector of the networks is derived, feature fusion, as well as loss calculation, is performed for multiple fully connected layers. The experimental results show that, compared with traditional deep and shallow machine learning and other state-of-the-art technologies, our GA-BiIndRNN model converges faster, the accuracy, precision, and F1 scores are all above 99%, and the false positive rate (FPR) is close to 0.36%, which can effectively identify normal and malicious network activities. These results provide a theoretical basis for the rapid implementation of protective measures.},
 author = {Li, Huang and Ge, Hongjuan and Yang, Haoqi and Yan, Jie and Sang, Yiqin},
 doi = {10.1109/ACCESS.2022.3159550},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Telecommunication traffic;Atmospheric modeling;Anomaly detection;Recurrent neural networks;Feature extraction;Computational modeling;Time series analysis;Networks;abnormal traffic detection;bidirectional independent recurrent neural network;global attention;time series data},
 month = {},
 number = {},
 pages = {30899-30912},
 title = {An Abnormal Traffic Detection Model Combined BiIndRNN With Global Attention},
 volume = {10},
 year = {2022}
}

@article{9745910,
 abstract = {The rise of interconnected devices through wireless networks provides two sides consequences. On one side, it helps many human tasks; on the other hand, the prone wireless medium opens the vulnerable system to be exploited by adversaries. An Intrusion Detection System (IDS) is one method to inspect the network traffic by leveraging state-of-the-art anomaly detection techniques. Deep learning models have been utilized to distinguish the benign and malicious traffic. However, projecting the tabular data into images before the image classification has been the main challenge of leveraging deep learning for IDS purposes. We propose the novel projection of tabular data into 2-coded color mapping for IDS purposes. The proposed method employs a feature selection method to ensure optimal dimensionality. We examined the different number of attribute subsets to obtain the relationship between the attributes. Furthermore, it takes advantage of the Convolutional Neural Network (CNN) model to classify the Wi-Fi attacks. We evaluate the proposed model using the most common Wi-Fi attacks dataset, Aegean Wi-Fi Intrusion Dataset (AWID2). The proposed method achieved an F1 score of 99.73% and a false positive rate of 0.24%. This study highlights the importance of addressing the mapping procedures from tabular data into grid-based data before deep learning training and validates the effectiveness of CNN to detect multiple types of wireless network attacks.},
 author = {Aminanto, Muhamad Erza and Wicaksono, R. Satrio Hariomurti and Aminanto, Achmad Eriza and Tanuwidjaja, Harry Chandra and Yola, Lin and Kim, Kwangjo},
 doi = {10.1109/ACCESS.2022.3164104},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Residual neural networks;Deep learning;Convolutional neural networks;Wireless networks;Wireless fidelity;Feature extraction;Image color analysis;Wireless attacks;intrusion detection system;convolutional neural network;anomaly detection},
 month = {},
 number = {},
 pages = {36791-36801},
 title = {Multi-Class Intrusion Detection Using Two-Channel Color Mapping in IEEE 802.11 Wireless Network},
 volume = {10},
 year = {2022}
}

@article{9748125,
 abstract = {The advanced development of computer networks and communication technologies has made covert communications easier to construct, faster, undetectable and more secure than ever. A covert channel is a path through which secret messages can be leaked by violating a system security policy. The detection of such dangerous, unwatchable, and hidden threats is still one of the most challenging aspects. This threat exploits methods that are not dedicated to communication purposes, meaning that traditional security measures fail to detect its existence. This review has introduced a brief introduction of covert channel definitions, types and developments, with a particular focus on detection techniques using machine learning (ML) approaches. It provides a thorough review of the most common covert channels and ML techniques that are used to counter them, as well as addressing their achievements and limitations. In addition, this paper introduces a comparative experimental study for some common ML approaches that are commonly used in this field. Accordingly, the performance of these classifiers was evaluated and reported. The paper concludes that our information is still at risk, nothing is said to be secured and more work on the detection of covert channels is required.},
 author = {Elsadig, Muawia A. and Gafar, Ahmed},
 doi = {10.1109/ACCESS.2022.3164392},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Protocols;Timing;Internet of Things;Security;Switches;Robustness;Receivers;Classification algorithms;covert channel detection;machine learning;covert traffic;covert storage channel;cover timing channel;deep learning;network traffic;network covert channels;overt traffic},
 month = {},
 number = {},
 pages = {38391-38405},
 title = {Covert Channel Detection: Machine Learning Approaches},
 volume = {10},
 year = {2022}
}

@article{9751703,
 abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
 author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
 doi = {10.1109/ACCESS.2022.3165809},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Industrial Internet of Things;Sensors;Temperature sensors;Computer crime;Security;Protocols;Computer security;Cybersecurity applications;IoT datasets;deep learning;federated learning;edge {computing}},
 month = {},
 number = {},
 pages = {40281-40306},
 title = {Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning},
 volume = {10},
 year = {2022}
}

@article{9758805,
 abstract = {Machine learning (ML) algorithms that are used in decision support (DS) and autonomous systems commonly train on labeled categorical samples from a closed set. This, however, poses a problem for deployed DS and autonomous systems when they encounter an anomalous pattern that did not originate from the closed set distribution used for training. In this case, the ML algorithm that was trained only on closed set samples may erroneously identify an anomalous pattern as having originated from one of the categories in the closed set, sometimes with very high confidence. In this paper, we consider the problem of unknown pattern recognition from a generative perspective in which additional synthetic training samples that represent anomalies are added to the training data. These synthetic samples are generated to optimally balance the desire to place anomalies all along the boundary of the training set in feature space, while not adversely effecting core classification performance on the test set. We demonstrate the efficacy of distance-based probabilistic anomaly augmentation (DPAA) that is proposed in this paper for a diverse set of applications such as character recognition and intrusion detection, and compare its combined classification and identification performance to both recent open set and more traditional novelty detection approaches.},
 author = {Goodman, Joel and Sarkani, Shahram and Mazzuchi, Thomas},
 doi = {10.1109/ACCESS.2022.3168003},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training;Anomaly detection;Generative adversarial networks;Deep learning;Weibull distribution;Probabilistic logic;Image reconstruction;Machine learning;outlier and novelty detection;open set recognition;anomalies;generative and discriminative architectures},
 month = {},
 number = {},
 pages = {42232-42242},
 title = {A Generative Approach to Open Set Recognition Using Distance-Based Probabilistic Anomaly Augmentation},
 volume = {10},
 year = {2022}
}

@article{9766348,
 abstract = {Internet of Things (IoT) is an instantly exacerbated communication technology that is manifesting miraculous effectuation to revolutionize conventional means of network communication. The applications of IoT are compendiously encompassing our prevalent lifestyle and the integration of IoT with other technologies makes this application spectrum even more latitudinous. However, this admissibility also introduces IoT with a pervasive array of imperative security hazards that demands noteworthy solutions to be swamped. In this scientific study, we proposed Deep Learning (DL) driven Software Defined Networking (SDN) enabled Intrusion Detection System (IDS) to combat emerging cyber threats in IoT. Our proposed model (DNNLSTM) is capable to encounter a tremendous class of common as well as less frequently occurring cyber threats in IoT communications. The proposed model is trained on CICIDS 2018 dataset, and its performance is evaluated on several decisive parameters i.e Accuracy, Precision, Recall, and F1-Score. Furthermore, the designed framework is analytically compared with relevant classifiers, i.e., DNNGRU, and BLSTM for appropriate validation. An exhaustive performance comparison is also conducted between the proposed system and a few preeminent solutions from the literature. The proposed design has circumvented the existing literature with unprecedented performance repercussions such as 99.55% accuracy, 99.36% precision, 99.44% recall, and 99.42% F1-score.},
 author = {Razib, Mohammad Al and Javeed, Danish and Khan, Muhammad Taimoor and Alkanhel, Reem and Muthanna, Mohammed Saleh Ali},
 doi = {10.1109/ACCESS.2022.3172304},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Intrusion detection;Feature extraction;Software defined networking;Convolutional neural networks;Deep learning (DL);Internet of Things (IoT);intrusion detection system (IDS);distributed denial of service (DDoS);software-defined networking (SDN)},
 month = {},
 number = {},
 pages = {53015-53026},
 title = {Cyber Threats Detection in Smart Environments Using SDN-Enabled DNN-LSTM Hybrid Framework},
 volume = {10},
 year = {2022}
}

@article{9767819,
 abstract = {Cybersecurity incidents have become a growing problem for the healthcare industry since the widespread introduction of technology into the healthcare systems. In recent years, the number of attacks has increased rapidly in healthcare, and it is now among the sectors most targeted by cyberattacks globally. These types of attacks are not only a threat to the data and finances of medical organizations, but they can also disrupt hospital operations and endanger the health and well-being of patients. Traditional security measures are not sufficient to protect the healthcare IT (Information Technology) environment due to its complexity and the heterogeneity of its medical devices. In this paper, we propose a new intrusion and malware detection system to secure the entire network of the healthcare system. The proposed solution includes two components: an intrusion detection system for medical devices installed in the healthcare network, and a malware detection system for data servers and medical staff computers. The objective is to secure the entire network independently of the installed devices and computers. The proposed system is based on an optimized LightGBM model and a Tranformer-based model. It is trained with four different datasets to guarantee a varied knowledge of the different types of attacks that can affect the healthcare sector. The used datasets have been generated from different environments undergoing IoT (Internet of Things), IoMT (Internet of Medical Things) and Windows malware attacks. The experimental evaluation of the approach showed remarkable accuracies of 99%.},
 author = {Ghourabi, Abdallah},
 doi = {10.1109/ACCESS.2022.3172432},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Medical services;Medical devices;Protocols;Intrusion detection;Hospitals;Machine learning algorithms;Transformers;Healthcare security;intrusion detection;malware detection;LightGBM;transformer},
 month = {},
 number = {},
 pages = {48890-48903},
 title = {A Security Model Based on LightGBM and Transformer to Protect Healthcare Systems From Cyberattacks},
 volume = {10},
 year = {2022}
}

@article{9772749,
 abstract = {As modern programs grow in size and complexity, the importance of program behavior modeling is emerging in various areas. Because of the large amount of data generated by a target program and the difficulty of runtime analysis, previous works in these areas employ deep learning. However, they did not sufficiently consider the input of a target program, since, in our view, program behavior is a history of computational steps consisting of a function and its input arguments. A naive, intuitive way to embed the value of $x$ as it is in a vector representation creates a tremendously large vector size. Instead, we found that all the values inducing the same runtime behavior can be represented as one identical characteristic value (CV). In this paper, we show that not only can a characteristic value sequence replace the argument input, but it is also efficient to use it as an input vector for a neural network. This efficiency comes from modeling the whole program with multiple LSTM-RNN models and reducing the input space of the neural network. To demonstrate the effectiveness of this replacement, we performed experiments on the problem of program behavior anomaly detection. Our results show that our model achieves better detection performance compared to previous models and similar detection performance even with smaller model sizes. We also provide a visualization of the embedded vectors extracted from the embedding layer in the neural network model to prove that the CV sequence well represents the arguments.},
 author = {Ahn, Sunwoo and Yi, Hayoon and Bae, Ho and Yoon, Sungroh and Paek, Yunheung},
 doi = {10.1109/TETCI.2022.3146425},
 issn = {2471-285X},
 journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
 keywords = {Data models;Runtime;Computational modeling;Analytical models;Neural networks;Codes;Adaptation models;Artificial neural network;deep learning;feature embedding;natural language processing;program behavior modeling},
 month = {Aug},
 number = {4},
 pages = {982-993},
 title = {Data Embedding Scheme for Efficient Program Behavior Modeling With Neural Networks},
 volume = {6},
 year = {2022}
}

@article{9773166,
 abstract = {The growth of the Internet of Things (IoT) generates new processing, networking infrastructure, data storage, and management capabilities. This massive volume of data may be used to provide high-value information for decision support and data-intensive science research, etc. However, owing to the nature of IoT in distribution, virtualisation, cloud integration, and internet connectivity, the IoT environment is prone to various cyber-attacks and security issues. Hence, the increasing frequency and potency of recent attacks and constantly evolving attack vectors necessitate the development of improved detection methods. Therefore, this study proposes a distributed computing-based security model to safeguard big data systems. The proposed ensemble multi binary attack model (EMBAM) is an intrusion detection system (IDS) that offers a unique anomaly based IDS to detect normal behaviour and abnormal attack(s), for example, threats in a network. EMBAM ensembles multiple binary classifiers into a single model through stacking. The core binary model is a decision tree classifier with hyperparameters optimised using the grid search method. The use of multiple binary classifiers allows each binary classifier to adopt the limitations of the others. Empirical analysis of the experimental profile of the EMBAM has been discussed with eight-plus state-of-the-art methods using performance metrics, such as accuracy, detection rate, precision, specificity, false alarm rate, and F1-score. EMBAM can recognise multiple attack types as a star plug and play advantageous in a highly dynamic scheme. The proposed approach outperforms existing approaches on the UNSW-NB15 dataset and yields competitive results on the CICIDS2017 dataset.},
 author = {Alhabshy, Abdallah A. and Hameed, Bashar I. and Eldahshan, Kamal Abdelraouf},
 doi = {10.1109/ACCESS.2022.3174482},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Big Data;Intrusion detection;Feature extraction;Classification algorithms;Telecommunication traffic;Distributed databases;Computer architecture;Anomaly-based IDS;ensemble learning;intrusion detection system;machine learning},
 month = {},
 number = {},
 pages = {52724-52743},
 title = {An Ameliorated Multiattack Network Anomaly Detection in Distributed Big Data System-Based Enhanced Stacking Multiple Binary Classifiers},
 volume = {10},
 year = {2022}
}

@article{9775989,
 abstract = {The work develops a network threat detection system, AI@NTDS, that uses the behavioral features of attackers and intelligent techniques. The proposed AI@NTDS system combines data analysis, feature extraction, and feature evaluation to construct a detection model, which supports a more straightforward strategy by which the operating system or its operators can defend against network attacks. The Linux system interaction information of SSH (Secure Shell) and Telnet are obtained from the Cowrie Honeypot and labeled according to Enterprise Tactics of MITRE ATT&CK to ensure dataset credibility. The proposed AI@NTDS system has three levels, depending on the attacker’s attacks and the user’s risk of damage. Fifty-two features are used to detect the network threat level. The features contain message-based features for all kinds of Linux operating instructions, host-based features for all types of information in the network connection process, and geography-based features are related to the attacker’s location. AI-based algorithms LightGBM, Random Forest and the K-NN algorithm are used to verify the identification of the custom features. Finally, the detection model that is trained using the best combination of features is used to predict the test dataset. The accuracy of the proposed AI@NTDS system reaches 99%, 95.66%, and 94.08% with the LightGBM, Random Forest, and K-NN algorithms, respectively. The mutual dependencies of features and network threats are evaluated. Results of a performance analysis reveal that the proposed AI@NTDS system has an accuracy of 99.20% and an F1-score of 99.80%. It is superior to existing detection mechanisms, which it outperforms by 4% and 1% in accuracy and F1-score, respectively.},
 author = {Wang, Bo-Xiang and Chen, Jiann-Liang and Yu, Chiao-Lin},
 doi = {10.1109/ACCESS.2022.3175886},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Internet of Things;Behavioral sciences;Botnet;Linux;Training;Servers;Honeypot;intent analysis;machine learning;remote shell access;threat detection},
 month = {},
 number = {},
 pages = {54029-54037},
 title = {An AI-Powered Network Threat Detection System},
 volume = {10},
 year = {2022}
}

@article{9777970,
 abstract = {Cybersecurity is important today because of the increasing growth of the Internet of Things (IoT), which has resulted in a variety of attacks on computer systems and networks. Cyber security has become an increasingly difficult issue to manage as various IoT devices and services grow. Malicious traffic identification using deep learning techniques has emerged as a key component of network intrusion detection systems (IDS). Deep learning methods have been a research focus in network intrusion detection. A Recurrent Neural Network (RNN) is useful in a wide range of applications. First, this paper proposes a novel deep learning model for anomaly detection in IoT networks using a recurrent neural network. Long Short Term Memory (LSTM), BiLSTM, and Gated Recurrent Unit (GRU) techniques are used to implement the proposed model for anomaly detection in IoT networks. A Convolutional Neural Network (CNN) can analyze input features without losing important information, making them particularly well suited for feature learning. Next, a hybrid deep learning model was proposed using convolutional and recurrent neural networks. Finally, a lightweight deep learning model for binary classification was proposed using LSTM, BiLSTM, and GRU based approaches. The proposed deep learning models are validated using NSLKDD, BoT-IoT, IoT-NI, IoT-23, MQTT, MQTTset, and IoT-DS2 datasets. Compared to current deep learning implementations, the proposed multiclass and binary classification model achieved high accuracy, precision, recall, and F1 score.},
 author = {Ullah, Imtiaz and Mahmoud, Qusay H.},
 doi = {10.1109/ACCESS.2022.3176317},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Deep learning;Intrusion detection;Computational modeling;Recurrent neural networks;Telecommunication traffic;Internet of Things;anomaly detection;recurrent neural network;convolutional neural network;LSTM;BiLSTM;GRU},
 month = {},
 number = {},
 pages = {62722-62750},
 title = {Design and Development of RNN Anomaly Detection Model for IoT Networks},
 volume = {10},
 year = {2022}
}

@article{9780135,
 abstract = {Traffic detection has attracted much attention in recent years, playing an essential role in intrusion detection systems (IDS). This paper proposes a new approach for traffic detection at the packet level, inspired by natural language processing (NLP), using simple contrastive learning of sentence embeddings (SimCSE) as an embedding model. The new approach can learn the features of traffic from raw packet data. Experiments were conducted on two well-known datasets to evaluate our approach. For detecting malicious activity, our model achieved an accuracy of 99.99% on the USTC-TFC2016 dataset, whereas for detecting virtual private network (VPN) activity, our model achieved an accuracy of 99.98% on the ISCXVPN2016 dataset. Furthermore, the resulting model was found to be robust based on zero-day attack detection, which shows the model’s ability to detect attacks that have not been seen before. Experiments show that our approach can effectively detect network traffic and outperforms many other state-of-the-art methods.},
 author = {Bar, Rotem and Hajaj, Chen},
 doi = {10.1109/ACCESS.2022.3177272},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Convolutional neural networks;Virtual private networks;Telecommunication traffic;Neural networks;Integrated circuits;Deep learning;Network traffic;SimCSE;packet capture;Word2vec;cyber security},
 month = {},
 number = {},
 pages = {56952-56960},
 title = {SimCSE for Encrypted Traffic Detection and Zero-Day Attack Detection},
 volume = {10},
 year = {2022}
}

@article{9785622,
 abstract = {As the Internet of Things (IoT) technology advances, billions of multidisciplinary smart devices act in concert, rarely requiring human intervention, posing significant challenges in supporting trusted computing and user privacy, as well as protecting against attacks such as spoofing, denial of service (DoS), jamming, and eavesdropping. To tackle attacks on the IoT and cyber-physical ecosystem, many intrusion detection and security approaches have been presented in the literature. Machine learning (ML) based intrusion and anomaly detection has lately gained traction due to its capacity to cope with encrypted and rapidly developing threat techniques. This work investigates into machine learning (ML) and deep learning (DL) methodologies for IoT device security and examine the benefits, drawbacks, and potential. To protect an IoT infrastructure, various solutions look into hardware-based methods for ML-based IoT authentication, access control, secure offloading, and malware detection schemes. This review aims to illuminate the value of various approaches for addressing IoT security in a truly effective, flexible, and seamless manner, as well as to provide answers to questions about tradeoffs in integrating accelerators and customizing embedded device architectures for effective use of ML-based methods.},
 author = {Kornaros, Georgios},
 doi = {10.1109/ACCESS.2022.3179047},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Machine learning;Hardware;Malware;Microprogramming;Cryptography;AI-based IoT security;hardware-based machine learning;IoT intrusion detection;trusted embedded devices},
 month = {},
 number = {},
 pages = {58603-58622},
 title = {Hardware-Assisted Machine Learning in Resource-Constrained IoT Environments for Security: Review and Future Prospective},
 volume = {10},
 year = {2022}
}

@article{9786787,
 abstract = {Anomaly detection in smart environments is important when dealing with rare events, which can be safety-critical to individuals or infrastructure. Safety-critical means in this case, that these events can be a threat to the safety of individuals (e.g. a person falling to the ground) or to the security of infrastructure (e.g. unauthorized access to protected facilities). However, recognizing abnormal events in smart environments is challenging, because of the complex and volatile nature of the data recorded by monitoring sensors. Methodologies proposed in the literature are frequently domain-specific and are subject to biased assumptions about the underlying data. In this work, we propose the adaption of a deep reinforcement learning algorithm, namely double deep q-learning (DDQN), for anomaly detection in smart environments. Our proposed anomaly detector directly learns a decision-making function, which can classify rare events based on multivariate sequential time series data. With an emphasis on improving the performance in rare event classification tasks, we extended the algorithm with a prioritized experience replay (PER) strategy, and showed that the PER extension yields an increase in detection performance. The adaption of the improved version of the DDQN reinforcement learning algorithm for anomaly detection in smart environments is the major contribution of this work. Empirical studies on publicly available real-world datasets demonstrate the effectiveness of our proposed solution. Here specifically, we use a dataset for fall and for occupancy detection to evaluate the solution proposed in this work. Our solution yields comparable detection performance to previous work, and has the additional advantages of being adaptable to different environments and capable of online learning.},
 author = {Fährmann, Daniel and Jorek, Nils and Damer, Naser and Kirchbuchner, Florian and Kuijper, Arjan},
 doi = {10.1109/ACCESS.2022.3179720},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Detectors;Task analysis;Q-learning;Intelligent sensors;Monitoring;Time series analysis;Anomaly detection;human activity recognition;machine learning;pattern recognition;safety},
 month = {},
 number = {},
 pages = {60836-60848},
 title = {Double Deep Q-Learning With Prioritized Experience Replay for Anomaly Detection in Smart Environments},
 volume = {10},
 year = {2022}
}

@article{9788529,
 abstract = {Manufacturers are willing to incorporate Machine Learning (ML) algorithms into their systems, especially those considered as Safety-Critical Systems (SCS). ML algorithms that perform binary classification (i.e., Binary Classifiers (BCs)) find a wide applicability as error, intrusion or failure detectors, provided that their performance complies with SCS safety requirements. However, the performance analysis of BCs relies on metrics that were not developed with safety in mind and consequently may not provide meaningful evidence to decide whether to incorporate a BC into a SCS. In this paper, we empirically assess the properness of such incorporation by analyzing the distribution of misclassifications of BCs instead of simply counting misclassifications. This allows us to better assess the adequacy of a given BC by identifying areas of the classification space where the BC is likely to misclassify and therefore constitutes actionable information to deal with the SCS. Our assessment takes a deeper view of the classification performance concerning safety by using new metrics that consider the proportions of predictions that are/are not considered sufficiently safe to be used by incorporating SCS. The results of our experiment allow discussing the potential of such distribution analysis for deciding if a BC can be incorporated into a SCS.},
 author = {Gharib, Mohamad and Zoppi, Tommaso and Bondavalli, Andrea},
 doi = {10.1109/TETC.2022.3178631},
 issn = {2168-6750},
 journal = {IEEE Transactions on Emerging Topics in Computing},
 keywords = {Safety;Measurement;Machine learning algorithms;Behavioral sciences;Computer hacking;Security;Machine learning;Machine learning;performance metrics;safety measures;safety-critical systems},
 month = {Oct},
 number = {4},
 pages = {1671-1686},
 title = {On the Properness of Incorporating Binary Classification Machine Learning Algorithms Into Safety-Critical Systems},
 volume = {10},
 year = {2022}
}

@article{9791234,
 abstract = {Ransomware is one of the most harmful types of cyber attacks that cause major concerns on a global scale. It makes the victims’ resources unusable by encrypting data or locking systems to extort ransom payments. Ransomware has variant families that continue to evolve. Moreover. cybercriminals use advanced techniques to develop ransomware, making it harder for anti-malware detection systems to detect them. Ransomware solutions need the capabilities of timely and effective detection and response to discover uncommon behavior before losing sensitive data. Cyber threat hunting (CTH) is a novel proactive malware detection approach that includes cyber threat intelligence (CTI) methods and data analysis methods. However, most present CTH solutions depend on internal data sources and reactive techniques to detect unusual activities. An effective CTI technique is required to obtain knowledge from external data sources and combine it with internal sources to enhance the hunting capabilities. Then, using the optimal data analysis technique is needed for the CTH approach to obtain valuable insights into abnormal patterns in running activities in the early stages. In this study, we investigate using a practical CTI approach and different CTH models. Subsequently, we discussed ransomware research directions to detect known and unknown ransomware attacks. Also, we discussed the available ransomware datasets used in present ransomware studies.},
 author = {Aldauiji, Fatimah and Batarfi, Omar and Bayousef, Manal},
 doi = {10.1109/ACCESS.2022.3181278},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Ransomware;Cryptography;Behavioral sciences;Internet of Things;Encryption;Support vector machines;Soft sensors;Ransomware;cyber threat hunting;cyber threat intelligence;malware analysis;machine learning;deep learning},
 month = {},
 number = {},
 pages = {61695-61706},
 title = {Utilizing Cyber Threat Hunting Techniques to Find Ransomware Attacks: A Survey of the State of the Art},
 volume = {10},
 year = {2022}
}

@article{9791420,
 abstract = {Traffic classification is considered an important research area due to the increasing demand in network users. It not only effectively improve the network service identifications and security issues of the traffic network, but also provide robust accuracy and efficiency in different Internet application behaviors and patterns. Several traffic classification techniques have been proposed and applied successfully in recent years. However, the existing literature lack of comprehensive survey which could provide an overview and analysis towards the recent developments in network traffic classification. To this end, this survey presents a comprehensive investigation on traffic classification techniques by carefully reviewing existing methods from a new perspective. We comprehensively discuss the procedures and datasets for traffic classification. Additionally, traffic criteria are proposed, which could be beneficial to assess the effectiveness of the developed classification algorithm. Then, the traffic classification techniques are discussed in detail. Then, we thoroughly discussed the machine learning (ML) methods for traffic classification. For researcher’s convenience, we present the traffic obfuscation techniques, which could be helpful for designing a better classifier. Finally, key findings and open research challenges for network traffic classification are identified along with recommendations for future research directions. In sum, this survey fills the gap of existing surveys and summarizes the latest research developments in traffic classification.},
 author = {Sheikh, Muhammad Sameer and Peng, Yinqiao},
 doi = {10.1109/ACCESS.2022.3181135},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Feature extraction;Intrusion detection;Telecommunication traffic;Internet;Peer-to-peer computing;Payloads;Classification criteria;machine learning method;obfuscation;security;traffic classification},
 month = {},
 number = {},
 pages = {61135-61158},
 title = {Procedures, Criteria, and Machine Learning Techniques for Network Traffic Classification: A Survey},
 volume = {10},
 year = {2022}
}

@article{9794665,
 abstract = {Due to the rapid growth in network traffic and increasing security threats, Intrusion Detection Systems (IDS) have become increasingly critical in the field of cyber security for providing secure communications against cyber adversaries. However, there exist many challenges for designing a robust, efficient and accurate IDS, especially when dealing with high-dimensional anomaly data with unforeseen and unpredictable attacks. In this paper, we propose a Robust Transformer-based Intrusion Detection System (RTIDS) reconstructing feature representations to make a trade-off between dimensionality reduction and feature retention in imbalanced datasets. The proposed method utilizes positional embedding technique to associate sequential information between features, then a variant stacked encoder-decoder neural network is used to learn low-dimensional feature representations from high-dimensional raw data. Furthermore, we apply self-attention mechanism to facilitate network traffic type classifications. Extensive experiments reveal the effectiveness of the proposed RTIDS on two publicly available real traffic intrusion detection datasets named CICIDS2017 and CIC-DDoS2019 with F1-Score of 99.17% and 98.48% respectively. A comparative study with classical machine learning algorithm support vector machine (SVM) and deep learning algorithms that include recurrent neural network (RNN), fuzzy neural network (FNN), and long short-term memory network (LSTM) is conducted to demonstrate the validity of the proposed method.},
 author = {Wu, Zihan and Zhang, Hong and Wang, Penghai and Sun, Zhibo},
 doi = {10.1109/ACCESS.2022.3182333},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Transformers;Feature extraction;Hidden Markov models;Decoding;Data models;Telecommunication traffic;Intrusion detection;feature representation;self-attention mechanism;transformer},
 month = {},
 number = {},
 pages = {64375-64387},
 title = {RTIDS: A Robust Transformer-Based Approach for Intrusion Detection System},
 volume = {10},
 year = {2022}
}

@article{9796521,
 abstract = {Nowadays, computer networks and the Internet are unprotected from many security threats. Introducing adaptive and flexible security-related techniques is challenging because of the new types of frequently occurring attacks. An intrusion detection system (IDS) is a security device similar to other measures, including firewalls, antivirus software, and access control models devised to strengthen communication and information security. Network intrusion detection system (NIDS) plays a vital function in defending computer networks and systems. However, several issues concerning the sustainability and feasibility of existing techniques are faced with recent networks. These concerns are directly related to the rising levels of necessary human interactions and reducing the level of detection accuracy. Several approaches are designed to detect and manage various security threats in a network. This study uses Chimp Chicken Swarm Optimization-based Deep Long Short-Term Memory (ChCSO-driven Deep LSTM) for the intrusion detection process. A CNN feature extraction process is necessary for effective intrusion detection. Here, the Deep LSTM is applied for detecting network intrusion, and the Deep LSTM is trained using a designed optimization technique to enhance the detection performance.},
 author = {Deore, Bhushan and Bhosale, Surendra},
 doi = {10.1109/ACCESS.2022.3183213},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Network intrusion detection;Deep learning;Computational modeling;Training;Security;Optimization;Intrusion detection;deep long short-term memory;chimp optimization algorithm;chicken swarm optimization algorithm;convolutional neural network features},
 month = {},
 number = {},
 pages = {65611-65622},
 title = {Hybrid Optimization Enabled Robust CNN-LSTM Technique for Network Intrusion Detection},
 volume = {10},
 year = {2022}
}

@article{9797689,
 abstract = {Wi-Fi is arguably the most proliferated wireless technology today. Due to its massive adoption, Wi-Fi deployments always remain in the epicenter of attackers and evildoers. Surprisingly, research regarding machine learning driven intrusion detection systems (IDS) that are specifically optimized to detect Wi-Fi attacks is lagging behind. On top of that, the field is dominated by false or half-true assumptions that potentially can lead to corresponding models being overfilled to certain validation datasets, simply giving the impression or illusion of high efficiency. This work attempts to provide concrete answers to the following key questions regarding IEEE 802.11 machine learning driven IDS. First, from an expert’s viewpoint and with reference to the relevant literature, what are the criteria for determining the smallest possible set of classification features, which are also common and potentially transferable to virtually any deployment types/versions of 802.11? And second, based on these features, what is the detection performance across different network versions and diverse machine learning techniques, i.e., shallow versus deep learning ones? To answer these questions, we rely on the renowned 802.11 security-oriented AWID family of datasets. In a nutshell, our experiments demonstrate that with a rather small set of 16 features and without the use of any optimization or ensemble method, shallow and deep learning classification can achieve an average F1 score of up to 99.55% and 97.55%, respectively. We argue that the suggested human expert driven feature selection leads to lightweight, deployment-agnostic detection systems, and therefore can be used as a basis for future work in this interesting and rapidly evolving field.},
 author = {Chatzoglou, Efstratios and Kambourakis, Georgios and Kolias, Constantinos and Smiliotopoulos, Christos},
 doi = {10.1109/ACCESS.2022.3183597},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;IEEE 802.11 Standard;Training;Wireless fidelity;Deep learning;Intrusion detection;Correlation;Intrusion detection;WiFi;80211;machine learning;deep learning;dataset;AWID},
 month = {},
 number = {},
 pages = {64761-64784},
 title = {Pick Quality Over Quantity: Expert Feature Selection and Data Preprocessing for 802.11 Intrusion Detection Systems},
 volume = {10},
 year = {2022}
}

@article{9805462,
 abstract = {The progression of Software Defined Networking (SDN) and the virtualisation technologies lead to the beyond 5G era, providing multiple benefits in the smart economies. However, despite the advantages, security issues still remain. In particular, SDN/NFV and cloud/edge computing are related to various security issues. Moreover, due to the wireless nature of the entities, they are prone to a wide range of cyberthreats. Therefore, the presence of appropriate intrusion detection mechanisms is critical. Although both Machine Learning (ML) and Deep Learning (DL) have optimised the typical rule-based detection systems, the use of ML and DL requires labelled pre-existing datasets. However, this kind of data varies based on the nature of the respective environment. Another smart solution for detecting intrusions is to use honeypots. A honeypot acts as a decoy with the goal to mislead the cyberatatcker and protect the real assets. In this paper, we focus on Wireless Honeypots (WHs) in ultra-dense networks. In particular, we introduce a strategic honeypot deployment method, using two Reinforcement Learning (RL) techniques: (a) $e-Greedy$e-Greedy and (b) $Q-Learning$Q-Learning. Both methods aim to identify the optimal number of honeypots that can be deployed for protecting the actual entities. The experimental results demonstrate the efficacy of both methods.},
 author = {Radoglou-Grammatikis, Panagiotis and Sarigiannidis, Panagiotis and Diamantoulakis, Panagiotis and Lagkas, Thomas and Saoulidis, Theocharis and Fountoukidis, Eleftherios and Karagiannidis, George},
 doi = {10.1109/TETC.2022.3184112},
 issn = {2168-6750},
 journal = {IEEE Transactions on Emerging Topics in Computing},
 keywords = {5G mobile communication;Security;Ultra-dense networks;Communication system security;Games;Protocols;Intrusion detection;Honeypot;intrusion detection;reinforcement learning;wireless communication},
 month = {April},
 number = {2},
 pages = {643-655},
 title = {Strategic Honeypot Deployment in Ultra-Dense Beyond 5G Networks: A Reinforcement Learning Approach},
 volume = {12},
 year = {2024}
}

@article{9807332,
 abstract = {In this letter, we present a two-stage pipeline for robust network intrusion detection. First, we implement an extreme gradient boosting (XGBoost) model to perform supervised intrusion detection, and leverage the SHapley Additive exPlanation (SHAP) framework to devise explanations of our model. In the second stage, we use these explanations to train an auto-encoder to distinguish between previously seen and unseen attacks. Experiments conducted on the NSL-KDD dataset show that our solution is able to accurately detect new attacks encountered during testing, while its overall performance is comparable to numerous state-of-the-art works from the cybersecurity literature.},
 author = {Barnard, Pieter and Marchetti, Nicola and DaSilva, Luiz A.},
 doi = {10.1109/LNET.2022.3186589},
 issn = {2576-3156},
 journal = {IEEE Networking Letters},
 keywords = {Pipelines;Computer security;Training;Anomaly detection;Testing;Numerical models;Network intrusion detection;Network intrusion detection system (NIDS);anomaly detection;machine learning;explainable artificial intelligence (XAI)},
 month = {Sep.},
 number = {3},
 pages = {167-171},
 title = {Robust Network Intrusion Detection Through Explainable Artificial Intelligence (XAI)},
 volume = {4},
 year = {2022}
}

@article{9808312,
 abstract = {An advanced metering infrastructure (AMI) system plays a key role in the smart grid (SG), but it is vulnerable to cyberattacks. Current detection methods for AMI cyberattacks mainly focus on the data center or a distributed independent node. On one hand, it is difficult to train an excellent detection intrusion model on a self-learning independent node. On the other hand, large amounts of data are shared over the network and uploaded to a central node for training. These processes may compromise data privacy, cause communication delay, and incur high communication costs. With these limitations, we propose an intrusion detection method for AMI system based on federated learning (FL). The intrusion detection system is deployed in the data concentrators for training, and only its model parameters are communicated to the data center. Furthermore, the data center distributes the learning to each data concentrator through aggregation and weight assignments for collaborative learning. An optimized deep neural network (DNN) is exploited for this proposed method, and extensive experiments based on the NSL-KDD dataset are carried out. From the results, this proposed method improves detection performance and reduces computation costs, communication delays, and communication overheads while guaranteeing data privacy.},
 author = {Liang, Haolan and Liu, Dongqi and Zeng, Xiangjun and Ye, Chunxiao},
 doi = {10.35833/MPCE.2021.000279},
 issn = {2196-5420},
 journal = {Journal of Modern Power Systems and Clean Energy},
 keywords = {Intrusion detection;Wide area networks;Data centers;WiMAX;Data models;Behavioral sciences;Smart meters;Federated learning (FL);advanced metering infrastructure (AMI) system;intrusion detection;data concentrator},
 month = {May},
 number = {3},
 pages = {927-937},
 title = {An Intrusion Detection Method for Advanced Metering Infrastructure System Based on Federated Learning},
 volume = {11},
 year = {2023}
}

@article{9810168,
 abstract = {Software Defined Networking (SDN) is an emerging network platform, which facilitates centralised network management. The SDN enables the network operators to manage the overall network consistently and holistically, regardless the complexity of infrastructure devices. The promising features of the SDN enhance network security and facilitate the implementation of threat detection systems through software applications using open APIs. However, the emerging technology creates new security concerns and new threats that do not exist in the current traditional networks. Distributed Denial of Service attacks (DDoS) are one of the most rampant attacks that can interrupt the functionality of the network and make most of the network services unreachable for network users. The efficient identification of DDos attacks on SDN environments in literature is still a challenge because of the number of network features taken into account and the overhead of applying machine learning based anomaly detection techniques. Hence, in this paper, we aim to use two popular feature selection methods, i.e., Information Gain (IG) and Random Forest (RF) in order to analyse the most comprehensive relevant features of DDoS attacks in SDN networks. Using the most relevant features will improve the accuracy of the anomaly detection system and reduce the false alarm rates. Moreover, we propose a Deep Learning (DL) technique based on Long Short Term Memory (LSTM) and Autoencoder to tackle the problem of DDoS attacks in SDNs. We perform our analysis and evaluation on three different datasets, i.e., InSDN, CICIDS2017 and CICIDS2018. We also measure the overhead of the proposed DL model on the SDN controller and test the network performance in terms of network throughput and end-to-end latency. The results validate that the DL approach can efficiently identify DDoS attacks in SDN environments without any significant degradation in the controller performance.},
 author = {Sayed, Mahmoud Said El and Le-Khac, Nhien-An and Azer, Marianne A. and Jurcut, Anca D.},
 doi = {10.1109/TCCN.2022.3186331},
 issn = {2332-7731},
 journal = {IEEE Transactions on Cognitive Communications and Networking},
 keywords = {Feature extraction;Denial-of-service attack;Computer crime;Performance evaluation;Control systems;Security;Intrusion detection;Anomaly detection;autoencoder;DDoS;deep learning;LSTM;InSDN dataset;SDN;traditional network},
 month = {Dec},
 number = {4},
 pages = {1862-1880},
 title = {A Flow-Based Anomaly Detection Approach With Feature Selection Method Against DDoS Attacks in SDNs},
 volume = {8},
 year = {2022}
}

@article{9825734,
 abstract = {Internet of Things (IoT) is an emerging paradigm that is turning and revolutionizing worldwide cities into smart cities. However, this emergence is accompanied with several cybersecurity concerns due mainly to the data sharing and constant connectivity of IoT networks. To address this problem, multiple Intrusion Detection Systems (IDSs) have been designed as security mechanisms, which showed their efficiency in mitigating several IoT-related attacks, especially when using deep learning (DL) algorithms. Indeed, Deep Neural Networks (DNNs) significantly improve the detection rate of IoT-related intrusions. However, DL-based models are becoming more and more complex, and their decisions are hardly interpreted by users, especially companies’ executive staff and cybersecurity experts. Hence, the corresponding users cannot neither understand and trust DL models decisions, nor optimize their decisions (users) based on DL models outputs. To overcome these limits, Explainable Artificial Intelligence (XAI) is an emerging paradigm of Artificial Intelligence (AI), that provides a set of techniques to help interpreting and understanding predictions made by DL models. Thus, XAI enables to explain the decisions of DL-based IDSs to make them interpretable by cybersecurity experts. In this paper, we design a new XAI-based framework to give explanations to any critical DL-based decisions for IoT-related IDSs. Our framework relies on a novel IDS for IoT networks, that we also develop by leveraging deep neural network, to detect IoT-related intrusions. In addition, our framework uses three main XAI techniques ( $i.e.$ , RuleFit, Local Interpretable Model-Agnostic Explanations (LIME), and SHapley Additive exPlanations (SHAP)), on top of our DNN-based model. Our framework can provide both local and global explanations to optimize the interpretation of DL-based decisions. The local explanations target a single/particular DL output, while global explanations focus on deducing the most important features that have conducted to each made decision (e.g., intrusion detection). Thus, our proposed framework introduces more transparency and trust between the decisions made by our DL-based IDS model and cybersecurity experts. Both NSL-KDD and UNSW-NB15 datasets are used to validate the feasibility of our XAI framework. The experimental results show the efficiency of our framework to improve the interpretability of the IoT IDS against well-known IoT attacks, and help the cybersecurity experts get a better understanding of IDS decisions.},
 author = {Houda, Zakaria Abou El and Brik, Bouziane and Khoukhi, Lyes},
 doi = {10.1109/OJCOMS.2022.3188750},
 issn = {2644-125X},
 journal = {IEEE Open Journal of the Communications Society},
 keywords = {Internet of Things;Deep learning;Computer security;Computer architecture;Artificial intelligence;Intrusion detection;Predictive models;Internet of Things;intrusion detection system;deep learning;explainable artificial intelligence;local and global explanations},
 month = {},
 number = {},
 pages = {1164-1176},
 title = {“Why Should I Trust Your IDS?”: An Explainable Deep Learning Framework for Intrusion Detection Systems in Internet of Things Networks},
 volume = {3},
 year = {2022}
}

@article{9826720,
 abstract = {Nowadays, it is common for applications to require servers to run constantly and aim as close as possible to zero downtime. The slightest failure might cause significant financial losses and sometimes even lives. For this reason, security and management measures against network threats are fundamental and have been researched for years. Software-defined networks (SDN) are an advancement in network management due to their centralization of the control plane, as it facilitates equipment setup and administration over the local network. However, this centralization makes the controller a target to denial of service attacks (DoS). In this study, we aim to develop a network anomaly detection and mitigation system that uses gated recurrent unit (GRU) neural networks combined with fuzzy logic. The neural network is trained to forecast future traffic, and anomalies are detected when the forecasting fails. The system is designed to operate in software-defined networks since they provide network flow information and tools to manage forwarding tables. We also demonstrate how the neural network’s hyperparameters affect the detection module. The system was tested using two datasets: one with emulated traffic generated by the data communication and networking research group called Orion, from computer science department at state university of Londrina, and CICDDoS2019, a well-known dataset by the anomaly detection community. The results show that GRU networks combined with fuzzy logic are a viable option to detect anomalies in SDN and possibly in other anomaly detection applications. The system was compared with other deep learning techniques.},
 author = {Brandão Lent, Daniel M. and Novaes, Matheus P. and Carvalho, Luiz F. and Lloret, Jaime and Rodrigues, Joel J. P. C. and Proença, Mario Lemes},
 doi = {10.1109/ACCESS.2022.3190008},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Deep learning;Logic gates;Fuzzy logic;Neural networks;Feature extraction;Security;Anomaly detection;deep learning;fuzzy logic;gated recurrent unit;software-defined networks},
 month = {},
 number = {},
 pages = {73229-73242},
 title = {A Gated Recurrent Unit Deep Learning Model to Detect and Mitigate Distributed Denial of Service and Portscan Attacks},
 volume = {10},
 year = {2022}
}

@article{9832511,
 abstract = {The rapid expansion of the Industrial Internet of Things (IIoT) necessitates the digitization of industrial processes in order to increase network efficiency. The integration of Digital Twin (DT) with IIoT digitizes physical objects into virtual representations to improve data analytics performance. Nevertheless, DT empowered IIoT generates a massive amount of data that is mostly sent to the cloud or edge servers for real-time analysis. However, unreliable public communication channels and lack of trust among participating entities causes various types of threats and attacks on the ongoing communication. Motivated from the aforementioned discussion, we present a blockchain and Deep Learning (DL) integrated framework for delivering decentralized data processing and learning in IIoT network. The framework first present a new DT model that facilitates construction of a virtual environment to simulate and replicate security-critical processes of IIoT. Second, we propose a blockchain-based data transmission scheme that uses smart contracts to ensure integrity and authenticity of data. Finally, the DL scheme is designed to apply the Intrusion Detection System (IDS) against valid data retrieved from blockchain. In DL scheme, a Long Short Term Memory-Sparse AutoEncoder (LSTMSAE) technique is proposed to learn the spatial-temporal representation. The extracted characteristics are further used by the proposed Multi-Head Self-Attention (MHSA)-based Bidirectional Gated Recurrent Unit (BiGRU) algorithm to learn long-distance features and accurately detect attacks. The practical implementation of our proposed framework proves considerable enhancement of communication security and data privacy in DT empowered IIoT network.},
 author = {Kumar, Prabhat and Kumar, Randhir and Kumar, Abhinav and Franklin, A. Antony and Garg, Sahil and Singh, Satinder},
 doi = {10.1109/TNSE.2022.3191601},
 issn = {2327-4697},
 journal = {IEEE Transactions on Network Science and Engineering},
 keywords = {Industrial Internet of Things;Blockchains;Security;Digital twins;Computational modeling;Data models;Virtual environments;Blockchain;deep learning (DL);digital twin (DT);industrial Internet of Things (IIoT);smart contract},
 month = {Sep.},
 number = {5},
 pages = {2802-2813},
 title = {Blockchain and Deep Learning for Secure Communication in Digital Twin Empowered Industrial IoT Network},
 volume = {10},
 year = {2023}
}

@article{9832899,
 abstract = {The staggering development of cyber threats has propelled experts, professionals and specialists in the field of security into the development of more dependable protection systems, including effective intrusion detection system (IDS) mechanisms which are equipped for boosting accurately detected threats and limiting erroneously detected threats simultaneously. Nonetheless, the proficiency of the IDS framework depends essentially on extracted features from network traffic and an effective classifier of the traffic into abnormal or normal traffic. The prime impetus of this study is to increase the performance of the IDS on networks by building a two-phase framework to reinforce and subsequently enhance detection rate and diminish the rate of false alarm. The initial stage utilizes the developed algorithm of a proficient wrapper-approach-based feature selection which is created on a multi-objective BAT algorithm (MOBBAT). The subsequent stage utilizes the features obtained from the initial stage to categorize the traffic based on the newly upgraded BAT algorithm (EBAT) for training multilayer perceptron (EBATMLP), to improve the IDS performance. The resulting methodology is known as the (MOB-EBATMLP). The efficiency of our proposition has been assessed by utilizing the mainstream benchmarked datasets: NLS-KDD, ISCX2012, UNSW-NB15, KDD CUP 1999, and CICIDS2017 which are established as standard datasets for evaluating IDS. The outcome of our experimental analysis demonstrates a noteworthy advancement in network IDS above other techniques.},
 author = {Ghanem, Waheed Ali H. M. and Ghaleb, Sanaa Abduljabbar Ahmed and Jantan, Aman and Nasser, Abdullah B. and Saleh, Sami Abdulla Mohsen and Ngah, Amir and Alhadi, Arifah Che and Arshad, Humaira and Saad, Abdul-Malik H. Y. and Omolara, Abiodun Esther and El-Ebiary, Yousef A. Baker and Abiodun, Oludare Isaac},
 doi = {10.1109/ACCESS.2022.3192472},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Training;Metaheuristics;Intrusion detection;Classification algorithms;Computer science;Artificial neural networks;Intrusion detection system (IDS);bat algorithm (BAT);metaheuristic algorithm (MA);feature selection (FS);multi-objective optimization (MOO);multilayer perceptron (MLP)},
 month = {},
 number = {},
 pages = {76318-76339},
 title = {Cyber Intrusion Detection System Based on a Multiobjective Binary Bat Algorithm for Feature Selection and Enhanced Bat Algorithm for Parameter Optimization in Neural Networks},
 volume = {10},
 year = {2022}
}

@article{9834261,
 abstract = {Cloud computing is perhaps the most enticing innovation in the present figuring situation. It gives an expense-effective arrangement by diminishing the enormous forthright expense of purchasing equipment foundations and processing power. Fog computing is an additional help to cloud infrastructure by utilizing a portion of the less-registered undertaking at the edge devices, reducing the end client’s reaction time, such as IoT. However, most of the IoT devices are resource-constrained, and there are many devices that cyber attacks could target. Cyber-attacks such as bottleneck, Dos, DDoS, and botnets are still significant threats in the IoT environment. Botnets are currently the most significant threat on the internet. A set of infected systems connected online and directed by an adversary to carry out malicious actions without authorization or authentication is known as a botnet. A botnet can compromise the system and steal the data. It can also perform attacks, like Phishing, spamming, and more. To overcome the critical issue, we exhibit a novel botnet attack detection approach that could be utilized in fog computing situations to dispense with the attack using the programmable nature of the software-defined network (SDN) environment. We carefully tested the most recent dataset for our proposed technique, standard and extended performance evaluation measures, and current DL models. To further illustrate overall performance, our findings are cross-validated. The proposed method performs better than previous ones in correctly identifying 99.98% of multi-variant sophisticated bot attacks. Additionally, the time of our suggested method is 0.022(ms), indicating good speed efficiency results.},
 author = {Sattari, Fraidoon and Farooqi, Ashfaq Hussain and Qadir, Zakria and Raza, Basit and Nazari, Hadi and Almutiry, Muhannad},
 doi = {10.1109/ACCESS.2022.3188635},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Botnet;Edge computing;Servers;Deep learning;Security;Support vector machines;Fog security;software defined networks;deep learning;Internet of Things;botnet;intrusion detection},
 month = {},
 number = {},
 pages = {77039-77053},
 title = {A Hybrid Deep Learning Approach for Bottleneck Detection in IoT},
 volume = {10},
 year = {2022}
}

@article{9851436,
 abstract = {This document classifies, selects and trains a deep learning algorithm to create an IDS/IPS (Intrusion Prevention/Detection System) called Dique, which can detect and prevent denial of service (DoS) attacks. To mitigate DoS attacks, the IDS/IPS system, using the proposed deep learning model, classifies incoming packets to the web server into two classes: benign (which are normal traffic packets) and malicious (which the system considers to contain possible DoS attacks). Dique has a Graphical User Interface (GUI) where “in real time” you can display graphically and textually the information of captured and classified packets, and allows you to switch between the IDS mode and the IPS mode of the system operation. The proposed DoS attack classification model uses a multi-layered Deep Feed Forward neural network, the CICDDoS2019 Dataset was used for training and an accuracy of 0.994 was achieved. In addition, an offensive system called Diluvio was developed to verify the functioning of the Dique system. In Diluvio seven different types of DoS attacks were implemented (five contents in the training Datset and two that are not in said dataset) that users can selectively launch against a web server.},
 author = {Cañola Garcia, Juan Fernando and Blandon, Gabriel Enrique Taborda},
 doi = {10.1109/ACCESS.2022.3196642},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Classification algorithms;Feature extraction;Denial-of-service attack;Deep learning;Machine learning algorithms;Computer crime;Artificial neural networks;Denial of service attack;deep learning;intrusion detection system;intrusion prevention system;neural networks},
 month = {},
 number = {},
 pages = {83043-83060},
 title = {A Deep Learning-Based Intrusion Detection and Preventation System for Detecting and Preventing Denial-of-Service Attacks},
 volume = {10},
 year = {2022}
}

@article{9854888,
 abstract = {Currently, malware is increasing in both number and complexity dramatically. Several techniques and methodologies have been proposed to detect and neutralize malicious software. However, traditional methods based on the signatures or behaviors of malware often require considerable computational time and resources for feature engineering. Recent studies have applied machine learning to the problems of identifying and classifying malware families. Combining many state-of-the-art techniques has become popular but choosing the appropriate combination with high efficiency is still a problem. The classification performance has been significantly improved using complex neural network architectures. However, the more complex the network, the more resources it requires. This paper proposes a novel lightweight architecture by combining small Convolutional Neural Networks and advanced Variational Autoencoder, enhanced by channel and spatial attention mechanisms. We achieve overperformance and sufficient time through various experiments compared to other cutting-edge techniques using unbalanced and balanced Malimg datasets.},
 author = {Dao, Tuan Van and Sato, Hiroshi and Kubo, Masao},
 doi = {10.1109/ACCESS.2022.3198072},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Malware;Feature extraction;Computer architecture;Convolutional neural networks;Computational modeling;Codes;Behavioral sciences;Encoding;Information security;Channel capacity;Malware classification;variational autoencoder;channel attention;spatial attention;latent representation;information security},
 month = {},
 number = {},
 pages = {85127-85136},
 title = {An Attention Mechanism for Combination of CNN and VAE for Image-Based Malware Classification},
 volume = {10},
 year = {2022}
}

@article{9858115,
 abstract = {Deep learning-based intrusion detection systems have advanced due to their technological innovations such as high accuracy, automation, and scalability to develop an effective network intrusion detection system (NIDS). However, most of the previous research has focused on model generation through intensive analysis of feature engineering instead of considering real environments. They have limitations to applying the previous methods for a real network environment to detect real-time network attacks. In this paper, we propose a new flexible and robust NIDS based on Recurrent Neural Network (RNN) with a multi-classifier to generate a detection model in real time. The proposed system adaptively and intelligently adjusts the generated model with given system parameters that can be used as security parameters to defend against the attacker’s obfuscation techniques in real time. In the experimental results, the proposed system detects network attacks with a high accuracy and high-speed model upgrade in real-time while showing robustness under an attack.},
 author = {Yu, Kicho and Nguyen, Khanh and Park, Younghee},
 doi = {10.1109/ACCESS.2022.3199375},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Real-time systems;Adaptation models;Data models;Deep learning;Random forests;Robustness;Recurrent neural networks;Data analysis;Network intrusion;Long short-term memory;network intrusion detection system;recurrent neural network;real-time data analysis},
 month = {},
 number = {},
 pages = {98959-98969},
 title = {Flexible and Robust Real-Time Intrusion Detection Systems to Network Dynamics},
 volume = {10},
 year = {2022}
}

@article{9862964,
 abstract = {In recent years, computer networks have become an indispensable part of our life, and these networks are vulnerable to various type of network attacks, compromising the security of our data and the freedom of our communications. In this paper, we propose a new intrusion detection method that uses image conversion from network data flow to produce an RGB image that can be classified using advanced deep learning models. In this method, we proposed to use the decision tree algorithm to identify the important features, and a windowing and overlapping mechanism to convert the varying input size to a standard size image for the classifier. We then use a Vision Transfomer (ViT) classifier to classify the resulting image. Our experimental results show that we can achieve 98.5% accuracy in binary classification on the CIC IDS2017 dataset, and 96.3% on the UNSW-NB15 dataset, which is 8.09% higher than the next best algorithm, the Deep Belief Network with Improved Kernel-Based Extreme Learning (DBN-KELM) method. For multi-class classification, our proposed method can achieve a testing accuracy of 96.4%, which is 5.6% higher than the next best method, the DBN-KELM.},
 author = {Ho, Chi Mai Kim and Yow, Kin-Choong and Zhu, Zhongwen and Aravamuthan, Sarang},
 doi = {10.1109/ACCESS.2022.3200034},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Classification algorithms;Training data;Transformers;Matrix converters;Data models;Convolutional neural networks;Intrusion detection;Image classification;Network intrusion detection;flow-to-image conversion;convolutional neural networks;vision transformers;image classification},
 month = {},
 number = {},
 pages = {97780-97793},
 title = {Network Intrusion Detection via Flow-to-Image Conversion and Vision Transformer Classification},
 volume = {10},
 year = {2022}
}

@article{9863843,
 abstract = {Recent research interests have been directed to study the security of vehicles due to the advancement of their technologies. Due to the rapid growth and accelerated development of electronic control units (ECUs), they are countered to be exploited by external attacks. As a result, recent research efforts have been focused on investigating alternative countermeasures that might be implemented by introducing different intrusion detection systems (IDSs). The problem with some of IDSs is the location of their deployment because of the ECU limitations and constraints. Other introduced IDSs require severe changes in the in-vehicle network, which is not preferred by vehicle manufacturers. In this research, we introduce a novel design of a framework to check the state of the vehicle and capture possible attacks by detecting any malicious data in the diagnostic parameters of the vehicle. The framework is divided into two phases: the specific-based detection phase and the anomaly-based detection phase. The proposed system employs the extreme gradient boosting (XGBoost) algorithm to detect anomalies in diagnostic data and it is optimized by a non-dominated sorting genetic algorithm II (NSGA-II). The model is verified against two datasets collected from real vehicles. To generate anomalies in datasets, an attack generation algorithm is introduced. The model is trained on a dataset that contains different attack types and verified blindly against various attacks that have not been seen before. The framework’s experimental results show that it can detect abnormalities with accuracy 97.00% for the Seat Leon 2018 dataset and 97.49% for the KIA SOUL dataset.},
 author = {Awaad, Tasneem A. and El-Kharashi, M. Watheq and Taher, Mohamed and Ammar, Khalid Ali},
 doi = {10.1109/ACCESS.2022.3200375},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Security;Machine learning;Boosting;Genetic algorithms;Data models;Machine learning algorithms;Cyber-physical systems;Vehicles;Anomaly detection;cyber-physical security threats;diagnostics;genetic algorithm;intrusion detection;machine learning;NSGA-II;vehicular security;XGBoost},
 month = {},
 number = {},
 pages = {88907-88919},
 title = {An Intelligent, Two-Stage, In-Vehicle Diagnostic-Based Secured Framework},
 volume = {10},
 year = {2022}
}

@article{9864095,
 abstract = {In industrial control systems (ICSs), intrusion detection is a vital task. Conventional intrusion detection systems (IDSs) rely on manually designed rules. These rules heavily depend on professional experience, thereby making it challenging to represent the increasingly complicated industrial control logic. Although deep learning-based approaches provide better accuracy than other methods, they can only provide alerts. However, they cannot provide administrators with detailed information. In this study, we propose the logic understanding IDS (LU-IDS), which is a rule-based IDS with in-depth understandings of industrial control logic. Our proposed LU-IDS uses a specially designed deep learning-based model to capture features automatically and carry out attack classification. More importantly, it analyzes the knowledge learned from the classification of attacks to understand the abnormal industrial control logic and generate rules. The experimental results indicate that our proposed LU-IDS demonstrates excellent performance on intrusion detection. The rules generated by our proposed LU-IDS can be used to successfully detect all types of attacks on two public datasets.},
 author = {Sun, Motong and Lai, Yingxu and Wang, Yipeng and Liu, Jing and Mao, Beifeng and Gu, Haoran},
 doi = {10.1109/TII.2022.3200363},
 issn = {1941-0050},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Intrusion detection;Sensors;Actuators;Industrial control;Integrated circuits;Informatics;Tensors;Control logic;industrial control systems (ICSs);intrusion detection systems (IDSs);logic attribution;rule generation},
 month = {March},
 number = {3},
 pages = {2295-2306},
 title = {Intrusion Detection System Based on In-Depth Understandings of Industrial Control Logic},
 volume = {19},
 year = {2023}
}

@article{9867983,
 abstract = {From a security perspective, the research of the jeopardized 6G wireless communications and its expected ultra-densified ubiquitous wireless networks urge the development of a robust intrusion detection system (IDS) with powerful capabilities which could not be sufficiently provided by the existing conventional systems. IDSs are still insufficient against continuous renewable unknown attacks on the wireless communication networks, especially with the new highly vulnerable networks, leading to low accuracy and detection rate with high (false-negative and false-positive) rates. To this end, this paper proposed a novel anomaly detection in communication networks by using an ensemble learning (EL) algorithm-based anomaly detection in communication networks (ADCNs). EL-ADCNs consists of four main stages; the first stage is the preprocessing steps. The feature selection method is the second stage. It adopts the proposed hybrid method using correlation with the random forest algorithm of ensemble learning (CFS–RF). It reduces dimensionality and retrieves the best subset feature of all the three datasets (NSL_KDD, UNSW_NB2015, and CIC_IDS2017) separately. The third stage is using hybrid EL algorithms to detect intrusions. It involves modifying two classifiers (i.e., random forest (RF), and support vector machine (SVM)) to apply them as adaboosting and bagging EL Algorithms; using the voting average technique as an aggregation process. The final stage is testing the proposal using binary and multi-class classification forms. The experimental results of applying 30, 35, and 40 features of the proposed system to the three datasets achieved the best results of a 99.6% accuracy with a 0.004 false-alarm rate for NSL_KDD, a 99.1% accuracy with a 0.008 false-alarm rate for UNSW_NB2015, and a 99.4% accuracy with a 0.0012 false-alarm rate for CIC_IDS2017.},
 author = {Oleiwi, Haider W. and Mhawi, Doaa N. and Al-Raweshidy, Hamed},
 doi = {10.1109/ACCESS.2022.3201869},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Classification algorithms;Intrusion detection;Correlation;Support vector machines;Bagging;Anomaly detection;Machine learning;Communication networks;Adaboosting algorithm;Bagging algorithm;correlation feature selection;ensemble method;intrusion detection systems},
 month = {},
 number = {},
 pages = {91006-91017},
 title = {MLTs-ADCNs: Machine Learning Techniques for Anomaly Detection in Communication Networks},
 volume = {10},
 year = {2022}
}

@article{9869814,
 abstract = {Wireless Sensor Networks(WSNs) are vulnerable to a variety of unique security risks and threats in their data collection and transmission processes. One of the most common attacks on WSNs that can target all layers of the protocol stack is the DoS attack. In this study, a unique DoS Intrusion Detection System (DDS) is proposed to detect DoS attacks specific to WSNs. The proposed system is an ensemble intrusion detection system called STLGBM-DDS, which is developed on Apache Spark big data platform in Google Colab environment, combining LightGBM machine learning algorithm, data balancing and feature selection processes. In order to reduce the effects of data imbalance on system performance, data imbalance processing consisting of Synthetic Minority Oversampling Technique (SMOTE) and Tomek-Links sampling methods called STL was used. In addition, Information Gain Ratio was used as a feature selection technique in the data preprocessing stage. The effects of both data balancing and feature selection stages on the detection performance of the system were investigated. The results obtained were evaluated using the Accuracy, F-Measure, Precision, Recall, ROC Curve and Precision-Recall Curve parameters. As a result, the proposed method achieved an overall accuracy of 99.95%. Also, it achieved 99.99%, 99.96%, 99.98%, 99.92%, and 99.87% accuracy performance according to Normal, Grayhole, Blackhole, TDMA and Flooding classes, respectively. According to the results obtained, the proposed method has achieved very successful results in DoS attack detection in WSNs compared to current methods.},
 author = {Dener, Murat and Al, Samed and Orman, Abdullah},
 doi = {10.1109/ACCESS.2022.3202807},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Intrusion detection;Feature extraction;Classification algorithms;Machine learning;Machine learning algorithms;Deep learning;Wireless sensor networks;DoS attacks;intrusion detection;deep learning;imbalanced data},
 month = {},
 number = {},
 pages = {92931-92945},
 title = {STLGBM-DDS: An Efficient Data Balanced DoS Detection System for Wireless Sensor Networks on Big Data Environment},
 volume = {10},
 year = {2022}
}

@article{9872064,
 abstract = {The recent development of Internet of Things (IoT) and unmanned aerial vehicles (UAVs) has revolutionized traditional agriculture with intelligence and automation. In a typical intelligent agriculture (IA) ecosystem, massive and real-time data are generated, analyzed, and sent to the cloud server (CS) for the purpose of addressing complex agricultural issues, such as yield prediction, water feed calculation, and so on. This helps farmer and associated stakeholders to take correct decision that improves the yield and quality of agricultural product. However, the distributed nature of IA entities and the usage of insecure wireless communication open various challenges related to data sharing, monitoring, storage, and further makes the entire IA ecosystem vulnerable to various potential attacks. In this article, we exploit deep learning and smart contract to propose a new IoT-enabled IA framework for enabling secure data sharing among its various entities. Specifically, first we develop new authentication and key management scheme to ensure secure data transmission in IoT-enabled IA. The encrypted transactions are then used by the CS to analyze and further detect intrusions by a novel deep learning architecture. In CS, the smart contract (SC)-based consensus mechanism is executed on legitimate transactions that verifies and adds the formed blocks into blockchain by a peer-to-peer CSs network. In comparison to existing competing security solutions, a rigorous comparative research demonstrates that the proposed approach provides greater security and more utility characteristics.},
 author = {Kumar, Randhir and Kumar, Prabhat and Aljuhani, Ahamed and Islam, A. K. M. Najmul and Jolfaei, Alireza and Garg, Sahil},
 doi = {10.1109/MIS.2022.3201553},
 issn = {1941-1294},
 journal = {IEEE Intelligent Systems},
 keywords = {Deep learning;Internet of Things;Autonomous aerial vehicles;Smart contracts;Ecosystems;Authentication;Training;Smart agriculture;Farming;Information sharing;Artificial intelligence;Blockchain;Deep Learning;Internet of Things (IoT);Smart Contracts;Intelligent Agriculture (IA)},
 month = {July},
 number = {4},
 pages = {42-51},
 title = {Deep Learning and Smart Contract-Assisted Secure Data Sharing for IoT-Based Intelligent Agriculture},
 volume = {38},
 year = {2023}
}

@article{9874817,
 abstract = {Smart environments consist of a collection of sensors, actuators, and numerous computing units that improve human life. With the booming of smart environments, data generation has been notably increasing in recent years, which must be managed in a smart and optimal manner. The components (i.e., workstations and cloud) used for data processing are not the best to recommend since it is risky and resource costing. For that matter, enterprises, firms and companies are deploying blockchain technologies (BT) as a more suitable alternative. In fact, blockchain is a distributed transaction ledger ensuring the reliability and transparency of data. However, BT faces some inherent security challenges such as DoS, eclipse and double spending attacks as well as Advanced Persistent Threat (APT) and malware. Thus, advanced anomaly detection and mitigation approaches, especially the ones using artificial intelligence (AI) techniques (e. g. Machine Learning, Deep Learning, Federated Learning) are required to address the aforementioned issues. In combination, AI and BT are capable of detecting anomalies within blockchain networks with high accuracy. In this paper, with a focus on cyber security issues, we explore the challenges of blockchain deployment in smart environments. Additionally, we explore the use of anomaly detection AI-based techniques as a ledger of blockchain technologies to address the security issues in smart environments. Thus, we propose a framework that emphasizes the challenges of BT, values and capabilities of BT-AI integration. We also present research trends to highlight potential research paths for improving the security of blockchain networks using artificial intelligence.},
 author = {Fadi, Oumaima and Karim, Zkik and Abdellatif, El Ghazi and Mohammed, Boulmalf},
 doi = {10.1109/ACCESS.2022.3203568},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Artificial intelligence;Security;Machine learning;Collaborative work;Privacy;Data models;Anomaly detection;Blockchain technology;artificial intelligence;security and privacy;smart environments;machine learning;anomaly detection},
 month = {},
 number = {},
 pages = {93168-93186},
 title = {A Survey on Blockchain and Artificial Intelligence Technologies for Enhancing Security and Privacy in Smart Environments},
 volume = {10},
 year = {2022}
}

@article{9875264,
 abstract = {This survey presents a comprehensive review of current literature on Explainable Artificial Intelligence (XAI) methods for cyber security applications. Due to the rapid development of Internet-connected systems and Artificial Intelligence in recent years, Artificial Intelligence including Machine Learning (ML) and Deep Learning (DL) has been widely utilized in the fields of cyber security including intrusion detection, malware detection, and spam filtering. However, although Artificial Intelligence-based approaches for the detection and defense of cyber attacks and threats are more advanced and efficient compared to the conventional signature-based and rule-based cyber security strategies, most ML-based techniques and DL-based techniques are deployed in the “black-box” manner, meaning that security experts and customers are unable to explain how such procedures reach particular conclusions. The deficiencies of transparencies and interpretability of existing Artificial Intelligence techniques would decrease human users’ confidence in the models utilized for the defense against cyber attacks, especially in current situations where cyber attacks become increasingly diverse and complicated. Therefore, it is essential to apply XAI in the establishment of cyber security models to create more explainable models while maintaining high accuracy and allowing human users to comprehend, trust, and manage the next generation of cyber defense mechanisms. Although there are papers reviewing Artificial Intelligence applications in cyber security areas and the vast literature on applying XAI in many fields including healthcare, financial services, and criminal justice, the surprising fact is that there are currently no survey research articles that concentrate on XAI applications in cyber security. Therefore, the motivation behind the survey is to bridge the research gap by presenting a detailed and up-to-date survey of XAI approaches applicable to issues in the cyber security field. Our work is the first to propose a clear roadmap for navigating the XAI literature in the context of applications in cyber security.},
 author = {Zhang, Zhibo and Hamadi, Hussam Al and Damiani, Ernesto and Yeun, Chan Yeob and Taher, Fatma},
 doi = {10.1109/ACCESS.2022.3204051},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Computer crime;Cyberattack;Computer security;Deep learning;Medical services;Malware;Intrusion detection;Artificial intelligence;Unsolicited e-mail;Information filters;Artificial intelligence;cyber security;deep learning;explanation artificial intelligence;intrusion detection;machine learning;malware detection;spam filtering},
 month = {},
 number = {},
 pages = {93104-93139},
 title = {Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research},
 volume = {10},
 year = {2022}
}

@article{9882118,
 abstract = {Attacks on computer networks have increased significantly in recent days, due in part to the availability of sophisticated tools for launching such attacks as well as the thriving underground cyber-crime economy to support it. Over the past several years, researchers in academia and industry used machine learning (ML) techniques to design and implement Intrusion Detection Systems (IDSes) for computer networks. Many of these researchers used datasets collected by various organizations to train ML classifiers for detecting intrusions. In many of the datasets used in training ML classifiers in such systems, data are imbalanced (i.e., not all classes had equal number of samples). ML classifiers trained with such imbalanced datasets may produce unsatisfactory results. Traditionally, researchers used over-sampling and under-sampling for balancing data in datasets to overcome this problem. In this work, in addition to random over-sampling, we also used a synthetic data generation method, called Conditional Generative Adversarial Network (CTGAN), to balance data and study their effect on the performance of various widely used ML classifiers. To the best of our knowledge, no one else has used CTGAN to generate synthetic samples to balance intrusion detection datasets. Based on extensive experiments using widely used datasets NSL-KDD and UNSW-NB15, we found that training ML classifiers on datasets balanced with synthetic samples generated by CTGAN increased their prediction accuracy by up to 8% and improved their MCC score by up to 13%, compared to training the same ML classifiers over imbalanced datasets. We also show that this approach consistently performs better than some of the recently proposed state-of-the-art IDSes on both datasets. Our experiments also demonstrate that the accuracy of some ML classifiers trained over datasets balanced with random over-sampling decline compared to the same ML classifiers trained over original imbalanced dataset.},
 author = {Dina, Ayesha Siddiqua and Siddique, A. B. and Manivannan, D.},
 doi = {10.1109/ACCESS.2022.3205337},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Training data;Intrusion detection;Machine learning;Data models;Computer networks;Computational modeling;Behavioral sciences;Cyberattack;Cyber security;conditional generative adversarial network (CTGAN);data imbalance problem;intrusion detection;machine learning;over-sampling;under-sampling},
 month = {},
 number = {},
 pages = {96731-96747},
 title = {Effect of Balancing Data Using Synthetic Data on the Performance of Machine Learning Classifiers for Intrusion Detection in Computer Networks},
 volume = {10},
 year = {2022}
}

@article{9889698,
 abstract = {Network security becomes indispensable to our daily interactions and networks. As attackers continue to develop new types of attacks and the size of networks continues to grow, the need for an effective intrusion detection system has become critical. Numerous studies implemented machine learning algorithms to develop an effective IDS; however, with the advent of deep learning algorithms and artificial neural networks that can generate features automatically without human intervention, researchers began to rely on deep learning. In our research, we took advantage of the Convolutional Neural Network’s ability to extract spatial features and the Long Short-Term Memory Network’s ability to extract temporal features to create a hybrid intrusion detection system model. We added batch normalization and dropout layers to the model to increase its performance. Based on the binary and multiclass classification, the model was trained using three datasets: CIC-IDS 2017, UNSW-NB15, and WSN-DS. The confusion matrix determines the system’s effectiveness, which includes evaluation criteria such as accuracy, precision, detection rate, F1-score, and false alarm rate (FAR). The effectiveness of the proposed model was demonstrated by experimental results showing a high detection rate, high accuracy, and a relatively low FAR.},
 author = {Halbouni, Asmaa and Gunawan, Teddy Surya and Habaebi, Mohamed Hadi and Halbouni, Murad and Kartiwi, Mira and Ahmad, Robiah},
 doi = {10.1109/ACCESS.2022.3206425},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Convolutional neural networks;Intrusion detection;Deep learning;Training data;Machine learning algorithms;Wireless sensor networks;Intrusion detection system;deep learning;convolutional neural network;long-short term memory;accuracy;false alarm rate;binary classification;multiclass classification},
 month = {},
 number = {},
 pages = {99837-99849},
 title = {CNN-LSTM: Hybrid Deep Neural Network for Network Intrusion Detection System},
 volume = {10},
 year = {2022}
}

@article{9895417,
 abstract = {Controller Area Network (CAN) is the de facto standard for in-vehicle networks. However, it is inherently vulnerable to various attacks due to the lack of security features. Intrusion detection systems (IDSs) are considered effective approaches to protect in-vehicle networks. IDSs based on advanced deep learning algorithms have been proposed to achieve higher detection accuracy. However, those systems generally involve high latency, require considerable memory space, and often result in high energy consumption. To accelerate intrusion detection and also reduce memory and energy costs, we propose a new IDS system using Binarized Neural Network (BNN). Compared to full-precision counterparts, BNNs can offer faster detection, smaller memory cost, and lower energy consumption. Moreover, BNNs can be further accelerated by leveraging Field-Programmable Grid Arrays (FPGAs) since BNNs cut down the hardware consumption. The proposed IDS is based on a BNN model that suits CAN traffic messages and takes advantage of sequential features of messages rather than each individual message. We also explore various design choices for BNN, including increasing network width and depth, to improve accuracy as BNNs typically sacrifice accuracy. The performance of our IDS is evaluated with four different real vehicle datasets. Experimental results show that the proposed IDS reduces the detection latency (3 times faster) on the same CPU platform while maintaining acceptable detection rates compared with full-precision models. We also examine the proposed IDS on multiple platforms, and our results show that using FPGA hardware reduces the detection latency dramatically (128 times faster) with lower power consumption compared to an embedded CPU device. Furthermore, we evaluate BNNs with different designs. Results demonstrate that wider or deeper models definitely improve accuracy at the cost of increased latency and model sizes to varying degrees. Applications are recommended to choose the appropriate model design they need depending on available resources they have.},
 author = {Zhang, Linxi and Yan, Xuke and Ma, Di},
 doi = {10.1109/ACCESS.2022.3208091},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Field programmable gate arrays;Memory management;Power demand;Costs;Automotive engineering;Encryption;Authentication;Intrusion detection;Neural networks;Machine learning;Automotive security;intrusion detection;in-vehicle network;controller area network (CAN);binary neural networks;machine learning},
 month = {},
 number = {},
 pages = {123505-123520},
 title = {A Binarized Neural Network Approach to Accelerate in-Vehicle Network Intrusion Detection},
 volume = {10},
 year = {2022}
}

@article{9899390,
 abstract = {Anomaly-based In-Vehicle Intrusion Detection System (IV-IDS) is one of the protection mechanisms to detect cyber attacks on automotive vehicles. Using artificial intelligence (AI) for anomaly detection to thwart cyber attacks is promising but suffers from generating false alarms and making decisions that are hard to interpret. Consequently, this issue leads to uncertainty and distrust towards such IDS design unless it can explain its behavior, e.g., by using eXplainable AI (XAI). In this paper, we consider the XAI-powered design of such an IV-IDS using CAN bus data from a public dataset, named “Survival”. Novel features are engineered, and a Deep Neural Network (DNN) is trained over the dataset. A visualization-based explanation, “VisExp”, is created to explain the behavior of the AI-based IV-IDS, which is evaluated by experts in a survey, in relation to a rule-based explanation. Our results show that experts’ trust in the AI-based IV-IDS is significantly increased when they are provided with VisExp (more so than the rule-based explanation). These findings confirm the effect, and by extension the need, of explainability in automated systems, and VisExp, being a source of increased explainability, shows promise in helping involved parties gain trust in such systems.},
 author = {Lundberg, Hampus and Mowla, Nishat I and Abedin, Sarder Fakhrul and Thar, Kyi and Mahmood, Aamir and Gidlund, Mikael and Raza, Shahid},
 doi = {10.1109/ACCESS.2022.3208573},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Intrusion detection;Automotive engineering;Behavioral sciences;Random forests;Deep learning;Trust management;Automotive;intrusion detection system;machine learning;deep learning;XAI;trustworthiness},
 month = {},
 number = {},
 pages = {102831-102841},
 title = {Experimental Analysis of Trustworthy In-Vehicle Intrusion Detection System Using eXplainable Artificial Intelligence (XAI)},
 volume = {10},
 year = {2022}
}

@article{9903592,
 abstract = {With the popularity of wireless networks, wireless sensor networks (WSNs) have advanced rapidly, and their flexibility and ease of deployment have resulted in more security concerns, making it critical to research network intrusion prevention for WSNs. Denial of service (DoS) is a common network attack, achieving its goal by bringing down the target network. A DoS attack on WSNs devices with limited resources would be fatal. This paper proposes a method based on principal component analysis (PCA) and a deep convolution neural network (DCNN) for DoS traffic anomaly detection in WSNs, based on the vulnerability of WSNs to attacks and the limited storage space of their devices. Compared with the conventional deep learning structure, the proposed model has a lightweight structure and more effective feature extraction capability, which can effectively detect network abnormal traffic in WSNs devices with limited storage capacity. To assure the effectiveness of the proposed model, receiver operating characteristic (ROC) curves, various classification metrics, and confusion matrices are used to verify the classification results of the model. Through experimental comparison, the proposed model, with small model size, outperforms other mainstream abnormal traffic detection models in terms of classification effect.},
 author = {Yao, Chengpeng and Yang, Yu and Yin, Kun and Yang, Jinwei},
 doi = {10.1109/ACCESS.2022.3210189},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Wireless sensor networks;Feature extraction;Anomaly detection;Principal component analysis;Telecommunication traffic;Convolutional neural networks;Representation learning;Wireless sensor networks;denial of service;network attack;principal component analysis;deep convolution neural network},
 month = {},
 number = {},
 pages = {103136-103149},
 title = {Traffic Anomaly Detection in Wireless Sensor Networks Based on Principal Component Analysis and Deep Convolution Neural Network},
 volume = {10},
 year = {2022}
}

@article{9907008,
 abstract = {Intrusion detection is an essential task for protecting the cyber environment from attacks. Many studies have proposed sophisticated models to detect intrusions from a large amount of data, yet they ignored the fact that poor data quality has a direct impact on the performance of intrusion detection systems. Examples of poor data quality include mislabeled, inaccurate, incomprehensive, irrelevant, inconsistent, duplicated, and overlapped data. In order to investigate how data quality may affect machine learning performance, we conducted a series of experiments on 11 host-based intrusion datasets using eight machine learning (ML) models and two pre-trained language models BERT and GPT-2. The experimental results showed: 1. BERT and GPT-2 outperformed the other models on every dataset. 2. Data duplications and overlaps in a dataset had different performance impacts on the pre-trained models and the classic ML models. The pre-trained models were less susceptible to duplicate and overlapped data than the classic ML models. 3. Removing overlaps and duplicates from training data with a normal range of sequence similarities could improve the pre-trained models’ performances on most datasets. However, it may have adverse effects on model performance in datasets with highly similar sequences. 4. The reliability of model evaluation could be affected when testing data contains duplicates. 5. The overlapped rate between the normal class and the intrusion class seemed to have an inverse relationship to the performance of the pre-trained models in intrusion detection. Given the results, we proposed a framework for model selection and data quality assurance for building a high-quality machine learning-based intrusion detection system.},
 author = {Tran, Ngan and Chen, Haihua and Bhuyan, Jay and Ding, Junhua},
 doi = {10.1109/ACCESS.2022.3211313},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Intrusion detection;Data models;Data integrity;Biological system modeling;Data quality;Information integrity;Support vector machines;Machine learning;Deep learning;Data curation;data quality;intrusion detection;machine learning;deep learning;language model},
 month = {},
 number = {},
 pages = {121900-121923},
 title = {Data Curation and Quality Evaluation for Machine Learning-Based Cyber Intrusion Detection},
 volume = {10},
 year = {2022}
}

@article{9908159,
 abstract = {As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.},
 author = {Park, Cheolhee and Lee, Jonghoon and Kim, Youngsoo and Park, Jong-Geun and Kim, Hyunjin and Hong, Dowon},
 doi = {10.1109/JIOT.2022.3211346},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 keywords = {Generative adversarial networks;Data models;Deep learning;Anomaly detection;Network intrusion detection;Feature extraction;Internet of Things;Anomaly detection;generative adversarial network (GAN);network intrusion detection system (NIDS);network security},
 month = {Feb},
 number = {3},
 pages = {2330-2345},
 title = {An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks},
 volume = {10},
 year = {2023}
}

@article{9908556,
 abstract = {As intrusion detection and prevention systems (IDPSs) grow in importance, the cost of managing signatures, which are pattern files of malicious communications, continues to increase. To ensure the optimal operation of an IDPS, network security experts need to classify the signatures generated over time according to their importance (low, medium, and high). Although machine learning approaches can be used to automatically classify signatures instead of human experts, there are several challenges to applying them, including (a) high annotation costs, (b) security incidents caused by classification errors, and (c) classification accuracy decreases due to domain shifts. To overcome these challenges, we propose a system based on active learning that collaborates with experts to periodically classify received signatures. The signatures are sorted by uncertainty sampling; some are transferred to experts, and the rest are automatically classified. The experts classify the transferred signatures and add them to the training dataset, and the classification model is retrained. After training, the new signatures that have not yet been labeled are classified. The proposed system executes this workflow each time it receives signatures. For evaluation purposes, a real dataset was collected monthly with the help of the experts. Experiments are conducted on this real dataset to evaluate the proposed system in a simulation case. An analysis is then performed by comparing several variants of the proposed system. The results show that the system with Monte Carlo dropout (MC-Dropout) performs best. We also show that this variation has two effects: it transfers more samples with “medium” importance to the experts and mitigates imbalances in the training dataset.},
 author = {Kawaguchi, Hidetoshi and Nakatani, Yuichi and Okada, Shogo},
 doi = {10.1109/ACCESS.2022.3211651},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Uncertainty;Machine learning;Costs;Deep learning;Estimation;Network security;Neural networks;Intrusion detection;Machine learning;active learning;real dataset;IDPS signatures;uncertainty estimation},
 month = {},
 number = {},
 pages = {105713-105725},
 title = {IDPS Signature Classification Based on Active Learning With Partial Supervision From Network Security Experts},
 volume = {10},
 year = {2022}
}

@article{9913466,
 abstract = {Recently, the massive increase in network users has dramatically increased network traffic, making it more difficult to maintain network security. The task of network security situation element extraction is to detect and classify network traffic. The detection rate of minority class samples is low in existing network traffic feature extraction classification methods, and most of the network threat data have seen extreme sample imbalance, which further affects the detection accuracy of minority class samples. To solve these problems, this paper proposes a network security situation element extraction method using conditional generative adversarial network (CGAN) and Transformer. Here, CGAN is applied to solve the sample imbalance problem in the data and improve the detection accuracy of minority samples. Transformer, as an effective feature learning method in natural language direction, has excellent long-distance feature extraction ability. By combining CGAN with Transformer, the detection accuracy of network traffic can be effectively improved. Also, validation was performed using the UNSW-NB15 and KDDcup99 datasets. Experimental results demonstrate that the method using a combination of CGAN and Transformer improved the detection rate for minority samples compared with other advanced-feature extraction classification methods, thereby improving the overall accuracy, F1-score, and specificity. The results are 89.38 % and 93.07 %, 89.75 % and 93.68 %, 87.65 % and 98.20 %, respectively.},
 author = {Yang, Yu and Yao, Chengpeng and Yang, Jinwei and Yin, Kun},
 doi = {10.1109/ACCESS.2022.3212751},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Telecommunication traffic;Transformers;Network security;Classification algorithms;Support vector machines;Supervised learning;Generative adversarial networks;Network security;network security situation element extraction;conditional generative adversarial network;transformer},
 month = {},
 number = {},
 pages = {107416-107430},
 title = {A Network Security Situation Element Extraction Method Based on Conditional Generative Adversarial Network and Transformer},
 volume = {10},
 year = {2022}
}

@article{9916253,
 abstract = {The innovation and evolution of hacking methodologies have led to a sharp rise in cyber attacks, highlighting the need for enhanced network security approaches. Network intrusion detection systems based on machine learning are playing a significant role in the domain of network security. However, designing an optimal framework for a network intrusion detection system is an ongoing concern. In this study, an optimal framework for a network intrusion detection system based on image processing is proposed. The framework is a fusion of augmented feature selection flow with an image transformation and enhancement methodology. Initially, the proposed framework reduces the number of features to achieve overall efficiency. Later, the non-image data is transformed into images. The transformed images are then enhanced for achieving effective anomaly detection based on a deep-learning classifier. The proposed method is implemented on three diverse benchmark datasets of intrusion detection. To illustrate the efficiency of the proposed framework it is compared with some of the most recent publications on image-processing-based network intrusion detection systems.},
 author = {Siddiqi, Murtaza Ahmed and Pak, Wooguil},
 doi = {10.1109/ACCESS.2022.3213937},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Feature extraction;Telecommunication traffic;Image processing;Network intrusion detection;Matrix converters;Convolutional neural networks;Intrusion detection;Computer hacking;Cyber attack;CNN;CSE-CIC-IDS 2018;CIC-IDS 2017;ISCX-IDS 2012;intrusion detection;network intrusion detection system},
 month = {},
 number = {},
 pages = {108530-108544},
 title = {Tier-Based Optimization for Synthesized Network Intrusion Detection System},
 volume = {10},
 year = {2022}
}

@article{9919162,
 abstract = {Network forensics focuses on the identification and investigation of internal and external network attacks, the reverse engineering of network protocols, and the uninstrumented investigation of networked devices. It lies at the intersection of digital forensics, incident response and network security. Network attacks exploit software and hardware vulnerabilities and communication protocols. The scope of a network forensic investigation can range from Internet-wide down to a single device’s network traffic. Network analysis tools (NATs) aid security professionals and law enforcement in the capturing, identification and analysis of network traffic. However, in most instances, the sheer volume of data to be analyzed is enormous and, despite some built-in NAT automation, the investigation of network traffic is often an arduous process. Furthermore, significant expert time remains wasted in the investigation of a high frequency of false positive alerting from automated systems. To address this globally impacting problem, artificial intelligence based approaches are becoming increasingly employed to automatically detect attacks and increase network traffic classification accuracy. This paper provides a comprehensive survey of the state-of-the-art in network forensics and the application of expert systems, machine learning, deep learning, and ensemble/hybrid approaches to a range of application areas in the field. These include network traffic analysis, intrusion detection systems, Internet-of-Things devices, cloud forensics, DNS tunneling, smart grid forensics, and vehicle forensics. In addition, the current challenges and future research directions for each of the aforementioned application areas is discussed.},
 author = {Rizvi, Syed and Scanlon, Mark and Mcgibney, Jimmy and Sheppard, John},
 doi = {10.1109/ACCESS.2022.3214506},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Forensics;Artificial intelligence;Telecommunication traffic;Internet of Things;Computer crime;Security;Digital forensics;Computer security;Network forensics;artificial intelligence;cybersecurity;digital forensics},
 month = {},
 number = {},
 pages = {110362-110384},
 title = {Application of Artificial Intelligence to Network Forensics: Survey, Challenges and Future Directions},
 volume = {10},
 year = {2022}
}

@article{9927396,
 abstract = {The application of Artificial Intelligence (AI) and Machine Learning (ML) to cybersecurity challenges has gained traction in industry and academia, partially as a result of widespread malware attacks on critical systems such as cloud infrastructures and government institutions. Intrusion Detection Systems (IDS), using some forms of AI, have received widespread adoption due to their ability to handle vast amounts of data with a high prediction accuracy. These systems are hosted in the organizational Cyber Security Operation Center (CSoC) as a defense tool to monitor and detect malicious network flow that would otherwise impact the Confidentiality, Integrity, and Availability (CIA). CSoC analysts rely on these systems to make decisions about the detected threats. However, IDSs designed using Deep Learning (DL) techniques are often treated as black box models and do not provide a justification for their predictions. This creates a barrier for CSoC analysts, as they are unable to improve their decisions based on the model’s predictions. One solution to this problem is to design explainable IDS (X-IDS). This survey reviews the state-of-the-art in explainable AI (XAI) for IDS, its current challenges, and discusses how these challenges span to the design of an X-IDS. In particular, we discuss black box and white box approaches comprehensively. We also present the tradeoff between these approaches in terms of their performance and ability to produce explanations. Furthermore, we propose a generic architecture that considers human-in-the-loop which can be used as a guideline when designing an X-IDS. Research recommendations are given from three critical viewpoints: the need to define explainability for IDS, the need to create explanations tailored to various stakeholders, and the need to design metrics to evaluate explanations.},
 author = {Neupane, Subash and Ables, Jesse and Anderson, William and Mittal, Sudip and Rahimi, Shahram and Banicescu, Ioana and Seale, Maria},
 doi = {10.1109/ACCESS.2022.3216617},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Artificial intelligence;Machine learning;Intrusion detection;Computer security;Deep learning;Cognition;Predictive models;Glass box;Closed box;Explainable intrusion detection systems;explainable artificial intelligence;machine learning;deep learning;white box;black box;explainability;cybersecurity},
 month = {},
 number = {},
 pages = {112392-112415},
 title = {Explainable Intrusion Detection Systems (X-IDS): A Survey of Current Methods, Challenges, and Opportunities},
 volume = {10},
 year = {2022}
}

@article{9934918,
 abstract = {Alzheimer’s disease (AD) is considered the 6 $^{\text {th}}$  leading cause of death worldwide. Early diagnosis of AD is not an easy task, and no preventive cures have been discovered yet. Having an accurate computer-aided system for the early detection of AD is important to help patients with AD. This study proposes a new approach for classifying disease stages. First, we worked on the MRI images and split them into an appropriate format to avoid data leakage. Subsequently, a simple and fast registration-free preprocessing pipeline was applied to the dataset. Numerous experiments were conducted to analyze the performances of different 3D classification architectures. Finally, an ensemble learning approach is applied to the top-performing models. The outstanding performance of the proposed method was demonstrated using augmentation of the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Our proposed ensemble approach outperforms studies in literature for distinguishing between people with AD and mild cognitive impairment (MCI), and MCI and cognitive normal (CN) with an AUC score of 91.28% and 88.42%, respectively. We also targeted the multiclass task, which was marginalized in previous work, by differentiating between the three stages of the disease.},
 author = {Gamal, Aya and Elattar, Mustafa and Selim, Sahar},
 doi = {10.1109/ACCESS.2022.3218621},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Three-dimensional displays;Magnetic resonance imaging;Alzheimer's disease;Ensemble learning;Convolutional neural networks;Feature extraction;Computer architecture;MRI;Alzheimer’s disease classification;convolutional neural network;ensemble learning},
 month = {},
 number = {},
 pages = {115974-115987},
 title = {Automatic Early Diagnosis of Alzheimer’s Disease Using 3D Deep Ensemble Approach},
 volume = {10},
 year = {2022}
}

@article{9941074,
 abstract = {The increasing number of connected devices in the era of Internet of Thing (IoT) has also increased the number intrusions. Intrusion Detection System (IDS) is a secondary intelligent system to monitor, detect, and alert about malicious activities; an Intrusion Prevention System (IPS) is an extension of a detection system that triggers relevant action when an attack is suspected in a futuristic aspect. Both IDS and IPS systems are significant and useful for developing a security model. Several studies exist to review the detection and prevention models; however, the coherence in the opportunistic or advancements in the models is missing. Besides, the existing models also have some limitations, which need to be surveyed to develop new security models. Our survey is the first one to present a study of risk factor analysis using mapping technique, and provide a proposal for hybrid framework for an efficient security model for intrusion detection and/or prevention. We explore the importance of various Artificial Intelligence (AI)-based techniques, tools, and methods used for the detection and/or prevention systems in IoTs. More specifically, we emphasize on Machine Learning (ML) and Deep Learning (DL) techniques for intrusion detection-prevention systems and provide a comparative analysis focusing on the feasibility, compatibility, challenges, and real-time issues. This present survey is beneficial for industry and academia to categorize the challenges and issues in the current security models and generate the new dimensions of developments of security frameworks with efficient ML or DL methods.},
 author = {Jayalaxmi, P. L. S. and Saha, Rahul and Kumar, Gulshan and Conti, Mauro and Kim, Tai-Hoon},
 doi = {10.1109/ACCESS.2022.3220622},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;IP networks;Intrusion detection;Firewalls (computing);Monitoring;Encryption;Machine learning;Intrusion detection;intrusion prevention;internet of thing;machine learning;deep learning artificial intelligence},
 month = {},
 number = {},
 pages = {121173-121192},
 title = {Machine and Deep Learning Solutions for Intrusion Detection and Prevention in IoTs: A Survey},
 volume = {10},
 year = {2022}
}

@article{9945933,
 abstract = {With the appearance of large-scale systems, the size of the generated logs increased rapidly. Almost every software produces such files. Log files contain runtime information of the software, as well as indicate noteworthy events or suspicious behaviors like errors. To understand and monitor the operation of the system, log files are a valuable source of information, which can be used to predict upcoming anomalies. In recent years numerous techniques have been proposed for this purpose. There are supervised models like SVM or decision trees and also unsupervised ones like Isolation Forest, Log Clustering, or PCA. There are also methods that use deep learning, like Autoencoder, CNN, LSTM, or Transformer. Many of the above-mentioned methods take advantage of template miners, that extract the event types from the unstructured data. In our paper, we propose a method that uses these templates to predict upcoming anomalies. We use 80% of our data for training, and 20% for tests. First, we use half of the train data and sort the templates that have an occurrence that is followed by an error to create a list of candidate templates. In the second step, we use the other half, to check how often the ten upcoming lines after a candidate template actually contain an anomaly. If a given percentage is reached, we consider the template as an indicator for upcoming anomalies. We conduct various experiments to verify the capability of our method like measuring the precision, recall, f-score accuracy, and speed on various data sources. The proposed method slightly falls behind SVM and CNN with an average of 88.06% precision, 90.43% recall, and 89.11% f-score, however, it has better accuracy with 98.19%. In addition, our algorithm is two times faster than SVM and three and a half times faster than CNN.},
 author = {Marjai, Péter and Lehotay-Kéry, PéTer and Kiss, Attila},
 doi = {10.1109/ACCESS.2022.3221427},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Support vector machines;Monitoring;Clustering methods;Behavioral sciences;Task analysis;Principal component analysis;Convolutional neural networks;Anomaly detection;autoencoder;CNN;IPLoM;isolation forest;log clustering;log parsing;LSTM;PCA;SVM;transformer},
 month = {},
 number = {},
 pages = {118953-118964},
 title = {A Heuristic Approach Using Template Miners for Error Prediction in Telecommunication Networks},
 volume = {10},
 year = {2022}
}

@article{9953983,
 abstract = {Deep Learning based Intrusion Detection Systems (IDSs) have received significant attention from the research community for their capability to handle modern-day security systems in large-scale networks. Despite their considerable improvement in performance over machine learning-based techniques and conventional statistical models, deep neural networks (DNN) suffer from catastrophic forgetting: the model forgets previously learned information when trained on newer data points. This vulnerability is specifically exaggerated in large scale systems due to the frequent changes in network architecture and behaviours, which leads to changes in data distribution and the introduction of zero-day attacks; this phenomenon is termed as covariate shift. Due to these constant changes in the data distribution, the DNN models will not be able to consistently perform at high accuracy and low false positive rate (FPR) rates without regular updates. However, before we update the DNN models, it is essential to understand the magnitude and nature of the drift in the data distribution. In this paper, to analyze the drift in data distribution, we propose an eight-stage statistics and machine learning guided implementation framework that objectively studies and quantifies the changes. Further, to handle the changes in data distribution, most IDS solutions collect the network packets and store them to retrain the DNN models periodically, but when the network’s size and complexity increase, those tasks become expensive. To efficiently solve this problem, we explore the potential of continual learning models to incrementally learn new data patterns while also retaining their previous knowledge. We perform an experimental and analytical study of advanced intrusion detection systems using three major continual learning approaches: learning without forgetting, experience replay, and dark experience replay on the NSL-KDD and the CICIDS 2017 dataset. Through extensive experimentation, we show that our continual learning models achieve improved accuracy and lower FPR rates when compared to the state-of-the-art works while also being able to incrementally learn newer data patterns. Finally, we highlight the drawbacks of traditional statistical and non-gradient based machine learning approaches in handling the covariate shift problem.},
 author = {Prasath, Sai and Sethi, Kamalakanta and Mohanty, Dinesh and Bera, Padmalochan and Samantaray, Subhransu Ranjan},
 doi = {10.1109/ACCESS.2022.3222715},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Feature extraction;Computational modeling;Brain modeling;Security;Analytical models;Adaptation models;Intrusion detection;Learning systems;Intrusion detection systems;catastrophic forgetting;covariate shift;continual learning},
 month = {},
 number = {},
 pages = {121444-121464},
 title = {Analysis of Continual Learning Models for Intrusion Detection System},
 volume = {10},
 year = {2022}
}

@article{9956995,
 abstract = {Anomaly detection has been used to detect and analyze anomalous elements from data for years. Various techniques have been developed to detect anomalies. However, the most convenient one is Machine learning which is performing well but still has limitations for large-scale unlabeled datasets. Deep Reinforcement Learning (DRL) based techniques outperform the existing supervised or unsupervised and other alternative techniques for anomaly detection. This study presents a Systematic Literature Review (SLR), which analyzes DRL models that detect anomalies in their application. This SLR aims to analyze the DRL frameworks for anomaly detection applications, proposed DRL methods, and their performance comparisons against alternative methods. In this review, we have identified 32 research articles published from 2017–2022 that discuss DRL techniques for various anomaly detection applications. After analyzing the selected research articles, this paper presents 13 different applications of anomaly detection found in the selected research articles. We identified 50 different datasets applied in experiments on anomaly detection and demonstrated 17 distinct DRL models used in the selected papers to detect anomalies. Finally, we analyzed the performance of these DRL models and reviewed them. Additionally, we observed that detecting anomalies using DRL frameworks is a promising area of research and showed that DRL had shown better performance for anomaly detection where other models lack. Therefore, we provide researchers with recommendations and guidelines based on this review.},
 author = {Arshad, Kinza and Ali, Rao Faizan and Muneer, Amgad and Aziz, Izzatdin Abdul and Naseer, Sheraz and Khan, Nabeel Sabir and Taib, Shakirah Mohd},
 doi = {10.1109/ACCESS.2022.3224023},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Anomaly detection;Reinforcement learning;Deep learning;Supervised learning;Data models;Systematics;Machine learning algorithms;Anomaly detection;deep reinforcement learning;systematic review},
 month = {},
 number = {},
 pages = {124017-124035},
 title = {Deep Reinforcement Learning for Anomaly Detection: A Systematic Review},
 volume = {10},
 year = {2022}
}

@article{9968009,
 abstract = {The use of artificial intelligence and machine learning is recognized as the key enabler for 5G mobile networks which would allow service providers to tackle the network complexity and ensure security, reliability and allocation of the necessary resources to their customers in a dynamic, robust and trustworthy way. Dependability of the future generation networks on accurate and timely performance of its artificial intelligence components means that disturbance in the functionality of these components may have negative impact on the entire network. As a result, there is an increasing concern about the vulnerability of intelligent machine learning driven frameworks to adversarial effects. In this study, we evaluate various adversarial example generation attacks against multiple artificial intelligence and machine learning models which can potentially be deployed in future 5G networks. First, we describe multiple use cases for which attacks on machine learning components are conceivable including the models employed and the data used for their training. After that, attack algorithms, their implementations and adjustments to the target models are summarised. Finally, the attacks implemented for the aforementioned use cases are evaluated based on deterioration of the objective functions optimised by the target models.},
 author = {Zolotukhin, Mikhail and Miraghaei, Parsa and Zhang, Di and Hämäläinen, Timo},
 doi = {10.1109/ACCESS.2022.3225921},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Data models;Training;5G mobile communication;Perturbation methods;Machine learning;Atmospheric modeling;Neurons;5G networks;adversarial machine learning;artificial intelligence;deep learning},
 month = {},
 number = {},
 pages = {126285-126303},
 title = {On Assessing Vulnerabilities of the 5G Networks to Adversarial Examples},
 volume = {10},
 year = {2022}
}

@article{9970340,
 abstract = {The Internet of Things (IoT) paradigm has matured and expanded rapidly across many disciplines. Despite these advancements, IoT networks continue to face an increasing security threat as a result of the constant and rapid changes in the network environment. In order to address these vulnerabilities, the Fog system is equipped with a robust environment that provides additional tools to beef up data security. However, numerous attacks are persistently evolving in IoT and fog environments as a result of the development of several breaches. To improve the efficiency of intrusion detection in the Internet of Things (IoT), this research introduced a novel tunicate swarm algorithm that combines a long-short-term memory-recurrent neural network. The presented model accomplishes this goal by first undergoing data pre-processing to transform the input data into a usable format. Additionally, attacks in the IoT ecosystem can be identified using a model built on long-short-term memory recurrent neural networks. There is a strong correlation between the number of parameters and the model’s capability and complexity in ANN models. It is critical to keep track of the number of parameters in each model layer to avoid over- or under-fitting. One way to prevent this from happening is to modify the number of layers in your data structure. The tunicate swarm algorithm is used to fine-tune the hyper-parameter values in the Long Short-Term Memory-Recurrent Neural Network model to improve how well it can find things. TSA was used to solve several problems that couldn’t be solved with traditional optimization methods. It also improved performance and shortened the time it took for the algorithm to converge. A series of tests were done on benchmark datasets. Compared to related models, the proposed TSA-LSTMRNN model achieved 92.67, 87.11, and 98.73 for accuracy, recall, and precision, respectively, which indicate the superiority of the proposed model.},
 author = {Taher, Fatma and Elhoseny, Mohamed and Hassan, Mohammed K. and El-Hasnony, Ibrahim M.},
 doi = {10.1109/ACCESS.2022.3226879},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Internet of Things;Security;Organizations;Intrusion detection;Recurrent neural networks;Deep learning;Behavioral sciences;Data security;deep learning;fog computing;internet of things;intrusion detection;tunicate swarm algorithm},
 month = {},
 number = {},
 pages = {127192-127204},
 title = {A Novel Tunicate Swarm Algorithm With Hybrid Deep Learning Enabled Attack Detection for Secure IoT Environment},
 volume = {10},
 year = {2022}
}

@article{9987501,
 abstract = {A network intrusion detection system (IDS) is commonly recognized as an effective solution for identifying threats and malicious attacks. Due to the rapid emergence of threats and new attack vectors, novel and adaptive approaches must be considered to maintain the effectiveness of IDSs. In this paper, we present a novel Threat Intelligence Detection Model (TIDM) for online intrusion detection. The proposed TIDM focuses on the online processing of massive data flows and is accordingly able to reveal unknown connections, including zero-day attacks. The TIDM consists of three components: an optimized filter (OptiFilter), an adaptive and hybrid classifier, and an alarm component. The main contributions of the OptiFilter component are in its ability to continuously capture data flows and construct unlabeled connection vectors. The second component of the TIDM employs a hybrid model made up of an enhanced growing hierarchical self-organizing map (EGHSOM) and a normal network behavior (NNB) model to jointly identify unknown connections. The proposed TIDM updates the hybrid model continually in real-time. The model’s performance evaluation has been carried out in both offline and online operational modes using a quantitative approach that considers all possible evaluation metrics for the datasets and the hybrid classification method. The achieved results show that the proposed TIDM is able, with promising performance, to process massive data flows in real-time, classify unlabeled connections, reveal the label of unknown connections, and perform online updates successfully.},
 author = {Salem, Maher and Al-Tamimi, Abdel-Karim},
 doi = {10.1109/ACCESS.2022.3229495},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Clustering methods;Security;Data models;Self-organizing feature maps;Computer networks;Neural networks;Numerical models;Intrusion detection;Neural networks;GHSOM;EGHSOM;NNB;threat intelligence;data processing;intrusion detection;clustering},
 month = {},
 number = {},
 pages = {131229-131245},
 title = {A Novel Threat Intelligence Detection Model Using Neural Networks},
 volume = {10},
 year = {2022}
}

@article{9994706,
 abstract = {With the rapid development of the IoT (Internet-of-Things), additional smart gadgets may be associated with the Internet, significantly enhancing data transfer and communication. Software-Defined Networking (SDN) is known as a new model that separates the control plane and the data plane, and is anticipated as a favorable solution for implementing Blockchain, to offer the scalability and adaptability required for IoT. The scalability of the network rises in direct proportion to the users’ enhanced privacy on the network. Blockchain and SDN are two top innovations utilized to create secure network architectures and provide trustworthy data transmission. They offer a strong and trustworthy platform to deal with dangers and problems, including security, privacy, adaptability, scalability, and secrecy. Unfortunately, the attackers can still inject traffic to disrupt a blockchain node’s regular functions. This study provides an optimized Blockchain-based SD IoT architecture for smart networks that is safe and energy-efficient. In this work, it is concentrated on blockchain-based SDN and creates an SDN-Blockchain Classifier. This IDS-based security tool provides a trust-based classifier by handling and reducing harmful traffic through traffic fusion and aggregation. Finally, it is concluded by evaluating the proposed framework SDN-Blockchain Classifier performance against MAC flooding attack in a simulation setting and demonstrating that it can attain optimized average throughput, response time, packet loss of crossing domain path, energy efficiency, end-to-end delay, file transfer operation, energy consumption, and CPU utilization compared to the baselines taken into consideration, thereby achieving efficacy and also security in the proposed smart network.},
 author = {Ghamdi, Mohammed A. Al},
 doi = {10.1109/ACCESS.2022.3230985},
 issn = {2169-3536},
 journal = {IEEE Access},
 keywords = {Blockchains;Internet of Things;Energy efficiency;Scalability;Peer-to-peer computing;Computer architecture;Software defined networking;Blockchain;Ethereum;IoT;mininet;openstack;pythereum;software-defined networking},
 month = {},
 number = {},
 pages = {133682-133697},
 title = {An Optimized and Secure Energy-Efficient Blockchain-Based Framework in IoT},
 volume = {10},
 year = {2022}
}
